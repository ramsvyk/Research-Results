@ARTICLE{8931757,
  author={Peng, Fei and Yin, Li-Ping and Zhang, Le-Bing and Long, Min},
  journal={IEEE Transactions on Multimedia}, 
  title={CGR-GAN: CG Facial Image Regeneration for Antiforensics Based on Generative Adversarial Network}, 
  year={2020},
  volume={22},
  number={10},
  pages={2511-2525},
  abstract={In this paper, a Computer-generated graphics (CG) facial image regeneration scheme for anti-forensics based on generative adversarial network (CGR-GAN) is proposed. The generator of CGR-GAN utilizes a deep U-Net structure, and its discriminator utilizes some stacked convolution layers. Besides, content loss and style loss are both designed to guarantee that the regenerated CG facial images (CGR) retain both the facial profile of the original CG and the characteristics of natural image (NI). Experimental results and analysis demonstrate that the CG facial images regenerated by the proposed anti-forensics scheme can achieve better visual quality compared with those of the existing CG facial image anti-forensics and domain adaptation methods, and it can strike a good balance between visual quality and deception ability.},
  keywords={Feature extraction;Detectors;Forensics;Image color analysis;Convolution;Histograms;Generative adversarial networks;Image anti-forensics;generative adversarial network (GAN);natural images (NI);computer-generated image;computer-generated graphics (CG) detector},
  doi={10.1109/TMM.2019.2959443},
  ISSN={1941-0077},
  month={Oct}
}

@ARTICLE{10816512,
  author={Duan, Rui and Qu, Zhe and Zhao, Shangqing and Ding, Leah and Liu, Yao and Lu, Zhuo},
  journal={IEEE Transactions on Dependable and Secure Computing}, 
  title={Perception-Aware Attack Against Music Copyright Detection: Impacts and Defenses}, 
  year={2024},
  volume={},
  number={},
  pages={1-18},
  abstract={Recently, adversarial machine learning attacks have posed serious security threats against practical audio signal classification systems, including speech recognition, speaker recognition, music copyright detection. Most existing studies have mainly focused on ensuring the effectiveness of attacking an audio signal classifier via creating a noise- like perturbation on the original signal, which remains a gap in preserving the human perception of adversarial audios. This paper presents a novel perspective to create adversarial audios by integrating the human perception model into the attack formulation to generate well-perceived adversarial examples. Different from conventional approaches which primarily focused on using $L_{p}$ norm to preserve the audio quality, we adopt a human study to understand how human participants react to different types of music perturbations, build a Siamese Neural Network (SNN) based model to characterize the human perception. The new findings of the human perception study guide us to formulate a new computationally efficient, multiple-feature-based perception-aware (CEMF-PA) attack, which manipulates different audio signal features to find an optimal perturbed music signal against music copyright detection. This novel attack vector opens a new door to generating highly effective, well-perceived adversarial audio signals via manipulating the auditory features. Experimental results show that the proposed attack is effective against YouTube's copyright detection. Finally, we propose the defense strategy design to make the copyright detection more robust to adversarial music signals generated by the CEMF-PA attack.},
  keywords={Multiple signal classification;Perturbation methods;Copyright protection;Speech recognition;Computational modeling;Neural networks;Fingerprint recognition;Adversarial machine learning;Web sites;Video on demand;Computer audio systems;applications;machine learning;and security},
  doi={10.1109/TDSC.2024.3522849},
  ISSN={1941-0018},
  month={}
}

@INPROCEEDINGS{9612547,
  author={Hassan, Omer Mohammed Salih and Abdulazeez, Adnan Mohsin and Mohammed, Arman Ismael and Salih, Sardar Omer and Alih, Sarbast Husien and Ahmed, Falah Y H and Zeebaree, Diyar Qader},
  booktitle={2021 IEEE 11th International Conference on System Engineering and Technology (ICSET)}, 
  title={An Efficient Robust Color Watermarking Algorithm Based on DWT, DCT, BFO and Implementation}, 
  year={2021},
  volume={},
  number={},
  pages={90-95},
  abstract={Digital watermarking is getting more research and industry attention. Digital multimedia data allows for robust and simple data editing and modification. However, the spread of digital media presents concerns for digital content owners. It is important to note that digital data can be copied without quality or content loss. This has a considerable impact on copyright holders' ability to safeguard their intellectual property rights. The method of transmitting information by imperceptibly embedding it into digital media is digital watermarking. There are various methods in literature, such as DWT and DCT, which take full energy, are seen and integrated. New strategies and procedures for optimization are required. The present study proposes a novel design and computation technique based on the discrete wavelet and discrete cosine transforms. Watermarking techniques have been progressing to shield media content such as text, audio, video, etc. From copyright. The proposed hybrid DWT-DCT Bacterial Foraging Optimization (BFO) technique improves the efficiency of watermarking digital images by 97%. Bacterial foraging optimization (BFO) is an innovative technique for intelligent optimization. It is a widely used optimization algorithm in a wide variety of applications. However, when compared to other optimizers, the BFO performs poorly in terms of convergence. This technique uses a high-frequency image region. A variety of techniques are compared with the (NCC) Normalized Cross Correlations, (PSNR) Peak Noise Signal Ratio and IF (Image Fidelity). The highest performance is seen in DWT-DCT-BFO watermarking.},
  keywords={Microorganisms;Image color analysis;Watermarking;Media;Systems engineering and theory;Robustness;Discrete wavelet transforms;Discrete wavelet transform;Watermarking;Discrete cosine transform;Bacterial foraging optimization},
  doi={10.1109/ICSET53708.2021.9612547},
  ISSN={2470-640X},
  month={Nov}
}

@INPROCEEDINGS{10843534,
  author={Bokaei, Mohammad Hadi and Rafati, Elham and Kani, Davood Heidari and Fard, Farbod Rabizadeh and Mehrabani, Ali Derakhshani and Mehrabani, Iman Derakhshani and Bodaghi, Nooshin and Baderestani, Reza and Nedaei, Neda},
  booktitle={2024 11th International Symposium on Telecommunications (IST)}, 
  title={Examining the legal challenges and loopholes of artificial intelligence by considering the upstream documents of the country}, 
  year={2024},
  volume={},
  number={},
  pages={249-256},
  abstract={In this article, the challenges and loopholes of laws in the world have been examined first. Issues that are generally challenging in the field of artificial intelligence and require risk management have been investigated. Based on this, some of the most important challenges and risks include the lack of algorithmic transparency - the lack of the possibility of protest - unfairness, bias and discrimination - liability for damages, etc. Also, due to the importance of artificial intelligence, the challenges related to this issue have also been investigated and studied. And finally, for the policies extracted from the previous phase of the project, legal criteria have been determined to evaluate these policies. Each of these legal criteria has been adapted to the obtained policies based on legal dimensions and aspects. The purpose of this process was to determine the legal loopholes in the above-mentioned documents based on the subject of artificial intelligence. For improvement and high accuracy, as well as for better analysis on the criteria that were adapted to the extracted policies, the data has been aggregated in an Excel file. For this purpose, the multiplicity of legal criteria in each of the legal dimensions related to each document was specified. Also, at the end, each of the documents is weighted based on the importance of connection with technology and the up-to-date ness of the subject in relation to the field of artificial intelligence. Based on the obtained analysis, the legal gaps in the documents related to artificial intelligence have been identified. Therefore, according to the rapid process of artificial intelligence, legal loopholes in the formulation of laws should be considered more sensitively.},
  keywords={Training;Ethics;Technological innovation;Law;Government;Regulation;Telecommunications;Risk management;Artificial intelligence;Monitoring;artificial intelligence;challenges;gaps;legal issues;legal requirements},
  doi={10.1109/IST64061.2024.10843534},
  ISSN={},
  month={Oct}
}

@ARTICLE{10855897,
  author={Khoramnejad, Fahime and Hossain, Ekram},
  journal={IEEE Communications Surveys & Tutorials}, 
  title={Generative AI for the Optimization of Next-Generation Wireless Networks: Basics, State-of-the-Art, and Open Challenges}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Next-generation (xG) wireless networks, with their complex and dynamic nature, present significant challenges to using traditional optimization techniques. Generative Artificial Intelligence (GAI) emerges as a powerful tool due to its unique strengths. Unlike traditional optimization techniques and other machine learning methods, GAI excels at learning from real-world network data, capturing its intricacies. This enables safe, offline exploration of various configurations and generation of diverse, unseen scenarios, empowering proactive, data-driven exploration and optimization for xG networks. Additionally, GAI’s scalability makes it ideal for large-scale xG networks. This paper surveys how GAI-based models unlock optimization opportunities in xG wireless networks. We begin by providing a review of GAI models and some of the major communication paradigms of xG (e.g., Sixth Generation) wireless networks. We then delve into exploring how GAI can be used to improve resource allocation and enhance overall network performance. Additionally, we briefly review the networking requirements for supporting GAI applications in xG wireless networks. The paper further discusses the key challenges and future research directions in leveraging GAI for network optimization. Finally, a case study demonstrates the application of a diffusion-based GAI model for load balancing, carrier aggregation, and backhauling optimization in non-terrestrial networks, a core technology of xG networks. This case study serves as a practical example of how the combination of reinforcement learning and GAI can be implemented to address real-world network optimization problems.},
  keywords={Artificial intelligence;Optimization;Wireless networks;Reliability;6G mobile communication;Training;Semantics;Resource management;Reconfigurable intelligent surfaces;Decoding;Generative AI;xG wireless networks;data-driven optimization;resource allocation;network-assisted generative AI},
  doi={10.1109/COMST.2025.3535554},
  ISSN={1553-877X},
  month={}
}

@ARTICLE{10158698,
  author={Panfilo, Daniele and Boudewijn, Alexander and Saccani, Sebastiano and Coser, Andrea and Svara, Borut and Chauvenet, Carlo Rossi and Mami, Ciro Antonio and Medvet, Eric},
  journal={IEEE Access}, 
  title={A Deep Learning-Based Pipeline for the Generation of Synthetic Tabular Data}, 
  year={2023},
  volume={11},
  number={},
  pages={63306-63323},
  abstract={The recent and rapid progresses in Machine Learning (ML) tools and methodologies paved the way for an accessible market of ML services. In principle, small and medium-sized enterprises, as well as big companies, could act as providers and consumers of services, resulting in an intense exchange of ML services where a consumer may ask many providers for a service preview based on its particular business case, that is, its data. In practice, however, many potential service consumers are reluctant to release their data, when seeking for ML services, because of privacy or intellectual property concerns. As a consequence, the market of ML services is not as fluid as it could be. An alternative to providing real data when looking for an ML service consists in generating and releasing synthetic data. The synthetic data should 1) allow the service provider to preview an ML service whose performance is predictive of the one the same service will achieve on the real data; and 2) prevent the disclosure of the real data. In this paper, we propose a data synthesis technique tailored to a family of very relevant business cases: supervised and unsupervised learning on single-table datasets and relational datasets. Our technique is based on generative deep learning models and we instantiate it in three variants: standard Variational Autoencoders (VAEs),  $\beta $ -VAEs, and Introspective VAEs. We experimentally evaluate the two variants to measure the degree to which they meet the two requirements above, using several performance indexes that capture different aspects of the quality of the generated data. The results suggest that data synthesis is a practical answer to the need of decoupling ML service providers and consumers and, hence, can favor the arising of an active and accessible market of ML services.},
  keywords={Synthetic data;Data models;Data privacy;Information integrity;Information filtering;Performance analysis;Generative adversarial networks;Synthetic data;variational auto encoders;data privacy;tabular data},
  doi={10.1109/ACCESS.2023.3288336},
  ISSN={2169-3536},
  month={}
}

@BOOK{10745316,
  author={Clinton, David},
  booktitle={The Complete Obsolete Guide to Generative AI},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={The last book on AI you’ll ever need. We swear! AI technology moves so fast that this book is probably already out of date! But don’t worry—The Complete Obsolete Guide to Generative AI is still an essential read for anyone who wants to make generative AI into a tool rather than a toy. It shows you how to get the best out of AI no matter what changes come in the future. You’ll be able to use common automation and scripting tools to take AI to a new level, and access raw (and powerful) GPT models via API. Inside The Complete Obsolete Guide to Generative AI you will find:  Just enough background info on AI! What an AI model is how it works Ways to create text, code, and images for your organization's needs Training AI models on your local data stores or on the internet Business intelligence and analytics uses for AI Building your own custom AI models Looking ahead to the future of generative AI  Where to get started? How about creating exciting images, video, and even audio with AI. Need more? Learn to harness AI to speed up any everyday work task, including writing boilerplate code, creating specialized documents, and analyzing your own data. Push beyond simple ChatGPT prompts! Discover ways to double your productivity and take on projects you never thought were possible! AI—and this book—are here to show you how.},
  keywords={models;text;code;images;custom;API;ChatGPT;Copilot;OpenAI;LLMs;large language models;video;voice;prompts;business intelligence;analytics;productivity;interactive},
  doi={},
  ISSN={},
  publisher={Manning},
  isbn={9781633436985},
  url={https://ieeexplore.ieee.org/document/10745316}
}

@ARTICLE{10602758,
  author={Majeed, Abdul and Hwang, Seong Oun},
  journal={IEEE Reliability Magazine}, 
  title={Reliability Issues of LLMs: ChatGPT a Case Study}, 
  year={2024},
  volume={1},
  number={4},
  pages={36-46},
  abstract={ChatGPT is a groundbreaking artificial intelligence (AI) invention, and this technology will see tremendous growth per the IEEE Computer Society’s 2024 technology predictions report.1 According to the report, generative AI applications top the list, and this paradigm is predicted to experience most of the advancements in the coming years. ChatGPT, a generative AI product, has demonstrated its effectiveness in many ways (e.g., answering questions, summarizing text, generating computer code, fixing programming bugs, and generating synthetic data). Despite the many promising applications, ChatGPT cannot produce desirable results for many difficult and pragmatic tasks [1]. For example, the inaccuracy from ChatGPT answers related to the emotional text is significantly high, owing to limited amounts of data—or no available data—concerning these tasks [1]. Similarly, ChatGPT can be manipulated to generate fake content, which can be hard to distinguish from real content. There are two schools of thought in the AI community about ChatGPT technology.},
  keywords={Chatbots;Codes;Servers;Reliability engineering;Generative AI;Training;Artificial intelligence;Generative AI;Large language models},
  doi={10.1109/MRL.2024.3420849},
  ISSN={2641-8819},
  month={Dec}
}

@INPROCEEDINGS{10605662,
  author={Chekhovich, Yury and Grabovoy, Andrey and Gritsai, German},
  booktitle={2024 4th International Conference on Technology Enhanced Learning in Higher Education (TELE)}, 
  title={Generative AI Models with Their Full Reveal*}, 
  year={2024},
  volume={},
  number={},
  pages={17-22},
  abstract={The paper deals with Large Language Models (LLM). We present a historical overview of the development of text generation algorithms. The aim of the paper is to show the main properties and limitations of services based on Large Language Models when their results are used in scientific and educational texts. We touch on concepts such as sampling from distribution, Recurrent Neural Network, Attention mechanism, Transformer architecture and provide guidelines for the ethical use of generated texts in scientific and academic papers. We have presented the material in a popular form, so that it is possible to understand the principles of generative services with general erudition and certain computer skills. At the same time, the key concepts are provided with references that will allow readers to delve into the area on their own if necessary.},
  keywords={Ethics;Recurrent neural networks;Generative AI;Large language models;Education;Computer architecture;Search engines;text generation;AI detection;Artificial intelligence;LLM},
  doi={10.1109/TELE62556.2024.10605662},
  ISSN={},
  month={June}
}

@INPROCEEDINGS{10556138,
  author={Li, Ziyu and Shin, Donghwan},
  booktitle={2024 IEEE/ACM 3rd International Conference on AI Engineering – Software Engineering for AI (CAIN)}, 
  title={Mutation-based Consistency Testing for Evaluating the Code Understanding Capability of LLMs}, 
  year={2024},
  volume={},
  number={},
  pages={150-159},
  abstract={Large Language Models (LLMs) have shown remarkable capabilities in processing both natural and programming languages, which have enabled various applications in software engineering, such as requirement engineering, code generation, and software testing. However, existing code generation benchmarks do not necessarily assess the code understanding performance of LLMs, especially for the subtle inconsistencies that may arise between code and its semantics described in natural language.In this paper, we propose a novel method, called Mutation-based Consistency Testing (MCT), to systematically assess the code understanding performance of LLMs, particularly focusing on subtle differences between code and its descriptions, by introducing code mutations to existing code generation datasets. Code mutations are small changes that alter the semantics of the original code, creating a mismatch with the natural language description. MCT uses different types of code mutations, such as operator replacement and statement deletion, to generate inconsistent code-description pairs. MCT then uses these pairs to test the ability of LLMs to detect the inconsistencies correctly.We conduct a case study on the two popular LLMs, GPT-3.5 and GPT-4, using the state-of-the-art code generation benchmark, HumanEval-X, which consists of 164 programming problems written in six programming languages (Python, C++, Java, Go, JavaScript, and Rust). The results show that the LLMs have significant variations in their code understanding performance and that they have different strengths and weaknesses depending on the mutation type and language. We further explain conditions under which the LLMs result in correct answers using input characteristics (e.g., number of tokens) and investigate to what extent the test results can be improved using one-shot prompts (i.e., providing an additional example). Our MCT method and the case study results provide valuable implications for future research and development of LLM-based software engineering.CCS CONCEPTS• Software and its engineering → Software testing and debug-ging; Empirical software validation.},
  keywords={Software testing;Training;Analytical models;Codes;Sensitivity;Semantics;Benchmark testing;Large Language Models;Software Engineering;Mutation Analysis},
  doi={},
  ISSN={},
  month={April}
}

@ARTICLE{10492913,
  author={Edwards, Words Chris},
  journal={Engineering & Technology}, 
  title={The AI plagiarism minefield: A series of legal disputes highlighted complex relationship between artificial intelligence copyright law}, 
  year={2023},
  volume={18},
  number={9},
  pages={42-47},
  abstract={It used to be easy to deduce if something is a copy - all you needed was a simple comparison. For most traditional plagiarism software, as long as enough of the text matched an original, it was easy to determine if it had been copied and passed off as original. Naturally, people who sought to profit from plagiarism found ways to avoid detection. The phenomenon of the ‘splog’ a spam blog that rips off copy from more famous providers - appeared not long after blogs themselves became fashionable in the mid-2000s. These sites, set up primarily to capture pay-per-click payments from online advertisers, used software to rewrite the source - usually not very well. For the most part, the programs based on simple techniques from the early days of artificial intelligence (AI) simply swapped words for synonyms, sometimes turning the copy into nonsense.},
  keywords={},
  doi={10.1049/et.2023.0904},
  ISSN={1750-9637},
  month={Nov}
}

@INPROCEEDINGS{10893017,
  author={Johri, Aditya and Hingle, Ashish and Schleiss, Johannes},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Misconceptions, Pragmatism, and Value Tensions: Evaluating Students' Understanding and Perception of Generative AI for Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={In this research paper we examine undergraduate students' use of and perceptions of generative AI (GenAI). Although the initial hype around ChatGPT has subsided, GenAI applications continue to make inroads across learning activities. Like any other emerging technology, there is a lack of consensus around using GenAI within higher education. Students are early adopters of the technology, utilizing it in atypical ways and forming a range of perceptions and aspirations about it. To understand where and how students are using these tools and how they view them, we present findings from an open-ended survey response study with undergraduate students pursuing information technology degrees. Students were asked to describe 1) their understanding of GenAI; 2) their use of GenAI; 3) their opinions on the benefits, downsides, and ethical issues pertaining to its use in education; and 4) how they envision GenAI could ideally help them with their education. Thirty-seven students provided responses ranging in length from 20 to 300 words for each question. Responses were iteratively coded by researchers to uncover patterns in the data and then categorized thematically. Findings reveal that students' definitions of GenAI differed substantially and included many misconceptions - some highlight it as a technique, an application, or a tool, while others described it as a type of AI. There was a wide variation in the use of GenAI by students, with two common uses being writing and coding. They identified the ability of GenAI to summarize information and its potential to personalize learning as an advantage. Students identified two primary ethical concerns with using GenAI: plagiarism and dependency, which means that students do not learn independently. They also cautioned that responses from GenAI applications are often untrustworthy and need verification. Overall, they appreciated that they could do things quickly with GenAI but were cautious as using the technology was not necessarily in their best long-term as it interfered with the learning process. In terms of aspirations for GenAI, students expressed both practical advantages and idealistic and improbable visions. They said it could serve as a tutor or coach and allow them to understand the material better. We discuss the implications of the findings for student learning and instruction.},
  keywords={Surveys;Ethics;Generative AI;Plagiarism;Education;Writing;Encoding;Distance measurement;Stakeholders;Information technology;generative artificial intelligence (GenAI);survey study;thematic analysis;undergraduate students},
  doi={10.1109/FIE61694.2024.10893017},
  ISSN={2377-634X},
  month={Oct}
}

@ARTICLE{10938596,
  author={Pwanedo Amos, Joanah and Ahmed Amodu, Oluwatosin and Azlina Raja Mahmood, Raja and Bolakale Abdulqudus, Akanbi and Zakaria, Anies Faziehan and Rhoda Iyanda, Abimbola and Ali Bukar, Umar and Mohd Hanapi, Zurina},
  journal={IEEE Access}, 
  title={A Bibliometric Exposition and Review on Leveraging LLMs for Programming Education}, 
  year={2025},
  volume={13},
  number={},
  pages={58364-58393},
  abstract={The world is experiencing an AI revolution, with large language models (LLMs) transforming various industries, including education. Academics are striving to harness the potential of LLMs while also contending with their risks. This paper presents the first bibliometric analysis focused on LLM research in programming education, identifying leading countries, authors, and institutions while analyzing key terms and popular keywords in this field. Additionally, it highlights influential studies on topics such as introductory programming, computer science, computing, programming education, and prompt engineering, discussing key insights from these works. Findings indicate that LLMs could play a significant role in programming education and may be integrated into computer science curricula. However, careful consideration is needed to ensure their benefits outweigh their risks across various use cases. This study specifically examines ChatGPT as a representative LLM, exploring its benefits and limitations as both a learning aid for students and a support tool for professionals. It also evaluates the quality of ChatGPT-generated code and its effectiveness in simplifying programming concepts for beginners. Furthermore, the ethical implications of increasing reliance on LLMs for programming tasks, including concerns about dependency, plagiarism, and potential effects on critical thinking, are addressed. By contributing to the ongoing discourse on integrating AI tools like ChatGPT in programming education, this research emphasizes the importance of responsible and ethical usage to maximize benefits for students, educators, and the broader educational community.},
  keywords={Chatbots;Programming profession;Education;Bibliometrics;Market research;Large language models;Codes;Ethics;Requirements engineering;Mathematics;ChatGPT;code generation;ethical concerns;large language models (LLMs);introductory programming;programming education;prompt engineering},
  doi={10.1109/ACCESS.2025.3554627},
  ISSN={2169-3536},
  month={}
}

@INPROCEEDINGS{10656194,
  author={Zhao, Zhengyue and Duan, Jinhao and Xu, Kaidi and Wang, Chenan and Zhang, Rui and Du, Zidong and Guo, Qi and Hu, Xing},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Can Protective Perturbation Safeguard Personal Data from Being Exploited by Stable Diffusion?}, 
  year={2024},
  volume={},
  number={},
  pages={24398-24407},
  abstract={Stable Diffusion has established itself as a foundation model in generative AI artistic applications, receiving widespread research and application. Some recent fine-tuning methods have made it feasible for individuals to implant personalized concepts onto the basic Stable Diffusion model with minimal computational costs on small datasets. However, these innovations have also given rise to issues like facial privacy forgery and artistic copyright infringement. In recent studies, researchers have explored the addition of imperceptible adversarial perturbations to images to prevent potential unauthorized exploitation and infringements when personal data is used for fine-tuning Stable Dif-fusion. Although these studies have demonstrated the ability to protect images, it is essential to consider that these methods may not be entirely applicable in real-world scenarios. In this paper, we systematically evaluate the use of perturbations to protect images within a practical threat model. The results suggest that these approaches may not be sufficient to safeguard image privacy and copyright effectively. Furthermore, we introduce a purification method capable of removing protected perturbations while preserving the original image structure to the greatest extent possible. Experiments reveal that Stable Diffusion can effectively learn from purified images over all protective methods1.},
  keywords={Threat modeling;Privacy;Technological innovation;Systematics;Perturbation methods;Semantics;Transform coding;protective perturbation;diffusion models;copyright protection;adversarial examples},
  doi={10.1109/CVPR52733.2024.02303},
  ISSN={2575-7075},
  month={June}
}

@ARTICLE{9306890,
  author={Xu, Guannan and Dong, Fang and Feng, Jiawen},
  journal={IEEE Transactions on Engineering Management}, 
  title={Mapping the Technological Landscape of Emerging Industry Value Chain Through a Patent Lens: An Integrated Framework With Deep Learning}, 
  year={2022},
  volume={69},
  number={6},
  pages={3367-3378},
  abstract={Recent research applies patent autoclassification using machine learning to map the technological landscape of an industry value chain. However, when these methods are applied to emerging industries, the available patent sample data are small-scale and unevenly distributed, which cause overfitting and reduce the accuracy of patent classification. Therefore, this article proposes a framework to map the technological landscape of an emerging industry value chain through patent analysis with deep learning, which integrates a generative adversarial network as a data-augmentation method to overcome the problem of low-quality emerging-industry patent samples, and a deep neural network as a patent classifier. Based on this framework, this article conducts an application case of the 3-D printing industry. The evaluation results show that the integrated framework can effectively classify the patents with small-scale and unevenly distributed sample data, and depict the technological landscape of an emerging industry value chain. This article develops an efficient, reliable framework for patent autoclassification of emerging industries to overcome the lack of high-quality training samples, and it sheds light on the emerging industry value chain analysis with deep learning.},
  keywords={Patents;Generative adversarial networks;Deep learning;Deep neural network (DNN);emerging industry;generative adversarial network (GAN);patent auto-lassification;value chain},
  doi={10.1109/TEM.2020.3041933},
  ISSN={1558-0040},
  month={Dec}
}

@ARTICLE{10902040,
  author={Zeng, Qingli and Nait-Abdesselam, Farid},
  journal={IEEE Internet of Things Journal}, 
  title={Enhancing UAV Network Security: A Human-in-the-Loop and GAN-Based Approach to Intrusion Detection}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Unmanned Aerial Vehicles (UAVs) are becoming essential in various sectors such as commercial delivery, agricultural monitoring, and disaster response. Despite their benefits, the rapid adoption of UAVs poses substantial security challenges, especially in drone network intrusion detection. Traditional intrusion detection datasets often suffer from limitations like small sample sizes and uneven distribution, undermining the effectiveness of Intrusion Detection Systems (IDS). Moreover, conventional machine learning (ML) approaches generally require extensive, well-labeled datasets that are expensive and labor intensive to produce. To overcome these challenges, we introduce a Generative Adversarial Network (GAN) model designed to enhance and balance the limited datasets available for drone networks. This model significantly improves data quality and quantity, thus optimizing the training process for intrusion detection models. Furthermore, we propose a Human-in-the-Loop (HITL) ML framework that integrates human expertise to guide the learning process and mitigate the costs of labeling. Our comprehensive evaluation demonstrates that the combined application of the GAN model and the HITL framework significantly outperforms traditional baseline models. This approach not only achieves an intrusion detection accuracy of up to 99% across various experimental datasets but also dramatically reduces the requirement for large amounts of labeled data by up to 98%, providing a cost-effective solution for enhancing UAV network security.},
  keywords={Drones;Intrusion detection;Generative adversarial networks;Machine learning;Autonomous aerial vehicles;Training;Data models;Labeling;Accuracy;Machine learning algorithms;UAV Networks;Intrusion Detection;HITL;Generative Adversarial Networks},
  doi={10.1109/JIOT.2025.3545389},
  ISSN={2327-4662},
  month={}
}

@INPROCEEDINGS{10200392,
  author={Su, Na},
  booktitle={2023 IEEE 13th International Conference on Electronics Information and Emergency Communication (ICEIEC)}, 
  title={Research on Multiparty Participation Collaborative Supervision Strategy of AIGC}, 
  year={2023},
  volume={},
  number={},
  pages={268-272},
  abstract={The emergence and popularity of ChatGPT has sparked a new wave of “artificial intelligence” worldwide. AIGC is a true industrial revolution-level artificial intelligence technology revolution that will bring significant changes to the entire country, the world, and humanity. Like all technologies, the development of AIGC technology not only brings convenience and innovation to people, but also brings many risks and challenges. By studying the principle of AIGC technology and combining with typical cases, this paper analyzes the causes of security problems caused by the model defects and abuse propagation, focusing on the analysis of privacy Data breach, prejudice and discrimination, copyright disputes caused by data collection, processing, output and other links, as well as the impact of controlled, malicious application, abuse, misuse and other propagation on personal privacy, social stability, national security and international order. From the perspective of both security issues inherent to AIGC and those caused by its application, a multi-party collaborative regulatory strategy is proposed to safeguard the innovative development of AIGC technology, provide theoretical support for the healthy and standardized development of related industries, and help with economic and social transformation and development.},
  keywords={Industries;Data privacy;Technological innovation;Humanities;Collaboration;Process control;Stability analysis;AIGC;Regulatory strategy;ChatGPT},
  doi={10.1109/ICEIEC58029.2023.10200392},
  ISSN={2377-844X},
  month={July}
}

@INPROCEEDINGS{10835578,
  author={Dasgupta, Dipankar and Roy, Arunava},
  booktitle={2024 IEEE 6th International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications (TPS-ISA)}, 
  title={Pitfalls of Generic Large Language Models (GLLMs) from reliability and security perspectives}, 
  year={2024},
  volume={},
  number={},
  pages={412-419},
  abstract={Generic Large Language Models (GLLMs) have grown popularity in many professions with limited or no technical knowledge. Larger and larger GLLMs are continuously being released with enhanced capabilities, promoting the abilities of these Generative AI at the grassroots level in businesses. These tools excel in text, image, and video generation (assembling, summarizing, translating) when proper queries and prompts are given; moreover, various augmentation of up-to-date knowledge bases, making these more efficient in providing current events. Practitioners and marketers showcase the benefits of GLLMs by demonstrating various use cases. However, the reliability of GLLMs' responses is yet questionable in certain scenarios, particularly due to issues like hallucinations, factual inaccuracies, and inappropriate or unrelated responses. Also there remain many open questions on data collection, privacy and ethical issues that need to be addressed. This study emphasizes the reliability and security aspects of GLLMs while recognizing significant benefits in a wide variety of applications. We also provide some insides of social impacts and future directions of AI/ML applications.},
  keywords={Data privacy;Ethics;Translation;Generative AI;Large language models;Knowledge based systems;Data models;Security;Reliability;Intelligent systems;Generative AI;Large Language Models (LLMs);Generative Pre-Trained Models (GPTs);Small Parameterized Data Models (SPDM)},
  doi={10.1109/TPS-ISA62245.2024.00054},
  ISSN={},
  month={Oct}
}

@ARTICLE{10510489,
  author={Zhu, Liuhao and Fang, Yixiang and Zhao, Yi and Peng, Yi and Wang, Junxiang and Ni, Jiangqun},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Lite Localization Network and DUE-Based Watermarking for Color Image Copyright Protection}, 
  year={2024},
  volume={34},
  number={10},
  pages={9311-9325},
  abstract={Deep learning-based watermarking frameworks have received extensive research attention in recent years. The main structure of this framework consists of an encoder, a noise layer and a decoder (Encoder-NoiseLayer-Decoder). However, such a framework has the major drawback that it requires visible markers to locate a watermarked image, which compromises the imperceptibility of watermarking. To address this restriction, a novel Lite localization network based on Lite-HRNet is proposed. In order to generate high-quality watermarked image, we designed the Double U-Net Encoder (DUE), which can better hide the watermarking information in image pixels that are invisible to the human eye. Meanwhile, to improve robustness, two bicubic interpolation operations are added to the noise layer to increase the type of distortion. In addition, to further enhance the performance of the watermarking algorithm, the novel WGAN-GP loss function based on discriminator is designed to guide the training of the model. Numerous experiments demonstrate the superior performance of our proposed scheme in terms of localization function, visual quality, and robustness. The proposed scheme shows better results compared to state-of-the-art algorithms.},
  keywords={Watermarking;Distortion;Noise measurement;Location awareness;Decoding;Robustness;Transforms;Watermarking;Encoding;Generative adversarial networks;Digital watermarking;double U-Net encoder (DUE);lite localization network;WGAN-GP;DNN},
  doi={10.1109/TCSVT.2024.3395304},
  ISSN={1558-2205},
  month={Oct}
}

@INPROCEEDINGS{9964997,
  author={KK, Sabari and Shrivastava, Saurabh and V, Sangeetha.},
  booktitle={2022 10th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)}, 
  title={Anomaly-based Intrusion Detection using GAN for Industrial Control Systems}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={In recent years, cyber-attacks on modern industrial control systems (ICS) have become more common and it acts as a victim to various kind of attackers. The percentage of attacked ICS computers in the world in 2021 is 39.6%. To identify the anomaly in a large database system is a challenging task. Deep-learning model provides better solutions for handling the huge dataset with good accuracy. On the other hand, real time datasets are highly imbalanced with their sample proportions. In this research, GAN based model, a supervised learning method which generates new fake samples that is similar to real samples has been proposed. GAN based adversarial training would address the class imbalance problem in real time datasets. Adversarial samples are combined with legitimate samples and shuffled via proper proportion and given as input to the classifiers. The generated data samples along with the original ones are classified using various machine learning classifiers and their performances have been evaluated. Gradient boosting was found to classify with 98% accuracy when compared to other},
  keywords={Integrated circuits;Training;Industrial control;Intrusion detection;Generative adversarial networks;Market research;Real-time systems;Adversarial training;Anomaly;Classification;Generative Adversarial Network;Intrusion detection system},
  doi={10.1109/ICRITO56286.2022.9964997},
  ISSN={},
  month={Oct}
}

@ARTICLE{10536000,
  author={Berengueres, J.},
  journal={IEEE Transactions on Technology and Society}, 
  title={How to Regulate Large Language Models for Responsible AI}, 
  year={2024},
  volume={5},
  number={2},
  pages={191-197},
  abstract={Large Language Models (LLMs) are predictive probabilistic models capable of passing several professional tests at a level comparable to humans. However, these capabilities come with ethical concerns. Ethical oversights in several LLM-based products include: (i) a lack of content or source attribution, and (ii) a lack of transparency in what was used to train the model. This paper identifies four touchpoints where ethical safeguards can be applied to realize a more responsible AI in LLMs. The key finding is that applying safeguards before the training occurs aligns with established engineering practices of addressing issues at the source. However, this approach is currently shunned. Finally, historical parallels are drawn with the U.S. automobile industry, which initially resisted safety regulations but later embraced them once consumer attitudes evolved.},
  keywords={Ethics;Codes;Artificial intelligence;Benchmark testing;Regulation;General Data Protection Regulation;Large language models;Predictive models;Probabilistic logic;Training;Data integrity;Information integrity;Data integrity;Artificial intelligence;ethical computing;codes of ethics;algorithmic bias;AI governance;accountability in AI;responsible AI},
  doi={10.1109/TTS.2024.3403681},
  ISSN={2637-6415},
  month={June}
}

@INPROCEEDINGS{10302997,
  author={Qin, Hua Xuan and Hui, Pan},
  booktitle={2023 IEEE 43rd International Conference on Distributed Computing Systems Workshops (ICDCSW)}, 
  title={Empowering the Metaverse with Generative AI: Survey and Future Directions}, 
  year={2023},
  volume={},
  number={},
  pages={85-90},
  abstract={This paper aims to motivate the development of the metaverse by highlighting the potential of artificial-intelligence-generated content (AIGC) for the metaverse. We present the first literature review on AIGC in the metaverse with state-of-the-art research classified into 5 key application areas (avatars and Non-player Characters (NPCs), content creation, virtual world generation, automatic digital twin, and personalization). Having noticed a notable gap in research through our review, we propose ways in which state-of-the-art generative AI can be applied to the metaverse. Additionally, we offer a roadmap for future research with related ethical implications.},
  keywords={Surveys;Ethics;Codes;Metaverse;Conferences;Distributed databases;Generators;metaverse;generative AI;co-creative AI;virtual reality;augmented reality;AI-generated content (AIGC)},
  doi={10.1109/ICDCSW60045.2023.00022},
  ISSN={2332-5666},
  month={July}
}

@INPROCEEDINGS{10548160,
  author={Quraishi, Aadam and Rusho, Maher Ali and Prasad, Anurag and Keshta, Ismail and Rivera, Richard and Bhatt, Mohammed Wasim},
  booktitle={2024 Third International Conference on Distributed Computing and Electrical Circuits and Electronics (ICDCECE)}, 
  title={Employing Deep Neural Networks for Real-Time Anomaly Detection and Mitigation in IoT-Based Smart Grid Cybersecurity Systems}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This research introduces a novel anomaly detection framework for IoT -based Smart Grid Cybersecurity Systems. Leveraging autoencoders, LSTM networks, GANs, SOMs, and transfer learning, our approach achieves superior precision, recall, and execution time compared to existing methods. Visualizations and an ablation study further validate the method's efficiency, emphasizing the critical roles of attention mechanisms and transfer learning. This comprehensive solution addresses the dynamic challenges of smart grid cybersecurity, offering a versatile and adaptive anomaly detection mechanism for real-world applications. This indicates the real-time efficacy of our anomaly detection method. Through our study of ablation and all aspects of computing, we discovered that attention processes and transfer learning facilitate faster problem solving in a dynamic smart grid. Our method is distinct and adaptable enough to address every problem arising from the discovery of anomalies in IoT-driven Smart Grid Cybersecurity Systems.},
  keywords={Visualization;Transfer learning;Circuits;Real-time systems;Smart grids;Problem-solving;Computer security;Anomaly Detection;Autoencoders;Cybersecurity;Flowchart;Generative Adversarial Networks (GANs);LSTM Networks;Self-Organizing Maps (SOMs);Transfer Learning;Training Algorithm;IoT-based Smart Grid},
  doi={10.1109/ICDCECE60827.2024.10548160},
  ISSN={},
  month={April}
}

@BOOK{10769305,
  author={Hwang, Yoon Hyup and Burtch, Nicholas C.},
  booktitle={Machine Learning and Generative AI for Marketing: Take your data-driven marketing strategies to the next level using Python},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Start transforming your data-driven marketing strategies and increasing customer engagement. Learn how to create compelling marketing content using advanced gen AI techniques and stay in touch with the future AI ML landscape. Purchase of the print or Kindle book includes a free eBook in PDF formatKey FeaturesEnhance customer engagement and personalization through predictive analytics and advanced segmentation techniquesCombine Python programming with the latest advancements in generative AI to create marketing content and address real-world marketing challengesUnderstand cutting-edge AI concepts and their responsible use in marketingBook DescriptionIn the dynamic world of marketing, the integration of artificial intelligence (AI) and machine learning (ML) is no longer just an advantage—it's a necessity. Moreover, the rise of generative AI (GenAI) helps with the creation of highly personalized, engaging content that resonates with the target audience. This book provides a comprehensive toolkit for harnessing the power of GenAI to craft marketing strategies that not only predict customer behaviors but also captivate and convert, leading to improved cost per acquisition, boosted conversion rates, and increased net sales. Starting with the basics of Python for data analysis and progressing to sophisticated ML and GenAI models, this book is your comprehensive guide to understanding and applying AI to enhance marketing strategies. Through engaging content & hands-on examples, you'll learn how to harness the capabilities of AI to unlock deep insights into customer behaviors, craft personalized marketing messages, and drive significant business growth. Additionally, you'll explore the ethical implications of AI, ensuring that your marketing strategies are not only effective but also responsible and compliant with current standards By the conclusion of this book, you'll be equipped to design, launch, and manage marketing campaigns that are not only successful but also cutting-edge.What you will learnMaster key marketing KPIs with advanced computational techniquesUse explanatory data analysis to drive marketing decisionsLeverage ML models to predict customer behaviors, engagement levels, and customer lifetime valueEnhance customer segmentation with ML and develop highly personalized marketing campaignsDesign and execute effective A/B tests to optimize your marketing decisionsApply natural language processing (NLP) to analyze customer feedback and sentimentsIntegrate ethical AI practices to maintain privacy in data-driven marketing strategiesWho this book is forThis book targets a diverse group of professionals: Data scientists and analysts in the marketing domain looking to apply advanced AI ML techniques to solve real-world marketing challenges Machine learning engineers and software developers aiming to build or integrate AI-driven tools and applications for marketing purposes Marketing professionals, business leaders, and entrepreneurs who must understand the impact of AI on marketing Reader are presumed to have a foundational proficiency in Python and a basic to intermediate grasp of ML principles and data science methodologies},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835889411},
  url={https://ieeexplore.ieee.org/document/10769305}
}

@ARTICLE{10376357,
  author={Zhang, Xiaoyu and Lin, Shen and Chen, Chao and Chen, Xiaofeng},
  journal={IEEE Transactions on Dependable and Secure Computing}, 
  title={MODA: Model Ownership Deprivation Attack in Asynchronous Federated Learning}, 
  year={2024},
  volume={21},
  number={4},
  pages={4220-4235},
  abstract={Training a deep learning model from scratch requires a great deal of available labeled data, computation resources, and expert knowledge. Thus, the time-consuming and complicated learning procedure catapulted the trained model to valuable intellectual property (IP), spurring interest from attackers in model copyright infringement and stealing. Recently, a new defense approach leverages watermarking techniques to inject watermarks into the training procedure and verify model ownership when necessary. To our best knowledge, there is no research work on model ownership stealing attacks in federated learning, and the existing defense or mitigation methods can not be directly used for federated learning scenarios. In this article, we introduce watermarking neural networks in asynchronous federated learning and propose a novel model privacy attack, dubbed model ownership deprivation attack (MODA). MODA is launched by an inside adversarial participant, targeting occupying and depriving the remaining participants’ (victims) copyright to achieve his maximum profit. The extensive experimental results on five benchmark datasets (MNIST, Fashion-MNIST, GTSRB, SVHN, CIFAR10) show that MODA is highly effective in a two-participant learning scenario with a minor impact on model's performance. When extending MODA into multiple participants scenario, MODA still maintains high attack success rate and classification accuracy. Compared to the state-of-the-art works, MODA has a higher attack success rate than the black-box solution and comparable efficacy with the approach in the white-box scenario.},
  keywords={Watermarking;Training;Computational modeling;Federated learning;Servers;Data models;Mathematical models;Asynchronous federated learning;DNN watermarking;ownership verification;privacy attack},
  doi={10.1109/TDSC.2023.3348204},
  ISSN={1941-0018},
  month={July}
}

@ARTICLE{10188887,
  author={Barni, Mauro and Campisi, Patrizio and Delp, Edward J. and Doërr, Gwenaël and Fridrich, Jessica and Memon, Nasir and Pérez-González, Fernando and Rocha, Anderson and Verdoliva, Luisa and Wu, Min},
  journal={IEEE Signal Processing Magazine}, 
  title={Information Forensics and Security: A quarter-century-long journey}, 
  year={2023},
  volume={40},
  number={5},
  pages={67-79},
  abstract={Information forensics and security (IFS) is an active R&D area whose goal is to ensure that people use devices, data, and intellectual properties for authorized purposes and to facilitate the gathering of solid evidence to hold perpetrators accountable. For over a quarter century, since the 1990s, the IFS research area has grown tremendously to address the societal needs of the digital information era. The IEEE Signal Processing Society (SPS) has emerged as an important hub and leader in this area, and this article celebrates some landmark technical contributions. In particular, we highlight the major technological advances by the research community in some selected focus areas in the field during the past 25 years and present future trends.},
  keywords={Privacy;Forensics;Surveillance;Machine learning;Intellectual property;Signal processing;Information processing;Information security;History},
  doi={10.1109/MSP.2023.3275319},
  ISSN={1558-0792},
  month={July}
}

@ARTICLE{10695056,
  author={Mittal, Uday and Sai, Siva and Chamola, Vinay and Sangwan, Devika},
  journal={IEEE Access}, 
  title={A Comprehensive Review on Generative AI for Education}, 
  year={2024},
  volume={12},
  number={},
  pages={142733-142759},
  abstract={Artificial Intelligence (AI) has immense potential for personalized learning experiences, content generation, and vivid educational support. This paper delves into generative AI (GAI) and its potential applications within GAI, specifically mentioning generative adversarial networks (GANs). The article delves into the transformative impact of GAI in education, underscoring its expertise in creating diverse instructional materials, from texts and images to videos. Adaptive learning, one of the chief abilities of GAI, has been highlighted, emphasizing its capability to select content customized to individual student profiles, learning habits, and preferences. The paper further explores the fusion of GAI with innovative education systems, highlighting how these models can mimic conversational interfaces, promoting an engaging, customized learning journey. The exploration doesn’t stop at the benefits; it delves into challenges like ensuring data privacy, mitigating biases, and ensuring accountability in AI-driven educational systems. The conclusion contemplates the potential limitations and assurances of embedding GAI within educational setups. An appeal has been made for more profound research and enhancement of AI’s educational function. The intersection of pedagogical insights and effective human-AI collaboration is pivotal in this journey. This paper serves as a compass, guiding educators, researchers, and policymakers toward harnessing GAI’s potential to sculpt enriched, immersive educational landscapes.},
  keywords={Artificial intelligence;Education;Computational modeling;Solid modeling;Videos;Three-dimensional displays;Metaverse;Learning systems;Generative AI;GAI;education;applications;case studies;challenges;metaverse},
  doi={10.1109/ACCESS.2024.3468368},
  ISSN={2169-3536},
  month={}
}

@INPROCEEDINGS{10541170,
  author={Briggs, Morgan and Cross, Miranda},
  booktitle={2024 4th International Conference on Applied Artificial Intelligence (ICAPAI)}, 
  title={Generative AI: Threatening Established Human Rights Instruments at Scale}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={We assess the impacts of generative AI technologies within the context of rights and freedoms enshrined in two codified international covenants, the International Covenant on Civil and Political Rights (ICCPR) and the International Covenant on Economic, Social, and Cultural Rights (ICESCR). Additionally, the UN Guiding Principles on Business and Human Rights (UNGPs) are explored in tandem to further motivate the requirement for businesses and States to carry out human rights due diligence processes. By providing specific use cases and examples of how generative AI’s cross-sectoral risks threaten established human rights and freedoms, such as the freedom of opinion and expression and the right to privacy, we argue that proper governance and accountability mechanisms for generative AI should be based in codified international human rights instruments and support frameworks such as the UNGPs. This paper is intended to serve as a catalogue of concrete evidence to support the enforcement and uptake of human rights due diligence processes and foster conversations at the policy level.},
  keywords={Economics;Privacy;Ethics;Generative AI;Instruments;Oral communication;Cultural differences;Generative AI;AI Ethics;Human Rights;Human Rights Due Diligence;UN Guiding Principles on Business and Human Rights},
  doi={10.1109/ICAPAI61893.2024.10541170},
  ISSN={},
  month={April}
}

@BOOK{10745298,
  author={McFedries, Paul},
  booktitle={Build a Website with ChatGPT: No coding experience necessary},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Create a portfolio of cool and creative websites—all without having to write your own code. Build a Website with ChatGPT teaches you zero-coding web development utilizing powerful generative AI tools like ChatGPT. If you can open a web browser, you’re ready to start building—absolutely no coding experience required. Inside Build a Website with ChatGPT you’ll learn the important skills of AI-assisted web programming, such as:  Crafting effective prompts to generate HTML, CSS, and JavaScript Converting text into images with DALL-E integration Building navigation bars, image galleries, and contact forms Deploying fully functional sites to the web for free Customizing the generated code for unique sites  Inside Build a Website with ChatGPT you’ll learn the high-level coding concepts that let you check and perfect AI output, prompting skills that deliver the exact code you need, and how to properly deploy your site to the web—for free! Annotated code samples and advice on code customization give you the perfect balance of understanding and convenience. Plus, you’ll get access to a tried-and-tested repository of prompts and working code.},
  keywords={generative;AI;zero-coding;HTML;CSS;JavaScript;DALL-E;free;prompts;fully functional;fonts;colors;headings;structure;image galleries;contact forms;navigation bars;image conversion;deployment},
  doi={},
  ISSN={},
  publisher={Manning},
  isbn={9781633436961},
  url={https://ieeexplore.ieee.org/document/10745298}
}

@INPROCEEDINGS{10646659,
  author={Wang, Jincheng and Yu, Le and Luo, Xiapu},
  booktitle={2024 IEEE Symposium on Security and Privacy (SP)}, 
  title={LLMIF: Augmented Large Language Model for Fuzzing IoT Devices}, 
  year={2024},
  volume={},
  number={},
  pages={881-896},
  abstract={Despite the efficacy of fuzzing in verifying the implementation correctness of network protocols, existing IoT protocol fuzzing approaches grapple with several limitations, including obfuscated message formats, unresolved message dependencies, and a lack of evaluations on the testing cases. These limitations significantly curtail the capabilities of IoT fuzzers in vulnerability identification. In this work, we show that the protocol specification contains fruitful descriptions of protocol messages, which can be used to overcome the above limitations and guide IoT protocol fuzzing. To automate the specification analysis, we augment the large language model with the specification contents, and drive it to perform two tasks (i.e., protocol information extraction, and device response reasoning). We further design and implement a fuzzing algorithm, LLMIF, which incorporates the LLM into IoT fuzzing. Finally, we select Zigbee as the target protocol and initiate comprehensive evaluations. The evaluation result shows that LLMIF successfully addressed the above limitations. Compared with the existing Zigbee fuzzers, it increases the protocol message coverage and code coverage by 55.2% and 53.9%, respectively. Besides the enhanced coverage, LLMIF unearthed 11 vulnerabilities on real-world Zigbee devices, which include eight previously unknown vulnerabilities. Seven of them are not covered by the existing Zigbee fuzzers.},
  keywords={Privacy;Protocols;Codes;Large language models;Zigbee;Fuzzing;Internet of Things;fuzzing;IoT device;large language model},
  doi={10.1109/SP54263.2024.00211},
  ISSN={2375-1207},
  month={May}
}

@BOOK{10769230,
  author={Bustos, Juan Pablo and Soria, Luis Lopez and Arsanjani, Dr. Ali},
  booktitle={Generative AI Application Integration Patterns: Integrate large language models into your applications},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Unleash the transformative potential of GenAI with this comprehensive guide that serves as an indispensable roadmap for integrating large language models into real-world applications. Gain invaluable insights into identifying compelling use cases, leveraging state-of-the-art models effectively, deploying these models into your applications at scale, and navigating ethical considerations.Key FeaturesGet familiar with the most important tools and concepts used in real scenarios to design GenAI appsInteract with GenAI models to tailor model behavior to minimize hallucinationsGet acquainted with a variety of strategies and an easy to follow 4 step frameworks for integrating GenAI into applicationsBook DescriptionExplore the transformative potential of GenAI in the application development lifecycle. Through concrete examples, you will go through the process of ideation and integration, understanding the tradeoffs and the decision points when integrating GenAI. With recent advances in models like Google Gemini, Anthropic Claude, DALL-E and GPT-4o, this timely resource will help you harness these technologies through proven design patterns. We then delve into the practical applications of GenAI, identifying common use cases and applying design patterns to address real-world challenges. From summarization and metadata extraction to intent classification and question answering, each chapter offers practical examples and blueprints for leveraging GenAI across diverse domains and tasks. You will learn how to fine-tune models for specific applications, progressing from basic prompting to sophisticated strategies such as retrieval augmented generation (RAG) and chain of thought. Additionally, we provide end-to-end guidance on operationalizing models, including data prep, training, deployment, and monitoring. We also focus on responsible and ethical development techniques for transparency, auditing, and governance as crucial design patterns.What you will learnConcepts of GenAI: pre-training, fine-tuning, prompt engineering, and RAGFramework for integrating AI: entry points, prompt pre-processing, inference, post-processing, and presentationPatterns for batch and real-time integrationCode samples for metadata extraction, summarization, intent classification, question-answering with RAG, and moreEthical use: bias mitigation, data privacy, and monitoringDeployment and hosting options for GenAI modelsWho this book is forThis book is not an introduction to AI/ML or Python. It offers practical guides for designing, building, and deploying GenAI applications in production. While all readers are welcome, those who benefit most include: Developer engineers with foundational tech knowledge Software architects seeking best practices and design patterns Professionals using ML for data science, research, etc., who want a deeper understanding of Generative AI Technical product managers with a software development background This concise focus ensures practical, actionable insights for experienced professionals},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835887615},
  url={https://ieeexplore.ieee.org/document/10769230}
}

@ARTICLE{10843672,
  author={Feng, Wenyan and Li, Yuhang and Ma, Chunhao and Yu, Lisai},
  journal={IEEE Access}, 
  title={From ChatGPT to Sora: Analyzing Public Opinions and Attitudes on Generative Artificial Intelligence in Social Media}, 
  year={2025},
  volume={13},
  number={},
  pages={14485-14498},
  abstract={This study examines public opinions, emotional tendencies, and psychological linguistic characteristics associated with the launch of OpenAI’s ChatGPT and the advanced video generation model, Sora, by analyzing discussions on the Chinese social media platform Weibo. A total of 24,727 valid user-generated texts (1,762,296 words) were collected and analyzed using Python and its associated APIs. Word co-occurrence network analysis, topic modeling based on Latent Dirichlet Allocation (LDA), and emotional characteristics based on the DLUT Emotion Ontology and psycholinguistic analyses based on the Linguistic Inquiry and Word Count (LIWC) dictionary were employed to explore public views on these generative AI technologies. The findings reveal a shift in public focus over time, from initial excitement about technological advancements to growing interest in commercialization, labor, education, ethics, and global competition. The public’s emotional responses to AI were a mix of excitement and apprehension. The study identifies seven distinct emotional types, providing a nuanced understanding of public psychological reactions, which contrasts with previous binary classifications. This research contributes valuable insights for policymakers, businesses, and researchers, highlighting the public’s evolving acceptance of generative AI technologies.},
  keywords={Chatbots;Artificial intelligence;Generative AI;Social networking (online);Blogs;Psychology;Sentiment analysis;Analytical models;Text mining;Ethics;Generative artificial intelligence;ChatGPT;sora;topic modeling;sentiment analysis;psycholinguistics},
  doi={10.1109/ACCESS.2025.3530683},
  ISSN={2169-3536},
  month={}
}

@BOOK{10769215,
  author={Meyer, Lucas A.},
  booktitle={Building AI Applications with Microsoft Semantic Kernel: Easily integrate generative AI capabilities and copilot experiences into your applications},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Unlock the power of GenAI by effortlessly linking your C# and Python apps with cutting-edge models, orchestrating diverse AI services with finesse, and crafting bespoke applications through immersive, real-world examplesKey FeaturesLink your C# and Python applications with the latest AI models from OpenAICombine and orchestrate different AI services such as text and image generatorsCreate your own AI apps with real-world use case examples that show you how to use basic generative AI, create images, process documents, use a vector databasePurchase of the print or Kindle book includes a free PDF eBookBook DescriptionIn the fast-paced world of AI, developers are constantly seeking efficient ways to integrate AI capabilities into their apps. Microsoft Semantic Kernel simplifies this process by using the GenAI features from Microsoft and OpenAI. Written by Lucas A. Meyer, a Principal Research Scientist in Microsoft’s AI for Good Lab, this book helps you get hands on with Semantic Kernel. It begins by introducing you to different generative AI services such as GPT-3.5 and GPT-4, demonstrating their integration with Semantic Kernel. You’ll then learn to craft prompt templates for reuse across various AI services and variables. Next, you’ll learn how to add functionality to Semantic Kernel by creating your own plugins. The second part of the book shows you how to combine multiple plugins to execute complex actions, and how to let Semantic Kernel use its own AI to solve complex problems by calling plugins, including the ones made by you. The book concludes by teaching you how to use vector databases to expand the memory of your AI services and how to help AI remember the context of earlier requests. You’ll also be guided through several real-world examples of applications, such as RAG and custom GPT agents. By the end of this book, you'll have gained the knowledge you need to start using Semantic Kernel to add AI capabilities to your applications.What you will learnWrite reusable AI prompts and connect to different AI providersCreate new plugins that extend the capabilities of AI servicesUnderstand how to combine multiple plugins to execute complex actionsOrchestrate multiple AI services to accomplish a taskLeverage the powerful planner to automatically create appropriate AI callsUse vector databases as additional memory for your AI tasksDeploy your application to ChatGPT, making it available to hundreds of millions of usersWho this book is forThis book is for beginner-level to experienced .NET or Python software developers who want to quickly incorporate the latest AI technologies into their applications, without having to learn the details of every new AI service. Product managers with some development experience will find this book helpful while creating proof-of-concept applications. This book requires working knowledge of programming basics.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835469590},
  url={https://ieeexplore.ieee.org/document/10769215}
}

@INPROCEEDINGS{9745023,
  author={Ren, Sihan and Sheng, Yiwei},
  booktitle={2022 IEEE International Conference on Electrical Engineering, Big Data and Algorithms (EEBDA)}, 
  title={Image Style Transfer Using Deep Learning Methods}, 
  year={2022},
  volume={},
  number={},
  pages={1190-1195},
  abstract={Image style transfer is an increasingly popular technology that can learn the style of an existing picture through neural network algorithms and apply this style to another picture. It is widely used in the field of art, such as oil painting, cartoon animation production, image season conversion and text style conversion. Meanwhile, deep learning methods are attracting more and more attention both in research and applications in various areas. In this paper, we give an overview on current research progress and results of image style transfer using deep learning methods. The deep learning methods are categorized into Convolutional Neural Networks (CNN) and Generative Adversarial Networks (GAN). As for CNN methods, we mainly talk about models based on VGG; and in terms of GAN methods, conditional GAN, Cycle GAN, and cartoon-GAN methods are contained. Finally, we summarized the shortcomings of the current results and the future study direction.},
  keywords={Deep learning;Training;Image quality;PSNR;Image coding;Neural networks;Production;image style transfer;deep learning;convolutional neural network;generative adversarial network},
  doi={10.1109/EEBDA53927.2022.9745023},
  ISSN={},
  month={Feb}
}

@BOOK{10769274,
  author={Antić, Zhenya and Chakravarty, Saurabh},
  booktitle={Python Natural Language Processing Cookbook: Over 60 recipes for building powerful NLP solutions using Python and LLM libraries},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Updated to include three new chapters on transformers, natural language understanding (NLU) with explainable AI, and dabbling with popular LLMs from Hugging Face and OpenAIKey FeaturesLeverage ready-to-use recipes with the latest LLMs, including Mistral, Llama, and OpenAI modelsUse LLM-powered agents for custom tasks and real-world interactionsGain practical, in-depth knowledge of transformers and their role in implementing various NLP tasks with open-source and advanced LLMsPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionHarness the power of Natural Language Processing to overcome real-world text analysis challenges with this recipe-based roadmap written by two seasoned NLP experts with vast experience transforming various industries with their NLP prowess. You’ll be able to make the most of the latest NLP advancements, including large language models (LLMs), and leverage their capabilities through Hugging Face transformers. Through a series of hands-on recipes, you’ll master essential techniques such as extracting entities and visualizing text data. The authors will expertly guide you through building pipelines for sentiment analysis, topic modeling, and question-answering using popular libraries like spaCy, Gensim, and NLTK. You’ll also learn to implement RAG pipelines to draw out precise answers from a text corpus using LLMs. This second edition expands your skillset with new chapters on cutting-edge LLMs like GPT-4, Natural Language Understanding (NLU), and Explainable AI (XAI)—fostering trust and in your NLP models. By the end of this book, you'll be equipped with the skills to apply advanced text processing techniques, use pre-trained transformer models, build custom NLP pipelines to extract valuable insights from text data to drive informed decision-making.What you will learnUnderstand fundamental NLP concepts along with their applications using examples in PythonClassify text quickly and accurately with rule-based and supervised methodsTrain NER models and perform sentiment analysis to identify entities and emotions in textExplore topic modeling and text visualization to reveal themes and relationships within textLeverage Hugging Face and OpenAI LLMs to perform advanced NLP tasksUse question-answering techniques to handle both open and closed domainsApply XAI techniques to better understand your model predictionsWho this book is forThis updated edition of the Python Natural Language Processing Cookbook is for data scientists, machine learning engineers, and developers with a background in Python. Whether you’re looking to learn NLP techniques, extract valuable insights from textual data, or create foundational applications, this book will equip you with basic to intermediate skills. No prior NLP knowledge is necessary to get started. All you need is familiarity with basic programming principles. For seasoned developers, the updated sections offer the latest on transformers, explainable AI, and Generative AI with LLMs.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781803241449},
  url={https://ieeexplore.ieee.org/document/10769274}
}

@ARTICLE{10897652,
  author={Huang, Yuantian and Iizuka, Satoshi and Simo-Serra, Edgar and Fukui, Kazuhiro},
  journal={Computational Visual Media}, 
  title={Controllable multi-domain semantic artwork synthesis}, 
  year={2024},
  volume={10},
  number={2},
  pages={355-373},
  abstract={We present a novel framework for the multidomain synthesis of artworks from semantic layouts. One of the main limitations of this challenging task is the lack of publicly available segmentation datasets for art synthesis. To address this problem, we propose a dataset called ArtSem that contains 40,000 images of artwork from four different domains, with their corresponding semantic label maps. We first extracted semantic maps from landscape photography and used a conditional generative adversarial network (GAN)-based approach for generating high-quality artwork from semantic maps without requiring paired training data. Furthermore, we propose an artwork-synthesis model using domain-dependent variational encoders for high-quality multi-domain synthesis. Subsequently, the model was improved and complemented with a simple but effective normalization method based on jointly normalizing semantics and style, which we call spatially style-adaptive normalization (SSTAN). Compared to the previous methods, which only take semantic layout as the input, our model jointly learns style and semantic information representation, improving the generation quality of artistic images. These results indicate that our model learned to separate the domains in the latent space. Thus, we can perform fine-grained control of the synthesized artwork by identifying hyperplanes that separate the different domains. Moreover, by combining the proposed dataset and approach, we generated user-controllable artworks of higher quality than that of existing approaches, as corroborated by quantitative metrics and a user study.},
  keywords={Semantics;Painting;Art;Training;Oils;Vectors;Translation;Layout;Image synthesis;Computational modeling;semantic artwork synthesis;generative adversarial network (GAN);datasets;non-photorealistic rendering},
  doi={10.1007/s41095-023-0356-2},
  ISSN={2096-0662},
  month={April}
}

@ARTICLE{10929015,
  author={Cao, Maida and Dai, Wenrui and Li, Shaohui and Li, Chenglin and Zou, Junni and Hu, Weisheng and Xiong, Hongkai},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Generative Probabilistic Entropy Modeling With Conditional Diffusion for Learned Image Compression}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Entropy modeling is the core component of learned image compression (LIC) that models the distribution of latent representation learned from input images via neural networks for bit-rate estimation. However, existing entropy models employ presumed parameterized distributions such as Gaussian models and are limited for the learned latent representation characterized by complex distributions. To address this problem, in this paper, we for the first time achieve generative probabilistic entropy modeling of latent representation based on conditional diffusion models. Specifically, we propose a conditional diffusion-based probabilistic entropy model (CDPEM) to parameterize the latent representation with distributions of arbitrary forms that are generated by well designed training-test consistent denoising diffusion implicit model (TC-DDIM) without introducing any presumption. TC-DDIM is designed to leverage ancestral sampling to gradually approximate the distribution of latent representation with guaranteed consistency in generation for training and test. Furthermore, we develop a hierarchical spatial-channel context model to incorporate with TC-DDIM to sufficiently exploit spatial correlations with the approximate contextual information produced by ancestral sampling and channel-wise correlations using channel-wise information aggregation with reweighted training loss. Experimental results demonstrate that the proposed entropy model achieves state-of-the-art performance on the Kodak, CLIC, and Tecnick datasets compared to existing LIC methods. Remarkably, when incorporated with recent baselines, the proposed model outperforms latest VVC standard by an evident gain in R-D performance.},
  keywords={Entropy;Context modeling;Diffusion models;Training;Image coding;Probabilistic logic;Adaptation models;Transforms;Noise reduction;Image reconstruction;Learned image compression;entropy modeling;conditional diffusion model},
  doi={10.1109/TCSVT.2025.3551780},
  ISSN={1558-2205},
  month={}
}

@ARTICLE{9335027,
  author={Subramanian, Nandhini and Elharrouss, Omar and Al-Maadeed, Somaya and Bouridane, Ahmed},
  journal={IEEE Access}, 
  title={Image Steganography: A Review of the Recent Advances}, 
  year={2021},
  volume={9},
  number={},
  pages={23409-23423},
  abstract={Image Steganography is the process of hiding information which can be text, image or video inside a cover image. The secret information is hidden in a way that it not visible to the human eyes. Deep learning technology, which has emerged as a powerful tool in various applications including image steganography, has received increased attention recently. The main goal of this paper is to explore and discuss various deep learning methods available in image steganography field. Deep learning techniques used for image steganography can be broadly divided into three categories - traditional methods, Convolutional Neural Network-based and General Adversarial Network-based methods. Along with the methodology, an elaborate summary on the datasets used, experimental set-ups considered and the evaluation metrics commonly used are described in this paper. A table summarizing all the details are also provided for easy reference. This paper aims to help the fellow researchers by compiling the current trends, challenges and some future direction in this field.},
  keywords={Deep learning;Media;Ciphers;Tools;Market research;Image color analysis;Image steganography;GAN steganography;CNN steganography;information hiding;image data hiding},
  doi={10.1109/ACCESS.2021.3053998},
  ISSN={2169-3536},
  month={}
}

@INPROCEEDINGS{9373209,
  author={Ko, Jindeuk and Lee, Jooyeoun},
  booktitle={2021 IEEE International Conference on Big Data and Smart Computing (BigComp)}, 
  title={Discovering Research Areas from Patents: A Case Study in Autonomous Vehicles Industry}, 
  year={2021},
  volume={},
  number={},
  pages={203-209},
  abstract={Seven research areas introduced by the `Autonomous Systems' research lab provide research areas required to enable the autonomous vehicle industry. For ensuring the validity of the research areas with the baseline, we apply Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA) on the US patents containing `Autonomous Vehicles' to identify keywords and research areas of relevant technologies. Keyword clustering and TF-IDF are repeatedly applied to the retrieved keywords to further filter out irrelevant words. Coherence values for LSA and LDA are evaluated to determine an adequate number of topics that need to be generated. We found that results from LSA provide a list of technologies already included in the baseline while topics from LDA provide associated keywords to support defining each technology. We conclude the numbers and topics provided by the baseline model closely represent the industry of autonomous vehicles but the identified topics from us provide a significant extension in research areas. The resulting research areas may provide overviews and guidelines on the autonomous vehicles industry for researchers and institutes.},
  keywords={Industries;Patents;Time series analysis;Coherence;Market research;Autonomous vehicles;Guidelines;Autonomous Vehicles;Big Data;Natural Language Processing;Topic Modelling;Patents Analysis},
  doi={10.1109/BigComp51126.2021.00046},
  ISSN={2375-9356},
  month={Jan}
}

@ARTICLE{10877890,
  author={Zhou, Qing and Wei, Ping and Qian, Zhenxing and Zhang, Xinpeng and Li, Sheng},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Improved Generative Steganography Based on Diffusion Model}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={The rapid growth of generative models has led to a new direction in steganography called generative steganography (GS). It allows message-to-image generation without the need for a carrier image. Recently, generative steganography methods have been proposed using generative adversarial networks (GANs) and Flow models. On the one hand, methods that use GANs to generate stego images struggle to fully recover the hidden message because the networks are not reversible. On the other hand, methods based on Flow encounter a problem where the images they create might not look real, mainly because the network has limitations in being reversible. Diffusion models fulfill network reversibility while generating high-quality images. However, the framework of existing diffusion models is reversible, but hidden message recovery is not perfectly reversible, resulting in the recovered message being similar but not exactly the same as the hidden one. Existing diffusion models are typically trained for one-directional image generation tasks, so they face some problems when dealing with bi-directional steganography tasks. If pre-trained diffusion models are directly used to generate stego images, exact secret data extraction through the diffusion process cannot be achieved. In this paper, we present an improved generative steganography based on the diffusion model (GSD), which conceals secret data in the frequency domain of random noise to enhance the security and accuracy of steganography, and re-trains the denoising diffusion implicit model (DDIM) for steganography, called the StegoDiffusion. During training StegoDiffusion, random noise is injected into the clean natural images and then trained through the forward diffusion process to obtain the re-trained StegoDiffusion. Our proposed GSD scheme achieves a 100% extraction accuracy for hidden secret data with a payload of 1 bit-per-pixel (bpp) in a single channel, and generates high-quality stego images in PNG format.},
  keywords={Steganography;Diffusion models;Data mining;Accuracy;Distortion;Data models;Security;Generators;Training;Noise reduction;Generative steganography;diffusion model;DDIM},
  doi={10.1109/TCSVT.2025.3539832},
  ISSN={1558-2205},
  month={}
}

@INPROCEEDINGS{10223888,
  author={Yu, Li and Bohao, Pei and Qiang, Yu and Wei, Zhang},
  booktitle={2023 26th ACIS International Winter Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD-Winter)}, 
  title={Improve Information Service Capabilities from Content Aggregation to Knowledge Provision with Generative Pre-trained Transformer (GPT)}, 
  year={2023},
  volume={},
  number={},
  pages={188-192},
  abstract={The exponential growth of data and information has led to unprecedented opportunities and challenges in processing, analyzing, and utilizing this vast amount of knowledge. Nowadays, with the emerging and evolving of some novel strong Artificial Intelligence (AI) technologies, especially GPT (short for Generative Pre-trained Transformer), it suddenly becomes possible for traditional information providers (such as Libraries, Data Intelligence Service Centers) to conduct business from resource and content aggregation to high-level knowledge provision. After analyzing the status of information businesses and mechanism of GPT, in this article, several possible changes and some corresponsive measures to achieve a higher intelligent level of knowledge service for traditional information providers are mainly discussed in depth. It's expected that such exploration will provide meaningful reference for facilitating the intelligent development of traditional information services.},
  keywords={Knowledge acquisition;Focusing;Transformers;Chatbots;Libraries;Artificial intelligence;Information technology;Information Service;Content Provision;Knowledge Generation;Artificial Intelligence;ChatGPT},
  doi={10.1109/SNPD-Winter57765.2023.10223888},
  ISSN={},
  month={July}
}

@INPROCEEDINGS{10436249,
  author={R, Oscar I. Iglesias and M, Christian G. Quintero},
  booktitle={2023 IEEE Colombian Caribbean Conference (C3)}, 
  title={Generative AI: The key for everyday problems. A comparison proposal for new users}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Generative AI is yet one of the biggest types of artificial intelligence brought to the public view, proposing a new vision and path for many industries around the world. This artificial intelligence model has brought a huge audience due to its impact on almost every industry, transforming the way some jobs can be pursued. Through an objective position, in this paper generative AI is evaluated to propose a comparison of some of their important tools to give new users a guide to solving their daily life problems, whether in their households or in their jobs, demonstrating the importance of knowing and using this type of AI.},
  keywords={Industries;Generative AI;Proposals;Generative AI;AI Tools;AI Models},
  doi={10.1109/C358072.2023.10436249},
  ISSN={},
  month={Nov}
}

@ARTICLE{10496545,
  author={Li, Belle and Bonk, Curtis J. and Wang, Chaoran and Kou, Xiaojing},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Reconceptualizing Self-Directed Learning in the Era of Generative AI: An Exploratory Analysis of Language Learning}, 
  year={2024},
  volume={17},
  number={},
  pages={1489-1503},
  abstract={This exploratory analysis investigates the integration of ChatGPT in self-directed learning (SDL). Specifically, this study examines YouTube content creators’ language-learning experiences and the role of ChatGPT in their SDL, building upon Song and Hill's conceptual model of SDL in online contexts. Thematic analysis of interviews with 19 YouTubers and relevant video contents reveals distinct constructs of ChatGPT-integrated SDL, suggesting a reconceptualization and refinement of the SDL framework in the consideration of generative artificial intelligence (AI). This framework emphasizes critical aspects of utilizing ChatGPT as an SDL tool on two distinct levels: 1) the interactive relationships and interplay between learners’ personal traits and their ongoing learning processes (local) and 2) the evolving nature of SDL in the rapidly advancing landscape of generative AI, with socio-political-cultural foundations of AI constantly shaping the learning environment where SDL occurs (global). The study highlights the potential of ChatGPT as a tool for promoting self-directed language learning (SDLL) and provides implications for the development of learning technologies and research on AI-facilitated SDL.},
  keywords={Chatbots;Education;Artificial intelligence;Web sites;Video on demand;Generative AI;Web 2.0;Artificial intelligence (AI);ChatGPT;language learning;self-directed learning (SDL);YouTuber},
  doi={10.1109/TLT.2024.3386098},
  ISSN={1939-1382},
  month={}
}

@INPROCEEDINGS{10021108,
  author={Searle, Richard and Gururaj, Prabhanjan and Gupta, Anubhav and Kannur, Kiran},
  booktitle={2022 IEEE International Conference on Big Data (Big Data)}, 
  title={Secure Implementation of Artificial Intelligence Applications for Anti-Money Laundering using Confidential Computing}, 
  year={2022},
  volume={},
  number={},
  pages={3092-3098},
  abstract={Money laundering not only facilitates the perpetration of dangerous and illegal activities it also damages the credibility and integrity of the global financial system and the financial institutions through whom money is laundered. Despite most financial institutions adhering to prevailing laws and regulations designed to prevent the practice of money laundering, it has been difficult to stop illicit activity using conventional methods. Hence, to combat money laundering, financial institutions are increasingly focused on the adoption of new technologies involving the use of artificial intelligence (AI) and machine learning (ML). One barrier to adoption of these new techniques for anti-money laundering (AML), however, is the need to maintain the confidentiality of the massive quantities of data required to train AI models, a financial data is the subject of regulatory controls and a target for cyber threat actors. In response to these challenges, this paper presents a secure and scalable architecture for AI implementation that uses confidential computing technology to provide complete end-to-end protection of sensitive financial data and the intellectual property of AML algorithm developers. Generative adversarial networks (GANs) are demonstrated using cloud infrastructure secured using Intel® Software Guard Extensions (Intel® SGX). The reported solution architecture can be adapted to support federated machine learning (FML), at scale, between mutually distrusting institutions, with independent control of data security at rest, in transit, and in use by individual data owners.},
  keywords={Training;Computers;Law enforcement;Computational modeling;Collaboration;Computer architecture;Machine learning;Anti-money laundering;confidential computing;artificial intelligence;machine learning;data security},
  doi={10.1109/BigData55660.2022.10021108},
  ISSN={},
  month={Dec}
}

@INPROCEEDINGS{10778724,
  author={McCully, Gary A. and Hastings, John D. and Xu, Shengjie and Fortier, Adam},
  booktitle={2024 Cyber Awareness and Research Symposium (CARS)}, 
  title={Bi-Directional Transformers vs. word2vec: Discovering Vulnerabilities in Lifted Compiled Code}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Detecting vulnerabilities within compiled binaries is challenging due to lost high-level code structures and other factors such as architectural dependencies, compilers, and optimization options. To address these obstacles, this research explores vulnerability detection using natural language processing (NLP) embedding techniques with word2vec, BERT, and RoBERTa to learn semantics from intermediate representation (LLVM IR) code. Long short-term memory (LSTM) neural networks were trained on embeddings from encoders created using approximately 48k LLVM functions from the Juliet dataset. This study is pioneering in its comparison of word2vec models with multiple bidirectional transformers (BERT, RoBERTa) embeddings built using LLVM code to train neural networks to detect vulnerabilities in compiled binaries. Word2vec Skip-Gram models achieved 92% validation accuracy in detecting vulnerabilities, outperforming word2vec Continuous Bag of Words (CBOW), BERT, and RoBERTa. This suggests that complex contextual embeddings may not provide advantages over simpler word2vec models for this task when a limited number (e.g. 48K) of data samples are used to train the bidirectional transformer-based models. The comparative results provide novel insights into selecting optimal embeddings for learning compiler-independent semantic code representations to advance machine learning detection of vulnerabilities in compiled binaries.},
  keywords={Codes;Accuracy;Semantics;Neural networks;Bidirectional control;Transformers;Encoding;Natural language processing;Long short term memory;Context modeling;Machine Learning;Buffer Overflows;BERT;RoBERTa;Binary Security;LLVM;word2vec},
  doi={10.1109/CARS61786.2024.10778724},
  ISSN={},
  month={Oct}
}

@INPROCEEDINGS{10035063,
  author={Ke, Zehui and Huang, Hailiang and Liang, Yingwei and Ding, Yi and Cheng, Xin and Wu, Qingyao},
  booktitle={2022 IEEE International Conference on e-Business Engineering (ICEBE)}, 
  title={Robust Video watermarking based on deep neural network and curriculum learning}, 
  year={2022},
  volume={},
  number={},
  pages={80-85},
  abstract={With the rapid development of multimedia and short video, there is a growing concern for video copyright protection. Some work has been proposed to add some copyright or fingerprint information to the video to trace the source of the video when it is stolen and protect video copyright. This paper proposes a video watermarking method based on a deep neural network and curriculum learning for watermarking of sliced videos. The first frame of the segmented video is perturbed by an encoder network, which is invisible and can be distinguished by the decoder network. Our model is trained and tested on an online educational video dataset consisting of 2000 different video clips. Experimental results show that our method can successfully discriminate most watermarked and non-watermarked videos with low visual disturbance, which can be achieved even under a relatively high video compression rate(H.264 video compress with CRF 32).},
  keywords={Deep learning;Visualization;Neural networks;Watermarking;Video compression;Streaming media;Fingerprint recognition;robust video watermark;deep neural network;copyright protection;curriculum learning},
  doi={10.1109/ICEBE55470.2022.00023},
  ISSN={},
  month={Oct}
}

@INPROCEEDINGS{10727145,
  author={Sallou, June and Durieux, Thomas and Panichella, Annibale},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER)}, 
  title={Breaking the Silence: the Threats of Using LLMs in Software Engineering}, 
  year={2024},
  volume={},
  number={},
  pages={102-106},
  abstract={Large Language Models (LLMs) have gained considerable traction within the Software Engineering (SE) community, impacting various SE tasks from code completion to test generation, from program repair to code summarization. Despite their promise, researchers must still be careful as numerous intricate factors can influence the outcomes of experiments involving LLMs. This paper initiates an open discussion on potential threats to the validity of LLM-based research including issues such as closed-source models, possible data leakage between LLM training data and research evaluation, and the reproducibility of LLM-based findings. In response, this paper proposes a set of guidelines tailored for SE researchers and Language Model (LM) providers to mitigate these concerns. The implications of the guidelines are illustrated using existing good practices followed by LLM providers and a practical example for SE researchers in the context of test case generation.},
  keywords={Codes;Large language models;Training data;Maintenance engineering;Reproducibility of results;Data models;Test pattern generators;Software engineering;Guidelines;Large Language Models;Software Engineering;Evaluation},
  doi={10.1145/3639476.3639764},
  ISSN={2832-7632},
  month={April}
}

@INPROCEEDINGS{10453750,
  author={Ghandour, Ahmad and Woodford, Brendon J.},
  booktitle={2023 24th International Arab Conference on Information Technology (ACIT)}, 
  title={Guidelines to Develop AI Ethics Policy in Organizations: Perspectives Informed from Two Different Countries’ Laws}, 
  year={2023},
  volume={},
  number={},
  pages={1-9},
  abstract={This paper draws on actual attempts being made to develop and implement ethical frameworks and discusses AI regulatory approaches of two countries (United Arab Emirates and New Zealand) and provides recommendations for organizations developing their own AI ethics policies. These recommendations aim to address key ethical considerations related to the adoption and implementation of AI tools, including data protection and ownership, accountability and responsibility, error management, physical safety, societal harms, and economic implications.},
  keywords={Economics;Ethics;Shape;Companies;Regulation;Safety;Artificial intelligence;AI;AI Ethics;AI Policy;UAE;New Zealand},
  doi={10.1109/ACIT58888.2023.10453750},
  ISSN={2831-4948},
  month={Dec}
}

@BOOK{10745288,
  author={Bahree, Amit},
  booktitle={Generative AI in Action},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Generative AI can transform your business by streamlining the process of creating text, images, and code. This book will show you how to get in on the action! Generative AI in Action is the comprehensive and concrete guide to generative AI you’ve been searching for. It introduces both AI’s fundamental principles and its practical applications in an enterprise context—from generating text and images for product catalogs and marketing campaigns, to technical reporting, and even writing software. Inside, author Amit Bahree shares his experience leading Generative AI projects at Microsoft for nearly a decade, starting well before the current GPT revolution. Inside Generative AI in Action you will find:  A practical overview of of generative AI applications Architectural patterns, integration guidance, and best practices for generative AI The latest techniques like RAG, prompt engineering, and multi-modality The challenges and risks of generative AI like hallucinations and jailbreaks How to integrate generative AI into your business and IT strategy  Generative AI in Action is full of real-world use cases for generative AI, showing you where and how to start integrating this powerful technology into your products and workflows. You’ll benefit from tried-and-tested implementation advice, as well as application architectures to deploy GenAI in production at enterprise scale.},
  keywords={prompt engineering;model fine tuning;enterprise;safety;ethics;integration;RAG;multi-modality;LLMs;hallucinations;jailbreaks;architectural patterns;ChatGPT;Bard;Copilot},
  doi={},
  ISSN={},
  publisher={Manning},
  isbn={9781633436947},
  url={https://ieeexplore.ieee.org/document/10745288}
}

@ARTICLE{9454564,
  author={Liu, Qianjun and Ji, Shouling and Liu, Changchang and Wu, Chunming},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={A Practical Black-Box Attack on Source Code Authorship Identification Classifiers}, 
  year={2021},
  volume={16},
  number={},
  pages={3620-3633},
  abstract={Existing researches have recently shown that adversarial stylometry of source code can confuse source code authorship identification (SCAI) models, which may threaten the security of related applications such as programmer attribution, software forensics, etc. In this work, we propose source code authorship disguise (SCAD) to automatically hide programmers' identities from authorship identification, which is more practical than the previous work that requires to known the output probabilities or internal details of the target SCAI model. Specifically, SCAD trains a substitute model and develops a set of semantically equivalent transformations, based on which the original code is modified towards a disguised style with small manipulations in lexical features and syntactic features. When evaluated under totally black-box settings, on a real-world dataset consisting of 1,600 programmers, SCAD induces state-of-the-art SCAI models to cause above 30% misclassification rates. The efficiency and utility-preserving properties of SCAD are also demonstrated with multiple metrics. Furthermore, our work can serve as a guideline for developing more robust identification methods in the future.},
  keywords={Feature extraction;Tools;Training;Syntactics;Predictive models;Perturbation methods;Transforms;Source code;authorship identification;adversarial stylometry},
  doi={10.1109/TIFS.2021.3080507},
  ISSN={1556-6021},
  month={}
}

@ARTICLE{10771593,
  author={Huang, Ling and Huang, Xiao-Dong and Zou, Han and Gao, Yuefang and Wang, Chang-Dong and Yu, Philip S.},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Knowledge-Reinforced Cross-Domain Recommendation}, 
  year={2024},
  volume={},
  number={},
  pages={1-15},
  abstract={Over the past few years, cross-domain recommendation has gained great attention to resolve the cold-start issue. Many existing cross-domain recommendation methods model a preference bridge between the source and target domains to transfer preferences by the overlapping users. However, when there are insufficient cross-domain users available to bridge the two domains, it will negatively impact the recommender system’s accuracy (ACC) and performance. Therefore, in this article, we propose to create a link between the source and the target domains by leveraging knowledge graph (KG) as the auxiliary information, and propose a novel knowledge-reinforced cross-domain recommendation (KR-CDR) method. First of all, we construct a new cross-domain KG (CDKG) by using the KGs that represent the source and target domains, respectively. Additionally, we employ reinforcement learning (RL) with meta learning on CDKG to discover meta-paths between the source and target domains. With these meta-paths, we obtain meta-path aggregated embedding vectors for cold-start users. Ultimately, the predicted rating can be acquired from the user meta-path aggregated embedding vector and item embedding vector. Experiments carried out on five real-world datasets show that the proposed method performs better than the state-of-the-art methods.},
  keywords={Vectors;Cognition;Bridges;Metalearning;Training;Feature extraction;Reviews;Recommender systems;Matrix decomposition;Data mining;Cross-domain recommendation;knowledge graph (KG);meta learning;reinforcement learning (RL)},
  doi={10.1109/TNNLS.2024.3500096},
  ISSN={2162-2388},
  month={}
}

@INPROCEEDINGS{10215977,
  author={Tubishat, Mohammad and Al-Obeidat, Feras and Shuhaiber, Ahmed},
  booktitle={2023 International Conference on Smart Applications, Communications and Networking (SmartNets)}, 
  title={Sentiment Analysis of Using ChatGPT in Education}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={This paper presents a study on the use of the Chat Generative Pretrained Transformer (ChatGPT) in education. In this work, we propose a sentiment analysis model of tweets related to the use of the ChatGPT in education. The purpose of this research is to identify common sentiments, topics, and perspectives that are expressed towards ChatGPT in the education field based on the data collected from Twitter. Twitter was used to collect 11830 tweets about the use of ChatGPT in education. Topics and emotions expressed in the tweets were extracted using NLP algorithms and organized into distinct groups. Also, the most frequent words in the positive and negative opinion words are determined. The findings of the paper indicate that most tweets about ChatGPT are either positive or neutral, with a small percentage expressing negative sentiments. In addition, the study analyzes the sentiments expressed in tweets about the employment of ChatGPT in education using four different classifiers: Naive Bayes (NB), Support Vector Machine (SVM), K-Nearest Neighbors (KNN), and Random Forest (RF). According to the results, the SVM classifier has the highest accuracy of 81.4 percent.},
  keywords={Support vector machines;Sentiment analysis;Analytical models;Social networking (online);Education;Blogs;Employment;ChatGPT;Sentiment Analysis;Education;Twitter},
  doi={10.1109/SmartNets58706.2023.10215977},
  ISSN={},
  month={July}
}

@INPROCEEDINGS{10545393,
  author={Saha, Dipayan and Yahyaei, Katayoon and Kumar Saha, Sujan and Tehranipoor, Mark and Farahmandi, Farimah},
  booktitle={2024 IEEE International Symposium on Hardware Oriented Security and Trust (HOST)}, 
  title={Empowering Hardware Security with LLM: The Development of a Vulnerable Hardware Database}, 
  year={2024},
  volume={},
  number={},
  pages={233-243},
  abstract={The scarcity of comprehensive databases and bench-marks in hardware design specifically tailored for security tasks is a significant challenge in the community. Such databases are crucial for developing machine learning-based methods and benchmarking, providing a foundation for evaluating and improving hardware security solutions. However, manually creating these extensive datasets is impractical due to the significant time and effort required. Given the proficiency of large language models (LLM) in natural language processing, coding, and advanced reasoning tasks, using LLM as an artificial intelligence (AI) agent presents a viable option to efficiently create such extensive datasets. In this light, this paper introduces Vul-FSM, a database of 10,000 vulnerable finite state machine (FSM) designs incorporating 16 distinct security weaknesses and vulnerabilities generated using the proposed SecRT-Llmframework. The framework combines the in-context learning capability of LLM, the guidance of developed prompting strategies, and the scrutiny of fidelity-check to not only insert but also detect hardware vulnerabilities and weaknesses. To demonstrate the efficacy of SecRT-LLM, we present an exhaustive analysis, highlighting the proficiency of GPT models in vulnerability insertion, detection, and mitigation. Our proposed SecRT-LLM framework, using gpt-3.5-turbo, demonstrates strong effectiveness, achieving macroaverage pass rates of 81.98% and 80.30% on the first attempt and 97.37% and 99.07% within five attempts for vulnerability insertion and detection, respectively.},
  keywords={Learning systems;Analytical models;Databases;Hardware security;Instruments;Linguistics;Cognition;Large Language Model;ChatGPT;RTL design;Hardware Security;Vulnerability Analysis;Common Weakness Enumeration (CWE)},
  doi={10.1109/HOST55342.2024.10545393},
  ISSN={2765-8406},
  month={May}
}

@ARTICLE{10681094,
  author={Ahmed, Zishan and Shanto, Shakib Sadat and Rime, Most. Humayra Khanom and Morol, Md. Kishor and Fahad, Nafiz and Hossen, Md. Jakir and Abdullah-Al-Jubair, Md.},
  journal={IEEE Access}, 
  title={The Generative AI Landscape in Education: Mapping the Terrain of Opportunities, Challenges, and Student Perception}, 
  year={2024},
  volume={12},
  number={},
  pages={147023-147050},
  abstract={Generative AI (GAI) technologies like ChatGPT are permanently changing academic education. Their integration opens up vast opportunities for bespoke learning and better student interaction but also brings about academic honesty issues and the application of real-life educators. This study aims to fill the literature gap regarding the use of multiple GAI tools and their effect on academic outcomes via a comprehensive review. A systematic literature review was performed following PRISMA guidelines to synthesize results on the potential and drawbacks of GAI in educational domains. We included theoretical and empirical papers that used qualitative, quantitative, or mixed-methods study designs. We have also explored conceptual frameworks and the most creative AI applications with a special emphasis on uniqueness and practicability. Experiences, and Perceptions Concerning To compile the information needed we gathered insights into what students were going through by conducting the survey which contains 200 respondents of undergraduate university students gathering insights into the college students’ experiences and perceptions related to GAI used for educational purposes. At the basic level, GAI comprises areas like personalization, task automation, teacher assistance, and efficiency among others, and respective solutions for the immersion of a learner in learning processes to reform directions. However, it generates plenty of challenges such as the question of assessment integrity, the risk that too much automated grading could overwhelm educational value, and relevantly the veracity of AI-generated content as well as the potential disruption to skills like critical thinking, in addition to data privacy and ethical issues. Student Perception Survey the text also indicates that most students, as per the student perception survey found AI systems useful in academic support. However, they also know the other side of the coin and are very familiar with the technology constraints and challenges.},
  keywords={Education;Generative AI;Artificial intelligence;Surveys;Chatbots;Ethics;Market research;Chatbots;education;generative AI;opportunities and challenges;student perception},
  doi={10.1109/ACCESS.2024.3461874},
  ISSN={2169-3536},
  month={}
}

@ARTICLE{10506327,
  author={Ahn, Sungjun and Yim, Hyun-Jeong and Lee, Youngwan and Park, Sung-Ik},
  journal={IEEE Transactions on Broadcasting}, 
  title={Dynamic and Super-Personalized Media Ecosystem Driven by Generative AI: Unpredictable Plays Never Repeating the Same}, 
  year={2024},
  volume={70},
  number={3},
  pages={980-994},
  abstract={This paper introduces a media service model that exploits artificial intelligence (AI) video generators at the receive end. This proposal deviates from the traditional multimedia ecosystem, completely relying on in-house production, by shifting part of the content creation onto the receiver. We bring a semantic process into the framework, allowing the distribution network to provide service elements that prompt the content generator rather than distributing encoded data of fully finished programs. The service elements include fine-tailored text descriptions, lightweight image data of some objects, or application programming interfaces, comprehensively referred to as semantic sources, and the user terminal translates the received semantic data into video frames. Empowered by the random nature of generative AI, users can experience super-personalized services accordingly. The proposed idea incorporates situations in which the user receives different service providers’ element packages, either in a sequence over time or multiple packages at the same time. Given promised in-context coherence and content integrity, the combinatory dynamics will amplify the service diversity, allowing the users to always chance upon new experiences. This work particularly aims at short-form videos and advertisements, which the users would easily feel fatigued by seeing the same frame sequence every time. In those use cases, the content provider’s role will be recast as scripting semantic sources, transformed from a thorough producer. Overall, this work explores a new form of media ecosystem facilitated by receiver-embedded generative models, featuring both random content dynamics and enhanced delivery efficiency simultaneously.},
  keywords={Media;Semantics;Artificial intelligence;Production;Ecosystems;Task analysis;Streaming media;Generative AI;semantic communications;6G multimedia casting;on-device AI},
  doi={10.1109/TBC.2024.3380474},
  ISSN={1557-9611},
  month={Sep.}
}

@ARTICLE{10879568,
  author={Zhang, Junzhe and Chen, Tong and You, Kang and Ding, Dandan and Ma, Zhan},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={ConPCAC: Conditional Lossless Point Cloud Attribute Compression via Spatial Decomposition}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={A conditional lossless point cloud attribute compression method, dubbed ConPCAC, is proposed. The previous work typically codes point attributes in a point cloud in an autoregressive way, incurring unbearable coding time. By contrast, ConPCAC proposes a group-wise conditional entropy model for fast coding while preserving coding performance. Specifically, ConPCAC adopts a “Group Decomposition - Attribute Initialization - Latent Distribution Prediction” framework. First, it flexibly decomposes the original point cloud into multiple groups according to the geometry coordinate distribution. Then, the first group is coded using a base coder, e.g., the standardized G-PCC, and the following groups are progressively coded using a neural coder conditioned on their preceding groups. Two key units, Attribute Initialization (Init) and Latent Distribution Prediction (LDP), are devised in the neural coder. The Init unit employs the nearest neighbor to initialize the attributes of a group, and the LDP unit further predicts the attribute probability distribution for the group. In this way, ConPCAC enables full correlation exploration across groups and parallel processing among points in a group. Finally, the predicted probabilities are fed into the arithmetic engine to code the true attribute values of each group. Extensive experiments demonstrate the performance of Con-PCAC. It achieves 14.59%, 10.32%, and 12.26% improvements over the latest G-PCC on the widely used 8iVFB, Owlii, and MVUB datasets, respectively, significantly outperforming state-of- the-art lossless PCAC methods. Moreover, its computational complexity is comparable to G-PCC and much lower than existing learning-based methods. Associated code and models will be released on the website https://github.com/3dpcc/ConPCAC.},
  keywords={Point cloud compression;Encoding;Geometry;Transforms;Entropy;Decoding;Three-dimensional displays;Image color analysis;Correlation;Codes;Point cloud;attribute compression;lossless coding;probability prediction},
  doi={10.1109/TCSVT.2025.3540931},
  ISSN={1558-2205},
  month={}
}

@BOOK{10948557,
  author={Mukherjee, Amit and Saladi, Adithya and Casalaina, Marco},
  booktitle={Azure OpenAI Essentials: A practical guide to unlocking generative AI-powered innovation with Azure OpenAI},
  year={2025},
  volume={},
  number={},
  pages={},
  abstract={Build innovative, scalable, and ethical AI solutions by harnessing the full potential of generative AI with this exhaustive guideKey FeaturesExplore the capabilities of Azure OpenAI’s LLMsCraft end-to-end applications by utilizing the synergy of Azure OpenAI and Cognitive ServicesDesign enterprise-grade GenAI solutions with effective prompt engineering, fine-tuning, and AI safety measuresPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionFind out what makes Azure OpenAI a robust platform for building AI-driven solutions that can transform how businesses operate. Written by seasoned experts from Microsoft, this book will guide you in understanding Azure OpenAI from fundamentals through to advanced concepts and best practices. The book begins with an introduction to large language models (LLMs) and the Azure OpenAI Service, detailing how to access, use, and optimize its models. You'll learn how to design and implement AI-driven solutions, such as question-answering systems, contact center analytics, and GPT-powered search applications. Additionally, the chapters walk you through advanced concepts, including embeddings, fine-tuning models, prompt engineering, and building custom AI applications using LangChain and Semantic Kernel. You'll explore real-world use cases such as QnA systems, document summarizers, and SQLGPT for database querying, as well as gain insights into securing and operationalizing these solutions in enterprises. By the end of this book, you'll be ready to design, develop, and deploy scalable AI solutions, ensuring business success through intelligent automation and data-driven insights.What you will learnUnderstand the concept of large language models and their capabilitiesInteract with different models in Azure OpenAI using APIs or web interfacesUse content filters and mitigations to prevent harmful content generationDevelop solutions with Azure OpenAI for content generation, summarization, semantic search, NLU, code and image generation and analysisIntegrate Azure OpenAI with other Azure Cognitive services for enhanced functionalityApply best practices for data privacy, security, and prompt engineering with Azure OpenAIWho this book is forThis book is for software developers, data scientists, AI engineers, ML engineers, system architects, LLM engineers, IT professionals, product managers, and business professionals who want to learn how to use Azure OpenAI to create innovative solutions with generative AI. To fully benefit from this book, you must have both an Azure subscription and Azure OpenAI access, along with knowledge of Python.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781805122654},
  url={https://ieeexplore.ieee.org/document/10948557}
}

@ARTICLE{10938391,
  author={Yuan, Zihan and Li, Li and Wang, Zichi and Jiang, Jingyuan and Zhang, Xinpeng},
  journal={IEEE Signal Processing Letters}, 
  title={Watermark removal attack against text-to-image generative model watermarking}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={The artist's style can be quickly imitated by fine-tuning a text-to-image model using artist's artworks, which raises serious copyright concerns. Scholars have proposed many watermarking methods to protect the artists' copyright. To evaluate the security and enhance the performance of existing watermarking, this paper proposes a watermark removal attack for text-to-image generative model watermarking for the first time. This attack aims to invalidate watermarking designed to detect art theft mimicry in text-to-image models. In this method, a watermark recognition network and a watermark removal network are designed. The watermark recognition network identifies whether an artwork contains watermark, and the watermark removal network is used to remove it. Consequently, text-to-image models fine-tuned with watermark-removed artworks can reproduce an artist's style while evading watermark detection. This makes the copyright authentication of artworks ineffective. Experiments show that the proposed attack can effectively remove watermarks, with watermark extraction accuracy dropping below 48.64%. Additionally, the images after watermark removal retain high similarity to the original images, with PSNR exceeding 27.96 and SSIM exceeding 0.92.},
  keywords={Watermarking;Text to image;Accuracy;Image recognition;Training;Data mining;Discrete wavelet transforms;Neural networks;Diffusion models;Tuning;Watermark removal attack;Text-to-image model;Model watermarking;Deep Learning},
  doi={10.1109/LSP.2025.3554514},
  ISSN={1558-2361},
  month={}
}

@ARTICLE{10896764,
  author={Yin, Bo and Yin, Kang},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Robust Image Watermarking Using Bidirection-Interactive and Context-Aware Networks}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Individuals can easily generate highly realistic images using artificial intelligence-generated content technologies, which complicates the verification of images’ ownership rights. This raises potential issues such as spreading misinformation, fraud, and copyright infringement. Digital watermarking is a promising solution to protect the copyright of a digital image by embedding watermarks within it. However, many existing deep learning-based watermarking approaches struggle to simultaneously resist multiple attacks effectively and maintain the quality of watermark images. In this paper, we propose a bidirectional-interactive and context-aware (BICA) deep network designed to enhance the robustness of the watermark while maintaining the quality of the encoded image. We propose a new attention module in the encoder to improve the invisibility and robustness of the watermarked images by implementing an adaptive two-way interaction between local and global features. Additionally, we employ fine-grained downsampling to enhance the attention module’s ability to capture comprehensive feature information. Extensive experimental results demonstrate that the BICA network can embed watermark information into an image without compromising image quality. For instance, BICA has an accuracy exceeding 95% against various moderate noise attacks, with average PSNR and SSIM values of 40.4021 dB and 0.9943, respectively.},
  keywords={Watermarking;Robustness;Transforms;Noise;Training;Accuracy;Feature extraction;Transform coding;Image coding;Discrete cosine transforms;Image watermarking;deep learning;digital watermarking;noise attacks},
  doi={10.1109/TCSVT.2025.3543969},
  ISSN={1558-2205},
  month={}
}

@BOOK{10769317,
  author={Suda, Vijaya Kumar},
  booktitle={Data Labeling in Machine Learning with Python: Explore modern ways to prepare labeled data for training and fine-tuning ML and generative AI models},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Take your data preparation, machine learning, and GenAI skills to the next level by learning a range of Python algorithms and tools for data labelingKey FeaturesGenerate labels for regression in scenarios with limited training dataApply generative AI and large language models (LLMs) to explore and label text dataLeverage Python libraries for image, video, and audio data analysis and data labelingPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionData labeling is the invisible hand that guides the power of artificial intelligence and machine learning. In today’s data-driven world, mastering data labeling is not just an advantage, it’s a necessity. Data Labeling in Machine Learning with Python empowers you to unearth value from raw data, create intelligent systems, and influence the course of technological evolution. With this book, you'll discover the art of employing summary statistics, weak supervision, programmatic rules, and heuristics to assign labels to unlabeled training data programmatically. As you progress, you'll be able to enhance your datasets by mastering the intricacies of semi-supervised learning and data augmentation. Venturing further into the data landscape, you'll immerse yourself in the annotation of image, video, and audio data, harnessing the power of Python libraries such as seaborn, matplotlib, cv2, librosa, openai, and langchain. With hands-on guidance and practical examples, you'll gain proficiency in annotating diverse data types effectively. By the end of this book, you’ll have the practical expertise to programmatically label diverse data types and enhance datasets, unlocking the full potential of your data.What you will learnExcel in exploratory data analysis (EDA) for tabular, text, audio, video, and image dataUnderstand how to use Python libraries to apply rules to label raw dataDiscover data augmentation techniques for adding classification labelsLeverage K-means clustering to classify unsupervised dataExplore how hybrid supervised learning is applied to add labels for classificationMaster text data classification with generative AIDetect objects and classify images with OpenCV and YOLOUncover a range of techniques and resources for data annotationWho this book is forThis book is for machine learning engineers, data scientists, and data engineers who want to learn data labeling methods and algorithms for model training. Data enthusiasts and Python developers will be able to use this book to learn data exploration and annotation using Python libraries. Basic Python knowledge is beneficial but not necessary to get started.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781804613788},
  url={https://ieeexplore.ieee.org/document/10769317}
}

@BOOK{10769248,
  author={Kavanagh, Kieran and Vergadia, Priyanka},
  booktitle={Google Machine Learning and Generative AI for Solutions Architects: ​Build efficient and scalable AI/ML solutions on Google Cloud},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Architect and run real-world AI/ML solutions at scale on Google Cloud, and discover best practices to address common industry challenges effectivelyKey FeaturesUnderstand key concepts, from fundamentals through to complex topics, via a methodical approachBuild real-world end-to-end MLOps solutions and generative AI applications on Google CloudGet your hands on a code repository with over 20 hands-on projects for all stages of the ML model development lifecyclePurchase of the print or Kindle book includes a free PDF eBookBook DescriptionMost companies today are incorporating AI/ML into their businesses. Building and running apps utilizing AI/ML effectively is tough. This book, authored by a principal architect with about two decades of industry experience, who has led cross-functional teams to design, plan, implement, and govern enterprise cloud strategies, shows you exactly how to design and run AI/ML workloads successfully using years of experience from some of the world’s leading tech companies. You’ll get a clear understanding of essential fundamental AI/ML concepts, before moving on to complex topics with the help of examples and hands-on activities. This will help you explore advanced, cutting-edge AI/ML applications that address real-world use cases in today’s market. You’ll recognize the common challenges that companies face when implementing AI/ML workloads, and discover industry-proven best practices to overcome these. The chapters also teach you about the vast AI/ML landscape on Google Cloud and how to implement all the steps needed in a typical AI/ML project. You’ll use services such as BigQuery to prepare data; Vertex AI to train, deploy, monitor, and scale models in production; as well as MLOps to automate the entire process. By the end of this book, you will be able to unlock the full potential of Google Cloud's AI/ML offerings.What you will learnBuild solutions with open-source offerings on Google Cloud, such as TensorFlow, PyTorch, and SparkSource, understand, and prepare data for ML workloadsBuild, train, and deploy ML models on Google CloudCreate an effective MLOps strategy and implement MLOps workloads on Google CloudDiscover common challenges in typical AI/ML projects and get solutions from expertsExplore vector databases and their importance in Generative AI applicationsUncover new Gen AI patterns such as Retrieval Augmented Generation (RAG), agents, and agentic workflowsWho this book is forThis book is for aspiring solutions architects looking to design and implement AI/ML solutions on Google Cloud. Although this book is suitable for both beginners and experienced practitioners, basic knowledge of Python and ML concepts is required. The book focuses on how AI/ML is used in the real world on Google Cloud. It briefly covers the basics at the beginning to establish a baseline for you, but it does not go into depth on the underlying mathematical concepts that are readily available in academic material.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781803247021},
  url={https://ieeexplore.ieee.org/document/10769248}
}

@ARTICLE{10500411,
  author={Yenduri, Gokul and Ramalingam, M. and Selvi, G. Chemmalar and Supriya, Y. and Srivastava, Gautam and Maddikunta, Praveen Kumar Reddy and Raj, G. Deepti and Jhaveri, Rutvij H. and Prabadevi, B. and Wang, Weizheng and Vasilakos, Athanasios V. and Gadekallu, Thippa Reddy},
  journal={IEEE Access}, 
  title={GPT (Generative Pre-Trained Transformer)— A Comprehensive Review on Enabling Technologies, Potential Applications, Emerging Challenges, and Future Directions}, 
  year={2024},
  volume={12},
  number={},
  pages={54608-54649},
  abstract={The Generative Pre-trained Transformer (GPT) represents a notable breakthrough in the domain of natural language processing, which is propelling us toward the development of machines that can understand and communicate using language in a manner that closely resembles that of humans. GPT is based on the transformer architecture, a deep neural network designed for natural language processing tasks. Due to their impressive performance on natural language processing tasks and ability to effectively converse, GPT have gained significant popularity among researchers and industrial communities, making them one of the most widely used and effective models in natural language processing and related fields, which motivated to conduct this review. This review provides a detailed overview of the GPT, including its architecture, working process, training procedures, enabling technologies, and its impact on various applications. In this review, we also explored the potential challenges and limitations of a GPT. Furthermore, we discuss potential solutions and future directions. Overall, this paper aims to provide a comprehensive understanding of GPT, its enabling technologies, their impact on various applications, emerging challenges, and potential solutions.},
  keywords={Natural language processing;Solid modeling;Artificial intelligence;Surveys;Task analysis;Reviews;Transformers;Generative pre-trained transformer;natural language processing;artificial intelligence},
  doi={10.1109/ACCESS.2024.3389497},
  ISSN={2169-3536},
  month={}
}

@ARTICLE{10176168,
  author={Ebert, Christof and Louridas, Panos},
  journal={IEEE Software}, 
  title={Generative AI for Software Practitioners}, 
  year={2023},
  volume={40},
  number={4},
  pages={30-38},
  abstract={Generative artificial intelligence (AI) tools, such as Bard, ChatGPT, and CoPilot, have rapidly gained widespread usage. They also have the potential to boost software engineering productivity. In this article, we elaborate technologies and usage of generative AI in the software industry. We address questions, such as: How does generative AI improve software productivity? How to connect generative AI to software development, and what are the risks? Which technologies have what sorts of benefits? Practitioner guidance and case studies are shared from our industry context. I look forward to hearing from you about this column and the technologies that matter most for your work.—Christof Ebert},
  keywords={Productivity;Industries;Auditory system;Chatbots;Software engineering;Artificial intelligence;Artificial intelligence;Chatbots;Risk management},
  doi={10.1109/MS.2023.3265877},
  ISSN={1937-4194},
  month={July}
}

@ARTICLE{10147844,
  author={Cheng, Hang and Li, Xibin and Wang, Huaxiong and Zhang, Xinpeng and Liu, Ximeng and Wang, Meiqing and Li, Fengyong},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={DeepDIST: A Black-Box Anti-Collusion Framework for Secure Distribution of Deep Models}, 
  year={2024},
  volume={34},
  number={1},
  pages={97-109},
  abstract={Due to enormous computing and storage overhead for well-trained Deep Neural Network (DNN) models, protecting the intellectual property of model owners is a pressing need. As the commercialization of deep models is becoming increasingly popular, the pre-trained models delivered to users may suffer from being illegally copied, redistributed, or abused. In this paper, we propose DeepDIST, the first end-to-end secure DNNs distribution framework in a black-box scenario. Specifically, our framework adopts a dual-level fingerprint (FP) mechanism to provide reliable ownership verification, and proposes two equivalent transformations that can resist collusion attacks, plus a newly designed similarity loss term to improve the security of the transformations. Unlike the existing passive defense schemes that detect colluding participants, we introduce an active defense strategy, namely damaging the performance of the model after the malicious collusion. The extensive experimental results show that DeepDIST can maintain the accuracy of the host DNN after embedding fingerprint conducted for true traitor tracing, and is robust against several popular model modifications. Furthermore, the anti-collusion effect is evaluated on two typical classification tasks (10-class and 100-class), and the proposed DeepDIST can drop the prediction accuracy of the collusion model to 10% and 1% (random guess), respectively.},
  keywords={Watermarking;Neural networks;Computational modeling;Closed box;Predictive models;Integrated circuit modeling;Glass box;Deep neural networks;anti-collusion;digital watermarking;digital fingerprinting},
  doi={10.1109/TCSVT.2023.3284914},
  ISSN={1558-2205},
  month={Jan}
}

@ARTICLE{10843334,
  author={Chaudhuri, Jayeeta and Thapar, Dhruv and Chaudhuri, Arjun and Firouzi, Farshad and Chakrabarty, Krishnendu},
  journal={IEEE Transactions on Very Large Scale Integration (VLSI) Systems}, 
  title={SPICED+: Syntactical Bug Pattern Identification and Correction of Trojans in A/MS Circuits Using LLM-Enhanced Detection}, 
  year={2025},
  volume={33},
  number={4},
  pages={1118-1131},
  abstract={Analog and mixed-signal (A/MS) integrated circuits (ICs) are crucial in modern electronics, playing key roles in signal processing, amplification, sensing, and power management. Many IC companies outsource manufacturing to third-party foundries, creating security risks such as syntactical bugs and stealthy analog Trojans. Traditional Trojan detection methods, including embedding circuit watermarks and hardware-based monitoring, impose significant area and power overheads while failing to effectively identify and localize the Trojans. To overcome these shortcomings, we present SPICED+, a software-based framework designed for syntactical bug pattern identification and the correction of Trojans in A/MS circuits, leveraging large language model (LLM)-enhanced detection. It uses LLM-aided techniques to detect, localize, and iteratively correct analog Trojans in SPICE netlists, without requiring explicit model training, and thus incurs zero area overhead. The framework leverages chain-of-thought reasoning and few-shot learning to guide the LLMs in understanding and applying anomaly detection rules, enabling accurate identification and correction of Trojan-impacted nodes. With the proposed method, we achieve an average Trojan coverage of 93.3%, average Trojan correction rate of 91.2%, and an average false-positive rate of 1.4%.},
  keywords={Trojan horses;Circuits;Computer bugs;SPICE;Codes;Prevention and mitigation;Hardware design languages;Syntactics;Fabrication;Watermarking;Anomaly detection;hardware security;large language models (LLMs);SPICE;Trojan horse},
  doi={10.1109/TVLSI.2025.3527382},
  ISSN={1557-9999},
  month={April}
}

@INPROCEEDINGS{8453131,
  author={Upadhyaya, Ganesha and Rajan, Hridesh},
  booktitle={2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)}, 
  title={Collective Program Analysis}, 
  year={2018},
  volume={},
  number={},
  pages={620-631},
  abstract={Popularity of data-driven software engineering has led to an increasing demand on the infrastructures to support efficient execution of tasks that require deeper source code analysis. While task optimization and parallelization are the adopted solutions, other research directions are less explored. We present collective program analysis (CPA), a technique for scaling large scale source code analyses, especially those that make use of control and data flow analysis, by leveraging analysis specific similarity. Analysis specific similarity is about, whether two or more programs can be considered similar for a given analysis. The key idea of collective program analysis is to cluster programs based on analysis specific similarity, such that running the analysis on one candidate in each cluster is sufficient to produce the result for others. For determining analysis specific similarity and clustering analysis-equivalent programs, we use a sparse representation and a canonical labeling scheme. Our evaluation shows that for a variety of source code analyses on a large dataset of programs, substantial reduction in the analysis time can be achieved; on average a 69% reduction when compared to a baseline and on average a 36% reduction when compared to a prior technique. We also found that a large amount of analysis-equivalent programs exists in large datasets.},
  keywords={Transfer functions;Cloning;Software engineering;Task analysis;Syntactics;Analytical models;Labeling;Source code analysis;Clustering;Boa},
  doi={10.1145/3180155.3180252},
  ISSN={1558-1225},
  month={May}
}

@INPROCEEDINGS{10516655,
  author={Li, Zhangheng and Hong, Junyuan and Li, Bo and Wang, Zhangyang},
  booktitle={2024 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML)}, 
  title={Shake to Leak: Fine-tuning Diffusion Models Can Amplify the Generative Privacy Risk}, 
  year={2024},
  volume={},
  number={},
  pages={18-32},
  abstract={While diffusion models have recently demonstrated remarkable progress in generating realistic images, privacy risks also arise: published models or APIs could generate training images and thus leak privacy-sensitive training information. In this paper, we reveal a new risk, Shake-to-Leak (S2L), that fine-tuning the pre-trained models with manipulated data can amplify the existing privacy risks. We demonstrate that S2L could occur in various standard fine-tuning strategies for diffusion models, including concept-injection methods (DreamBooth and Textual Inversion) and parameter-efficient methods (LoRA and Hypernetwork), as well as their combinations. In the worst case, S2L can amplify the state-of-the-art membership inference attack (MIA) on diffusion models by 5.4% (absolute difference) AUC and can increase extracted private samples from almost 0 samples to 16.3 samples on average per target domain. This discovery underscores that the privacy risk with diffusion models is even more severe than previously recognized. Codes are available at https://github.com/VITA-Group/Shake-to-Leak.},
  keywords={Training;Privacy;Differential privacy;Systematics;Codes;Image synthesis;Oral communication;Deep learning;generative models;diffusion models;privacy risk;fine-tuning},
  doi={10.1109/SaTML59370.2024.00010},
  ISSN={},
  month={April}
}

@ARTICLE{10261269,
  author={Akbar, Muhammad Azeem and Khan, Arif Ali and Liang, Peng},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Ethical Aspects of ChatGPT in Software Engineering Research}, 
  year={2025},
  volume={6},
  number={2},
  pages={254-267},
  abstract={ChatGPT can improve software engineering (SE) research practices by offering efficient, accessible information analysis, and synthesis based on natural language interactions. However, ChatGPT could bring ethical challenges, encompassing plagiarism, privacy, data security, and the risk of generating biased or potentially detrimental data. This research aims to fill the given gap by elaborating on the key elements: motivators, demotivators, and ethical principles of using ChatGPT in SE research. To achieve this objective, we conducted a literature survey, identified the mentioned elements, and presented their relationships by developing a taxonomy. Furthermore, the identified literature-based elements (motivators, demotivators, and ethical principles) were empirically evaluated by conducting a comprehensive questionnaire-based survey involving SE researchers. In addition, we employed an interpretive structure modeling approach to analyze the relationships between the ethical principles of using ChatGPT in SE research and develop a level-based decision model. We further conducted a cross-impact matrix multiplication applied to classification analysis to create a cluster-based decision model. These models aim to help SE researchers devise effective strategies for ethically integrating ChatGPT into SE research by following the identified principles by adopting the motivators and addressing the demotivators. The findings of this study will establish a benchmark for incorporating ChatGPT services in SE research with an emphasis on ethical considerations.},
  keywords={Chatbots;Surveys;Ethics;Software engineering;Data models;Artificial intelligence;Sociology;ChatGPT;demotivators;ethical principles;motivators;software engineering (SE)},
  doi={10.1109/TAI.2023.3318183},
  ISSN={2691-4581},
  month={Feb}
}

@INPROCEEDINGS{9213037,
  author={Li, Qinya and Zheng, Zhenzhe and Wu, Fan and Chen, Guihai},
  booktitle={2020 IEEE/ACM 28th International Symposium on Quality of Service (IWQoS)}, 
  title={Generative Adversarial Networks-based Privacy-Preserving 3D Reconstruction}, 
  year={2020},
  volume={},
  number={},
  pages={1-10},
  abstract={A large-scale image collection is crucial to the success of 3D reconstruction. Crowdsourcing, as a new pattern, can be utilized to collect high-quality images in an efficient way. However, the sensitive information in images may be exposed during the image transmission process. The general privacy policies perhaps will cause the loss or change of critical information, which may give rise to a decline in the performance of 3D reconstruction. Hence, how to achieve image privacy-preserving while guaranteeing to reconstruct a complete 3D model is important and significant. In this paper, we propose PicPrivacy to address this problem, which consists of three parts. (1) Using a pre-trained deep convolution neural network to segment sensitive information and erase it from images. (2) Using a GAN-based image feature completion algorithm to repair blank regions and minimize the absolute information gap between generated images and raw ones. (3) Taking generated images as the input of 3D reconstruction and using a structure-from-motion algorithm to reconstruct 3D models. Finally, we extensively evaluate the performance of PicPrivacy on realworld datasets. The results demonstrate that PicPrivacy not only achieves individual privacy-preserving but also can guarantee to create complete 3D models.},
  keywords={Three-dimensional displays;Privacy;Image segmentation;Solid modeling;Image reconstruction;Crowdsourcing;Convolution;3D reconstruction;Privacy-preserving;Generative adversarial networks;Crowdsourcing},
  doi={10.1109/IWQoS49365.2020.9213037},
  ISSN={1548-615X},
  month={June}
}

@ARTICLE{10897565,
  author={Xue, Yuan and Guo, Yuan-Chen and Zhang, Han and Xu, Tao and Zhang, Song-Hai and Huang, Xiaolei},
  journal={Computational Visual Media}, 
  title={Deep image synthesis from intuitive user input: A review and perspectives}, 
  year={2022},
  volume={8},
  number={1},
  pages={3-31},
  abstract={In many applications of computer graphics, art, and design, it is desirable for a user to provide intuitive non-image input, such as text, sketch, stroke, graph, or layout, and have a computer system automatically generate photo-realistic images according to that input. While classically, works that allow such automatic image content generation have followed a framework of image retrieval and composition, recent advances in deep generative models such as generative adversarial networks (GANs), variational autoencoders (VAEs), and flow-based methods have enabled more powerful and versatile image generation approaches. This paper reviews recent works for image synthesis given intuitive user input, covering advances in input versatility, image generation methodology, benchmark datasets, and evaluation metrics. This motivates new perspectives on input representation and interactivity, cross fertilization between major image generation paradigms, and evaluation and comparison of generation methods.},
  keywords={Image synthesis;Measurement;Reviews;Semantics;Feature extraction;Visualization;Vectors;Noise;Electronic mail;Computational modeling;image synthesis;intuitive user input;deep generative models;synthesized image quality evaluation},
  doi={10.1007/s41095-021-0234-8},
  ISSN={2096-0662},
  month={March}
}

@INPROCEEDINGS{10945231,
  author={Yang, Dong and Li, Weihai and Xu, Zikai and Zhang, Zhiling and Chen, Yiling},
  booktitle={2024 IEEE 23rd International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)}, 
  title={FCADD: Robust Watermarking Resisting JPEG Compression with Frequency Channel Attention and Distortion De-gradient}, 
  year={2024},
  volume={},
  number={},
  pages={1817-1824},
  abstract={Recently, the majority of deep learning-based robust watermarking techniques exhibit proficiency in concealing secret information, thereby providing effective protection for the copyright information of images. However, during the digital transmission process, images typically undergo JPEG compression, which significantly compromises the integrity of the watermarks. We found that most current methodologies are inadequately equipped to mitigate the adverse impacts of JPEG compression. In this work, we proposed a robust watermarking method against JPEG compression by applying Frequency Channel Attention and Distortion De-gradient mechanism (FCADD). Specifically, we introduce a only forward propagation mechanism in the attack simulation layer that bypasses the difference caused by image processing, such as compression, dropout, during transmission, allowing a portion of the loss function’s gradient to be passed back to the encoder. Additionally, for the sake of model stability and generalizability, we assign a certain probability to both the JPEG simulation function and a lossless function in different training batches to participate in the training process. Furthermore, we introduce Frequency Channel Attention Blocks (FCA Block) in the feature extraction process, leveraging the information on the image frequency domain to achieve better visual effects. Extensive experiments have demonstrated that our approach outperforms the current state-of-the-art (SOTA) models in JPEG compression across any quality factor, and also exhibits superior visual effects and robustness against other distortions such as Gaussian filtering and Dropout.},
  keywords={Training;Q-factor;Image coding;Frequency-domain analysis;Transform coding;Watermarking;Distortion;Visual effects;Robustness;Stability analysis;robust watermarking;frequency channel attention;JPEG compression;none-differentiable},
  doi={10.1109/TrustCom63139.2024.00250},
  ISSN={2324-9013},
  month={Dec}
}

@INPROCEEDINGS{10806963,
  author={Liu, Yanxiao and Li, Cheuk Ting},
  booktitle={2024 IEEE Information Theory Workshop (ITW)}, 
  title={One-Shot Information Hiding}, 
  year={2024},
  volume={},
  number={},
  pages={169-174},
  abstract={We present a one-shot information-theoretic analysis of the information hiding problem, which has a wide range of applications including watermarking, fingerprinting, steganogra-phy and copyright protection. The problem can be viewed as a game: one party includes an information hider and a decoder, where the former embeds a message into a host data source and introduces some tolerable distortion, and the latter wishes to reconstruct the message; another party is an attacker that is modeled as a noisy channel which aims at removing the hidden information. We derive a one-shot achievability result using the Poisson matching lemma. Unlike previous asymptotic results, our result applies to any distribution of the host data, and any class of attack channels (not necessarily memoryless or ergodic).},
  keywords={Soft sensors;Conferences;Watermarking;Games;Fingerprint recognition;Copyright protection;Distortion;Data models;Decoding;Noise measurement;Information hiding;one-shot achievability;finite blocklength;network information theory;watermarking},
  doi={10.1109/ITW61385.2024.10806963},
  ISSN={2475-4218},
  month={Nov}
}

@INPROCEEDINGS{9394151,
  author={Sakhovskiy, Andrey and Solovyev, Valery and Solnyshkina, Marina},
  booktitle={2020 Ivannikov Ispras Open Conference (ISPRAS)}, 
  title={Topic Modeling for Assessment of Text Complexity in Russian Textbooks}, 
  year={2020},
  volume={},
  number={},
  pages={102-108},
  abstract={This article explores the problem of assessing the complexity of Russian educational texts. We present a quantitative and qualitative investigation of topics in the textbooks of different grades by applying several topic models. The corpus compiled for the current study comprises a collection of textbooks used in middle and high schools of the Russian Federation. The corpus consists of two sets of texts derived from textbooks on Social science by L.N. Bogolyubov and A.F. Nikitin. For our analysis, we employ Latent Dirichlet Allocation (LDA) and Additive regularization of topic models (ARTM). In this paper, we use the grades of educational texts as indicators of text complexity. To identify quantitative measures of text complexity, we analyze the correlation of book grades with topic properties. We also analyze a correlation of a topic's properties with the growth of its proportion in a book of a specific complexity level. The key finding of our research is the identification of statistically significant correlations of educational texts complexity with the revealed topic features, i.e., topic coherence and distance between topic words in a semantic space. This study can be beneficial for two communities: textbook writers and their consumers, i.e., teachers and schoolchildren.},
  keywords={Analytical models;Correlation;Social sciences;Semantics;Coherence;Complexity theory;Resource management;Textbooks;Social science;Text complexity;Topic modeling;Latent Dirichlet Allocation;Spearman's correlation},
  doi={10.1109/ISPRAS51486.2020.00022},
  ISSN={},
  month={Dec}
}

@INPROCEEDINGS{10835426,
  author={Patwardhan, Aditya and Vaidya, Vivek and Kundu, Ashish},
  booktitle={2024 IEEE 6th International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications (TPS-ISA)}, 
  title={Automated Consistency Analysis of LLMs}, 
  year={2024},
  volume={},
  number={},
  pages={118-127},
  abstract={Generative AI (Gen AI) with large language models (LLMs) are being widely adopted across the industry, academia and government. Cybersecurity is one of the key sectors where LLMs can be and/or are already being used. There are a number of problems that inhibit the adoption of trustworthy Gen AI and LLMs in cybersecurity and such other critical areas. One of the key challenge to the trustworthiness and reliability of LLMs is: how consistent an LLM is in its responses?In this paper, we have analyzed and developed a formal definition of consistency of responses of LLMs. We have formally defined what is consistency of responses and then develop a framework for consistency evaluation. The paper proposes two approaches to validate consistency: self-validation, and validation across multiple LLMs. We have carried out extensive experiments for several LLMs such as GPT4oMini, GPT3.5, Gemini, Cohere, and Llama3, on a security benchmark consisting of several cybersecurity questions: informational and situational. Our experiments corroborate the fact that even though these LLMs are being considered and/or already being used for several cybersecurity tasks today, they are often inconsistent in their responses, and thus are untrustworthy and unreliable for cybersecurity.},
  keywords={Industries;Privacy;Analytical models;Generative AI;Large language models;Government;Benchmark testing;Reliability;Intelligent systems;Computer crime;Cybersecurity;Generative AI;Large Language Models;Agents;Consistency;Trustworthiness;Validity;Reliability;Hallucination},
  doi={10.1109/TPS-ISA62245.2024.00023},
  ISSN={},
  month={Oct}
}

@INPROCEEDINGS{9710737,
  author={Girish, Sharath and Suri, Saksham and Rambhatla, Saketh and Shrivastava, Abhinav},
  booktitle={2021 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Towards Discovery and Attribution of Open-world GAN Generated Images}, 
  year={2021},
  volume={},
  number={},
  pages={14074-14083},
  abstract={With the recent progress in Generative Adversarial Networks (GANs), it is imperative for media and visual forensics to develop detectors which can identify and attribute images to the model generating them. Existing works have shown to attribute images to their corresponding GAN sources with high accuracy. However, these works are limited to a closed set scenario, failing to generalize to GANs unseen during train time and are therefore, not scalable with a steady influx of new GANs. We present an iterative algorithm for discovering images generated from previously unseen GANs by exploiting the fact that all GANs leave distinct fingerprints on their generated images. Our algorithm consists of multiple components including network training, out-of-distribution detection, clustering, merge and refine steps. Through extensive experiments, we show that our algorithm discovers unseen GANs with high accuracy and also generalizes to GANs trained on unseen real datasets. We additionally apply our algorithm to attribution and discovery of GANs in an online fashion as well as to the more standard task of real/fake detection. Our experiments demonstrate the effectiveness of our approach to discover new GANs and can be used in an open-world setup.},
  keywords={Training;Visualization;Pipelines;Clustering algorithms;Fingerprint recognition;Media;Generative adversarial networks;Image and video manipulation detection and integrity methods;Representation learning;Transfer/Low-shot/Semi/Unsupervised Learning},
  doi={10.1109/ICCV48922.2021.01383},
  ISSN={2380-7504},
  month={Oct}
}

@ARTICLE{9222304,
  author={Wu, Hanzhou and Liu, Gen and Yao, Yuwei and Zhang, Xinpeng},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Watermarking Neural Networks With Watermarked Images}, 
  year={2021},
  volume={31},
  number={7},
  pages={2591-2601},
  abstract={Watermarking neural networks is a quite important means to protect the intellectual property (IP) of neural networks. In this paper, we introduce a novel digital watermarking framework suitable for deep neural networks that output images as the results, in which any image outputted from a watermarked neural network must contain a certain watermark. Here, the host neural network to be protected and a watermark-extraction network are trained together, so that, by optimizing a combined loss function, the trained neural network can accomplish the original task while embedding a watermark into the outputted images. This work is totally different from previous schemes carrying a watermark by network weights or classification labels of the trigger set. By detecting watermarks in the outputted images, this technique can be adopted to identify the ownership of the host network and find whether an image is generated from a certain neural network or not. We demonstrate that this technique is effective and robust on a variety of image processing tasks, including image colorization, super-resolution, image editing, semantic segmentation and so on.},
  keywords={Watermarking;Neural networks;Training;Task analysis;Media;IP networks;Intellectual property;Watermarking;neural networks;deep learning;image transformation;information hiding},
  doi={10.1109/TCSVT.2020.3030671},
  ISSN={1558-2205},
  month={July}
}

@INPROCEEDINGS{10917597,
  author={Zhou, Kerou and Qiu, Jiakang and Wang, Yuehua and Ye, Xiaojun},
  booktitle={2024 Annual Computer Security Applications Conference (ACSAC)}, 
  title={Enhancing Database Encryption: Adaptive Measures for Digital Assets Against LLMs-Based Reverse Engineering}, 
  year={2024},
  volume={},
  number={},
  pages={1-14},
  abstract={With the development of large language models (LLMs) technology, generative AI (GAI) has significantly lowered the barriers to software reverse engineering attacks. Traditional database system security controls, face new challenges when confronted with the powerful analytical capabilities of GAI. This paper provides a detailed demonstration of the reverse engineering of database cryptographic functions using GAI tools. It finds that existing encryption mechanisms in embedded DBSs need new approaches to prevent internal data attacks. The main contributions are in two aspects. First, by emulating human reverse engineering and encrypted data theft behaviors, it demonstrates how to perform software reverse engineering using GAI tools. It reveals that LLMs can accelerate analysts in obtaining the keys needed for decryption or in identifying cache extraction points for decrypted data, enabling attackers to access sensitive information. Second, to counteract the strong code generation and analytical capabilities of LLMs, the paper proposes a solution based on random data blocks and timestamp-based decryption mechanisms. This approach aims to increase the cost for attackers using GAI tools to perform software reverse engineering and exploit potential vulnerabilities in database systems.},
  keywords={Costs;Generative AI;Large language models;Reverse engineering;Software;Database systems;Encryption;Software measurement;Data mining;Faces;Software Vulnerability Analysis;Large Language Models;Software Reverse Engineering;Database Encryption},
  doi={10.1109/ACSAC63791.2024.00018},
  ISSN={2576-9103},
  month={Dec}
}

@ARTICLE{10462177,
  author={Ahmad, Baleegh and Thakur, Shailja and Tan, Benjamin and Karri, Ramesh and Pearce, Hammond},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={On Hardware Security Bug Code Fixes by Prompting Large Language Models}, 
  year={2024},
  volume={19},
  number={},
  pages={4043-4057},
  abstract={Novel AI-based code-writing Large Language Models (LLMs) such as OpenAI’s Codex have demonstrated capabilities in many coding-adjacent domains. In this work, we consider how LLMs may be leveraged to automatically repair identified security-relevant bugs present in hardware designs by generating replacement code. We focus on bug repair in code written in Verilog. For this study, we curate a corpus of domain-representative hardware security bugs. We then design and implement a framework to quantitatively evaluate the performance of any LLM tasked with fixing the specified bugs. The framework supports design space exploration of prompts (i.e., prompt engineering) and identifying the best parameters for the LLM. We show that an ensemble of LLMs can repair all fifteen of our benchmarks. This ensemble outperforms a state-of-the-art automated hardware bug repair tool on its own suite of bugs. These results show that LLMs have the ability to repair hardware security bugs and the framework is an important step towards the ultimate goal of an automated end-to-end bug repair tool.},
  keywords={Maintenance engineering;Computer bugs;Codes;Hardware;Security;Software;Registers;Hardware security;large language models;bug repair},
  doi={10.1109/TIFS.2024.3374558},
  ISSN={1556-6021},
  month={}
}

@INPROCEEDINGS{10578883,
  author={Pérez-Colado, Iván J. and Freire-Morán, Manuel and Calvo-Morata, Antonio and Pérez-Colado, Víctor M. and Fernández-Manjón, Baltasar},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={AI Asyet Another Tool in Undergraduate Student Projects: Preliminary Results}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={How do students use artificial intelligence tools in coursework projects when given the liberty to do so, with the only requirement of documenting how, where and why? We describe experiences with two groups of undergraduates in courses related to serious game authoring and human-computer interaction, both carried out in the second semester of 2023. In the serious games course, students were given the option of following a teacher-developed methodology for generating graphical assets for their serious games using a set of generative AI tools. This methodology was explained in the class but not hands on lab was carried out. In the interaction course, students were free to choose which AI tools to use when designing their system or in the development of their project documentation. Despite the limited number of participants (41 in total) we can see very different views and degrees of involvement: while some tried to use AI for as many tasks as possible, others considered that the learning curve for those tools was too steep to be worthwhile. Both experiences included a free-text survey at the end, and taken together, provide insights into how both supervised and unsupervised generative AI use could impact undergraduate projects in similar subjects. In addition to describing how students chose to use the tools, and the main takeaways from their survey response, we also discuss some of the ethical aspects about the access to the tools and what should be the minimal conditions to be met to allow the equitable use of AI in the classroom.},
  keywords={Surveys;Human computer interaction;Generative AI;Games;Documentation;Task analysis;Engineering education;AI in education;generative artificial intelligence;game development;serious games authoring;goal-driven design},
  doi={10.1109/EDUCON60312.2024.10578883},
  ISSN={2165-9567},
  month={May}
}

@ARTICLE{8320864,
  author={Psannis, Kostas E. and Stergiou, Christos and Gupta, B. B.},
  journal={IEEE Transactions on Sustainable Computing}, 
  title={Advanced Media-Based Smart Big Data on Intelligent Cloud Systems}, 
  year={2019},
  volume={4},
  number={1},
  pages={77-87},
  abstract={Today's advanced media technology preaches an enthralling time that will enormously bear on daily life. Moreover, the rapid raise of wireless communications and networking will ultimately bring advanced media to our lives anytime, anywhere, and on any device. According to the National Institute of Standards and Technology (NIST), Cloud Computing (CC) is a scheme for enabling convenient, on-demand network access to a shared pool of configurable computing pores (for example networks, applications, storage, servers, and services) which could be promptly foresighted and delivered with minimal management effort or service provider interaction. This paper proposed an efficient algorithm for advanced scalable Media-basedSmart Big Data (3D, Ultra HD) on Intelligent Cloud Computing systems. The proposed encoding algorithmoutperforms the conventional HEVC standard which demonstrated by the performance evaluations. In order to ratify the proposed approach, in addition, a relative study has been carried out. The proposed method could be used and integrated into HEVC, as a Smart Big Data, without violating the standard.},
  keywords={Video coding;Standards;Cloud computing;Encoding;Big Data;Transform coding;Complexity theory;Algorithm;HEVC media;3D;ultra HD;big data delivery;cloud computing},
  doi={10.1109/TSUSC.2018.2817043},
  ISSN={2377-3782},
  month={Jan}
}

@INPROCEEDINGS{10554981,
  author={Al-Kaswan, Ali},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)}, 
  title={Towards Safe, Secure, and Usable LLMs4Code}, 
  year={2024},
  volume={},
  number={},
  pages={258-260},
  abstract={Large Language Models (LLMs) are gaining popularity in the field of Natural Language Processing (NLP) due to their remarkable accuracy in various NLP tasks. LLMs designed for coding are trained on massive datasets, which enables them to learn the structure and syntax of programming languages. These datasets are scraped from the web and LLMs memorise information in these datasets. LLMs for code are also growing, making them more challenging to execute and making users increasingly reliant on external infrastructure. We aim to explore the challenges faced by LLMs for code and propose techniques to measure and prevent memorisation. Additionally, we suggest methods to compress models and run them locally on consumer hardware.},
  keywords={Computer languages;Codes;Accuracy;Syntactics;Natural language processing;Hardware;Encoding;large language models;privacy;memorisation;data leakage;compression},
  doi={10.1145/3639478.3639803},
  ISSN={2574-1934},
  month={April}
}

@ARTICLE{10460548,
  author={Malanowska, Agnieszka and Mazurczyk, Wojciech and Araghi, Tanya Koohpayeh and Megías, David and Kuribayashi, Minoru},
  journal={IEEE Access}, 
  title={Digital Watermarking—A Meta-Survey and Techniques for Fake News Detection}, 
  year={2024},
  volume={12},
  number={},
  pages={36311-36345},
  abstract={During the past few decades, research on digital media watermarking–initially designed for digital images with the envisioned applications of copyright protection or copy control– has significantly evolved with respect to other covers (i.e., video, audio, speech) and many more potential applications, including tamper detection, broadcast monitoring, and, more recently, fake news detection. As a result, various surveys have tried to summarize certain aspects of this research field as it has grown. This has led to more than 130 survey papers being written at different points in time, describing various parts of the scientific efforts focused on digital media watermarking. Considering the above, the aim of this paper is twofold. First, we conduct a meta-survey based on 64 selected research works, in order to summarize the most notable survey papers in this field, which allows us to “draw a map” of this research area. Second, we focus on providing the requirements for digital watermarking techniques when applied to their most recent application: detecting fake news in multimedia content. Finally, an outline of the approach taken within the DISSIMILAR (Detection of fake newS on SocIal MedIa pLAtfoRms) project for the detection of disinformation is presented.},
  keywords={Watermarking;Robustness;Transforms;Surveys;Fake news;Feature extraction;Copyright protection;Digital systems;Digital watermarking;fake news detection;information hiding;meta-survey;signal processing},
  doi={10.1109/ACCESS.2024.3374201},
  ISSN={2169-3536},
  month={}
}

@ARTICLE{10897735,
  author={Tian, Huiyuan and Zhang, Li and Li, Shijian and Yao, Min and Pan, Gang},
  journal={Computational Visual Media}, 
  title={Pyramid-VAE-GAN: Transferring hierarchical latent variables for image inpainting}, 
  year={2023},
  volume={9},
  number={4},
  pages={827-841},
  abstract={Significant progress has been made in image inpainting methods in recent years. However, they are incapable of producing inpainting results with reasonable structures, rich detail, and sharpness at the same time. In this paper, we propose the Pyramid-VAE-GAN network for image inpainting to address this limitation. Our network is built on a variational autoencoder (VAE) backbone that encodes high-level latent variables to represent complicated high-dimensional prior distributions of images. The prior assists in reconstructing reasonable structures when inpainting. We also adopt a pyramid structure in our model to maintain rich detail in low-level latent variables. To avoid the usual incompatibility of requiring both reasonable structures and rich detail, we propose a novel cross-layer latent variable transfer module. This transfers information about long-range structures contained in high-level latent variables to low-level latent variables representing more detailed information. We further use adversarial training to select the most reasonable results and to improve the sharpness of the images. Extensive experimental results on multiple datasets demonstrate the superiority of our method. Our code is available at https://github.com/thy960112/Pyramid-VAE-GAN.},
  keywords={Semantics;Training;Probabilistic logic;Decoding;Image reconstruction;Image restoration;Generative adversarial networks;Computational modeling;Autoencoders;Hybrid power systems;image inpainting;variational autoencoder (VAE);latent variable transfer (LTN);pyramid structure;generative model},
  doi={10.1007/s41095-022-0331-3},
  ISSN={2096-0662},
  month={Dec}
}

@BOOK{10769323,
  author={Wen, Jun},
  booktitle={Accelerating IoT Development with ChatGPT: A practical guide to building your first IoT project using AI-assisted coding and cloud integration},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Build cutting-edge projects with ChatGPT, PlatformIO, ESP32, and Arduino-compatible sensors by integrating AWS Cloud and the ThingsBoard dashboardKey FeaturesLeverage ChatGPT to generate code on ESP32 for sending sensor data to AWS CloudCreate your own visualization dashboard on ThingsBoard CloudFollow step-by-step configuration guidance to ingest, process, store, and query data on AWS CloudPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionUnlike other IoT books that focus on theory and generic applications, this guide takes a practical approach, empowering you to leverage ChatGPT to build your very first IoT prototype. With over 20 years of experience in wireless and IoT technologies and a background as an instructor, Jun Wen expertly guides you from project kick-off to a fully functional prototype. The book emphasizes the transformative impact of ChatGPT for IoT, teaching you how to use ChatGPT to generate code for your applications, even with limited coding experience. You’ll be introduced to using PlatformIO IDE within Visual Studio Code and discover the cutting-edge RISC-V architecture, the ESP32 MCU, Arduino-compatible sensors, and integration methods for AWS and the ThingsBoard dashboard. Working through 10 different project examples, including flame detection, smoke detection, and air quality measurement, you’ll become proficient in the functions and specifications of each sensor and the use cases they solve. By the end of this book, you’ll be ready to undertake IoT development projects, bridging the gap between your ideas and functional creations.What you will learnMaster IoT essentials, such as networks, end devices, wireless connectivity, and the cloudExplore the ChatGPT prompting framework and build crucial skills for IoT projectsDiscover best practices for building robust IoT hardware prototypesFind out how to set up Visual Studio Code and PlatformIO IDEConnect ESP32 to AWS through TLS and MQTTExplore popular connectivity technologies widely adopted in IoTIntegrate IoT sensors with ESP32 to capture accurate data using ChatGPT's assistanceWho this book is forIf you’re a beginner interested in applying IoT technology to your projects but face challenges due to limited experience in embedded software coding, specifically in C and C++, this book is for you. Whether you’re a student, hardware hobbyist, DIY enthusiast, IoT developer, or professional from a non-technical background, if you feel that your ability to innovate is often stalled by the complexity of software coding, this easy-to-follow guide to using ChatGPT for generating example code will boost your IoT prototype development.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835467879},
  url={https://ieeexplore.ieee.org/document/10769323}
}

@BOOK{10769219,
  author={Chow, Dennis and Bruskin, David},
  booktitle={Automating Security Detection Engineering: A hands-on guide to implementing Detection as Code},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Accelerate security detection development with AI-enabled technical solutions using threat-informed defenseKey FeaturesCreate automated CI/CD pipelines for testing and implementing threat detection use casesApply implementation strategies to optimize the adoption of automated work streamsUse a variety of enterprise-grade tools and APIs to bolster your detection programPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionToday's global enterprise security programs grapple with constantly evolving threats. Even though the industry has released abundant security tools, most of which are equipped with APIs for integrations, they lack a rapid detection development work stream. This book arms you with the skills you need to automate the development, testing, and monitoring of detection-based use cases. You’ll start with the technical architecture, exploring where automation is conducive throughout the detection use case lifecycle. With the help of hands-on labs, you’ll learn how to utilize threat-informed defense artifacts and then progress to creating advanced AI-powered CI/CD pipelines to bolster your Detection as Code practices. Along the way, you'll develop custom code for EDRs, WAFs, SIEMs, CSPMs, RASPs, and NIDS. The book will also guide you in developing KPIs for program monitoring and cover collaboration mechanisms to operate the team with DevSecOps principles. Finally, you'll be able to customize a Detection as Code program that fits your organization's needs. By the end of the book, you'll have gained the expertise to automate nearly the entire use case development lifecycle for any enterprise.What you will learnUnderstand the architecture of Detection as Code implementationsDevelop custom test functions using Python and TerraformLeverage common tools like GitHub and Python 3.x to create detection-focused CI/CD pipelinesIntegrate cutting-edge technology and operational patterns to further refine program efficacyApply monitoring techniques to continuously assess use case healthCreate, structure, and commit detections to a code repositoryWho this book is forThis book is for security engineers and analysts responsible for the day-to-day tasks of developing and implementing new detections at scale. If you’re working with existing programs focused on threat detection, you’ll also find this book helpful. Prior knowledge of DevSecOps, hands-on experience with any programming or scripting languages, and familiarity with common security practices and tools are recommended for an optimal learning experience.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781837631421},
  url={https://ieeexplore.ieee.org/document/10769219}
}

@ARTICLE{10904900,
  author={Wang, Yiru and Wu, Peng and Fang, Senlin and Cao, Bozhan and Wu, Xinyu and Lu, Xu and Yi, Zhengkun},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={Semisupervised Domain Adaptation for Wafer Map Defect Recognition via Cross-Alignment Network}, 
  year={2025},
  volume={74},
  number={},
  pages={1-13},
  abstract={Wafer map defect recognition is a crucial step in semiconductor manufacturing and measurement. Semisupervised domain adaptation (SSDA) aims to leverage abundant labeled data in the source domain to achieve accurate classification in the target domain with limited labeled data, effectively addressing the challenge of insufficient labels in wafer map datasets. However, a significant obstacle lies in the label mismatch among wafer map datasets, a problem that most current SSDA methods struggle to mitigate. To solve this problem, this article proposes a new SSDA algorithm named cross-alignment network (CAN). CAN decouples the feature subspace and label space using different encoders and classifiers. To facilitate knowledge transfer between the source and target domains, we propose cross-alignment learning (CAL). CAL consists of sample-wise cross-alignment and class-wise cross-alignment, designed to ensure the consistency of encoders’ outputs and facilitate the formation of robust clusters. We also integrate consistency regularization to enforce uniformity in outputs across different views of a sample. Additionally, we introduce a dynamic threshold strategy that tailors thresholds for each class based on its learning effect, thereby enhancing the model’s efficiency and data utilization. Empirically, our method outperforms the current state-of-the-art SSDA methods on public wafer map datasets. Furthermore, detailed experiments are conducted to verify the effectiveness of each component in CAN.},
  keywords={Deep learning;Production;Semiconductor device modeling;Training;Knowledge transfer;Data models;Classification algorithms;Accuracy;Training data;Service robots;Defect recognition;domain alignment;label mismatch;semiconductor manufacturing;semisupervised domain adaptation (SSDA);wafer map},
  doi={10.1109/TIM.2025.3545980},
  ISSN={1557-9662},
  month={}
}

@ARTICLE{9373945,
  author={Zhang, Jie and Chen, Dongdong and Liao, Jing and Zhang, Weiming and Feng, Huamin and Hua, Gang and Yu, Nenghai},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Deep Model Intellectual Property Protection via Deep Watermarking}, 
  year={2022},
  volume={44},
  number={8},
  pages={4005-4020},
  abstract={Despite the tremendous success, deep neural networks are exposed to serious IP infringement risks. Given a target deep model, if the attacker knows its full information, it can be easily stolen by fine-tuning. Even if only its output is accessible, a surrogate model can be trained through student-teacher learning by generating many input-output training pairs. Therefore, deep model IP protection is important and necessary. However, it is still seriously under-researched. In this work, we propose a new model watermarking framework for protecting deep networks trained for low-level computer vision or image processing tasks. Specifically, a special task-agnostic barrier is added after the target model, which embeds a unified and invisible watermark into its outputs. When the attacker trains one surrogate model by using the input-output pairs of the barrier target model, the hidden watermark will be learned and extracted afterwards. To enable watermarks from binary bits to high-resolution images, a deep invisible watermarking mechanism is designed. By jointly training the target model and watermark embedding, the extra barrier can even be absorbed into the target model. Through extensive experiments, we demonstrate the robustness of the proposed framework, which can resist attacks with different network structures and objective functions.},
  keywords={Watermarking;Computational modeling;Training;Task analysis;IP networks;Image processing;Media;Deep model IP protection;model watermarking;image processing},
  doi={10.1109/TPAMI.2021.3064850},
  ISSN={1939-3539},
  month={Aug}
}

@ARTICLE{10816641,
  author={Ur Rehman Ahmed, Naveed and Badshah, Afzal and Adeel, Hanan and Tajammul, Ayesha and Daud, Ali and Alsahfi, Tariq},
  journal={IEEE Access}, 
  title={Visual Deepfake Detection: Review of Techniques, Tools, Limitations, and Future Prospects}, 
  year={2025},
  volume={13},
  number={},
  pages={1923-1961},
  abstract={In recent years, rapid advancements in deepfakes (incorporating Artificial Intelligence (AI), machine, and deep learning) have updated tools and techniques for manipulating multimedia. Though technology has primarily been utilized for beneficial purposes, such as education and entertainment, it is also used for malicious or unethical tasks to spread disinformation or ruin someone’s dignity, even if it encompasses harassing and blackmailing victims. Deepfakes refer to high-quality and realistic multimedia-manipulated content that has been digitally modified or synthetically generated. We conducted a systematic literature review of deepfake detection to offer an updated overview of existing research work that initially describes the widely accessible deepfake generation tools, classifications, and detection process. We highlighted recent techniques in visual deepfake detection based on the feature representations, grouped into four domains: spatial, temporal, frequency, and spatio-temporal, including their key features and limitations by providing details of existing datasets, together with the potentials of deepfake and its future directions. This study tried to add an updated repository of technological change in deepfake, which could help researchers to develop robust deepfake models.},
  keywords={Deepfakes;Face recognition;Deep learning;Faces;Training;Generators;Decoding;Social networking (online);Generative adversarial networks;Feature extraction;Deepfake detection;machine learning;deep learning;deepfake applications;deepfake datasets;deepfake generation tools},
  doi={10.1109/ACCESS.2024.3523288},
  ISSN={2169-3536},
  month={}
}

@ARTICLE{10935812,
  author={Yan, Ran and Niu, Weina and Hou, Qinsheng and Su, YuChi and Gong, Jiacheng and Zhang, Xiaosong},
  journal={IEEE Internet of Things Journal}, 
  title={CAED: A Comprehensive Android Emulator Detection Framework with Data Augmentation}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Anti-emulation is crucial for Android and IoT security as it helps apps determine whether they are running on a real mobile device or in an emulation environment. This prevents apps from being analyzed, debugged, or reverse-engineered in emulators, ultimately stopping criminals from making illegal profits. Current emulator detection methods cannot balance accuracy, universality, robustness, and compatibility. Their universality is often hindered by limited data diversity and accessibility. To address these issues, we propose the Comprehensive Android Emulator Detection (CAED) framework. The Preprocessing Module of CAED collects and normalizes data from both phones and emulators. We propose the first data augmentation method for emulator detection, EDA-GAN, which is tailored to the characteristics of our data and effectively enhances data diversity. The classifier module MFBoost employs an adaptive imputation algorithm and multiple Classification and Regression Trees (CART) for precise classification. Experiments on 324 devices show that CAED improves detection rate by at least 12.5% and up to 44.71% over state-of-the-art (SOTA) methods. The EDA-GAN data augmentation method boosts classifier accuracy, achieving a performance of up to 99.62%. Additionally, CAED’s unique loss function and imputation algorithm enhance the robustness and compatibility of CAED, with a 24% smaller accuracy drop than other methods when features are modified or unavailable. This study presents the CAED framework as an effective solution for protecting apps against real-world security threats in Android and IoT environments.},
  keywords={Accuracy;Smart phones;Robustness;Data augmentation;Training;Internet of Things;Imputation;Generators;Generative adversarial networks;Classification algorithms;Emulator detection;roid;Anti-emulation;Generative Model;Security},
  doi={10.1109/JIOT.2025.3552426},
  ISSN={2327-4662},
  month={}
}

@ARTICLE{10921674,
  author={Yang, Xiao and Li, Gaolei and Zhou, Kai and Li, Jianhua and Lin, Xingqin and Liu, Yuchen},
  journal={IEEE Open Journal of Vehicular Technology}, 
  title={Exploring Graph Neural Backdoors in Vehicular Networks: Fundamentals, Methodologies, Applications, and Future Perspectives}, 
  year={2025},
  volume={},
  number={},
  pages={1-22},
  abstract={Advances in Graph Neural Networks (GNNs) have substantially enhanced Vehicular Networks (VNs) across primary domains, encompassing traffic forecasting and management, route optimization and algorithmic planning, and cooperative driving. Despite the boosts of the GNN for VNs, recent research has empirically demonstrated its potential vulnerability to backdoor attacks, wherein adversaries integrate triggers into inputs to manipulate GNNs to generate adversary-premeditated malicious outputs (e.g., misclassification of vehicle actions or traffic signals). This susceptibility is attributable to adversarial manipulation attacks targeting the training process of GNN-based VN systems. Although there is a rapid increase in research on GNN backdoors, systematic surveys within this domain remain lacking. To bridge this gap, we present the first survey dedicated to GNN backdoors. We start with outlining the fundamental definition of GNNs, followed by the detailed summarization and categorization of current GNN backdoors and countermeasures based on their technical features and application scenarios. Subsequently, an analysis of the applicability paradigms of GNN backdoors is conducted, and prospective research trends are presented. Unlike prior surveys on vision-centric backdoors, we uniquely investigate GNN-oriented backdoor attacks in VNs, which aims to explore attack surfaces across spatiotemporal vehicular graphs and provide insights to security research.},
  keywords={Graph neural networks;Training;Vehicle dynamics;Surveys;Roads;Data models;Predictive models;Optimization;Vehicle-to-everything;Vehicular and wireless technologies;Vehicular networks;graph neural networks;backdoor attacks;backdoor defenses;backdoor applications;deep network security;adversarial learning},
  doi={10.1109/OJVT.2025.3550411},
  ISSN={2644-1330},
  month={}
}

@ARTICLE{10123415,
  author={Wang, Zihan and Byrnes, Olivia and Wang, Hu and Sun, Ruoxi and Ma, Congbo and Chen, Huaming and Wu, Qi and Xue, Minhui},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Data Hiding With Deep Learning: A Survey Unifying Digital Watermarking and Steganography}, 
  year={2023},
  volume={10},
  number={6},
  pages={2985-2999},
  abstract={The advancement of secure communication and identity verification fields has significantly increased through the use of deep learning techniques for data hiding. By embedding information into a noise-tolerant signal, such as audio, video, or images, digital watermarking and steganography techniques can be used to protect sensitive intellectual property (IP) and enable confidential communication, ensuring that the information embedded is only accessible to authorized parties. This survey provides an overview of recent developments in deep learning techniques deployed for data hiding, categorized systematically according to model architectures and noise injection methods. In addition, potential future research directions that unite digital watermarking and steganography on software engineering to enhance security and mitigate risks are suggested and deliberated. This contribution furthers the creation of a more trustworthy digital world and advances responsible artificial intelligence (AI).},
  keywords={Media;Watermarking;Steganography;Deep learning;Data models;Surveys;Data mining;Artificial intelligence;Software engineering;Artificial intelligence (AI);cybersecurity;software engineering},
  doi={10.1109/TCSS.2023.3268950},
  ISSN={2329-924X},
  month={Dec}
}

@ARTICLE{8924972,
  author={},
  journal={IEEE Std 11073-10101-2019 (Revision of ISO/IEEE 11073-10101:2004) - Redline}, 
  title={IEEE Standard for Health informatics--Point-of-care medical device communication - Part 10101: Nomenclature - Redline}, 
  year={2019},
  volume={},
  number={},
  pages={1-1529},
  abstract={Within the context of the ISO/IEEE 11073 family of standards for point-of-care (POC) and personal health devices (PHD) medical device communication (MDC), this standard provides the nomenclature that supports both the domain information model and service model components of the standards family, as well as the semantic content exchanged with medical devices. The nomenclature is specialized for patient vital signs information representation and medical device informatics, with major areas including concepts for electrocardiograph (ECG), haemodynamics, respiration, blood gas, urine, fluid-related metrics, and neurology, as well as specialized units of measurement, general device events, alarms, and body sites. The standard defines both the architecture and major components of the nomenclature, along with extensive definitions for each conceptual area.},
  keywords={IEEE Standards;Biomedical monitoring;Medical devices;Point of care;Bioinformatics;codes;IEEE 11073-10101;IHE PCD-01;independent living;information model;medical device communication;nomenclature;ontology;patient;personal health devices;PHD;POC;point-of-care;semantics;service model;terminology},
  doi={},
  ISSN={},
  month={Oct}
}

@INPROCEEDINGS{10656760,
  author={Jang, Youngdong and Lee, Dong In and Jang, MinHyuk and Kim, Jong Wook and Yang, Feng and Kim, Sangpil},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={WateRF: Robust Watermarks in Radiance Fields for Protection of Copyrights}, 
  year={2024},
  volume={},
  number={},
  pages={12087-12097},
  abstract={The advances in the Neural Radiance Fields (NeRF) research offer extensive applications in diverse domains, but protecting their copyrights has not yet been researched in depth. Recently, NeRF watermarking has been considered one of the pivotal solutions for safely deploying NeRF-based 3D representations. However, existing methods are designed to apply only to implicit or explicit NeRF representations. In this work, we introduce an innovative watermarking method that can be employed in both representations of NeRF. This is achieved by fine-tuning NeRF to embed binary messages in the rendering process. In detail, we propose utilizing the discrete wavelet transform in the NeRF space for watermarking. Furthermore, we adopt a deferred back-propagation technique and introduce a combination with the patch-wise loss to improve rendering quality and bit accuracy with minimum trade-offs. We evaluate our method in three different aspects: capacity, invisibility, and robustness of the embedded watermarks in the 2D-rendered images. Our method achieves state-of-the-art performance with faster training speed over the compared state-of-the-art methods. Project page: https://kuai-lab.github.io/cvpr2024waterf/},
  keywords={Training;Solid modeling;Three-dimensional displays;Watermarking;Transforms;Neural radiance field;Rendering (computer graphics);NeRF;Watermark;CopyRights},
  doi={10.1109/CVPR52733.2024.01149},
  ISSN={2575-7075},
  month={June}
}

@ARTICLE{9464888,
  author={},
  journal={IEEE Std 2857-2021}, 
  title={IEEE Standard for Wireless Smart Utility Network Field Area Network (FAN)}, 
  year={2021},
  volume={},
  number={},
  pages={1-182},
  abstract={This document describes a complete communications specification, encompassing layers 1 to 4 of the Open Systems Integration (OSI) network model, for a secure, wireless mesh communications network, using open standards communications and cybersecurity standards from standards organizations including Institute of Electrical and Electronics Engineers (IEEE) and Internet Engineering Task Force (IETF). The specification describes the functionality of the physical (PHY layer), medium access control (MAC layer), the network layer, transport layer and security parameters including certificate format for a highly scaleable and secure wireless mesh network for critical infrastructure ipv6 wireless communications networks.},
  keywords={IEEE Standards;Wireless communication;Wireless mesh networks;Physical layer;Computer security;Open systems;Internet;Critical infrastructure;Media Access Control;adoption;FAN;field area network;IEEE 2857;Internet of Things;IoT;OSI;smart city;smart utility network;Wi-SUN;wireless mesh},
  doi={10.1109/IEEESTD.2021.9464888},
  ISSN={},
  month={June}
}

@INPROCEEDINGS{10599579,
  author={Wang, Guanyu and Li, Yuekang and Liu, Yi and Deng, Gelei and Li, Tianlin and Xu, Guosheng and Liu, Yang and Wang, Haoyu and Wang, Kailong},
  booktitle={2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering (Forge) Conference Acronym:}, 
  title={MeTMaP: Metamorphic Testing for Detecting False Vector Matching Problems in LLM Augmented Generation}, 
  year={2024},
  volume={},
  number={},
  pages={12-23},
  abstract={Augmented generation techniques such as Retrieval-Augmented Generation (RAG) and Cache-Augmented Generation (CAG) have revolutionized the field by enhancing large language model (LLM) outputs with external knowledge and cached information. However, the integration of vector databases, which serve as a backbone for these augmentations, introduces critical challenges, particularly in ensuring accurate vector matching. False vector matching in these databases can significantly compromise the integrity and reliability of LLM outputs, leading to misinformation or erroneous responses. Despite the crucial impact of these issues, there is a notable research gap in methods to effectively detect and address false vector matches in LLM-augmented generation. This paper presents MeTMaP, a metamorphic testing framework developed to identify false vector matching in LLM -augmented generation systems. We derive eight metamorphic relations (MRs) from six NLP datasets, which form our method's core, based on the idea that semantically similar texts should match and dissim-ilar ones should not. MeTMaP uses these MRs to create sentence triplets for testing, simulating real-world matching scenarios. Our evaluation of MeTMaP over 203 vector matching configurations, involving 29 embedding models and 7 distance metrics, uncovers significant inaccuracies. The results, showing a maximum accuracy of only 41.51% on our tests compared to the original datasets, em-phasize the widespread issue of false matches in vector matching methods and the critical need for effective detection and mitigation in LLM -augmented applications.},
  keywords={Accuracy;Databases;Terminology;Prevention and mitigation;Semantics;Reliability engineering;Vectors;Metamorphic Testing;Vector Matching;Augmented Generation},
  doi={10.1145/3650105.3652297},
  ISSN={},
  month={April}
}

@ARTICLE{10857354,
  author={Chen, Xiaofu and Deng, Jiangyi and Chen, Yanjiao and Li, Chaohao and Fang, Xin and Liu, Cong and Xu, Wenyuan},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={Imprints: Mitigating Watermark Removal Attacks With Defensive Watermarks}, 
  year={2025},
  volume={20},
  number={},
  pages={1866-1881},
  abstract={Watermark is essential for protecting the intellectual property of private images. However, a wide range of watermark removal attacks, especially many AI-powered ones, can automatically predict and remove watermarks, posing serious concerns. In this paper, we present the design of Imprints, a defensive watermarking framework that fortifies watermarks against watermark removal attacks. By formulating an optimization problem that deters watermark removal attacks, we design image-independent/dependent defensive watermark models for effective batch/customized protection. We further enhance the watermark to be transferable to unseen watermark removal attacks and robust to editing distortions. Extensive experiments verify that Imprints outperforms existing baselines in terms of its immunity to 8 state-of-the-art watermark removal attacks and 3 commercial black-box watermark removal software. The source code is available at https://github.com/Imprints-wm/Imprints.},
  keywords={Watermarking;Image restoration;Optimization;Robustness;Generative adversarial networks;Prediction algorithms;Distortion;Resistance;Protection;Vaccines;Adversarial watermark;automatic watermark removal;removal resistance},
  doi={10.1109/TIFS.2025.3536299},
  ISSN={1556-6021},
  month={}
}

@ARTICLE{10296520,
  author={Xiao, Shishi and Huang, Suizi and Lin, Yue and Ye, Yilin and Zeng, Wei},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Let the Chart Spark: Embedding Semantic Context into Chart with Text-to-Image Generative Model}, 
  year={2024},
  volume={30},
  number={1},
  pages={284-294},
  abstract={Pictorial visualization seamlessly integrates data and semantic context into visual representation, conveying complex information in an engaging and informative manner. Extensive studies have been devoted to developing authoring tools to simplify the creation of pictorial visualizations. However, mainstream works follow a retrieving-and-editing pipeline that heavily relies on retrieved visual elements from a dedicated corpus, which often compromise data integrity. Text-guided generation methods are emerging, but may have limited applicability due to their predefined entities. In this work, we propose ChartSpark, a novel system that embeds semantic context into chart based on text-to-image generative models. ChartSpark generates pictorial visualizations conditioned on both semantic context conveyed in textual inputs and data information embedded in plain charts. The method is generic for both foreground and background pictorial generation, satisfying the design practices identified from empirical research into existing pictorial visualizations. We further develop an interactive visual interface that integrates a text analyzer, editing module, and evaluation module to enable users to generate, modify, and assess pictorial visualizations. We experimentally demonstrate the usability of our tool, and conclude with a discussion of the potential of using text-to-image generative models combined with an interactive interface for visualization design.},
  keywords={Visualization;Data visualization;Semantics;Authoring systems;Pipelines;Data models;Interviews;pictorial visualization;generative model;authoring tool},
  doi={10.1109/TVCG.2023.3326913},
  ISSN={1941-0506},
  month={Jan}
}

@INPROCEEDINGS{10651233,
  author={Du, Mingshan and Wang, Hongxia and Zhang, Rui and Yan, Zihan},
  booktitle={2024 International Joint Conference on Neural Networks (IJCNN)}, 
  title={RPA-SCD: Rhythm and Pitch Aware Dual-Branch Network for Songs Conversion Detection}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Song voice conversion tools have gained more and more popularity in the recent past. People have been uploading their self-made forgery songs on video websites, and these songs have been converted in timbre. However, singing voice conversion technology may cause copyright infringement of the songs. In order to protect the copyright of songs, the method of singing voice conversion detection needs to be investigated. We propose Rhythm and Pitch Aware Songs Conversion Detection (RPA-SCD), a dual-branch network for song voice conversion detection. RPA-SCD can predict forged song fragments through rhythm and pitch which are the global and local information of music. To evaluate the proposed method, we contribute a multilingual song conversion detection(MSCD) dataset. Our proposed model achieves the EER of 2.30% in the original domain of MSCD, which is lower than other benchmarks for speech forgery detection. The experiments show that our approach achieves state-of-the-art performance on the song conversion detection task. The MSCD dataset can be found at https://drive.google.com/file/d/1rFsvMYihVtk81uFbL7UpyUEs-qBgsX6H/view?usp=drive_link. The code can be found at https://github.com/Samantha-Du/RPA-SDD.},
  keywords={Codes;Neural networks;Speech enhancement;Copyright protection;Benchmark testing;Rhythm;Forgery;audio forensics;songs conversion detection;transformer},
  doi={10.1109/IJCNN60899.2024.10651233},
  ISSN={2161-4407},
  month={June}
}

@INPROCEEDINGS{10652263,
  author={Gautam, Sangeeta and Kumar, Manoj},
  booktitle={2024 IEEE Students Conference on Engineering and Systems (SCES)}, 
  title={A Coverless Information Hiding Approach using the Most Significant Bit}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Demands for information hiding technology are high in the area of information security, as it enables secretive communication of confidential data. Traditionally, information hiding methods have relied on designating an original image and embedding the secret information into it to create a stego-image. However, this approach leaves behind modification traces in the cover image, making it susceptible to detection by steganalysis tools. A new method for coverless information hiding has been proposed to tackle this issue. Coverless information hiding eliminates the need for a specific cover image by choosing suitable original images from an established database that already contains the secret data. The proposed method extracts the hash sequence from the most significant bit (MSB) of the average of image blocks. The original image without modification is treated as stego image where hash sequences express the secret data. The proposed approach has proven effective in resisting steganalysis tools and demonstrating robustness against various image processing attacks, indicating potential for secure data transmission. The ultimate objectives of the proposed method are undetectability, robustness, and the hiding capacity of hidden data. The experimental results show that the proposed approach outperforms over the other existing state-of-the-art coverless information hiding methods in terms of robustness and accuracy.},
  keywords={Accuracy;Databases;Image processing;Information security;Generative adversarial networks;Robustness;Data mining;Security;Most significant bit;Image steganography;Coverless information hiding;Robust},
  doi={10.1109/SCES61914.2024.10652263},
  ISSN={},
  month={June}
}

@INPROCEEDINGS{10944887,
  author={Sun, Yalin and Lu, Ruiying and Li, Kang and Zheng, Yu},
  booktitle={2024 IEEE 23rd International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)}, 
  title={Topic-Aware Sensitive Information Detection in Chinese Large Language Model}, 
  year={2024},
  volume={},
  number={},
  pages={908-915},
  abstract={With the rapid advancement of deep learning, generative AI models have emerged as a prominent area of focus. However, these developments bring potential security concerns. China’s guiding document of government on generative AI security identifies 31 specific security risks across five categories, including content that violates socialist core values and discriminatory content. Detecting the sensitivity of both user input and model-generated content has therefore become a critical challenge for the security of generative AI models. This paper proposes a robust scheme for detecting sensitive information in the Chinese languages generated from the large language models. Initially, we detect and classify the security risks outlined in the document "Basic Security Requirements for Generative Artificial Intelligence Service" and develop a comprehensive dataset, named Chinese Sensitive Language Detection (CSLD). Specifically, in order to leverage the semantics of languages, we introduce the topic model to pre-analyze text data and construct topic-augmented classification vectors (TACV) that supply effective contextual information for sensitive content detection. Additionally, we propose a topic-infused attention mechanism (TIAM) to provide richer contextual information and relevant topics to guide sensitive information detection. At the same time, the proposed framework is designed to integrate with various classes of Chinese pre-trained models, enabling accurate classification of sensitive content while maintaining low latency and memory usage. Furthermore, the proposed dataset surpasses existing ones in terms of coverage, data volume, and its focus on the security challenges specific to Chinese large language models. Without bells and whistles, our experiments demonstrate that our model outperforms existing models in terms of accuracy and efficiency on the CSLD dataset.},
  keywords={Privacy;Accuracy;Sensitivity;Generative AI;Large language models;Computational modeling;Semantics;Transformers;Vectors;Security;generative AI security;sensitive information detection;topic analysis;transformer},
  doi={10.1109/TrustCom63139.2024.00133},
  ISSN={2324-9013},
  month={Dec}
}
