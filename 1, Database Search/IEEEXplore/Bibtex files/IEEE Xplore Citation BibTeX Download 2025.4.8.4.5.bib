@ARTICLE{9829265,
  author={Gupta, Chitralekha and Li, Haizhou and Goto, Masataka},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={Deep Learning Approaches in Topics of Singing Information Processing}, 
  year={2022},
  volume={30},
  number={},
  pages={2422-2451},
  abstract={Singing, the vocal productionof musical tones, is one of the most important elements of music. Addressing the needs of real-world applications, the study of technologies related to singing voices has become an increasingly active area of research. In this paper, we provide a comprehensive overview of the recent developments in the field of singing information processing, specifically in the topics of singing skill evaluation, singing voice synthesis, singing voice separation, and lyrics synchronization and transcription. We will especially focus on deep learning approaches including modern representation learning techniques for singing voices. We will also provide an overview of contributions in public datasets for singing voice research.},
  keywords={Music;Information processing;Synchronization;Speech processing;Rhythm;Instruments;Deep learning;Singing information processing;singing voice;singing skill evaluation;singing voice synthesis;singing voice separation;lyrics synchronization;lyrics transcription},
  doi={10.1109/TASLP.2022.3190732},
  ISSN={2329-9304},
  month={}
}

@ARTICLE{8344521,
  author={Mahalakshmi, G. S. and Muthu Selvi, G. and Sendhilkumar, S. and Vijayakumar, P. and Zhu, Yongxin and Chang, Victor},
  journal={IEEE Transactions on Sustainable Computing}, 
  title={Sustainable Computing Based Deep Learning Framework for Writing Research Manuscripts}, 
  year={2019},
  volume={4},
  number={1},
  pages={4-16},
  abstract={Writing research manuscripts is always a tough task at the eleventh hour. Often researchers do not find time to rewrite the manuscript to satisfaction, which is not quantifiable though. This paper proposes a sustainable computing based deep learning framework for iterated accumulation of ideas while writing research manuscripts. The framework suggests Deep Author Topic Models (DATM) where every author of the manuscript is modeled. For this, we have assumed time based sustainable computing as a measure of evaluation for research manuscript effectiveness. Using respective DATM, the region contributed by every author in the manuscriptis analyzed and fine-tuned semantically such that the manuscript is made to perfection in least time.},
  keywords={Writing;Gold;Semantics;Computational modeling;Machine learning;Analytical models;History;Author contribution analysis;deep learning;stacked auto encoder;sustainable computing;topic models},
  doi={10.1109/TSUSC.2018.2829196},
  ISSN={2377-3782},
  month={Jan}
}

@ARTICLE{10897726,
  author={Jing, Yaping and Lu, Xuequan and Gao, Shang},
  journal={Computational Visual Media}, 
  title={3D face recognition: A comprehensive survey in 2022}, 
  year={2023},
  volume={9},
  number={4},
  pages={657-685},
  abstract={In the past ten years, research on face recognition has shifted to using 3D facial surfaces, as 3D geometric information provides more discriminative features. This comprehensive survey reviews 3D face recognition techniques developed in the past decade, both conventional methods and deep learning methods. These methods are evaluated with detailed descriptions of selected representative works. Their advantages and disadvantages are summarized in terms of accuracy, complexity, and robustness to facial variations (expression, pose, occlusion, etc.). A review of 3D face databases is also provided, and a discussion of future research challenges and directions of the topic.},
  keywords={Face recognition;Three-dimensional displays;Databases;Feature extraction;Surveys;Lasers;Reviews;Lighting;Cameras;Accuracy;3D face recognition;3D face databases;deep learning;local features;global features},
  doi={10.1007/s41095-022-0317-1},
  ISSN={2096-0662},
  month={Dec}
}

@ARTICLE{9433546,
  author={Babushkin, Vahan and Jamil, Muhammad Hassan and Park, Wanjoo and Eid, Mohamad},
  journal={IEEE Access}, 
  title={Sensorimotor Skill Communication: A Literature Review}, 
  year={2021},
  volume={9},
  number={},
  pages={75132-75149},
  abstract={A sensorimotor skill is a sequence of motions generated in response to external stimuli and aiming to accomplish a particular task. It can be communicated to reproduce the task in a distant environment with similar settings. In this work, we conceptualize a multi-modal sensorimotor skill communication system that incorporates modeling, simulation, and evaluation of the sensorimotor skill. The proposed sensorimotor skill communication system can be applied for learning a specific style of human sensorimotor skill and teaching the skill to distant learners, which can be implemented in a variety of applications such as Tele-consultation, Tele-diagnosis, Tele-treatment, Tele-monitoring, and Tele-support. To understand the processes behind the communication of sensorimotor skill we review the representation of a human sensorimotor system from the neurobiological perspective. Then we analyze the existing literature on sensorimotor skill communication systems and propose a taxonomy of currently available methods for sensorimotor skill modeling, simulation, and evaluation. Furthermore, we propose a benchmark for evaluating the quality of the sensorimotor skill communication system. We present a case study aiming to demonstrate modeling the dental sensorimotor skill of periodontal probing. Lastly, we discuss challenges and limitations and provide perspectives for future research in developing sensorimotor skill communication systems.},
  keywords={Robot sensing systems;Solid modeling;Task analysis;Internet;Communication systems;Visualization;Tactile Internet;Haptics and haptic interfaces;learning from demonstration;sensorimotor learning;virtual reality and interfaces},
  doi={10.1109/ACCESS.2021.3081449},
  ISSN={2169-3536},
  month={}
}

@ARTICLE{10897656,
  author={Wang, Lili and Shi, Xuehuai and Liu, Yi},
  journal={Computational Visual Media}, 
  title={Foveated rendering: A state-of-the-art survey}, 
  year={2023},
  volume={9},
  number={2},
  pages={195-228},
  abstract={Recently, virtual reality (VR) technology has been widely used in medical, military, manufacturing, entertainment, and other fields. These applications must simulate different complex material surfaces, various dynamic objects, and complex physical phenomena, increasing the complexity of VR scenes. Current computing devices cannot efficiently render these complex scenes in real time, and delayed rendering makes the content observed by the user inconsistent with the user's interaction, causing discomfort. Foveated rendering is a promising technique that can accelerate rendering. It takes advantage of human eyes' inherent features and renders different regions with different qualities without sacrificing perceived visual quality. Foveated rendering research has a history of 31 years and is mainly focused on solving the following three problems. The first is to apply perceptual models of the human visual system into foveated rendering. The second is to render the image with different qualities according to foveation principles. The third is to integrate foveated rendering into existing rendering paradigms to improve rendering performance. In this survey, we review foveated rendering research from 1990 to 2021. We first revisit the visual perceptual models related to foveated rendering. Subsequently, we propose a new foveated rendering taxonomy and then classify and review the research on this basis. Finally, we discuss potential opportunities and open questions in the foveated rendering field. We anticipate that this survey will provide new researchers with a high-level overview of the state-of-the-art in this field, furnish experts with up-to-date information, and offer ideas alongside a framework to VR display software and hardware designers and engineers.},
  keywords={Rendering (computer graphics);Visualization;Sensitivity;Surveys;Spatial resolution;Taxonomy;Reviews;Solid modeling;Computational modeling;Virtual reality;foveated rendering;virtual reality (VR);real-time rendering},
  doi={10.1007/s41095-022-0306-4},
  ISSN={2096-0662},
  month={June}
}

@INPROCEEDINGS{9564992,
  author={},
  booktitle={2021 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC)}, 
  title={Programme}, 
  year={2021},
  volume={},
  number={},
  pages={1-102},
  abstract={Presents abstracts for the articles comprising the conference proceedings.},
  keywords={},
  doi={10.1109/ICSPCC52875.2021.9564992},
  ISSN={},
  month={Aug}
}

@ARTICLE{10729262,
  author={Jiang, Xingguo and Zhang, Yuchao and Lin, Guojun and Yu, Ling},
  journal={IEEE Access}, 
  title={Music Emotion Recognition Based on Deep Learning: A Review}, 
  year={2024},
  volume={12},
  number={},
  pages={157716-157745},
  abstract={In recent years, with the development of the digital era, music emotion recognition technology has been widely used in the fields of music recommendation system, music classification, psychotherapy, music visualization, background music generation, smart home, and other applications of music emotion recognition, and has received attention from all walks of life. Especially the rapid development of artificial intelligence and deep learning, the music emotion recognition model using efficient deep neural network composition has become the mainstream model. This paper provides a more detailed overview of music emotion recognition, first introducing the background of music and emotion, and briefly summarizing the content of related works as well as the content framework. In the process, we also compare the similarities and differences in the content of other researchers’ reviews of related research areas. And in the middle section, we provide a detailed account of datasets, emotion models, feature extraction, and emotion recognition algorithms. Finally, we discuss the current challenges in music emotion recognition and explore future research priorities.},
  keywords={Emotion recognition;Reviews;Music;Feature extraction;Deep learning;Brain modeling;Speech recognition;Machine learning algorithms;Visualization;Support vector machines;Artificial intelligence;Music emotion recognition;deep learning;artificial intelligence;music emotion datasets},
  doi={10.1109/ACCESS.2024.3484470},
  ISSN={2169-3536},
  month={}
}

@ARTICLE{10643250,
  author={Richard, Guy Junior and Habonneau, Jérôme and Guériot, Didier and Caillec, Jean-Marc Le},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 
  title={Explainable AI Methods for Underwater Mine Warfare}, 
  year={2024},
  volume={},
  number={},
  pages={1-19},
  abstract={Artificial Intelligence (AI) has brought new algorithms providing high performance compared to the usual methods. However, the internal behavior of the decision-making process carried out by Neural Networks requires to be finely understood. This questioning has led to the development of the eXplainable Artificial Intelligence (XAI). This is especially true in areas where following AI decisions may have serious consequences, such as underwater mine hunting to increase the AI acceptance. We study the application of XAI methods (backpropagation and perturbation) to the classification (mine vs non-mine) and identification (type of mines) of an object detected by a sonar on the seabed. Although the aim of XAI is to locate relevant features in an image, the classification or identification decisions do not involve the same cognitive process. The main aims of our paper were to verify that the XAI methods, designed for optical images, can be applied to grayscale sonar images (in particular, we explain why backpropagation methods are not suitable for grayscale images, unlike perturbation methods) and whether they are neural network-dependent (two kinds of network have been tested). The features highlighted by XAI methods for the different classes of mines are compared with each other, but also with those involved in the operator decision-making. Three examples of feature extraction are finally discussed in the case of misclassification. Furthermore, the perturbation approach provides the same highlighted areas for both networks, and these areas on which the Neural Networks base their classification can be linked to the explanations given by operators.},
  keywords={Sonar;Fuel processing industries;Artificial neural networks;Shape;Feature extraction;Explainable AI;Task analysis;eXplainable AI;mine warfare;sonar images;heat maps;SHAP},
  doi={10.1109/JSTARS.2024.3447093},
  ISSN={2151-1535},
  month={}
}

@INPROCEEDINGS{10561413,
  author={},
  booktitle={2024 International Conference on Smart Systems for applications in Electrical Sciences (ICSSES)}, 
  title={ICSSES 2024 Book of Abstracts}, 
  year={2024},
  volume={},
  number={},
  pages={i-cxv},
  abstract={},
  keywords={Education;Recording;Instruments;ISO Standards;Diamonds;Communications technology},
  doi={10.1109/ICSSES62373.2024.10561413},
  ISSN={},
  month={May}
}

@ARTICLE{10255703,
  author={},
  journal={IEEE P2894/D8, August 2023}, 
  title={IEEE Draft Guide for an Architectural Framework for Explainable Artificial Intelligence}, 
  year={2023},
  volume={},
  number={},
  pages={1-51},
  abstract={A new wave of artificial intelligence applications that offer extensive benefits to our daily lives has been led to by dramatic success in machine learning. The loss of explainability during this transition, however, means vulnerability to vicious data, poor model structure design, and suspicion of stakeholders and the general public--all with a range of legal implications. The study of explainable AI (XAI), which is an active research field that aims to make AI systems results more understandable to humans, has been called for by this dilemma. This is a field with great hopes for improving the trust and transparency of AI-based systems and is considered a necessary route for AI to move forward. A technological blueprint for building, deploying, and managing machine learning models, while meeting the requirements of transparent and trustworthy AI by adopting a variety of XAI methodologies, is provided by this guide. It defines the architectural framework and application guidelines for explainable AI, including: description and definition of XAI; the types of XAI methods and the application scenarios to which each type applies; and performance evaluation of XAI.},
  keywords={IEEE Standards;Artificial intelligence;Software architecture;AI;architectural framework;artificial intelligence;explainable AI;explainable artificial intelligence;IEEE 2894™;machine learning;XAI},
  doi={},
  ISSN={},
  month={Aug}
}

@INPROCEEDINGS{10911402,
  author={Sehgal, Vishakha and Sharma, Sanjay and Pathak, Shivansh and Ahuja, Kamlesh},
  booktitle={2024 IEEE 4th International Conference on ICT in Business Industry & Government (ICTBIG)}, 
  title={Navigating The Battleground: An Analysis Of Adversarial Threats And Protections In Deep Neural Networks}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={Deep learning techniques find broad applications in important areas such as malware detection systems, self-driving cars, and health care. However, it is still possible to attack deep learning soft intelligent models using adversarial example approaches. This study investigates the works and findings of recent research, whose central focus has been on adversarial machine learning, its weaknesses, and its application. Some of the focus has been on malware attacks that use deep learning frameworks, such as neural network based Jacobian saliency map attacks and anatomy of the Carlini and Wagner attacks. This has again posed a limitation to the present-day research on the increasing range of the actors and their role within the range of types of attack as well as strategies and development of countermeasures, including making biases and models to mitigate the threats. Furthermore, there is also a deficiency in the evaluation of defence mechanisms, particularly in developing appropriate parameters that would demonstrate the efficacy of the existing models. In conclusion, this paper presents communication and deliberations on areas that offer an interesting promise for future research in which the challenges experienced in applying deep learning systems will be satisfactorily addressed.},
  keywords={Deep learning;Jacobian matrices;Navigation;Government;Medical services;Malware;Adversarial machine learning;Robustness;Autonomous automobiles;Protection;Adversarial Defence;Adversarial Examples;Adversarial Machine Learning;Adversarial Threats;Deep Learning;Model Robustness;Neural Network},
  doi={10.1109/ICTBIG64922.2024.10911402},
  ISSN={},
  month={Dec}
}

@ARTICLE{10897671,
  author={Wang, Bingnan and Xu, Fanjiang and Zheng, Quan},
  journal={Computational Visual Media}, 
  title={A survey on facial image deblurring}, 
  year={2024},
  volume={10},
  number={1},
  pages={3-25},
  abstract={When a facial image is blurred, it significantly affects high-level vision tasks such as face recognition. The purpose of facial image deblurring is to recover a clear image from a blurry input image, which can improve the recognition accuracy, etc. However, general deblurring methods do not perform well on facial images. Therefore, some face deblurring methods have been proposed to improve performance by adding semantic or structural information as specific priors according to the characteristics of the facial images. In this paper, we survey and summarize recently published methods for facial image deblurring, most of which are based on deep learning. First, we provide a brief introduction to the modeling of image blurring. Next, we summarize face deblurring methods into two categories: model-based methods and deep learning-based methods. Furthermore, we summarize the datasets, loss functions, and performance evaluation metrics commonly used in the neural network training process. We show the performance of classical methods on these datasets and metrics and provide a brief discussion on the differences between model-based and learning-based methods. Finally, we discuss the current challenges and possible future research directions.},
  keywords={Kernel;Face recognition;Image edge detection;Degradation;Surveys;Estimation;Deep learning;Cameras;Learning systems;Hands;facial image deblurring;model-based;deep learning-based;semantic or structural prior},
  doi={10.1007/s41095-023-0336-6},
  ISSN={2096-0662},
  month={Feb}
}

@ARTICLE{10847755,
  author={Bai, Shaojin and Li, Yalu and Chang, Rihao and Liang, Qi and Nie, Weizhi},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={SCDL: Sketch Causal Disentangled Learning for Sketch-based 3D Shape Retrieval}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Sketch-based 3D shape retrieval (SBSR) has been a challenging task for decades, crucially depending on aligning shared semantic attributes between sketches and 3D shapes. Previous efforts mainly aimed at creating a common embedding space to bridge domain gaps. However, sketches’ subjective and abstract nature, known as confounders, potentially reduces learning performance of matching with 3D shapes. To address this issue, in this paper, we propose a sketch causal disentangled learning for SBSR, named SCDL, which introduce causal intervention to explicitly disentangle sketches into the inherent shared semantic part, and other unrelated confounders to classification (styles, abstraction levels, etc.) for the first time. Specifically, we construct a structural causal model (SCM) in the sketch branch under the dual variational autoencoder (VAE) architectures to alleviate confounders negative impact through learning the semantic attributes in the latent variable space. Next, we adopt a learning strategy on the separated semantic latent variables to construct a shared semantic embedding space further to make cross-modal features of the same class more similar, alleviating the cross-modality discrepancies effectively and establishing new state-of-the-art on three benchmarks. Comprehensive experiment results, ablation studies, and visualization validate the effectiveness of our approach.},
  keywords={Three-dimensional displays;Shape;Semantics;Feature extraction;Disentangled representation learning;Visualization;Circuits and systems;Autoencoders;Solid modeling;Electronic mail;Sketch-based 3D Shape retrieval;Causal Inference;Disentangled Learning},
  doi={10.1109/TCSVT.2025.3531892},
  ISSN={1558-2205},
  month={}
}

@INPROCEEDINGS{9429649,
  author={},
  booktitle={2020 International Conference on Computer, Control, Electrical, and Electronics Engineering (ICCCEEE)}, 
  title={Abstract Book}, 
  year={2021},
  volume={},
  number={},
  pages={1-105},
  abstract={Presents abstracts for the articles comprising the conference proceedings.},
  keywords={},
  doi={10.1109/ICCCEEE49695.2021.9429649},
  ISSN={},
  month={Feb}
}

@BOOK{10769299,
  author={Galloro, Giovanni and Avery, Nathaniel and Dorbin, David and Seroter, Richard},
  booktitle={Secure Continuous Delivery on Google Cloud: Implement an automated and secure software delivery pipeline on Google Cloud using native services},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Build an end-to-end continuous delivery pipeline on Google Cloud and secure your software supply chain using GCP tools and services including Cloud Code, Cloud Workstations, Cloud Build, Artifact Registry, and Cloud DeployKey FeaturesGain hands-on experience building an end-to-end software delivery pipeline using Google Cloud servicesDeploy your applications on GKE, Cloud Run, and across hybrid and multi-cloud environmentsSecure pipelines with artifact scanning, dependency vulnerability checks, signed provenance, and admission controlPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionContinuous delivery, a cornerstone of modern software engineering, facilitates quick and secure software delivery using a robust toolkit encompassing automated builds, testing, source code management, artifact storage, and deployment. Whether you integrate tools from different providers or use a set of managed services from a single cloud provider, the goal is to streamline setup, integration, and management. This book focuses on continuous delivery on Google Cloud. Starting with an introduction to continuous delivery and secure software supply chain concepts, this book uses hands-on exercises to demonstrate how to continuously test your application with Skaffold and Cloud Code, leverage AI-assisted code generation with Cloud Code and Cloud Workstations, and automate your continuous integration with Cloud Build. You’ll see how to store and scan your software artifacts on Artifact Registry, orchestrate deployments with Cloud Deploy, and release your software on GKE and Cloud Run, configured to admit only trusted code. Using an example application, you’ll implement tools for creating an end-to-end delivery pipeline using Google Cloud services. By the end of this book, you’ll be able to build a secure software delivery pipeline from development to production using Google Cloud managed services and best practices.What you will learnCreate an end-to-end continuous delivery pipeline using Cloud Build, Artifact Registry, and Cloud DeployDevelop, build, and deploy container-based applications with Skaffold and Cloud CodeExperiment with AI-assisted code generation in Cloud CodeAutomate continuous integration with Cloud Build triggersAutomate deployment on GKE and Cloud Run through Cloud DeployEnhance pipeline security with Artifact Analysis, Binary Authorization, and SLSAApply best practices, including logging and monitoringWho this book is forThis book is for DevOps, Platform, and Cloud Engineers tasked with managing application deployment and creating continuous delivery pipelines who want to automate workflows in a fully managed, scalable, and secure platform. Software developers involved in application delivery and interested in harnessing Google Cloud tools to optimize development flow status and feedback loop will also find this book useful. Prior knowledge of Google Cloud fundamentals (including Cloud APIs and IAM), software delivery, containerization, and Kubernetes will enhance the reading experience.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781805127642},
  url={https://ieeexplore.ieee.org/document/10769299}
}

@INPROCEEDINGS{10682661,
  author={Wang, Zeng and Alrahis, Lilas and Mankali, Likhitha and Knechtel, Johann and Sinanoglu, Ozgur},
  booktitle={2024 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)}, 
  title={LLMs and the Future of Chip Design: Unveiling Security Risks and Building Trust}, 
  year={2024},
  volume={},
  number={},
  pages={385-390},
  abstract={Chip design is about to be revolutionized by the integration of large language, multimodal, and circuit models (collectively LxMs). While exploring this exciting frontier with tremendous potential, the community must also carefully consider the related security risks and the need for building trust into using LxMs for chip design. First, we review the recent surge of using LxMs for chip design in general. We cover state-of-the-art works for the automation of hardware description language code generation and for scripting and guidance of essential but cumbersome tasks for electronic design automation tools, e.g., design-space exploration, tuning, or designer training. Second, we raise and provide initial answers to novel research questions on critical issues for security and trustworthiness of LxM-powered chip design from both the attack and defense perspectives.},
  keywords={Training;Reviews;Hardware security;Buildings;Very large scale integration;Chip scale packaging;Integrated circuit modeling;Electronic Design Automation;Integrated Circuits;Large Language Models;Hardware Security},
  doi={10.1109/ISVLSI61997.2024.00076},
  ISSN={2159-3477},
  month={July}
}

@ARTICLE{10489849,
  author={Sun, Gan and Liang, Wenqi and Dong, Jiahua and Li, Jun and Ding, Zhengming and Cong, Yang},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Create Your World: Lifelong Text-to-Image Diffusion}, 
  year={2024},
  volume={46},
  number={9},
  pages={6454-6470},
  abstract={Text-to-image generative models can produce diverse high-quality images of concepts with a text prompt, which have demonstrated excellent ability in image generation, image translation, etc. We in this work study the problem of synthesizing instantiations of a user's own concepts in a never-ending manner, i.e., create your world, where the new concepts from user are quickly learned with a few examples. To achieve this goal, we propose a Lifelong text-to-image Diffusion Model (L $^{2}$2 DM), which intends to overcome knowledge “catastrophic forgetting” for the past encountered concepts, and semantic “catastrophic neglecting” for one or more concepts in the text prompt. In respect of knowledge “catastrophic forgetting”, our L $^{2}$2 DM framework devises a task-aware memory enhancement module and an elastic-concept distillation module, which could respectively safeguard the knowledge of both prior concepts and each past personalized concept. When generating images with a user text prompt, the solution to semantic “catastrophic neglecting” is that a concept attention artist module can alleviate the semantic neglecting from concept aspect, and an orthogonal attention module can reduce the semantic binding from attribute aspect. To the end, our model can generate more faithful image across a range of continual text prompts in terms of both qualitative and quantitative metrics, when comparing with the related state-of-the-art models.},
  keywords={Task analysis;Dogs;Computational modeling;Semantics;Training;Neural networks;Electronic mail;Continual learning;image generation;lifelong machine learning;stable diffusion},
  doi={10.1109/TPAMI.2024.3382753},
  ISSN={1939-3539},
  month={Sep.}
}

@ARTICLE{9656734,
  author={Duy, Kha Dinh and Noh, Taehyun and Huh, Siwon and Lee, Hojoon},
  journal={IEEE Access}, 
  title={Confidential Machine Learning Computation in Untrusted Environments: A Systems Security Perspective}, 
  year={2021},
  volume={9},
  number={},
  pages={168656-168677},
  abstract={As machine learning (ML) technologies and applications are rapidly changing many computing domains, security issues associated with ML are also emerging. In the domain of systems security, many endeavors have been made to ensure ML model and data confidentiality. ML computations are often inevitably performed in untrusted environments and entail complex multi-party security requirements. Hence, researchers have leveraged the Trusted Execution Environments (TEEs) to build confidential ML computation systems. We conduct a systematic and comprehensive survey by classifying attack vectors and mitigation in confidential ML computation in untrusted environments, analyzing the complex security requirements in multi-party scenarios, and summarizing engineering challenges in confidential ML implementation. Lastly, we suggest future research directions based on our study.},
  keywords={Security;Computational modeling;Hardware;Data models;Software;Machine learning;Codes;Confidential machine learning computation;trusted execution;side-channel attacks;multi-party ML computation},
  doi={10.1109/ACCESS.2021.3136889},
  ISSN={2169-3536},
  month={}
}

@INPROCEEDINGS{10810811,
  author={Patel, Samay and Patel, Jeet and Shah, Dhairya and Goel, Parth and Patel, Bankim},
  booktitle={2024 5th International Conference on Data Intelligence and Cognitive Informatics (ICDICI)}, 
  title={A RAG based Personal Placement Assistant System using Large Language Models for Customized Interview Preparation}, 
  year={2024},
  volume={},
  number={},
  pages={1468-1475},
  abstract={This paper introduces a Personal Placement Assistant (PPA) framework that utilizes advanced Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs) to automate and personalize job placement preparation. The system integrates Natural Language Processing (NLP) techniques, including text embedding using the all-MiniLM-L6-v2 transformer model and semantic retrieval using ChromaDB for accurate resume analysis and context-aware question generation. The PPA is structured into three core components: the Retriever, using PyMuPDF for resume parsing and recursive text chunking for efficient vector storage and search; the Analyzer, employing the Google Gemini-1.5-flash model for domain extraction and percentage-based content profiling; and the Generator, which produces domain-specific MCQs, coding challenges, and interview questions aligned with Bloom’s Taxonomy. RAG enhances the system’s ability to integrate external knowledge, improving the contextual relevance of the generated content. Evaluation results demonstrate an 83.77% accuracy in domainspecific extraction and question generation, confirming the PPA’s effectiveness in automating personalized job preparation across industries.},
  keywords={Analytical models;Accuracy;Large language models;Retrieval augmented generation;Resumes;Transformer cores;Transformers;Question generation;Vectors;Interviews;Retrieval Augmented Generation (RAG);Large Language Models (LLMs);Transformers;Personal Placement Assistant (PPA);ChromaDB;Interview Preparation},
  doi={10.1109/ICDICI62993.2024.10810811},
  ISSN={},
  month={Nov}
}

@BOOK{10769313,
  author={Bulmash, Greg and Segura, Thomas},
  booktitle={Crafting Secure Software: An engineering leader's guide to security by design},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Gain a solid understanding of the threat landscape and discover best practices to protect your software factory throughout the SDLC, with valuable insights from security experts at GitGuardianKey FeaturesDevelop a strong security posture by grasping key attack vectors in the SDLCImplement industry-leading best practices to protect software from evolving threatsUtilize legislative and regulatory landscapes to mitigate compliance-related costsBook DescriptionDrawing from GitGuardian's extensive experience in securing millions of lines of code for organizations worldwide, Crafting Secure Software takes you on an exhaustive journey through the complex world of software security and prepares you to face current and emerging security challenges confidently. Authored by security experts, this book provides unique insights into the software development lifecycle (SDLC) and delivers actionable advice to help you mitigate and prevent risks. From securing code-writing tools and secrets to ensuring the integrity of the source code and delivery pipelines, you’ll get a good grasp on the threat landscape, uncover best practices for protecting your software, and craft recommendations for future-proofing against upcoming security regulations and legislation. By the end of this book, you’ll have gained a clear vision of the improvements needed in your security posture, along with concrete steps to implement them, empowering you to make informed decisions and take decisive action in safeguarding your software assets.What you will learnGet to grips with security trends and GitGuardian's role in modern softwareAnalyze major security breaches and their impact on the industryDevelop a threat model tailored to your business and risk appetiteImplement security measures across your entire SDLCSecure secrets within codebases, configurations, and artifactsDesign and maintain secure build pipelines and deployment setupsNavigate security compliance, including current and future lawsPrepare for future security with AI-generated code integrationWho this book is forThis book is an essential read for security and IT leaders navigating the complexities of modern software development. The book is also useful for chief security officers (CSOs), chief information security officers (CISOs), security architects, DevOps professionals, and IT decision makers. A basic understanding of software engineering, version control, and build and delivery mechanisms is needed. This guide will empower you to comprehend and mitigate threats in today's dynamic software factories, regardless of your technical depth.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835885079},
  url={https://ieeexplore.ieee.org/document/10769313}
}

@INBOOK{10896990,
  author={Basta, Alfred and Basta, Nadine and Anwar, Waqar and Essar, Mohammad Ilyas},
  booktitle={Open-Source Security Operations Center (SOC): A Complete Guide to Establishing, Managing, and Maintaining a Modern SOC}, 
  title={Threat Intelligence and Advanced Threat Hunting}, 
  year={2025},
  volume={},
  number={},
  pages={361-393},
  abstract={Summary <p>Threat intelligence and proactive hunting empower security teams to uncover sophisticated threats that evade traditional protective controls. Intelligence provides context to focus hunts while hunting informs intelligence analysis to drive detection engineering. Advanced methodologies fuse an outside perspective from threat intelligence with inside&#x2013;&#x2013;out defenses structured across high&#x2010;value data, identities, and systems. Scaling beyond manual processes, purpose&#x2010;built threat intelligence also directly fuels automated incident response by keeping pace with attacker innovation through continually updated countermeasures applied instantly against emergent infrastructure linked to known campaigns. In today's interconnected world, cyberattacks aimed at financial gain rather than ideological or geopolitical motives are an ever&#x2010;present threat to businesses. Cloud environments require updated threat&#x2010;hunting techniques addressing expanded attack surfaces across fragmented infrastructure sprawl, accessing sensitive data through managed services with restricted monitoring increasingly provisioned outside security team visibility.</p>},
  keywords={Security;Malware;Codes;Telemetry;Vectors;Training;Surface reconstruction;Real-time systems;Prevention and mitigation;Phishing},
  doi={10.1002/9781394201631.ch13},
  ISSN={},
  publisher={Wiley},
  isbn={9781394201617},
  url={https://ieeexplore.ieee.org/document/10896990}
}

@BOOK{10803970,
  author={Okeyode, David and Kirui, Joylynn and Hanselman, Scott},
  booktitle={DevSecOps for Azure: End-to-end supply chain security for GitHub, Azure DevOps, and the Azure cloud},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Gain holistic insights and practical expertise in embedding security within the DevOps pipeline, specifically tailored for Azure cloud environments Key FeaturesLearn how to integrate security into Azure DevOps workflows for cloud infrastructureFind out how to integrate secure practices across all phases of the Azure DevOps workflow, from planning to monitoringHarden the entire DevOps workflow, from planning and coding to source control, CI, and cloud workload deploymentPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionBusinesses must prioritize security, especially when working in the constantly evolving Azure cloud. However, many organizations struggle to maintain security and compliance. Attackers are increasingly targeting software development processes, making software supply chain security crucial. This includes source control systems, build systems, CI/CD platforms, and various artifacts. With the help of this book, you’ll be able to enhance security and compliance in Azure software development processes. Starting with an overview of DevOps and its relationship with Agile methodologies and cloud computing, you'll gain a solid foundation in DevSecOps principles. The book then delves into the security challenges specific to DevOps workflows and how to address them effectively. You'll learn how to implement security measures in the planning phase, including threat modeling and secure coding practices. You'll also explore pre-commit security controls, source control security, and the integration of various security tools in the build and test phases. The book covers crucial aspects of securing the release and deploy phases, focusing on artifact integrity, infrastructure as code security, and runtime protection. By the end of this book, you’ll have the knowledge and skills to implement a secure code-to-cloud process for the Azure cloud.What you will learnUnderstand the relationship between Agile, DevOps, and the cloudSecure the use of containers in a CI/CD workflowImplement a continuous and automated threat modeling processSecure development toolchains such as GitHub Codespaces, Microsoft Dev Box, and GitHubIntegrate continuous security throughout the code development workflow, pre-source and post-source control contributionIntegrate SCA, SAST, and secret scanning into the build process to ensure code safetyImplement security in release and deploy phases for artifact and environment complianceWho this book is forThis book is for security professionals and developers transitioning to a public cloud environment or moving towards a DevSecOps paradigm. It's also designed for DevOps engineers, or anyone looking to master the implementation of DevSecOps in a practical manner. Individuals who want to understand how to integrate security checks, testing, and other controls into Azure cloud continuous delivery pipelines will also find this book invaluable. Prior knowledge of DevOps principles and practices, as well as an understanding of security fundamentals will be beneficial. },
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781837633333},
  url={https://ieeexplore.ieee.org/document/10803970}
}

@BOOK{10162806,
  author={George, Nathan},
  booktitle={Practical Data Science with Python: Learn tools and techniques from hands-on examples to extract insights from data},
  year={2021},
  volume={},
  number={},
  pages={},
  abstract={Learn to effectively manage data and execute data science projects from start to finish using PythonKey FeaturesUnderstand and utilize data science tools in Python, such as specialized machine learning algorithms and statistical modelingBuild a strong data science foundation with the best data science tools available in PythonAdd value to yourself, your organization, and society by extracting actionable insights from raw dataBook DescriptionPractical Data Science with Python teaches you core data science concepts, with real-world and realistic examples, and strengthens your grip on the basic as well as advanced principles of data preparation and storage, statistics, probability theory, machine learning, and Python programming, helping you build a solid foundation to gain proficiency in data science. The book starts with an overview of basic Python skills and then introduces foundational data science techniques, followed by a thorough explanation of the Python code needed to execute the techniques. You'll understand the code by working through the examples. The code has been broken down into small chunks (a few lines or a function at a time) to enable thorough discussion. As you progress, you will learn how to perform data analysis while exploring the functionalities of key data science Python packages, including pandas, SciPy, and scikit-learn. Finally, the book covers ethics and privacy concerns in data science and suggests resources for improving data science skills, as well as ways to stay up to date on new data science developments. By the end of the book, you should be able to comfortably use Python for basic data science projects and should have the skills to execute the data science process on any data source.What you will learnUse Python data science packages effectivelyClean and prepare data for data science work, including feature engineering and feature selectionData modeling, including classic statistical models (such as t-tests), and essential machine learning algorithms, such as random forests and boosted modelsEvaluate model performanceCompare and understand different machine learning methodsInteract with Excel spreadsheets through PythonCreate automated data science reports through PythonGet to grips with text analytics techniquesWho this book is forThe book is intended for beginners, including students starting or about to start a data science, analytics, or related program (e.g. Bachelor’s, Master’s, bootcamp, online courses), recent college graduates who want to learn new skills to set them apart in the job market, professionals who want to learn hands-on data science techniques in Python, and those who want to shift their career to data science. The book requires basic familiarity with Python. A "getting started with Python" section has been included to get complete novices up to speed.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781801076654},
  url={https://ieeexplore.ieee.org/document/10162806}
}

@ARTICLE{10693287,
  author={Zhang, Yi and Zhao, Yuying and Li, Zhaoqing and Cheng, Xueqi and Wang, Yu and Kotevska, Olivera and Yu, Philip S. and Derr, Tyler},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={A Survey on Privacy in Graph Neural Networks: Attacks, Preservation, and Applications}, 
  year={2024},
  volume={36},
  number={12},
  pages={7497-7515},
  abstract={Graph Neural Networks (GNNs) have gained significant attention owing to their ability to handle graph-structured data and the improvement in practical applications. However, many of these models prioritize high utility performance, such as accuracy, with a lack of privacy consideration, which is a major concern in modern society where privacy attacks are rampant. To address this issue, researchers have started to develop privacy-preserving GNNs. Despite this progress, there is a lack of a comprehensive overview of the attacks and the techniques for preserving privacy in the graph domain. In this survey, we aim to address this gap by summarizing the attacks on graph data according to the targeted information, categorizing the privacy preservation techniques in GNNs, and reviewing the datasets and applications that could be used for analyzing/solving privacy issues in GNNs. We also outline potential directions for future research in order to build better privacy-preserving GNNs.},
  keywords={Privacy;Data privacy;Deep learning;Aggregates;Training;Surveys;Electronic mail;Deep learning on graphs;graph neural networks;privacy attacks;privacy preservation},
  doi={10.1109/TKDE.2024.3454328},
  ISSN={1558-2191},
  month={Dec}
}

@ARTICLE{10938587,
  author={Sivakumar, Eashwar and Singh, Kiran Jot and Chawla, Paras and Ganesan, Geetha},
  journal={IEEE Access}, 
  title={RBEDH: A Decentralized Role Based Event Driven Hybrid Framework for Smart Contracts}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={The complex nature of smart contracts necessities the development of a novel adaptable framework. As blockchain technology continues to expand into diverse fields, the demand for secure, efficient, and transparent systems becomes increasingly critical. RBEDH is the integration of Role Based Access Control (RBAC), Event Driven Architecture (EDA) and Hybrid Functionalities. The framework is applied to the scholarly publishing sector, where academic integrity, transparency, and reliability are crucial for ensuring the credibility and trustworthiness of published research. The smart contracts are executed between authors, reviewers and publishers. Functionality test was conducted using Ganache, Ropsten, and Ethereum Mainnet. These evaluations confirmed the consistency and effectiveness of contract deployment. Vulnerabilities such as re-entrancy, integer overflow/underflow, unauthorized access were tested using Securify, Mythril, Smartcheck and Oynete. It is found that the system is secure and it not susceptible to any of the above vulnerability. Further timestamp dependency was tested through Manticore, Slither and Echidna and the test results indicate the absence of vulnerability. Performance analysis results proves that the proposed framework is better on the basis of average energy consumption, latency and memory requirement when compared with the existing literature.},
  keywords={Smart contracts;Blockchains;Security;Access control;Soft sensors;Scalability;Ecosystems;Costs;Codes;Authorization;Blockchain;Smart Contract;Design Pattern;Role Based;Access Control;Event Driven Architecture;Hybrid Functionality},
  doi={10.1109/ACCESS.2025.3554630},
  ISSN={2169-3536},
  month={}
}

@ARTICLE{9828025,
  author={Gurcan, Fatih and Dalveren, Gonca Gokce Menekse and Cagiltay, Nergiz Ercil and Soylu, Ahmet},
  journal={IEEE Access}, 
  title={Detecting Latent Topics and Trends in Software Engineering Research Since 1980 Using Probabilistic Topic Modeling}, 
  year={2022},
  volume={10},
  number={},
  pages={74638-74654},
  abstract={The landscape of software engineering research has changed significantly from one year to the next in line with industrial needs and trends. Therefore, today’s research literature on software engineering has a rich and multidisciplinary content that includes a large number of studies; however, not many of them demonstrate a holistic view of the field. From this perspective, this study aimed to reveal a holistic view that reflects topics, trends, and trajectories in software engineering research by analyzing the majority of domain-specific articles published over the last 40 years. This study first presents an objective and systematic method for corpus creation through major publication sources in the field. A corpus was then created using this method, which includes 44 domain-specific conferences and journals and 57,174 articles published between 1980 and 2019. Next, this corpus was analyzed using an automated text-mining methodology based on a probabilistic topic-modeling approach. As a result of this analysis, 24 main topics were found. In addition, topical trends in the field were revealed. Finally, three main developmental stages of the field were identified as: the programming age, the software development age, and the software optimization age.},
  keywords={Market research;Systematics;Software engineering;Bibliometrics;Text mining;Corpus creation;research trends and topics;software engineering;text mining;topic model},
  doi={10.1109/ACCESS.2022.3190632},
  ISSN={2169-3536},
  month={}
}

@INPROCEEDINGS{10483613,
  author={Dubiński, Jan and Kowalczuk, Antoni and Pawlak, Stanisław and Rokita, Przemyslaw and Trzcinski, Tomasz and Morawiecki, Paweł},
  booktitle={2024 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)}, 
  title={Towards More Realistic Membership Inference Attacks on Large Diffusion Models}, 
  year={2024},
  volume={},
  number={},
  pages={4848-4857},
  abstract={Generative diffusion models, including Stable Diffusion and Midjourney, can generate visually appealing, diverse, and high-resolution images for various applications. These models are trained on billions of internet-sourced images, raising significant concerns about the potential unauthorized use of copyright-protected images. In this paper, we examine whether it is possible to determine if a specific image was used in the training set, a problem known in the cybersecurity community as a membership inference attack. Our focus is on Stable Diffusion, and we address the challenge of designing a fair evaluation framework to answer this membership question. We propose a new dataset to establish a fair evaluation setup and apply it to Stable Diffusion, also applicable to other generative models. With the proposed dataset, we execute membership attacks (both known and newly introduced). Our research reveals that previously proposed evaluation setups do not provide a full understanding of the effectiveness of membership inference attacks. We conclude that the membership inference attack remains a significant challenge for large diffusion models (often deployed as black-box systems), indicating that related privacy and copyright issues will persist in the foreseeable future.},
  keywords={Training;Privacy;Data privacy;Computer vision;Computational modeling;Closed box;Reliability;Algorithms;Explainable;fair;accountable;privacy-preserving;ethical computer vision},
  doi={10.1109/WACV57701.2024.00479},
  ISSN={2642-9381},
  month={Jan}
}

@BOOK{10614674,
  author={Weitz, Joshua S. and Taylor, Bradford},
  booktitle={Quantitative Biosciences Companion in MATLAB: Dynamics across Cells, Organisms, and Populations},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={A hands-on lab guide in the MATLAB programming language that enables students in the life sciences to reason quantitatively about living systems across scalesThis lab guide accompanies the textbook Quantitative Biosciences, providing students with the skills they need to translate biological principles and mathematical concepts into computational models of living systems. This hands-on guide uses a case study approach organized around central questions in the life sciences, introducing landmark advances in the field while teaching students—whether from the life sciences, physics, computational sciences, engineering, or mathematics—how to reason quantitatively in the face of uncertainty.Draws on real-world case studies in molecular and cellular biosciences, organismal behavior and physiology, and populations and ecological communitiesEncourages good coding practices, clear and understandable modeling, and accessible presentation of resultsHelps students to develop a diverse repertoire of simulation approaches, enabling them to model at the appropriate scaleBuilds practical expertise in a range of methods, including sampling from probability distributions, stochastic branching processes, continuous time modeling, Markov chains, bifurcation analysis, partial differential equations, and agent-based simulationsBridges the gap between the classroom and research discovery, helping students to think independently, troubleshoot and resolve problems, and embark on research of their ownStand-alone computational lab guides for Quantitative Biosciences also available in Python and R},
  keywords={Pars;Dynamics;Code;Distribution;Probability;Function;Tmph;Random;Parameters;Protein;Cells;Prey;Population;Simulation;Event;Hawks;Stochastic;Predator;Variables;Mean;Equations;Numbers;Equilibrium;Models;Transition;Game;Space;Plot;= pars;Dove;Mrna;Data;Rates;Laboratory;Lab;Simulate;Matrix;Rand;Systems;Position;Trajectories;Exponential;Payoff;Direction;Fraction;Solution;Growth;Zeros;Dynamical;Command;Link;Length;Basis;Phase;Core;Note;Sum;Voltage;Player;Equal;Focal;Gca;Generation;Trajectory;= zeros;Poisson;Line;Gene;Points;Cdf},
  doi={},
  ISSN={},
  publisher={Princeton University Press},
  isbn={9780691259628},
  url={https://ieeexplore.ieee.org/document/10614674}
}

@BOOK{10614680,
  author={Weitz, Joshua S. and English, Nolan and Lee, Alexander B. and Zamani, Ali},
  booktitle={Quantitative Biosciences Companion in Python: Dynamics across Cells, Organisms, and Populations},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={A hands-on lab guide in the Python programming language that enables students in the life sciences to reason quantitatively about living systems across scalesThis lab guide accompanies the textbook Quantitative Biosciences, providing students with the skills they need to translate biological principles and mathematical concepts into computational models of living systems. This hands-on guide uses a case study approach organized around central questions in the life sciences, introducing landmark advances in the field while teaching students—whether from the life sciences, physics, computational sciences, engineering, or mathematics—how to reason quantitatively in the face of uncertainty.Draws on real-world case studies in molecular and cellular biosciences, organismal behavior and physiology, and populations and ecological communitiesEncourages good coding practices, clear and understandable modeling, and accessible presentation of resultsHelps students to develop a diverse repertoire of simulation approaches, enabling them to model at the appropriate scaleBuilds practical expertise in a range of methods, including sampling from probability distributions, stochastic branching processes, continuous time modeling, Markov chains, bifurcation analysis, partial differential equations, and agent-based simulationsBridges the gap between the classroom and research discovery, helping students to think independently, troubleshoot and resolve problems, and embark on research of their ownStand-alone computational lab guides for Quantitative Biosciences also available in R and MATLAB},
  keywords={Initial;Array;Zeros;Variables;= pars;Mean;Result;Numbers;Current;Equilibrium;Models;Exponential;Transition;Space;Dove;Boid;Integrate;Mrna;Matrix;Equations;Color=;Uniform;Rates;Run;Len;Laboratory;Lab;Simulate;Odeint;Data;Direction;Systems;Trajectories;Stochastic;Hawk;Event;Predator;Np random;Simulation;Plt;Population;Range;Cells;Prey;Protein;Values;Probability;Parameters;Function;Distribution;Random;Plot;Code;Dynamics;= np;Pars;Np;Payoff;= plt;Points;Fraction;Lambda;Gamma;Link;Dyn;Np array;Growth;Game;Dynamical;Note},
  doi={},
  ISSN={},
  publisher={Princeton University Press},
  isbn={9780691259611},
  url={https://ieeexplore.ieee.org/document/10614680}
}

@BOOK{10614698,
  author={Weitz, Joshua S. and Domínguez-Mirazo, Marian},
  booktitle={Quantitative Biosciences Companion in R: Dynamics across Cells, Organisms, and Populations},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={A hands-on lab guide in the R programming language that enables students in the life sciences to reason quantitatively about living systems across scalesThis lab guide accompanies the textbook Quantitative Biosciences, providing students with the skills they need to translate biological principles and mathematical concepts into computational models of living systems. This hands-on guide uses a case study approach organized around central questions in the life sciences, introducing landmark advances in the field while teaching students—whether from the life sciences, physics, computational sciences, engineering, or mathematics—how to reason quantitatively in the face of uncertainty.Draws on real-world case studies in molecular and cellular biosciences, organismal behavior and physiology, and populations and ecological communitiesEncourages good coding practices, clear and understandable modeling, and accessible presentation of resultsHelps students to develop a diverse repertoire of simulation approaches, enabling them to model at the appropriate scaleBuilds practical expertise in a range of methods, including sampling from probability distributions, stochastic branching processes, continuous time modeling, Markov chains, bifurcation analysis, partial differential equations, and agent-based simulationsBridges the gap between the classroom and research discovery, helping students to think independently, troubleshoot and resolve problems, and embark on research of their ownStand-alone computational lab guides for Quantitative Biosciences also available in Python and MATLAB},
  keywords={Matrix;Result;Equations;Mean;Numbers;Current;Denotes;Mrna;Equilibrium;Models;Transition;Pars;Length;Space;Dove;= element_text;Element_text;Rates;Title =;Title;Lab;Laboratory;Simulate;Systems;Color=;Axis;Fraction;Line;Trajectories;Exponential;Ggplot;Hawks;Plot;Frame;Predator;Stochastic;Event;Variables;Initial;Simulation;Values;Population;Data;Cells;Prey;= function;Protein;Random;Parameters;Probability;Aes;Distribution;Function;Code;Dynamics;Data frame;Df;Behavior;Focal;Variance;= data;Markov;Sum;Exponentially;Element;Snippet;Gait;Transition matrix;Production;Positive},
  doi={},
  ISSN={},
  publisher={Princeton University Press},
  isbn={9780691259604},
  url={https://ieeexplore.ieee.org/document/10614698}
}

@ARTICLE{8654686,
  author={Baluja, Shumeet},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Hiding Images within Images}, 
  year={2020},
  volume={42},
  number={7},
  pages={1685-1697},
  abstract={We present a system to hide a full color image inside another of the same size with minimal quality loss to either image. Deep neural networks are simultaneously trained to create the hiding and revealing processes and are designed to specifically work as a pair. The system is trained on images drawn randomly from the ImageNet database, and works well on natural images from a wide variety of sources. Beyond demonstrating the successful application of deep learning to hiding images, we examine how the result is achieved and apply numerous transformations to analyze if image quality in the host and hidden image can be maintained. These transformation range from simple image manipulations to sophisticated machine learning-based adversaries. Two extensions to the basic system are presented that mitigate the possibility of discovering the content of the hidden image. With these extensions, not only can the hidden information be kept secure, but the system can be used to hide even more than a single image. Applications for this technology include image authentication, digital watermarks, finding exact regions of image manipulation, and storing meta-information about image rendering and content.},
  keywords={Containers;Neural networks;Image coding;Image reconstruction;Image color analysis;Training;Receivers;Information hiding;image verification;image trust},
  doi={10.1109/TPAMI.2019.2901877},
  ISSN={1939-3539},
  month={July}
}

@ARTICLE{10897713,
  author={Wu, Tong and Yuan, Yu-Jie and Zhang, Ling-Xiao and Yang, Jie and Cao, Yan-Pei and Yan, Ling-Qi and Gao, Lin},
  journal={Computational Visual Media}, 
  title={Recent advances in 3D Gaussian splatting}, 
  year={2024},
  volume={10},
  number={4},
  pages={613-642},
  abstract={The emergence of 3D Gaussian splatting (3DGS) has greatly accelerated rendering in novel view synthesis. Unlike neural implicit representations like neural radiance fields (NeRFs) that represent a 3D scene with position and viewpoint-conditioned neural networks, 3D Gaussian splatting utilizes a set of Gaussian ellipsoids to model the scene so that efficient rendering can be accomplished by rasterizing Gaussian ellipsoids into images. Apart from fast rendering, the explicit representation of 3D Gaussian splatting also facilitates downstream tasks like dynamic reconstruction, geometry editing, and physical simulation. Considering the rapid changes and growing number of works in this field, we present a literature review of recent 3D Gaussian splatting methods, which can be roughly classified by functionality into 3D reconstruction, 3D editing, and other downstream applications. Traditional point-based rendering methods and the rendering formulation of 3D Gaussian splatting are also covered to aid understanding of this technique. This survey aims to help beginners to quickly get started in this field and to provide experienced researchers with a comprehensive overview, aiming to stimulate future development of the 3D Gaussian splatting representation.},
  keywords={Three-dimensional displays;Rendering (computer graphics);Neural radiance field;Image color analysis;Image coding;Ellipsoids;Solid modeling;Training;Geometry;Image reconstruction;3D Gaussian splatting (3DGS);radiance field;novel view synthesis;3D editing;scene generation},
  doi={10.1007/s41095-024-0436-y},
  ISSN={2096-0662},
  month={Aug}
}

@ARTICLE{10703164,
  author={Huang, Ling-Hsuan and Lu, Ching-Hu},
  journal={IEEE Systems Journal}, 
  title={Average Sparse Attention for Dense Video Captioning From Multiperspective Edge-Computing Cameras}, 
  year={2024},
  volume={18},
  number={4},
  pages={1939-1950},
  abstract={In recent years, the artificial intelligence of things (AIoT) has accelerated the development of edge computing. Since existing edge computing for dense video captioning has only explored single-camera decision-making, we propose a lightweight image stitching model that uses a proposed inverted pruned residual model to realize multicamera decision-making to generate more accurate captions. Existing dense video captioning uses an intensive attention mechanism, which readily results in the loss of important information. Thus, our study proposes an average sparse attention mechanism such that the resultant dense video-captioning model is better able to focus on important information and improve the quality of its generated captions. The experiments show that the lightweight video stitching model can reduce model parameters by 13.40% and increase frames per second by 28.96% on an edge platform when compared to the latest studies. Furthermore, a dense video caption network with the average sparse attention mechanism yielded improvements of 22.97% for BLEU3, 35.04% for BLEU4, and 7.51% for METEOR.},
  keywords={Cameras;Computational modeling;Attention mechanisms;Image edge detection;Accuracy;Image coding;Detectors;Synthesizers;Streaming media;Image annotation;Neural networks;Dense video captioning;edge computing;image stitching;Internet of Things;lightweight neural networks;sparse attention},
  doi={10.1109/JSYST.2024.3456864},
  ISSN={1937-9234},
  month={Dec}
}

@INPROCEEDINGS{10400363,
  author={},
  booktitle={2023 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC)}, 
  title={Title Page}, 
  year={2023},
  volume={},
  number={},
  pages={1-136},
  abstract={},
  keywords={Signal processing;Speech processing;Codes;Wireless communication;Urban areas;Uncertainty;Schedules},
  doi={10.1109/ICSPCC59353.2023.10400363},
  ISSN={2837-116X},
  month={Nov}
}

@BOOK{10769287,
  author={Walker, Michael},
  booktitle={Python Data Cleaning Cookbook: Prepare your data for analysis with pandas, NumPy, Matplotlib, scikit-learn, and OpenAI},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Learn the intricacies of data description, issue identification, and practical problem-solving, armed with essential techniques and expert tips.Key FeaturesGet to grips with new techniques for data preprocessing and cleaning for machine learning and NLP modelsUse new and updated AI tools and techniques for data cleaning tasksClean, monitor, and validate large data volumes to diagnose problems using cutting-edge methodologies including Machine learning and AIBook DescriptionJumping into data analysis without proper data cleaning will certainly lead to incorrect results. The Python Data Cleaning Cookbook - Second Edition will show you tools and techniques for cleaning and handling data with Python for better outcomes. Fully updated to the latest version of Python and all relevant tools, this book will teach you how to manipulate and clean data to get it into a useful form. he current edition focuses on advanced techniques like machine learning and AI-specific approaches and tools for data cleaning along with the conventional ones. The book also delves into tips and techniques to process and clean data for ML, AI, and NLP models. You will learn how to filter and summarize data to gain insights and better understand what makes sense and what does not, along with discovering how to operate on data to address the issues you've identified. Next, you’ll cover recipes for using supervised learning and Naive Bayes analysis to identify unexpected values and classification errors and generate visualizations for exploratory data analysis (EDA) to identify unexpected values. Finally, you’ll build functions and classes that you can reuse without modification when you have new data. By the end of this Data Cleaning book, you'll know how to clean data and diagnose problems within it.What you will learnUsing OpenAI tools for various data cleaning tasksProducing summaries of the attributes of datasets, columns, and rowsAnticipating data-cleaning issues when importing tabular data into pandasApplying validation techniques for imported tabular dataImproving your productivity in pandas by using method chainingRecognizing and resolving common issues like dates and IDsSetting up indexes to streamline data issue identificationUsing data cleaning to prepare your data for ML and AI modelsWho this book is forThis book is for anyone looking for ways to handle messy, duplicate, and poor data using different Python tools and techniques. The book takes a recipe-based approach to help you to learn how to clean and manage data with practical examples. Working knowledge of Python programming is all you need to get the most out of the book.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781803246291},
  url={https://ieeexplore.ieee.org/document/10769287}
}

@BOOK{10769217,
  author={Staveley, Confidence and Romeo, Christopher},
  booktitle={API Security for White Hat Hackers: Uncover offensive defense strategies and get up to speed with secure API implementation},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Become an API security professional and safeguard your applications against threats with this comprehensive guide Key FeaturesGain hands-on experience in testing and fixing API security flaws through practical exercisesDevelop a deep understanding of API security to better protect your organization's dataIntegrate API security into your company's culture and strategy, ensuring data protectionPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionAPIs have evolved into an essential part of modern applications, making them an attractive target for cybercriminals. Written by a multi-award-winning cybersecurity leader , this comprehensive guide offers practical insights into testing APIs, identifying vulnerabilities, and fixing them. With a focus on hands-on learning, this book guides you through securing your APIs in a step-by-step manner. You'll learn how to bypass authentication controls, circumvent authorization controls, and identify vulnerabilities in APIs using open-source and commercial tools. Moreover, you'll gain the skills you need to write comprehensive vulnerability reports and recommend and implement effective mitigation strategies to address the identified vulnerabilities. This book isn't just about hacking APIs; it's also about understanding how to defend them. You'll explore various API security management strategies and understand how to use them to safeguard APIs against emerging threats. By the end of this book, you'll have a profound understanding of API security and how to defend against the latest threats. Whether you're a developer, security professional, or ethical hacker, this book will ensure that your APIs are secure and your organization's data is protected.What you will learnImplement API security best practices and industry standardsConduct effective API penetration testing and vulnerability assessmentsImplement security measures for API security managementUnderstand threat modeling and risk assessment in API securityGain proficiency in defending against emerging API security threatsBecome well-versed in evasion techniques and defend your APIs against themIntegrate API security into your DevOps workflowImplement API governance and risk management initiatives like a proWho this book is forIf you’re a cybersecurity professional, web developer, or software engineer looking to gain a comprehensive understanding of API security, this book is for you. The book is ideal for those who have beginner to advanced-level knowledge of cybersecurity and API programming concepts. Professionals involved in designing, developing, or maintaining APIs will also benefit from the topics covered in this book. },
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781800569355},
  url={https://ieeexplore.ieee.org/document/10769217}
}

@INPROCEEDINGS{9984366,
  author={},
  booktitle={2022 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC)}, 
  title={ICSPCC 2022 Proceedings}, 
  year={2022},
  volume={},
  number={},
  pages={i-cxiv},
  abstract={Presents the front cover, title page, cover page, or splash screen of the proceedings record.},
  keywords={Signal processing;Faces;Codes;COVID-19;Writing;Wireless communication;Urban areas},
  doi={10.1109/ICSPCC55723.2022.9984366},
  ISSN={},
  month={Oct}
}

@INPROCEEDINGS{9465397,
  author={Saki, Abdullah Ash and Alam, Mahabubul and Phalak, Koustubh and Suresh, Aakarshitha and Topaloglu, Rasit Onur and Ghosh, Swaroop},
  booktitle={2021 IEEE European Test Symposium (ETS)}, 
  title={A Survey and Tutorial on Security and Resilience of Quantum Computing}, 
  year={2021},
  volume={},
  number={},
  pages={1-10},
  abstract={Present-day quantum computers suffer from various noises or errors such as, gate error, relaxation, dephasing, readout error, and crosstalk. Besides, they offer a limited number of qubits with restrictive connectivity. Therefore, quantum programs running these computers face resilience issues and low output fidelities. The noise in the cloud-based access of quantum computers also introduce new modes of security and privacy issues. Furthermore, quantum computers face several threat models from insider and outsider adversaries including input tampering, program misallocation, fault injection, Reverse Engineering (RE) and Cloning. This paper provides an overview of various assets embedded in quantum computers and programs, vulnerabilities and attack models and the relation between resilience and security. We also cover countermeasures against the reliability and security issues and present future outlook for security of quantum computing.},
  keywords={Computers;Privacy;Quantum computing;Computational modeling;Reverse engineering;Tutorials;Security;Quantum Computing;Security;Privacy;Resilience;Fault Injection;Reverse Engineering},
  doi={10.1109/ETS50041.2021.9465397},
  ISSN={1558-1780},
  month={May}
}

@ARTICLE{10949493,
  author={Popoola, Segun I. and Tsado, Yakubu and Ogunjinmi, Abimbola A. and Sanchez-Velazquez, Erika and Peng, Yonghong and Rawat, Danda B.},
  journal={IEEE Access}, 
  title={Multi-Stage Deep Learning for Intrusion Detection in Industrial Internet of Things}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={The Industrial Internet of Things (IIoT) facilitates enhanced automation, predictive maintenance, real-time monitoring, and data analytics across various sectors, including manufacturing, energy, transportation, agriculture, and supply chain management, thereby improving productivity, efficiency, and operational safety. However, as IIoT networks continue to expand, it is imperative to secure them against increasingly sophisticated cyber threats. Deep Learning (DL) techniques have been extensively utilized for intrusion detection within IIoT systems. Nevertheless, addressing the class imbalance problem remains a significant challenge. The underrepresentation of certain attack types in training data frequently results in the development of DL models that struggle to accurately detect these categories of malicious activities. This limitation represents considerable risks to the security of IIoT networks, as undetected attacks and false alarms may lead to severe operational disruptions. In this paper, we propose a multi-stage deep learning (MSDL) method specifically designed to enhance intrusion detection within IIoT networks by addressing the class imbalance issue. We assessed the effectiveness of our approach utilizing two highly imbalanced datasets: X-IIoTID and WUSTL-IIoT. Our experimental findings indicate that the proposed MSDL method surpasses the baseline DL models as well as state-of-the-art oversampling and undersampling techniques. Specifically, the MSDL method exhibits significant improvements in recognizing minority-class attacks that are frequently misclassified. Consequently, the implementation of the MSDL for intrusion detection is anticipated to strengthen the overall security and resilience of IIoT systems, providing stronger protection against a diverse array of cyber threats in industrial applications.},
  keywords={Industrial Internet of Things;Intrusion detection;Deep learning;Security;Real-time systems;Training data;Training;Telecommunication traffic;Reviews;Manufacturing;Cyber attacks;intrusion detection;artificial intelligence;machine learning;deep learning;network security;Internet of Things;fifth industrial revolution},
  doi={10.1109/ACCESS.2025.3557959},
  ISSN={2169-3536},
  month={}
}

@BOOK{10162421,
  author={Meglio, Alberto Di and Combarro, Elías F. and González-Castillo, Samuel and Meglio, Alberto Di},
  booktitle={A Practical Guide to Quantum Machine Learning and Quantum Optimization: Hands-on Approach to Modern Quantum Algorithms},
  year={2023},
  volume={},
  number={},
  pages={},
  abstract={Work with fully explained algorithms and ready-to-use examples that can be run on quantum simulators and actual quantum computers with this comprehensive guideKey FeaturesGet a solid grasp of the principles behind quantum algorithms and optimization with minimal mathematical prerequisitesLearn the process of implementing the algorithms on simulators and actual quantum computersSolve real-world problems using practical examples of methodsBook DescriptionThis book provides deep coverage of modern quantum algorithms that can be used to solve real-world problems. You’ll be introduced to quantum computing using a hands-on approach with minimal prerequisites. You’ll discover many algorithms, tools, and methods to model optimization problems with the QUBO and Ising formalisms, and you will find out how to solve optimization problems with quantum annealing, QAOA, Grover Adaptive Search (GAS), and VQE. This book also shows you how to train quantum machine learning models, such as quantum support vector machines, quantum neural networks, and quantum generative adversarial networks. The book takes a straightforward path to help you learn about quantum algorithms, illustrating them with code that’s ready to be run on quantum simulators and actual quantum computers. You’ll also learn how to utilize programming frameworks such as IBM’s Qiskit, Xanadu’s PennyLane, and D-Wave’s Leap. Through reading this book, you will not only build a solid foundation of the fundamentals of quantum computing, but you will also become familiar with a wide variety of modern quantum algorithms. Moreover, this book will give you the programming skills that will enable you to start applying quantum methods to solve practical problems right away.What you will learnReview the basics of quantum computingGain a solid understanding of modern quantum algorithmsUnderstand how to formulate optimization problems with QUBOSolve optimization problems with quantum annealing, QAOA, GAS, and VQEFind out how to create quantum machine learning modelsExplore how quantum support vector machines and quantum neural networks work using Qiskit and PennyLaneDiscover how to implement hybrid architectures using Qiskit and PennyLane and its PyTorch interfaceWho this book is forThis book is for professionals from a wide variety of backgrounds, including computer scientists and programmers, engineers, physicists, chemists, and mathematicians. Basic knowledge of linear algebra and some programming skills (for instance, in Python) are assumed, although all mathematical prerequisites will be covered in the appendices.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781804618301},
  url={https://ieeexplore.ieee.org/document/10162421}
}

@ARTICLE{10807354,
  author={Tanaka, Tsunehiko and Simo-Serra, Edgar},
  journal={IEEE Transactions on Games}, 
  title={Grammar-based Game Description Generation using Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-14},
  abstract={Game Description Language (GDL) provides a standardized way to express diverse games in a machine-readable format, enabling automated game simulation, and evaluation. While previous research has explored game description generation using search-based methods, generating GDL descriptions from natural language remains a challenging task. This paper presents a novel framework that leverages Large Language Models (LLMs) to generate grammatically accurate game descriptions from natural language. Our approach consists of two stages: first, we gradually generate a minimal grammar based on GDL specifications; second, we iteratively improve the game description through grammar-guided generation. Our framework employs a specialized parser that identifies valid subsequences and candidate symbols from LLM responses, enabling gradual refinement of the output to ensure grammatical correctness. Experimental results demonstrate that our iterative improvement approach significantly outperforms baseline methods that directly use LLM outputs. Our code is available at https://github.com/tsunehiko/ggdg},
  keywords={Games;Grammar;Natural languages;Iterative decoding;Accuracy;Large language models;Decoding;Symbols;Evolutionary computation;Semantics;Large Language Model;Ludii;Game Description Language;Grammar;Game Description Generation},
  doi={10.1109/TG.2024.3520214},
  ISSN={2475-1510},
  month={}
}

@BOOK{10745290,
  author={Crocker, Nathan},
  booktitle={AI-Powered Developer: Build software with ChatGPT and Copilot},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Use groundbreaking generative AI tools to increase your productivity, efficiency, and code quality. AI coding tools like ChatGPT and GitHub Copilot are changing the way we write code and build software. AI-Powered Developer reveals the practical best practices you need to deliver reliable results with AI. It cuts through the hype, showcasing real-world examples of how these tools ease and enhance your everyday tasks, and make you more creative. In AI-Powered Developer you’ll discover how to get the most out of AI:  Harness AI to help you design and plan software Use AI for code generation, debugging, and documentation Improve your code quality assessments with the help of AI Articulate complex problems to prompt an AI solution Develop a continuous learning mindset that keeps you up to date Adapt your development skills to almost any language  AI coding tools give you a smart and reliable junior developer that’s fast and keen to help out with your every task and query. AI-Powered Developer helps you put your new assistant to work. You’ll learn to use AI for everything from writing boilerplate, to testing and quality assessment, managing infrastructure, delivering security, and even assisting with software design.},
  keywords={Copilot;test;ChatGPT;solutions;software design;adaptive;CodeWhisperer;fast;code generation;debugging;documentation;quality assessment;hands-on},
  doi={},
  ISSN={},
  publisher={Manning},
  isbn={9781633437616},
  url={https://ieeexplore.ieee.org/document/10745290}
}

@INPROCEEDINGS{10917407,
  author={Wang, Yaqi and Xu, Haipei},
  booktitle={2024 IEEE International Conference on Data Mining Workshops (ICDMW)}, 
  title={SRSA: A Cost-Efficient Strategy-Router Search Agent for Real-world Human-Machine Interactions}, 
  year={2024},
  volume={},
  number={},
  pages={307-316},
  abstract={Recently, as Large Language Models (LLMs) have shown impressive emerging capabilities and gained widespread popularity, research on LLM-based search agents has proliferated. In real-world situations, users often input contextual and highly personalized queries to chatbots, challenging LLMs to capture context and generate appropriate answers. However, much of the prior research has not focused specifically on authentic human-machine dialogue scenarios. It also ignores the important balance between response quality and computational cost by forcing all queries to follow the same agent process. To address these gaps, we propose a Strategy-Router Search Agent (SRSA), routing different queries to appropriate search strategies and enabling fine-grained serial searches to obtain high-quality results at a relatively low cost. To evaluate our work, we introduce a new dataset, Contextual Query Enhancement Dataset (CQED), comprising contextual queries to simulate authentic and daily interactions between humans and chatbots. Using LLM-based automatic evaluation metrics, we assessed SRSA’s performance in terms of informativeness, completeness, novelty, and actionability. To conclude, SRSA provides an approach that resolves the issue of simple serial searches leading to degenerate answers for lengthy and contextual queries, effectively and efficiently parses complex user queries, and generates more comprehensive and informative responses without fine-tuning an LLM. The code is available at https://anonymous.4open.science/r/SRSA-3A04/.},
  keywords={Measurement;Large language models;Human-machine systems;Retrieval augmented generation;Search problems;Routing;Chatbots;Information retrieval;Computational efficiency;Data mining;Retrieval-Augmented Generation;Large Language Models;Search Agent;Human-Computer Interaction;Information Retrieval},
  doi={10.1109/ICDMW65004.2024.00046},
  ISSN={2375-9259},
  month={Dec}
}

@BOOK{10163179,
  author={Tingiris, Steve and Kinsella, Bret},
  booktitle={Exploring GPT-3: An unofficial first look at the general-purpose language processing API from OpenAI},
  year={2021},
  volume={},
  number={},
  pages={},
  abstract={Get started with GPT-3 and the OpenAI API for natural language processing using JavaScript and PythonKey FeaturesUnderstand the power of potential GPT-3 language models and the risks involvedExplore core GPT-3 use cases such as text generation, classification, and semantic search using engaging examplesPlan and prepare a GPT-3 application for the OpenAI review process required for publishing a live applicationBook DescriptionGenerative Pre-trained Transformer 3 (GPT-3) is a highly advanced language model from OpenAI that can generate written text that is virtually indistinguishable from text written by humans. Whether you have a technical or non-technical background, this book will help you understand and start working with GPT-3 and the OpenAI API. If you want to get hands-on with leveraging artificial intelligence for natural language processing (NLP) tasks, this easy-to-follow book will help you get started. Beginning with a high-level introduction to NLP and GPT-3, the book takes you through practical examples that show how to leverage the OpenAI API and GPT-3 for text generation, classification, and semantic search. You'll explore the capabilities of the OpenAI API and GPT-3 and find out which NLP use cases GPT-3 is best suited for. You’ll also learn how to use the API and optimize requests for the best possible results. With examples focusing on the OpenAI Playground and easy-to-follow JavaScript and Python code samples, the book illustrates the possible applications of GPT-3 in production. By the end of this book, you'll understand the best use cases for GPT-3 and how to integrate the OpenAI API in your applications for a wide array of NLP tasks.What you will learnUnderstand what GPT-3 is and how it can be used for various NLP tasksGet a high-level introduction to GPT-3 and the OpenAI APIImplement JavaScript and Python code examples that call the OpenAI APIStructure GPT-3 prompts and options to get the best possible resultsSelect the right GPT-3 engine or model to optimize for speed and cost-efficiencyFind out which use cases would not be suitable for GPT-3Create a GPT-3-powered knowledge base application that follows OpenAI guidelinesWho this book is forExploring GPT-3 is for anyone interested in natural language processing or learning GPT-3 with or without a technical background. Developers, product managers, entrepreneurs, and hobbyists looking to get to grips with NLP, AI, and GPT-3 will find this book useful. Basic computer skills are all you need to get the most out of this book.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781800565494},
  url={https://ieeexplore.ieee.org/document/10163179}
}

@ARTICLE{10486845,
  author={McDonald, Carol and Carmicino, Bonny and Schildmeyer, Katy and Scott, Emma and Dabolina, Inga},
  journal={Position, Posture, and Pose Definitions for 3D Body Processing}, 
  title={Position, Posture, and Pose Definitions for 3D Body Processing}, 
  year={2024},
  volume={},
  number={},
  pages={1-47},
  abstract={The interchangeable use of the terms position, posture, and pose causes confusion for 3D body processing (3DBP) applications. This paper reviews current definitions and contextual use of these terms to suggest standardized nomenclature for posture and pose. This paper also reviews and discusses possible standard definitions for location, body regions, landmarks, and anatomical relationships. With large language models being central to artificial intelligence (AI), standardized terminology is imperative to all digitization efforts. Replicating, or cloning of, actual posture is a known challenge inhibiting cloned human body models, optimized virtual try-on, and critical fit assessment. 3DBP applications need to be sophisticated enough to accept and utilize unique actual postures, in a given pose, which may vary drastically from a predetermined norm. The discussion builds off of current ISO standards to an open discussion for standards toward posture-improved human body models inclusive of widely varying morphology.},
  keywords={3DBP;3D body processing;body models;definitions;pose;posture;standardized terminology;terminology},
  doi={},
  ISSN={},
  month={March}
}

@BOOK{10769390,
  author={Batista, Josué R. and Papile, Christopher},
  booktitle={Learn OpenAI Whisper: Transform your understanding of GenAI through robust and accurate speech processing solutions},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Master automatic speech recognition (ASR) with groundbreaking generative AI for unrivaled accuracy and versatility in audio processing Key FeaturesUncover the intricate architecture and mechanics behind Whisper's robust speech recognitionApply Whisper's technology in innovative projects, from audio transcription to voice synthesisNavigate the practical use of Whisper in real-world scenarios for achieving dynamic tech solutionsPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionAs the field of generative AI evolves, so does the demand for intelligent systems that can understand human speech. Navigating the complexities of automatic speech recognition (ASR) technology is a significant challenge for many professionals. This book offers a comprehensive solution that guides you through OpenAI's advanced ASR system. You’ll begin your journey with Whisper's foundational concepts, gradually progressing to its sophisticated functionalities. Next, you’ll explore the transformer model, understand its multilingual capabilities, and grasp training techniques using weak supervision. The book helps you customize Whisper for different contexts and optimize its performance for specific needs. You’ll also focus on the vast potential of Whisper in real-world scenarios, including its transcription services, voice-based search, and the ability to enhance customer engagement. Advanced chapters delve into voice synthesis and diarization while addressing ethical considerations. By the end of this book, you'll have an understanding of ASR technology and have the skills to implement Whisper. Moreover, Python coding examples will equip you to apply ASR technologies in your projects as well as prepare you to tackle challenges and seize opportunities in the rapidly evolving world of voice recognition and processing.What you will learnIntegrate Whisper into voice assistants and chatbotsUse Whisper for efficient, accurate transcription servicesUnderstand Whisper's transformer model structure and nuancesFine-tune Whisper for specific language requirements globallyImplement Whisper in real-time translation scenariosExplore voice synthesis capabilities using Whisper's robust techExecute voice diarization with Whisper and NVIDIA's NeMoNavigate ethical considerations in advanced voice technologyWho this book is forLearn OpenAI Whisper is designed for a diverse audience, including AI engineers, tech professionals, and students. It's ideal for those with a basic understanding of machine learning and Python programming, and an interest in voice technology, from developers integrating ASR in applications to researchers exploring the cutting-edge possibilities in artificial intelligence. },
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835087497},
  url={https://ieeexplore.ieee.org/document/10769390}
}

@INPROCEEDINGS{9869995,
  author={Liu, Yuntao and Zuzak, Michael and Xing, Daniel and McDaniel, Isaac and Mittu, Priya and Ozbay, Olsan and Akib, Abir and Srivastava, Ankur},
  booktitle={2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS)}, 
  title={A Survey on Side-Channel-based Reverse Engineering Attacks on Deep Neural Networks}, 
  year={2022},
  volume={},
  number={},
  pages={312-315},
  abstract={Hardware side-channels have been exploited to leak sensitive information. With the emergence of deep learning, their hardware platforms have also been scrutinized for side-channel information leakage. It has been shown that the structure, weights, and input samples of deep neural networks (DNN) can all be the victim of reverse engineering attacks that rely on side-channel information leakage. In this paper, we survey existing work on hardware side-channel-based reverse engineering attacks on DNNs as well as the countermeasures.},
  keywords={Deep learning;Circuits and systems;Reverse engineering;Neural networks;Side-channel attacks;Hardware;Resource management;Reverse Engineering;Side-Channel Attacks;Deep Neural Networks},
  doi={10.1109/AICAS54282.2022.9869995},
  ISSN={},
  month={June}
}

@BOOK{10949058,
  author={Bachlmayr, Gerald and Ziegelaar, Aiden and Blockley, Alan and Zivic, Bojan and Triantafillou, Nick},
  booktitle={Cloud Native Anti-Patterns: Avoiding Common Mistakes and Driving Success with Best Practices and Real-World Cases},
  year={2025},
  volume={},
  number={},
  pages={},
  abstract={Build a resilient, cloud-native foundation by tackling common anti-patterns head on with practical strategies, cultural shifts, and technical fixes across AWS, Azure, and GCPKey FeaturesIdentify common anti-patterns in agile cloud-native delivery and learn to adopt good habitsLearn high-performing cloud-native delivery with expert strategies and real-world examplesGet prescriptive guidance on how to spot and remediate anti-patterns in your organizationPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionSuccessfully transitioning to a cloud-native architecture demands more than just new tools—it requires a change in mindset. Written by cloud transformation experts Gerald Bachlmayr, Aiden Ziegelaar, Alan Blockley, and Bojan Zivic—each with extensive experience in cloud transformation, AWS technologies, and DevOps practices, this guide shows you how to identify and remediate cloud anti-patterns, steering your organization to become truly cloud native. You’ll start by exploring the events that shaped our understanding of the modern cloud-native stack. Through practical examples, you’ll learn how to establish a solid strategy, implement a suitable governance model, adopt FinOps practices, foster a mature DevSecOps culture, and automate security and compliance measures. For each domain, you’ll identify common anti-patterns and refactor them into best practices. The book then examines how to evolve application, data, and networking tiers from potential pitfalls into solutions that enhance business agility. You’ll also gain expert insights into observability, operations, migrations, and testing of cloud-native solutions. By the end of this book, you'll possess the knowledge to spot anti-patterns, develop effective remediation strategies, and confidently guide your organization to cloud-native success.What you will learnGet to grips with the common anti-patterns of building on and migrating to the cloudIdentify security pitfalls before they become insurmountableAcknowledge governance challenges before they become problematicDrive cultural change in your organization for cloud adoptionExplore examples across the SDLC phases and technology layersMinimize the operational risk of releases using powerful deployment strategiesRefactor or migrate a solution from an anti-pattern to a best practice designEffectively adopt supply chain security practicesWho this book is forThis book is for cloud professionals with any level of experience who want to deepen their knowledge and guide their organization toward cloud-native success. It is Ideal for cloud architects, engineers (cloud, software, data, or network), cloud security experts, technical leaders, and cloud operations personnel. While no specific expertise is required, a background in architecture, software development, data, networks, operations, or governance will be helpful. },
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781836200581},
  url={https://ieeexplore.ieee.org/document/10949058}
}

@BOOK{10162713,
  author={Jha, Ashish Ranjan and Pillai, Dr. Gopinath},
  booktitle={Mastering PyTorch: Build powerful neural network architectures using advanced PyTorch 1.x features},
  year={2021},
  volume={},
  number={},
  pages={},
  abstract={Master advanced techniques and algorithms for deep learning with PyTorch using real-world examplesKey FeaturesUnderstand how to use PyTorch 1.x to build advanced neural network modelsLearn to perform a wide range of tasks by implementing deep learning algorithms and techniquesGain expertise in domains such as computer vision, NLP, Deep RL, Explainable AI, and much moreBook DescriptionDeep learning is driving the AI revolution, and PyTorch is making it easier than ever before for anyone to build deep learning applications. This PyTorch book will help you uncover expert techniques to get the most out of your data and build complex neural network models. The book starts with a quick overview of PyTorch and explores using convolutional neural network (CNN) architectures for image classification. You'll then work with recurrent neural network (RNN) architectures and transformers for sentiment analysis. As you advance, you'll apply deep learning across different domains, such as music, text, and image generation using generative models and explore the world of generative adversarial networks (GANs). You'll not only build and train your own deep reinforcement learning models in PyTorch but also deploy PyTorch models to production using expert tips and techniques. Finally, you'll get to grips with training large models efficiently in a distributed manner, searching neural architectures effectively with AutoML, and rapidly prototyping models using PyTorch and fast.ai. By the end of this PyTorch book, you'll be able to perform complex deep learning tasks using PyTorch to build smart artificial intelligence models.What you will learnImplement text and music generating models using PyTorchBuild a deep Q-network (DQN) model in PyTorchExport universal PyTorch models using Open Neural Network Exchange (ONNX)Become well-versed with rapid prototyping using PyTorch with fast.aiPerform neural architecture search effectively using AutoMLEasily interpret machine learning (ML) models written in PyTorch using CaptumDesign ResNets, LSTMs, Transformers, and more using PyTorchFind out how to use PyTorch for distributed training using the torch.distributed APIWho this book is forThis book is for data scientists, machine learning researchers, and deep learning practitioners looking to implement advanced deep learning paradigms using PyTorch 1.x. Working knowledge of deep learning with Python programming is required.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781789616408},
  url={https://ieeexplore.ieee.org/document/10162713}
}

@BOOK{10251209,
  author={Webber, Emily and Olgiati, Andrea},
  booktitle={Pretrain Vision and Large Language Models in Python: End-to-end techniques for building and deploying foundation models on AWS},
  year={2023},
  volume={},
  number={},
  pages={},
  abstract={Master the art of training vision and large language models with conceptual fundaments and industry-expert guidance. Learn about AWS services and design patterns, with relevant coding examplesKey FeaturesLearn to develop, train, tune, and apply foundation models with optimized end-to-end pipelinesExplore large-scale distributed training for models and datasets with AWS and SageMaker examplesEvaluate, deploy, and operationalize your custom models with bias detection and pipeline monitoringBook DescriptionFoundation models have forever changed machine learning. From BERT to ChatGPT, CLIP to Stable Diffusion, when billions of parameters are combined with large datasets and hundreds to thousands of GPUs, the result is nothing short of record-breaking. The recommendations, advice, and code samples in this book will help you pretrain and fine-tune your own foundation models from scratch on AWS and Amazon SageMaker, while applying them to hundreds of use cases across your organization. With advice from seasoned AWS and machine learning expert Emily Webber, this book helps you learn everything you need to go from project ideation to dataset preparation, training, evaluation, and deployment for large language, vision, and multimodal models. With step-by-step explanations of essential concepts and practical examples, you’ll go from mastering the concept of pretraining to preparing your dataset and model, configuring your environment, training, fine-tuning, evaluating, deploying, and optimizing your foundation models. You will learn how to apply the scaling laws to distributing your model and dataset over multiple GPUs, remove bias, achieve high throughput, and build deployment pipelines. By the end of this book, you’ll be well equipped to embark on your own project to pretrain and fine-tune the foundation models of the future.What you will learnFind the right use cases and datasets for pretraining and fine-tuningPrepare for large-scale training with custom accelerators and GPUsConfigure environments on AWS and SageMaker to maximize performanceSelect hyperparameters based on your model and constraintsDistribute your model and dataset using many types of parallelismAvoid pitfalls with job restarts, intermittent health checks, and moreEvaluate your model with quantitative and qualitative insightsDeploy your models with runtime improvements and monitoring pipelinesWho this book is forIf you’re a machine learning researcher or enthusiast who wants to start a foundation modelling project, this book is for you. Applied scientists, data scientists, machine learning engineers, solution architects, product managers, and students will all benefit from this book. Intermediate Python is a must, along with introductory concepts of cloud computing. A strong understanding of deep learning fundamentals is needed, while advanced topics will be explained. The content covers advanced machine learning and cloud techniques, explaining them in an actionable, easy-to-understand way.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781804612545},
  url={https://ieeexplore.ieee.org/document/10251209}
}

@ARTICLE{9506866,
  author={Yang, Jian and Zhang, Qi and Jiang, Xiaofeng and Chen, Shuangwu and Yang, Feng},
  journal={IEEE Transactions on Dependable and Secure Computing}, 
  title={Poirot: Causal Correlation Aided Semantic Analysis for Advanced Persistent Threat Detection}, 
  year={2022},
  volume={19},
  number={5},
  pages={3546-3563},
  abstract={The volatile, covert and slow multistage attack patterns of Advanced Persistent Threat (APT) present a tricky challenge of APT detection, which are vital for organisations to protect their critical assets. In this article, we aim to develop system that aggregates and uses existing systems’ alerts to detect APTs. In order to achieve this, we propose a causal correlation aided semantic analysis system, called Poirot, for detecting the multi-stage threats over a long-time span from existing systems’ alerts. Poirot is capable of autonomously mining causality between anomalous events, which instructs us in reorganizing the original alerts and in constructing alert-chains. The system further exploits the Latent Dirichlet Allocation (LDA) to model the semantic context of the alert-chains. This LDA model facilitates us to carry out the semantic analysis for capturing the latent attack intent as well as for reconstructing the APT scenario. We use an alert dataset provided by a cyber security company to verify the proposed Poirot in terms of the detection accuracy and the capability of attack scenario reconstruction. The experiment results are presented to show the achievable performance of the proposed semantic analysis based APT detection.},
  keywords={Semantics;Correlation;Inference algorithms;Tools;Support vector machines;Resource management;Integrated circuit modeling;Advanced persistent threat;alert-chain;causality analysis;average causal effect;latent Dirichlet allocation},
  doi={10.1109/TDSC.2021.3101649},
  ISSN={1941-0018},
  month={Sep.}
}

@INPROCEEDINGS{9207576,
  author={Szuba, Tadeusz and Sztuba, Danuta},
  booktitle={2020 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Can Adam Smith’s Invisible Hand phenomenon be used for the analysis of Fourth Estate’s impact and behavior?}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  abstract={Paper presents research conducted in order to understand why neural networks from Evolution point of view are developing in such a strange way. When observing development of species, development of consistent neural network is always stopped on certain level and is continued as development of distributed, cooperating neural networks. Such networks are organized into social structures. Adam Smith's Invisible Hand (ASIH) phenomena emerges here as key factor to understand this. ASIH is perceived here as meta-computational process on platform of local neural networks, hosted by agents. ASIH theoretically is able to provide self-regulation for social structures, better than any centralized structure (dictator, government, authority) can do. Contrary to deterministic computational processes in today's digital computers, the computational processes that are behind Invisible Hand are: unconscious, nondeterministic, multithread, chaotic and non-continuous. This research methodology has provided astonishing results: . Understanding of Elementary Invisible Hand, which is ruling so efficiently anthill. On this basis Artificial Invisible Hand can be derived to provide self-control of teams of AI mobile robots for situations when human-supervisor cannot assist them or management is too complicated; . Invisible Hand applied to problem of understanding the Fourth (4th) Estate allowed, for the first time, to point to very clear, well visible real (not abstract) case of Invisible Hand; . The 4th Estate on the platform of modern electronic media (MEM) emerges as a new worldwide governing superpower.},
  keywords={Bridges;Media;Biological neural networks;Economics;Companies;Artificial intelligence;Evolution of neural networks;Adam Smith’s Invisible Hand (ASIH);Fourth (4th) Estate;self-regulation;meta-computational process;modern electronic media (MEM)},
  doi={10.1109/IJCNN48605.2020.9207576},
  ISSN={2161-4407},
  month={July}
}

@BOOK{10163570,
  author={Mueller, John Paul and Stephens, Rod},
  booktitle={Machine Learning Security Principles: Keep data, networks, users, and applications safe from prying eyes},
  year={2022},
  volume={},
  number={},
  pages={},
  abstract={Thwart hackers by preventing, detecting, and misdirecting access before they can plant malware, obtain credentials, engage in fraud, modify data, poison models, corrupt users, eavesdrop, and otherwise ruin your dayKey FeaturesDiscover how hackers rely on misdirection and deep fakes to fool even the best security systemsRetain the usefulness of your data by detecting unwanted and invalid modificationsDevelop application code to meet the security requirements related to machine learningBook DescriptionBusinesses are leveraging the power of AI to make undertakings that used to be complicated and pricy much easier, faster, and cheaper. The first part of this book will explore these processes in more depth, which will help you in understanding the role security plays in machine learning. As you progress to the second part, you’ll learn more about the environments where ML is commonly used and dive into the security threats that plague them using code, graphics, and real-world references. The next part of the book will guide you through the process of detecting hacker behaviors in the modern computing environment, where fraud takes many forms in ML, from gaining sales through fake reviews to destroying an adversary’s reputation. Once you’ve understood hacker goals and detection techniques, you’ll learn about the ramifications of deep fakes, followed by mitigation strategies. This book also takes you through best practices for embracing ethical data sourcing, which reduces the security risk associated with data. You’ll see how the simple act of removing personally identifiable information (PII) from a dataset lowers the risk of social engineering attacks. By the end of this machine learning book, you'll have an increased awareness of the various attacks and the techniques to secure your ML systems effectively.What you will learnExplore methods to detect and prevent illegal access to your systemImplement detection techniques when access does occurEmploy machine learning techniques to determine motivationsMitigate hacker access once security is breachedPerform statistical measurement and behavior analysisRepair damage to your data and applicationsUse ethical data collection methods to reduce security risksWho this book is forWhether you’re a data scientist, researcher, or manager working with machine learning techniques in any aspect, this security book is a must-have. While most resources available on this topic are written in a language more suitable for experts, this guide presents security in an easy-to-understand way, employing a host of diagrams to explain concepts to visual learners. While familiarity with machine learning concepts is assumed, knowledge of Python and programming in general will be useful.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781804615409},
  url={https://ieeexplore.ieee.org/document/10163570}
}

@BOOK{10522530,
  author={Roy, Ankur},
  booktitle={Hands-On Python for DevOps: Leverage Python's native libraries to streamline your workflow and save time with automation},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Unleash DevOps excellence with Python and its ecosystem of tools for seamless orchestration on both local and cloud platforms, such as GCP, AWS, and AzureKey FeaturesIntegrate Python into DevOps for streamlined workflows, task automation, and improved collaborationCombine the principles of Python and DevOps into a unified approach for problem solvingLearn about Python’s role in Infrastructure as Code (IaC), MLOps, networking, and other domainsPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionPython stands out as a powerhouse in DevOps, boasting unparalleled libraries and support, which makes it the preferred programming language for problem solvers worldwide. This book will help you understand the true flexibility of Python, demonstrating how it can be integrated into incredibly useful DevOps workflows and workloads, through practical examples. You'll start by understanding the symbiotic relation between Python and DevOps philosophies and then explore the applications of Python for provisioning and manipulating VMs and other cloud resources to facilitate DevOps activities. With illustrated examples, you’ll become familiar with automating DevOps tasks and learn where and how Python can be used to enhance CI/CD pipelines. Further, the book highlights Python’s role in the Infrastructure as Code (IaC) process development, including its connections with tools like Ansible, SaltStack, and Terraform. The concluding chapters cover advanced concepts such as MLOps, DataOps, and Python’s integration with generative AI, offering a glimpse into the areas of monitoring, logging, Kubernetes, and more. By the end of this book, you’ll know how to leverage Python in your DevOps-based workloads to make your life easier and save time.What you will learnImplement DevOps practices and principles using PythonEnhance your DevOps workloads with PythonCreate Python-based DevOps solutions to improve your workload efficiencyUnderstand DevOps objectives and the mindset needed to achieve themUse Python to automate DevOps tasks and increase productivityExplore the concepts of DevSecOps, MLOps, DataOps, and moreUse Python for containerized workloads in Docker and KubernetesWho this book is forThis book is for IT professionals venturing into DevOps, particularly programmers seeking to apply their existing programming knowledge to excel in this field. For DevOps professionals without a coding background, this book serves as a resource to enhance their understanding of development practices and communicate more effectively with developers. Solutions architects, programmers, and anyone regularly working with DevOps solutions and Python will also benefit from this hands-on guide.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835081495},
  url={https://ieeexplore.ieee.org/document/10522530}
}

@BOOK{10260289,
  author={Khuat, Thanh Tung and Kedziora, David Jacob and Gabrys, Bogdan},
  booktitle={The Roles and Modes of Human Interactions with Automated Machine Learning Systems: A Critical Review and Perspectives},
  year={2023},
  volume={},
  number={},
  pages={},
  abstract={Recent years have seen an unprecedented level of technological uptake and engagement by the mainstream. From deepfakes for memes to recommendation systems for commerce, machine learning (ML) has become a regular fixture in society. This ongoing transition from purely academic confines to the general public is not smooth as the public does not have the extensive expertise in data science required to fully exploit the capabilities of ML. As automated machine learning (AutoML) systems continue to progress in both sophistication and performance, it becomes important to understand the ‘how’ and ‘why’ of human-computer interaction (HCI) within these frameworks. This is necessary for optimal system design and leveraging advanced data-processing capabilities to support decision-making involving humans. It is also key to identifying the opportunities and risks presented by ever-increasing levels of machine autonomy. In this monograph, the authors focus on the following questions: (i) What does HCI currently look like for state-of-the-art AutoML algorithms? (ii) Do the expectations of HCI within AutoML frameworks vary for different types of users and stakeholders? (iii) How can HCI be managed so that AutoML solutions acquire human trust and broad acceptance? (iv) As AutoML systems become more autonomous and capable of learning from complex open-ended environments, will the fundamental nature of HCI evolve? To consider these questions, the authors project existing literature in HCI into the space of AutoML and review topics such as user-interface design, human-bias mitigation, and trust in artificial intelligence (AI). Additionally, to rigorously gauge the future of HCI, they contemplate how AutoML may manifest in effectively open-ended environments. Ultimately, this review serves to identify key research directions aimed at better facilitating the roles and modes of human interactions with both current and future AutoML systems.},
  keywords={},
  doi={},
  ISSN={},
  publisher={now},
  isbn={9781638282693},
  url={https://ieeexplore.ieee.org/document/10260289}
}

@INPROCEEDINGS{10298592,
  author={Li, Linyu and Xu, Sihan and Liu, Yang and Gao, Ya and Cai, Xiangrui and Wu, Jiarun and Song, Wenli and Liu, Zheli},
  booktitle={2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={LiSum: Open Source Software License Summarization with Multi-Task Learning}, 
  year={2023},
  volume={},
  number={},
  pages={787-799},
  abstract={Open source software (OSS) licenses regulate the conditions under which users can reuse, modify, and distribute the software legally. However, there exist various OSS licenses in the community, written in a formal language, which are typically long and complicated to understand. In this paper, we conducted a 661-participants online survey to investigate the perspectives and practices of developers towards OSS licenses. The user study revealed an indeed need for an automated tool to facilitate license understanding. Motivated by the user study and the fast growth of licenses in the community, we propose the first study towards automated license summarization. Specifically, we released the first high quality text summarization dataset and designed two tasks, i.e., license text summarization (LTS), aiming at generating a relatively short summary for an arbitrary license, and license term classification (LTC), focusing on the attitude inference towards a predefined set of key license terms (e.g., Distribute). Aiming at the two tasks, we present LiSum, a multi-task learning method to help developers overcome the obstacles of understanding OSS licenses. Comprehensive experiments demonstrated that the proposed jointly training objective boosted the performance on both tasks, surpassing state-of-the-art baselines with gains of at least 5 points w.r.t. F1 scores of four summarization metrics and achieving 95.13% micro average F1 score for classification simultaneously. We released all the datasets, the replication package, and the questionnaires for the community.},
  keywords={Training;Measurement;Learning systems;Surveys;Formal languages;Licenses;Multitasking;Open Source Software Licenses;Multi-Task Learning;License comprehension},
  doi={10.1109/ASE56229.2023.00150},
  ISSN={2643-1572},
  month={Sep.}
}

@ARTICLE{10759678,
  author={Cheng, Yujun and Zhang, Weiting and Zhang, Zhewei and Zhang, Chuan and Wang, Shengjin and Mao, Shiwen},
  journal={IEEE Communications Surveys & Tutorials}, 
  title={Towards Federated Large Language Models: Motivations, Methods, and Future Directions}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  abstract={Large Language Models (LLMs), such as LLaMA and GPT-4, have transformed the paradigm of natural language comprehension and generation. Despite their impressive performance, these models still face certain challenges, including the need for extensive data, high computational resources, and privacy concerns related to their data sources. Recently, Federated Learning (FL) has surfaced as a cooperative AI methodology that enables AI training across distributed computation entities while maintaining decentralized data. Integrating FL with LLMs presents an encouraging solution for privacy-preserving and collaborative LLM learning across multiple end-users, thus addressing the aforementioned challenges. In this paper, we provide an exhaustive review of federated Large Language Models, starting from an overview of the latest progress in FL and LLMs, and proceeding to a discourse on their motivation and challenges for integration. We then conduct a thorough review of the existing federated LLM research from the perspective of the entire lifespan, from pre-training to fine-tuning and practical applications. Moreover, we address the threats and issues arising from this integration, shedding light on the delicate balance between privacy and robustness, and introduce existing approaches and potential strategies for enhancing federated LLM privacy and resilience. Finally, we conclude this survey by outlining promising avenues for future research in this emerging field.},
  keywords={Privacy;Surveys;Data models;Computational modeling;Training;Artificial intelligence;Security;Robustness;Reviews;Federated learning;Federated Learning;Large Language Model;Foundation model;Privacy},
  doi={10.1109/COMST.2024.3503680},
  ISSN={1553-877X},
  month={}
}

@BOOK{10769280,
  author={Harley, Maurício},
  booktitle={Pentesting APIs: A practical guide to discovering, fingerprinting, and exploiting APIs},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Learn the essential steps to successfully identify and leverage API endpoints with a sequenced and structured approachKey FeaturesGain detailed insights into vulnerabilities and attack vectors for RESTful and GraphQL APIsFollow practical advice and best practices for securing APIs against potential threatsExplore essential security topics, potential vulnerabilities, common attack vectors, and the overall API security landscapePurchase of the print or Kindle book includes a free PDF eBookBook DescriptionUnderstanding API security is crucial as APIs form the backbone of modern interconnected applications, making them prime targets for cyberattacks. Drawing on nearly 30 years of cybersecurity experience and an extensive background in network security and forensic analysis, this book provides the knowledge and tools to strengthen your API security practices and protect against cyber threats comprehensively. This book begins by establishing a foundational understanding of APIs, particularly focusing on REST and GraphQL, emphasizing their critical role and potential security vulnerabilities. It guides you through setting up a penetration testing environment to ensure the practical application of concepts. You’ll learn reconnaissance techniques, information-gathering strategies, and the discovery of API vulnerabilities. Authentication and authorization testing are thoroughly explored, covering mechanisms, weaknesses, and methods to bypass security controls. By comprehensively addressing these aspects, the book equips you to understand, identify, and mitigate risks, strengthening API security and effectively minimizing potential attack surfaces. By the end of this book, you’ll have developed practical skills to identify, exploit, and secure APIs against various vulnerabilities and attacks.What you will learnGet an introduction to APIs and their relationship with securitySet up an effective pentesting lab for API intrusionConduct API reconnaissance and information gathering in the discovery phaseExecute basic attacks such as injection, exception handling, and DoSPerform advanced attacks, including data exposure and business logic abuseBenefit from expert security recommendations to protect APIs against attacksWho this book is forThis book is for security engineers, particularly those focused on application security, as well as security analysts, application owners, web developers, pentesters, and all curious enthusiasts who want to learn about APIs, effective testing methods for their robustness, and how to protect them against cyber attacks. Basic knowledge of web development, familiarity with API concepts, and a foundational understanding of cybersecurity principles will help you get started with this book.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781837639731},
  url={https://ieeexplore.ieee.org/document/10769280}
}

@ARTICLE{10132377,
  author={Wang, James Z. and Zhao, Sicheng and Wu, Chenyan and Adams, Reginald B. and Newman, Michelle G. and Shafir, Tal and Tsachor, Rachelle},
  journal={Proceedings of the IEEE}, 
  title={Unlocking the Emotional World of Visual Media: An Overview of the Science, Research, and Impact of Understanding Emotion}, 
  year={2023},
  volume={111},
  number={10},
  pages={1236-1286},
  abstract={The emergence of artificial emotional intelligence technology is revolutionizing the fields of computers and robotics, allowing for a new level of communication and understanding of human behavior that was once thought impossible. While recent advancements in deep learning have transformed the field of computer vision, automated understanding of evoked or expressed emotions in visual media remains in its infancy. This foundering stems from the absence of a universally accepted definition of “emotion,” coupled with the inherently subjective nature of emotions and their intricate nuances. In this article, we provide a comprehensive, multidisciplinary overview of the field of emotion analysis in visual media, drawing on insights from psychology, engineering, and the arts. We begin by exploring the psychological foundations of emotion and the computational principles that underpin the understanding of emotions from images and videos. We then review the latest research and systems within the field, accentuating the most promising approaches. We also discuss the current technological challenges and limitations of emotion analysis, underscoring the necessity for continued investigation and innovation. We contend that this represents a “Holy Grail” research problem in computing and delineate pivotal directions for future inquiry. Finally, we examine the ethical ramifications of emotion-understanding technologies and contemplate their potential societal impacts. Overall, this article endeavors to equip readers with a deeper understanding of the domain of emotion analysis in visual media and to inspire further research and development in this captivating and rapidly evolving field.},
  keywords={Visualization;Emotion recognition;Behavioral sciences;Psychology;Media;Videos;Ethics;Affective computing;Deep learning;Human factors;Artificial emotional intelligence (AEI);bodily expressed emotion understanding (BEEU);deep learning;ethics;evoked emotion;expressed emotion;human behavior;intelligent robots;movement analysis;psychology},
  doi={10.1109/JPROC.2023.3273517},
  ISSN={1558-2256},
  month={Oct}
}

@ARTICLE{8465996,
  author={Mathew, George and Agrawal, Amritanshu and Menzies, Tim},
  journal={IEEE Transactions on Software Engineering}, 
  title={Finding Trends in Software Research}, 
  year={2023},
  volume={49},
  number={4},
  pages={1397-1410},
  abstract={Text mining methods can find large scale trends within research communities. For example, using stable Latent Dirichlet Allocation (a topic modeling algorithm) this study found 10 major topics in 35,391 SE research papers from 34 leading SE venues over the last 25 years (divided, evenly, between conferences and journals). Out study also shows how those topics have changed over recent years. Also, we note that (in the historical record) mono-focusing on a single topic can lead to fewer citations than otherwise. Further, while we find no overall gender bias in SE authorship, we note that women are under-represented in the top-most cited papers in our field. Lastly, we show a previously unreported dichotomy between software conferences and journals (so research topics that succeed at conferences might not succeed at journals, and vice versa). An important aspect of this work is that it is automatic and quickly repeatable (unlike prior SE bibliometric studies that used tediously slow and labor intensive methods). Automation is important since, like any data mining study, its conclusions are skewed by the data used in the analysis. The automatic methods of this paper make it far easier for other researchers to re-apply the analysis to new data, or if they want to use different modeling assumptions.},
  keywords={Software engineering;Conferences;Software;Analytical models;Data models;Predictive models;Testing;Software engineering;bibliometrics;topic modeling;text mining},
  doi={10.1109/TSE.2018.2870388},
  ISSN={1939-3520},
  month={April}
}

@ARTICLE{8611359,
  author={PRIETO, ALVARO E. and Mazón, Jose-Norberto and Lozano-Tello, Adolfo},
  journal={IEEE Transactions on Emerging Topics in Computing}, 
  title={Framework for Prioritization of Open Data Publication: An Application to Smart Cities}, 
  year={2021},
  volume={9},
  number={1},
  pages={131-143},
  abstract={Public Sector Information is considered to play a fundamental role in the growth of the knowledge economy and improvements in society. Given the difficulty in publishing and maintaining all available data, due to budget constraints, institutions need to select which data to publish, giving priority to data most likely to generate social and economic impact. Priority of publication could become an even more significant problem in Smart Cities: as huge amounts of information are generated from different domains, the way data is prioritized and thus reused, could be a determining factor in promoting, among others, new and sustainable business opportunities for local entrepreneurs, and to improve citizen quality of life. However, people in charge of prioritizing which data to publish through open data portals (such as Chief Data Officers, or CDOs) do not have available any specific support in their decision-making process. In this work, a proposal of a framework for prioritization of open data publication as well as its application to Smart Cities is presented. This specific application of the framework relies on OSS (Open Source Software) indicators to help making decisions on the most relevant data to publish focused on developers and businesses operating within the Smart City context.},
  keywords={Smart cities;Portals;II-VI semiconductor materials;Cadmium compounds;Decision making;Economics;Publishing;Decision support;dataset reuse indicators;open data;smart city application},
  doi={10.1109/TETC.2019.2893016},
  ISSN={2168-6750},
  month={Jan}
}

@ARTICLE{9224250,
  author={},
  journal={IEEE P2675/D2, October 2020}, 
  title={IEEE Draft Standard for DevOps: Building Reliable and Secure Systems Including Application Build, Package and Deployment}, 
  year={2020},
  volume={},
  number={},
  pages={1-93},
  abstract={Technical principles and processes to build, package, and deploy systems and applications in a reliable and secure way are specified. Establishing effective compliance and information technology (IT) controls is the focus. DevOps principles presented include mission first, customer focus, left-shift, continuous everything, and systems thinking. How stakeholders, including developers and operations staff, can collaborate and communicate effectively is described. The process outcomes and activities herein are aligned with the process model specified in ISO/IEC/IEEE 12207:2017 and ISO/IEC/IEEE 15288:2015.},
  keywords={IEEE Standards;IEC Standards;ISO Standards;Software engineering;Product life cycle management;Information technology;Stakeholders;Security;Systems thinking;agile;continuous delivery;continuous deployment;continuous integration;DevOps;IEEE 2675;left-shift},
  doi={},
  ISSN={},
  month={Oct}
}

@ARTICLE{10713347,
  author={Guo, Yuan and Liu, Ziqi},
  journal={IEEE Access}, 
  title={Coverless Steganography for Face Recognition Based on Diffusion Model}, 
  year={2024},
  volume={12},
  number={},
  pages={148770-148782},
  abstract={As a highly recognizable biometric face recognition technology, it has been widely used in many identity verification systems. In order to enhance the protection of personal privacy and ensure the safe transmission and sharing of sensitive information without affecting the user experience, this paper proposes an innovative coverless steganography framework for face recognition images based on diffusion model. The framework firstly extracts face features and generates masks containing these features. Then, combined with conditional diffusion model and text key, a deterministic Denoising Diffusion Implicit Model (DDIM) is used to sample coverless steganography images. Secret images can also be recovered in high quality with DDIM Inversion technology. A large number of experiments show that compared with the existing methods, this approach has markedly enhanced the quality of steganographic and restored images. The face recognition rate of the restored image is more than 96%, which can effectively replace the original image for face recognition. The detection accuracy of this method is 55.25% on the steganographic detection tool, which is closer to random guessing and can resist steganographic analysis. It ensures the higher security of hidden images and solves the limitation of existing methods in protecting the privacy of face images. Moreover, it is shown how to achieve controlled local steganography with a custom mask, which enhances the controllability and flexibility of the method. In conclusion, the proposed method outperforms traditional steganography in security, controllability and robustness, and provides an effective technical scheme for steganography protection of face recognition images without additional training.},
  keywords={Steganography;Face recognition;Diffusion models;Security;Noise measurement;Robustness;Image restoration;Image recognition;Visualization;Noise reduction;Biometrics (access control);Face recognition;coverless steganography;diffusion model;DDIM},
  doi={10.1109/ACCESS.2024.3477469},
  ISSN={2169-3536},
  month={}
}

@INPROCEEDINGS{10692304,
  author={Kanjalkar, Jyoti and Talele, Ajay and Kanjalkar, Pramod and Dhobale, Harshada and Gavali, Shrushti and Pimple, Akhilesh and Waghmare, Nikita},
  booktitle={2024 2nd World Conference on Communication & Computing (WCONF)}, 
  title={Random Pixel Embedding: A Novel Approach to Image Steganography}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={This project presents a novel approach to image steganography titled “Random Pixel Embedding: A Novel Approach to Image Steganography.” Steganography, the art of concealing information within an innocuous carrier, finds widespread applications in secure communication and data protection. Our method employs a combination of LSB (Least Significant Bit) steganography, random pixel selection and AES (Advanced Encryption Standard) encryption to embed secret messages into digital images securely. The Tkinter library was used to create the system's user-friendly graphical user interface, which makes encoding and decoding processes easier. Additionally, it enhances the security of message encryption by incorporating PBKDF2 (Password-Based Key Derivation Function 2) for deriving cryptographic keys. By using this method, the project hopes to advance the fields of secure communication and data security by providing a reliable and effective way to conceal important information from view. The experimental results show that the suggested algorithm is reliable and effective, underscoring its potential for practical uses in data security and secure communication channels.},
  keywords={Steganography;Visualization;Digital images;Inspection;Libraries;Encryption;Reliability;Standards;Resilience;Graphical user interfaces;image steganography;random pixel;embedding algorithm;lsb steganography;aes encryption;pbkdf2;data security;secure communication;cryptography;information hiding},
  doi={10.1109/WCONF61366.2024.10692304},
  ISSN={},
  month={July}
}

@INPROCEEDINGS{10829177,
  author={Kotagi, Veeranna and Nassa, Vinay Kumar and Patil, Dipti and Gadhave, Rajashree and Adusumilli, Sri Bhargav Krishna and Kumar, Pitcheri Praveen},
  booktitle={2024 7th International Conference on Contemporary Computing and Informatics (IC3I)}, 
  title={Ensuring Dataset Accountability in Machine Learning: Insights from Software Engineering}, 
  year={2024},
  volume={7},
  number={},
  pages={385-389},
  abstract={Machine learning is facing a crisis of accountability. On some tasks, deep learning can match or surpass human performance. It is extensive This work may be reproduced in whole or in part, for educational or personal purposes, in hard copy or digital format without monetary compensation as long as copies are made or distributed for non-commercial purposes and carry this notice and the whole citation on the first page. Conversely, the datasets that are crucial to machine learning (ML) are typically produced using opaque creation processes, poor maintenance, poor documentation, and a lack of answerability, which frequently results in errors. The study focused on several problems related to software engineering tasks, including performance evaluation metrics, software metrics, failure prediction, and problems with data quality. The paper draws attention to many methodological problems and difficulties associated with these software fault prediction tasks. Feature extraction and classification are commonly used to explore the excessive dimensionality of data and data class imbalance linked to software quality issues.},
  keywords={Support vector machines;Performance evaluation;Electric breakdown;Software quality;Documentation;Feature extraction;Maintenance;Software measurement;Informatics;Software engineering;Dataset;Accountability;Machine Learning;Software Engineering},
  doi={10.1109/IC3I61595.2024.10829177},
  ISSN={},
  month={Sep.}
}

@ARTICLE{9346094,
  author={},
  journal={IEEE P2857/D3, October 2020}, 
  title={IEEE Approved Draft Standard for Wireless Smart Utility Network Field Area Network (FAN)}, 
  year={2021},
  volume={},
  number={},
  pages={1-177},
  abstract={This document describes a complete communications specification, encompassing layers 1 to 4 of the Open Systems Integration (OSI) network model, for a secure, wireless mesh communications network, using open standards communications and cybersecurity standards from standards organizations including Institute of Electrical and Electronics Engineers (IEEE) and Internet Engineering Task Force (IETF). The specification describes the functionality of the physical (PHY layer), medium access control (MAC layer), the network layer, transport layer and security parameters including certificate format for a highly scaleable and secure wireless mesh network for critical infrastructure ipv6 wireless communications networks.},
  keywords={IEEE Standards;Wireless communication;Open systems;Communication system security;Wireless mesh networks;Wireless networks;Physical layer;adoption;FAN;field area network;IEEE 2857;Internet of Things;IoT;OSI;smart city;smart utility network;Wi-SUN;wireless mesh},
  doi={},
  ISSN={},
  month={June}
}

@ARTICLE{9353440,
  author={},
  journal={IEEE P2675/D2, October 2020}, 
  title={IEEE Approved Draft Standard for DevOps: Building Reliable and Secure Systems Including Application Build, Package and Deployment}, 
  year={2021},
  volume={},
  number={},
  pages={1-93},
  abstract={Technical principles and processes to build, package, and deploy systems and applications in a reliable and secure way are specified. Establishing effective compliance and information technology (IT) controls is the focus. DevOps principles presented include mission first, customer focus, left-shift, continuous everything, and systems thinking. How stakeholders, including developers and operations staff, can collaborate and communicate effectively is described. The process outcomes and activities herein are aligned with the process model specified in ISO/IEC/IEEE 12207:2017 and ISO/IEC/IEEE 15288:2015.},
  keywords={IEEE Standards;Security;Reliability;Packaging;agile;continuous delivery;continuous deployment;continuous integration;DevOps;IEEE 2675;left-shift},
  doi={},
  ISSN={},
  month={Feb}
}

@ARTICLE{10926495,
  author={Gao, Zhirui and Yi, Renjiao and Zhu, Chenyang and Zhuang, Ke and Chen, Wei and Xu, Kai},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Generic Objects as Pose Probes for Few-shot View Synthesis}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Radiance fields, including NeRFs and 3D Gaussians, demonstrate great potential in high-fidelity rendering and scene reconstruction, while they require a substantial number of posed images as input. COLMAP is frequently employed for preprocessing to estimate poses. However, COLMAP necessitates a large number of feature matches to operate effectively, and struggles with scenes characterized by sparse features, large baselines, or few-view images. We aim to tackle few-view NeRF reconstruction using only 3 to 6 unposed scene images, freeing from COLMAP initializations. Inspired by the idea of calibration boards in traditional pose calibration, we propose a novel approach of utilizing everyday objects, commonly found in both images and real life, as “pose probes”. By initializing the probe object as a cube shape, we apply a dual-branch volume rendering optimization (object NeRF and scene NeRF) to constrain the pose optimization and jointly refine the geometry. PnP matching is used to initialize poses between images incrementally, where only a few feature matches are enough. PoseProbe achieves state-of-the-art performance in pose estimation and novel view synthesis across multiple datasets in experiments. We demonstrate its effectiveness, particularly in few-view and large-baseline scenes where COLMAP struggles. In ablations, using different objects in a scene yields comparable performance, showing that PoseProbe is robust to the choice of probe objects. Our project page is available at: https://zhirui-gao.github.io/PoseProbe.github.io/.},
  keywords={Probes;Cameras;Rendering (computer graphics);Neural radiance field;Optimization;Geometry;Pose estimation;Image reconstruction;Accuracy;Training;Neural radiance fields;few-view reconstruction;pose optimization;pose probe},
  doi={10.1109/TCSVT.2025.3551303},
  ISSN={1558-2205},
  month={}
}

@ARTICLE{10891521,
  author={Bian, Dongze and Liu, Jingmei},
  journal={IEEE Internet of Things Journal}, 
  title={GMCWAE: A Representation Learning Technique for Network Intrusion Detection in IoT}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={In the context of the Internet of Things (IoT), edge nodes often face constraints in computational and storage resources, making dimensionality reduction of high-dimensional raw traffic essential to alleviate the device burden. However, current Representation Learning (RL) methods struggle to extract meaningful features from such data, leading to reduced accuracy in network intrusion detection (NID). To address this challenge, we propose the Gaussian Mixture Cramer-Wold Auto-Encoder (GMCWAE), designed to learn low-dimensional representations of network traffic that are both interpretable and discriminative, thereby enhancing the detection performance of classifiers. Furthermore, we integrate the lightweight ensemble learning method Light Gradient Boosting Machine (LightGBM) for detecting intrusive traffic. A comprehensive evaluation of the multiclass classification performance was conducted using three benchmark datasets: NSL-KDD, UNSW-NB15, and CIC-IoT 2023. Compared to existing supervised dimensionality reduction methods, the low-dimensional representations learned by GMCWAE across the three datasets achieved higher accuracy and F1-scores across all classifiers used. And the proposed NID method achieved accuracies of 83.1%, 81.1%, and 97.62% across the three datasets, showing strong competitiveness compared to recent related works. The results indicate that GMCWAE is capable of providing high-quality low-dimensional representations of network traffic for resource-constrained devices, and the proposed NID model effectively safeguards against network threats in IoT environments.},
  keywords={Feature extraction;Internet of Things;Telecommunication traffic;Representation learning;Kernel;Accuracy;Iron;Gaussian distribution;Benchmark testing;Bayes methods;Network intrusion detection;Internet of Things;Dimensionality reduction;Representation Learning},
  doi={10.1109/JIOT.2025.3542845},
  ISSN={2327-4662},
  month={}
}

@INPROCEEDINGS{10555612,
  author={Jiang, Wenxin and Yasmin, Jerin and Jones, Jason and Synovic, Nicholas and Kuo, Jiashen and Bielanski, Nathaniel and Tian, Yuan and Thiruvathukal, George K. and Davis, James C.},
  booktitle={2024 IEEE/ACM 21st International Conference on Mining Software Repositories (MSR)}, 
  title={PeaTMOSS: A Dataset and Initial Analysis of Pre-Trained Models in Open-Source Software}, 
  year={2024},
  volume={},
  number={},
  pages={431-443},
  abstract={The development and training of deep learning models have become increasingly costly and complex. Consequently, software engineers are adopting pre-trained models (PTMs) for their downstream applications. The dynamics of the PTM supply chain remain largely unexplored, signaling a clear need for structured datasets that document not only the metadata but also the subsequent applications of these models. Without such data, the MSR community cannot comprehensively understand the impact of PTM adoption and reuse.This paper presents the PeaTMOSS dataset, which comprises metadata for 281,638 PTMs and detailed snapshots for all PTMs with over 50 monthly downloads (14,296 PTMs), along with 28,575 open-source software repositories from GitHub that utilize these models. Additionally, the dataset includes 44,337 mappings from 15,129 downstream GitHub repositories to the 2,530 PTMs they use. To enhance the dataset’s comprehensiveness, we developed prompts for a large language model to automatically extract model metadata, including the model’s training datasets, parameters, and evaluation metrics. Our analysis of this dataset provides the first summary statistics for the PTM supply chain, showing the trend of PTM development and common shortcomings of PTM package documentation. Our example application reveals inconsistencies in software licenses across PTMs and their dependent projects. PeaTMOSS lays the foundation for future research, offering rich opportunities to investigate the PTM supply chain. We outline mining opportunities on PTMs, their downstream usage, and cross-cutting questions.Our artifact is available at https://github.com/PurdueDualityLab/PeaTMOSS-Artifact. Our dataset is available at https://transfer.rcac.purdue.edu/file-manager?origin_id=ff978999-16c2-4b50-ac7a-947ffdc3eb1d&origin_path=%2F.CCS Concepts• Computing methodologies → Artificial intelligence; Information extraction; • Information systems → Database design and models; • Software and its engineering → Software libraries and repositories.},
  keywords={Training;Analytical models;Software libraries;Computational modeling;Supply chains;Metadata;Licenses;Datasets;Machine learning;Deep neural networks;Model zoos;Package registries;Open-source;Empirical software engineering},
  doi={},
  ISSN={2574-3864},
  month={April}
}

@INPROCEEDINGS{10928654,
  author={Li, Shiying and Xiong, Xi and Yu, Yan and Lu, Jiazhong and Li, Zhongzhi},
  booktitle={2024 4th International Conference on Communication Technology and Information Technology (ICCTIT)}, 
  title={An Efficient and Flexible Black-Box Watermarking Framework for Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={235-242},
  abstract={To prevent misuse of text generated by large language models (LLMs), watermarking technology offers a straightforward and effective means of verification. Existing approaches, however, suffer from several limitations, including a high dependency on the underlying logic of LLMs, inadequate performance against sophisticated watermarking attacks, and poor stealth, making them less suitable for complex and dynamic real-world applications. To address these challenges, we propose an efficient and flexible black-box watermarking framework for large language models. This framework enhances robustness and stealth by embedding watermarks in key areas of the text through the identification and sampling of high-entropy words. Furthermore, we introduce an encryption-based encoding algorithm that allows users to verify watermarks with their personal keys, supporting the customization of watermarking algorithms. Comparative experiments on four datasets with five baseline methods demonstrate that the proposed method excels in accuracy while significantly improving robustness and concealability with minimal semantic changes.},
  keywords={Accuracy;Large language models;Semantics;Closed box;Watermarking;Robustness;Encoding;Encryption;Logic;Information technology;Large Language Models;Watermarking;HighEntropy Words;Key-Based Encryption;Black-Box Framework},
  doi={10.1109/ICCTIT64404.2024.10928654},
  ISSN={},
  month={Dec}
}

@INPROCEEDINGS{10849122,
  author={Raja, Rohit Singh},
  booktitle={2025 IEEE 4th International Conference on AI in Cybersecurity (ICAIC)}, 
  title={"SQLSynthGen: Generating Synthetic Data for Healthcare Databases"}, 
  year={2025},
  volume={},
  number={},
  pages={1-11},
  abstract={Synthetic data generation is crucial for leveraging machine learning in healthcare without compromising patient privacy. SQLSynthGen (SSG) offers a solution by generating synthetic datasets from relational databases, preserving data structure and integrity. By extracting statistical properties via SQL queries and applying differential privacy, SSG ensures data utility while protecting individual privacy. Transparency is maintained through configurable YAML files, facilitating data auditing and stakeholder trust. Despite its advancements, SSG faces challenges in relational data handling and privacy explainability, necessitating future improvements in these areas to enhance adoption in healthcare and other sensitive domains.},
  keywords={Sensitivity;Time series analysis;Focusing;Medical services;Relational databases;Data structures;Generators;Stakeholders;Faces;Synthetic data;Synthetic Data Generation;Differential Privacy;Data Fidelity;Relational Databases;Statistical Refinement},
  doi={10.1109/ICAIC63015.2025.10849122},
  ISSN={},
  month={Feb}
}

@ARTICLE{10780952,
  author={Zhang, Le and Lu, Yao and Lu, Guangming},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={Contrastive Noise-Guided Invertible Network for Image Steganography}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  abstract={Image steganography aims to produce stego images through hiding secret images in the cover images to achieve covert communication. To simultaneously improve the invisibility and revealing quality of covert communication, this paper proposes a Contrastive Noise-Guided Invertible Network (CNGI-Net). Specifically, the Noised-Guided Invertible (NGI) mechanism is first proposed to actively and gradually generate adaptive noise in the forward hiding process using the interaction mechanism. The generated adaptive noise effectively guides and adjusts the cover-secret fusion process, as well as blurs the secret information in the stego images, which can significantly improve the transmission security. Besides, benefiting from the reversible property of NGI, high-quality revealed secret images can also be progressively decoupled from the stego images along the backward flow of NGI. To further ensure the invisibility and security of communication, Contrastive Hiding Learning (CHL) is proposed to improve the cover-stego similarity using the contrastive information. Extensive experiments demonstrate that the proposed CNGINet significantly promotes concealment security of transmission process and the quality of revealing for covert communication. Especially, the quality of stego and revealed secret images on 1, 2, 3 image hiding has been respectively promoted by 1.53, 0.43, 0.38 dB and 4.26, 3.45, 4.98 dB on ImageNet dataset, compared to SOTA steganography methods.},
  keywords={Steganography;Security;Noise;Consumer electronics;Visualization;Image edge detection;Receivers;Inverse problems;Couplings;Contrastive learning;Image steganography;covert communication;contrastive noise-guided invertible network (CNGI-Net);noisedguided invertible (NGI);contrastive hiding learning (CHL)},
  doi={10.1109/TCE.2024.3509479},
  ISSN={1558-4127},
  month={}
}

@ARTICLE{10848260,
  author={Pang, Shanchen and Yao, Jiamin and Liu, Ting and Zhao, Hua and Chen, Hongqi},
  journal={Chinese Journal of Electronics}, 
  title={A Text Similarity Measurement Based on Semantic Fingerprint of Characteristic Phrases}, 
  year={2020},
  volume={29},
  number={2},
  pages={233-241},
  abstract={Text similarity measurements are the basis for measuring the degree of matching between two or more texts. Traditional large-scale similarity detection methods based on a digital fingerprint have the advantage of high detection speed, which are only suitable for accurate detection. We propose a method of Chinese text similarity measurement based on feature phrase semantics. Natural language processing (NLP) technology is used to pre-process text and extract the keywords by the Term frequency-Inverse document frequency (TF-IDF) model and further screen out the feature words. We get the exact meaning of a word and semantic similarities between words and a HowNet semantic dictionary. We substitute concepts to get the feature phrases and generate a semantic fingerprint and calculate similarity. The experimental results indicate that the method proposed is superior in similarity detection in terms of its accuracy rate, recall rate, and $F$-value to the traditional and digital fingerprinting method.},
  keywords={Accuracy;Dictionaries;Semantics;Fingerprint recognition;Feature extraction;Natural language processing;Frequency measurement;Term frequency-Inverse document frequency(TF-IDF) model;Semantic fingerprint;Similarity;Characteristic phrases},
  doi={10.1049/cje.2019.12.011},
  ISSN={2075-5597},
  month={March}
}

@ARTICLE{10504286,
  author={Zhu, Hong and Zhao, Yue and Zhang, Shengzhi and Chen, Kai},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={NeuralSanitizer: Detecting Backdoors in Neural Networks}, 
  year={2024},
  volume={19},
  number={},
  pages={4970-4985},
  abstract={Deep neural networks (DNNs) have been pervasively used in many areas, e.g., computer vision, speech recognition, natural language processing, etc. However, recent works show that they are vulnerable to backdoor/Trojan attacks, severely restricting their usage in various scenarios. In this paper, we propose NeuralSanitizer, a novel approach to detect and remove backdoors in DNNs, capable of capturing various triggers with better accuracy and higher efficiency. In particular, we identify two fundamental properties of triggers, i.e., their effectiveness in the backdoored model and ineffectiveness in other clean models, and design a novel objective function to reconstruct triggers based on them. Then we present a new approach that leverages transferability to identify adversarial patches that could be generated during trigger reconstruction, thus detecting backdoors more accurately. We evaluate NeuralSanitizer on real-world backdoored DNNs and achieve 2.1% FNR and 0.9% FPR on average, significantly outperforming the state-of-the-art works by 1~14 times. In addition, NeuralSanitizer can reconstruct triggers up to 25% of the size of the original inputs on average, compared to only 6~10% by existing works. Finally, NeuralSanitizer is also 1~25 times faster than existing works.},
  keywords={Training;Data models;Artificial neural networks;Computational modeling;Image reconstruction;Computer vision;Analytical models;AI security;deep learning;backdoor attack;backdoor detection},
  doi={10.1109/TIFS.2024.3390599},
  ISSN={1556-6021},
  month={}
}

@BOOK{10163225,
  author={Martínez, Jesús},
  booktitle={TensorFlow 2.0 Computer Vision Cookbook: Implement machine learning solutions to overcome various computer vision challenges},
  year={2021},
  volume={},
  number={},
  pages={},
  abstract={Get well versed with state-of-the-art techniques to tailor training processes and boost the performance of computer vision models using machine learning and deep learning techniquesKey FeaturesDevelop, train, and use deep learning algorithms for computer vision tasks using TensorFlow 2.xDiscover practical recipes to overcome various challenges faced while building computer vision modelsEnable machines to gain a human level understanding to recognize and analyze digital images and videosBook DescriptionComputer vision is a scientific field that enables machines to identify and process digital images and videos. This book focuses on independent recipes to help you perform various computer vision tasks using TensorFlow. The book begins by taking you through the basics of deep learning for computer vision, along with covering TensorFlow 2.x’s key features, such as the Keras and tf.data.Dataset APIs. You’ll then learn about the ins and outs of common computer vision tasks, such as image classification, transfer learning, image enhancing and styling, and object detection. The book also covers autoencoders in domains such as inverse image search indexes and image denoising, while offering insights into various architectures used in the recipes, such as convolutional neural networks (CNNs), region-based CNNs (R-CNNs), VGGNet, and You Only Look Once (YOLO). Moving on, you’ll discover tips and tricks to solve any problems faced while building various computer vision applications. Finally, you’ll delve into more advanced topics such as Generative Adversarial Networks (GANs), video processing, and AutoML, concluding with a section focused on techniques to help you boost the performance of your networks. By the end of this TensorFlow book, you’ll be able to confidently tackle a wide range of computer vision problems using TensorFlow 2.x.What you will learnUnderstand how to detect objects using state-of-the-art models such as YOLOv3Use AutoML to predict gender and age from imagesSegment images using different approaches such as FCNs and generative modelsLearn how to improve your network’s performance using rank-N accuracy, label smoothing, and test time augmentationEnable machines to recognize people’s emotions in videos and real-time streamsAccess and reuse advanced TensorFlow Hub models to perform image classification and object detectionGenerate captions for images using CNNs and RNNsWho this book is forThis book is for computer vision developers and engineers, as well as deep learning practitioners looking for go-to solutions to various problems that commonly arise in computer vision. You will discover how to employ modern machine learning (ML) techniques and deep learning architectures to perform a plethora of computer vision tasks. Basic knowledge of Python programming and computer vision is required.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781838820688},
  url={https://ieeexplore.ieee.org/document/10163225}
}

@BOOK{10769331,
  author={Palmer, Rachelle and Perlmutter, Ben and Gangadhar, Ashwin and Larew, Nicholas and Narváez, Sigfrido and Rueckstiess, Thomas and Weller, Henry and Alake, Richmond and Ranjan, Shubham},
  booktitle={Building AI Intensive Python Applications: Create intelligent apps with LLMs and vector databases},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Master retrieval-augmented generation architecture and fine-tune your AI stack, along with discovering real-world use cases and best practices to create powerful AI appsKey FeaturesGet to grips with the fundamentals of LLMs, vector databases, and Python frameworksImplement effective retrieval-augmented generation strategies with MongoDB AtlasOptimize AI models for performance and accuracy with model compression and deployment optimizationPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionThe era of generative AI is upon us, and this book serves as a roadmap to harness its full potential. With its help, you’ll learn the core components of the AI stack: large language models (LLMs), vector databases, and Python frameworks, and see how these technologies work together to create intelligent applications. The chapters will help you discover best practices for data preparation, model selection, and fine-tuning, and teach you advanced techniques such as retrieval-augmented generation (RAG) to overcome common challenges, such as hallucinations and data leakage. You’ll get a solid understanding of vector databases, implement effective vector search strategies, refine models for accuracy, and optimize performance to achieve impactful results. You’ll also identify and address AI failures to ensure your applications deliver reliable and valuable results. By evaluating and improving the output of LLMs, you’ll be able to enhance their performance and relevance. By the end of this book, you’ll be well-equipped to build sophisticated AI applications that deliver real-world value.What you will learnUnderstand the architecture and components of the generative AI stackExplore the role of vector databases in enhancing AI applicationsMaster Python frameworks for AI developmentImplement Vector Search in AI applicationsFind out how to effectively evaluate LLM outputOvercome common failures and challenges in AI developmentWho this book is forThis book is for software engineers and developers looking to build intelligent applications using generative AI. While the book is suitable for beginners, a basic understanding of Python programming is required to make the most of it.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781836207245},
  url={https://ieeexplore.ieee.org/document/10769331}
}

@ARTICLE{9755446,
  author={Taofeek, Olayiwola Tokunbo and Alawida, Moatsum and Alabdulatif, Abdulatif and Omolara, Abiodun Esther and Abiodun, Oludare Isaac},
  journal={IEEE Access}, 
  title={A Cognitive Deception Model for Generating Fake Documents to Curb Data Exfiltration in Networks During Cyber-Attacks}, 
  year={2022},
  volume={10},
  number={},
  pages={41457-41476},
  abstract={The exponential increase in the compromise of sensitive and intellectual properties alludes to the huge price the global community must pay for the digital revolution we are currently experiencing. This irrefutable reality is a major reason why cybersecurity defences continue to be a pressing and timely area of research. Traditional countermeasures of cyber defence using boundary controllers and filters such as intrusion detection, access controls, firewalls and so on, have proven ineffective. Such measures fail to account for the attacker’s inherent advantage of being increasingly techno-savvy, as well as their persistence in attempting to compromise the security of not only high-value targets, but also the vast pool of oblivious users of technology. The use of decoys and deception is one of the emerging solutions for cyber defence. Leveraging decoys and deception for security pre-date the advent of the digital revolution as centuries have witnessed the military using human decoys to deceive and successfully defeat their adversaries during wars. However, its benefits for reducing cyberattacks in these digital times have not been thoroughly investigated. One of its use requires that fake text documents are positioned in the repository of critical documents in order to mislead and catch hackers attempting to exfiltrate sensitive documents. Current methods of generating fake text documents involve using symbols, junk documents, randomly generated texts. Such approaches fail to capture the empirical and linguistic properties of language, resulting in messages that do not scale well, are not realistic, fail in the context of syntax and are semantically void. Consequently, failing to convince the attackers to believe they are the original messages. This paper presents a Cognitive Deception Model (CDM) based on a neural model which takes an input message and generates syntactically cohesive and semantically coherent independent looking but plausible and convincing decoy messages to cognitively burden and deceive the adversaries. The experimental results used to validate the models, as well as the comparison with state-of-the-art tools, show that it outperforms existing systems.},
  keywords={Electronic mail;Task analysis;Servers;Natural language processing;Symbols;Production;Passwords;Artificial advanced persistent threats (APTs);cyber-attacks;cyber defence;deception;decoys},
  doi={10.1109/ACCESS.2022.3166628},
  ISSN={2169-3536},
  month={}
}

@BOOK{10559421,
  author={Guilmette, Aaron},
  booktitle={Power Platform and the AI Revolution: Explore modern AI services to develop apps, bots, and automation patterns to enhance customer experiences},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Unlock the untapped potential of ChatGPT, CoPilot, and Azure AI services by integrating them with the Microsoft Power PlatformKey FeaturesGain insights into the latest AI technologies and their business applicationsUse generative AI to build apps, workflows, and chatbotsLearn how to integrate AI services to automate work and deliver apps for specific business needsPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionIn this AI era, employing leading machine learning and AI models such as ChatGPT for responding to customer feedback and prototyping applications is crucial to drive business success in the competitive market. This book is an indispensable guide to integrating cutting-edge technology into business operations and leveraging AI to analyze sentiment at scale, helping free up valuable time to enhance customer relationships. Immerse yourself in the future of AI-enabled application development by working with Power Automate, Power Apps, and the new Copilot Studio. With this book, you’ll learn foundational AI concepts as you explore the extensive capabilities of the low-code Power Platform. You’ll see how Microsoft's advanced machine learning technologies can streamline common business tasks such as extracting key data elements from customer documents, reviewing customer emails, and validating passports and drivers’ licenses. The book also guides you in harnessing the power of generative AI to expedite tasks like creating executive summaries, building presentations, and analyzing resumes. You’ll build apps using natural language prompting and see how ChatGPT can be used to power chatbots in your organization. By the end of this book, you’ll have charted your path to developing your own reusable AI automation patterns to propel your business operations into the future.What you will learnInteract with ChatGPT using connectors and HTTP callsTrain AI models to identify the key elements of documentsUse generative AI to answer questions about organizational contentLeverage AI image recognition services to describe picturesUse generative AI tools to help build workflows and appsBuild chatbots using the new Copilot StudioAnalyze customer feedback using AI sentiment analysis tools such as AI BuilderWho this book is forIf you’re interested in exploring the capabilities of modern AI technologies in the workplace, this book is for you. Specially tailored for IT professionals, developers, business leaders, human resources administrators, managers, and entrepreneurs–anyone aspiring to become a productivity rockstar will find this book helpful for extending their skill set through hands-on exercises. The content is beginner-friendly, assuming no knowledge of machine learning or artificial intelligence concepts, making it a perfect starting point for newcomers to the field.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835089927},
  url={https://ieeexplore.ieee.org/document/10559421}
}

@BOOK{10162164,
  author={Raschka, Sebastian and Liu, Yuxi (Hayden) and Mirjalili, Vahid and Dzhulgakov, Dmytro},
  booktitle={Machine Learning with PyTorch and Scikit-Learn: Develop machine learning and deep learning models with Python},
  year={2022},
  volume={},
  number={},
  pages={},
  abstract={This book of the bestselling and widely acclaimed Python Machine Learning series is a comprehensive guide to machine and deep learning using PyTorch's simple to code framework. Purchase of the print or Kindle book includes a free eBook in PDF format.Key FeaturesLearn applied machine learning with a solid foundation in theoryClear, intuitive explanations take you deep into the theory and practice of Python machine learningFully updated and expanded to cover PyTorch, transformers, XGBoost, graph neural networks, and best practicesBook DescriptionMachine Learning with PyTorch and Scikit-Learn is a comprehensive guide to machine learning and deep learning with PyTorch. It acts as both a step-by-step tutorial and a reference you'll keep coming back to as you build your machine learning systems. Packed with clear explanations, visualizations, and examples, the book covers all the essential machine learning techniques in depth. While some books teach you only to follow instructions, with this machine learning book, we teach the principles allowing you to build models and applications for yourself. Why PyTorch? PyTorch is the Pythonic way to learn machine learning, making it easier to learn and simpler to code with. This book explains the essential parts of PyTorch and how to create models using popular libraries, such as PyTorch Lightning and PyTorch Geometric. You will also learn about generative adversarial networks (GANs) for generating new data and training intelligent agents with reinforcement learning. Finally, this new edition is expanded to cover the latest trends in deep learning, including graph neural networks and large-scale transformers used for natural language processing (NLP). This PyTorch book is your companion to machine learning with Python, whether you're a Python developer new to machine learning or want to deepen your knowledge of the latest developments.What you will learnExplore frameworks, models, and techniques for machines to 'learn' from dataUse scikit-learn for machine learning and PyTorch for deep learningTrain machine learning classifiers on images, text, and moreBuild and train neural networks, transformers, and boosting algorithmsDiscover best practices for evaluating and tuning modelsPredict continuous target outcomes using regression analysisDig deeper into textual and social media data using sentiment analysisWho this book is forIf you have a good grasp of Python basics and want to start learning about machine learning and deep learning, then this is the book for you. This is an essential resource written for developers and data scientists who want to create practical machine learning and deep learning applications using scikit-learn and PyTorch. Before you get started with this book, you’ll need a good understanding of calculus, as well as linear algebra.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781801816380},
  url={https://ieeexplore.ieee.org/document/10162164}
}

@BOOK{10251383,
  author={Vandenbussche, Vincent and Kazakci, Akin Osman},
  booktitle={The Regularization Cookbook: Explore practical recipes to improve the functionality of your ML models},
  year={2023},
  volume={},
  number={},
  pages={},
  abstract={Methodologies and recipes to regularize any machine learning and deep learning model using cutting-edge technologies such as stable diffusion, Dall-E and GPT-3 Purchase of the print or Kindle book includes a free PDF eBookKey FeaturesLearn to diagnose the need for regularization in any machine learning modelRegularize different ML models using a variety of techniques and methodsEnhance the functionality of your models using state of the art computer vision and NLP techniquesBook DescriptionRegularization is an infallible way to produce accurate results with unseen data, however, applying regularization is challenging as it is available in multiple forms and applying the appropriate technique to every model is a must. The Regularization Cookbook provides you with the appropriate tools and methods to handle any case, with ready-to-use working codes as well as theoretical explanations. After an introduction to regularization and methods to diagnose when to use it, you’ll start implementing regularization techniques on linear models, such as linear and logistic regression, and tree-based models, such as random forest and gradient boosting. You’ll then be introduced to specific regularization methods based on data, high cardinality features, and imbalanced datasets. In the last five chapters, you’ll discover regularization for deep learning models. After reviewing general methods that apply to any type of neural network, you’ll dive into more NLP-specific methods for RNNs and transformers, as well as using BERT or GPT-3. By the end, you’ll explore regularization for computer vision, covering CNN specifics, along with the use of generative models such as stable diffusion and Dall-E. By the end of this book, you’ll be armed with different regularization techniques to apply to your ML and DL models.What you will learnDiagnose overfitting and the need for regularizationRegularize common linear models such as logistic regressionUnderstand regularizing tree-based models such as XGBoosUncover the secrets of structured data to regularize ML modelsExplore general techniques to regularize deep learning modelsDiscover specific regularization techniques for NLP problems using transformersUnderstand the regularization in computer vision models and CNN architecturesApply cutting-edge computer vision regularization with generative modelsWho this book is forThis book is for data scientists, machine learning engineers, and machine learning enthusiasts, looking to get hands-on knowledge to improve the performances of their models. Basic knowledge of Python is a prerequisite.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781837639724},
  url={https://ieeexplore.ieee.org/document/10251383}
}

@BOOK{9785669,
  author={Quamar, Abdul and Efthymiou, Vasilis and Lei, Chuan and Özcan, Fatma},
  booktitle={Natural Language Interfaces to Data},
  year={2022},
  volume={},
  number={},
  pages={},
  abstract={Natural language interfaces provide an easy way to query and interact with data and enable non-technical users to investigate data sets without the need to know a query language. Recent advances in natural language understanding and processing have resulted in a renewed interest in natural language interfaces to data. The main challenges in natural language querying are identifying the entities involved in the user utterance, connecting the different entities in a meaningful way over the underlying data source to interpret user intents, and generating a structured query. There are two main approaches in the literature for interpreting a user’s natural language query. The first are rule-based systems that make use of semantic indices, ontologies, and knowledge graphs to identify the entities in the query, understand the intended relationships between those entities, and utilize grammars to generate the target queries. Second are hybrid approaches that utilize both rule-based techniques as well as deep learning models. Conversational interfaces are the next natural step to one-shot natural language querying by exploiting query context between multiple turns of conversation for disambiguation. In this monograph, the authors review the rule-based and hybrid technologies that are used in natural language interfaces and survey the different approaches to natural language querying. They also describe conversational interfaces for data analytics and discuss several benchmarks used for natural language querying research and evaluation. The monograph concludes with discussion on challenges that need to be addressed before these systems can be widely adopted.},
  keywords={},
  doi={},
  ISSN={},
  publisher={now},
  isbn={9781638280293},
  url={https://ieeexplore.ieee.org/document/9785669}
}

@ARTICLE{10915651,
  author={Chen, Xiaoyu and Xu, Wanru and Kan, Shichao and Zhang, Linna and Jin, Yi and Cen, Yigang and Li, Yidong},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Vision-Semantics-Label: A New Two-step Paradigm for Action Recognition with Large Language Model}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={In recent years, the rapid advancement of multi-modal large language models has propelled the development of video-based conversation models. Due to their exceptional video understanding capabilities, there is often an expectation that these models can handle all video-related tasks, including action recognition. However, because action recognition datasets typically lack semantic information, limiting the performance of dialogue models. Additionally, as these dialogue models are designed for video understanding, they frequently overlook critical information required for action recognition—continuous motion—in their model architecture and training dataset configurations. To address these challenges, we first propose a novel two-step mapping framework based on large language models, termed “Vision-Semantics-Label” mapping, to better adapt video-based large language models for action recognition. In the first step, we proposed a visual-skeletal collaborative learning large language model (VS-LLM), which utilizes human keypoints to compensate for the missing motion details without increasing the input token length of the large language model. In the second step, we designed two mapping methods: verb noun match (VN-Match) and all text match (ALL-Match), which can effectively extract relevant action descriptions from the text. Finally, we construct semantic action recognition datasets to ensure that the training data inherently contains action details, enabling the model to better achieve action recognition. We evaluate our approach on five benchmark datasets, demonstrating the state-of-the-art performance of large language models in action recognition. The source code and dataset are publicly available at https://github.com/xiaoyu92568/VS-LLM.},
  keywords={Large language models;Visualization;Feature extraction;Semantics;Oral communication;Streaming media;Sports;Load modeling;Adaptation models;Electronic mail;Action recognition;video-based large language model;semantic mapping;semantic action recognition datasets},
  doi={10.1109/TCSVT.2025.3548845},
  ISSN={1558-2205},
  month={}
}

@BOOK{10489933,
  author={Abhishek, Kumar and Abdelaziz, Dr. Mounir},
  booktitle={Machine Learning for Imbalanced Data: Tackle imbalanced datasets using machine learning and deep learning techniques},
  year={2023},
  volume={},
  number={},
  pages={},
  abstract={Take your machine learning expertise to the next level with this essential guide, utilizing libraries like imbalanced-learn, PyTorch, scikit-learn, pandas, and NumPy to maximize model performance and tackle imbalanced dataKey FeaturesUnderstand how to use modern machine learning frameworks with detailed explanations, illustrations, and code samplesLearn cutting-edge deep learning techniques to overcome data imbalanceExplore different methods for dealing with skewed data in ML and DL applicationsPurchase of the print or Kindle book includes a free eBook in the PDF formatBook DescriptionAs machine learning practitioners, we often encounter imbalanced datasets in which one class has considerably fewer instances than the other. Many machine learning algorithms assume an equilibrium between majority and minority classes, leading to suboptimal performance on imbalanced data. This comprehensive guide helps you address this class imbalance to significantly improve model performance. Machine Learning for Imbalanced Data begins by introducing you to the challenges posed by imbalanced datasets and the importance of addressing these issues. It then guides you through techniques that enhance the performance of classical machine learning models when using imbalanced data, including various sampling and cost-sensitive learning methods. As you progress, you’ll delve into similar and more advanced techniques for deep learning models, employing PyTorch as the primary framework. Throughout the book, hands-on examples will provide working and reproducible code that’ll demonstrate the practical implementation of each technique. By the end of this book, you’ll be adept at identifying and addressing class imbalances and confidently applying various techniques, including sampling, cost-sensitive techniques, and threshold adjustment, while using traditional machine learning or deep learning models.What you will learnUse imbalanced data in your machine learning models effectivelyExplore the metrics used when classes are imbalancedUnderstand how and when to apply various sampling methods such as over-sampling and under-samplingApply data-based, algorithm-based, and hybrid approaches to deal with class imbalanceCombine and choose from various options for data balancing while avoiding common pitfallsUnderstand the concepts of model calibration and threshold adjustment in the context of dealing with imbalanced datasetsWho this book is forThis book is for machine learning practitioners who want to effectively address the challenges of imbalanced datasets in their projects. Data scientists, machine learning engineers/scientists, research scientists/engineers, and data scientists/engineers will find this book helpful. Though complete beginners are welcome to read this book, some familiarity with core machine learning concepts will help readers maximize the benefits and insights gained from this comprehensive resource.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781801070881},
  url={https://ieeexplore.ieee.org/document/10489933}
}

@INPROCEEDINGS{10786729,
  author={Jasserand, Catherine},
  booktitle={2024 International Conference of the Biometrics Special Interest Group (BIOSIG)}, 
  title={Deceptive Deepfakes: Is the Law Coping with AI-Altered Representations of Ourselves?}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Deceptive deepfakes are AI-generated hyper-realistic content that harms individuals (e.g. pornographic deepfake content) or society (as disinformation and impersonation tools). The technologies are becoming increasingly sophisticated, making their detection extremely difficult. Deepfakes can impair national and international security, undermine elections, threaten democracy, and challenge justice, but also cause mental distress and reputational damage. What are the regulatory answers to these deceptive deepfakes? As this paper will show, there is no single approach and answer to the topic. Currently, the problem is tackled by existing, albeit non-specific regulations, (e.g. privacy, intellectual property, image rights), and by newly adopted regulations focusing on a specific aspect (deepfakes aimed at manipulating elections or non-consensual pornographic materials). To present an overview of these regulations, the paper compares the approaches of the USA and the EU, including examples of national legislation. Summarizing the findings, the paper shows the laws need to regulate the ecosystem of actors involved in these deceptive contents (from the creators to the distributors and possibly the viewers in case of deepfake child pornography). Beyond the ecosystem, solutions should also focus on individuals who are victims of these deepfakes created without their consent and knowledge. A different approach might be well needed to ensure they can defend their digital self and prevent malicious AI-altered reproductions and use of themselves.},
  keywords={Deepfakes;Privacy;Voting;Face recognition;Ecosystems;Legislation;Pressing;Speech recognition;Regulation;Security;Deepfakes;Regulation;harms;Europe;digital self;societal issue},
  doi={10.1109/BIOSIG61931.2024.10786729},
  ISSN={1617-5468},
  month={Sep.}
}

@BOOK{8922855,
  author={McCann, Michael T. and Unser, Michael},
  booktitle={Biomedical Image Reconstruction: From the Foundations to Deep Neural Networks},
  year={2019},
  volume={},
  number={},
  pages={},
  abstract={Biomedical imaging is a vast and diverse field. There are a plethora of imaging devices using light, X-rays, sound waves, magnetic fields, electrons, or protons, to measure structures ranging from nano to macroscale. In many cases, computer software is needed to turn the signals collected by the hardware into a meaningful image. These computer algorithms are similarly diverse and numerous. This survey presents a wide swath of biomedical image reconstruction algorithms under a single framework. It is a coherent, yet brief survey of some six decades of research. The underpinning theory of the techniques are described and practical considerations for designing reconstruction algorithms for use in biomedical systems form the central theme of each chapter. The unifying framework deployed throughout the monograph models imaging modalities as combinations of a small set of building blocks, which identify connections between modalities Thus, the user can quickly port ideas and computer code from one to the next. Furthermore, reconstruction algorithms can treat the imaging model as a black. box, meaning that one algorithm can work for many modalities. This provides a pragmatic approach to designing effective reconstruction algorithms. This monograph is written in a tutorial style that concisely introduces students, researchers and practitioners to the development and design of effective biomedical image reconstruction algorithms.},
  keywords={},
  doi={10.1561/2000000101},
  ISSN={},
  publisher={now},
  isbn={9781680836516},
  url={https://ieeexplore.ieee.org/document/8922855}
}

@BOOK{10763460,
  author={Gowda, Deepak},
  booktitle={Apache Spark for Machine Learning: Build and deploy high-performance big data AI solutions for large-scale clusters},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Develop your data science skills with Apache Spark to solve real-world problems for Fortune 500 companies using scalable algorithms on large cloud computing clustersKey FeaturesApply techniques to analyze big data and uncover valuable insights for machine learningLearn to use cloud computing clusters for training machine learning models on large datasetsDiscover practical strategies to overcome challenges in model training, deployment, and optimizationPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionIn the world of big data, efficiently processing and analyzing massive datasets for machine learning can be a daunting task. Written by Deepak Gowda, a data scientist with over a decade of experience and 30+ patents, this book provides a hands-on guide to mastering Spark’s capabilities for efficient data processing, model building, and optimization. With Deepak’s expertise across industries such as supply chain, cybersecurity, and data center infrastructure, he makes complex concepts easy to follow through detailed recipes. This book takes you through core machine learning concepts, highlighting the advantages of Spark for big data analytics. It covers practical data preprocessing techniques, including feature extraction and transformation, supervised learning methods with detailed chapters on regression and classification, and unsupervised learning through clustering and recommendation systems. You’ll also learn to identify frequent patterns in data and discover effective strategies to deploy and optimize your machine learning models. Each chapter features practical coding examples and real-world applications to equip you with the knowledge and skills needed to tackle complex machine learning tasks. By the end of this book, you’ll be ready to handle big data and create advanced machine learning models with Apache Spark.What you will learnMaster Apache Spark for efficient, large-scale data processing and analysisUnderstand core machine learning concepts and their applications with SparkImplement data preprocessing techniques for feature extraction and transformationExplore supervised learning methods – regression and classification algorithmsApply unsupervised learning for clustering tasks and recommendation systemsDiscover frequent pattern mining techniques to uncover data trendsWho this book is forThis book is ideal for data scientists, ML engineers, data engineers, students, and researchers who want to deepen their knowledge of Apache Spark’s tools and algorithms. It’s a must-have for those struggling to scale models for real-world problems and a valuable resource for preparing for interviews at Fortune 500 companies, focusing on large dataset analysis, model training, and deployment.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835460016},
  url={https://ieeexplore.ieee.org/document/10763460}
}

@BOOK{10163018,
  author={Ghidersa, Mihaela Roxana},
  booktitle={Software Architecture for Web Developers: An introductory guide for developers striving to take the first steps toward software architecture or just looking to grow as professionals},
  year={2022},
  volume={},
  number={},
  pages={},
  abstract={Discover an accessible pathway to advancing your career and becoming a web architect by building a solid technical ground in software architectureKey FeaturesFollow your desired career path that leads to a lucrative job as a web architectDevelop a solid technical background in software architecture using real-world practices and patternsLearn proven techniques and design considerations from an industry expertBook DescriptionLarge-scale web applications require you to write code efficiently following business and architectural considerations. They require web developers to understand the impact of their work on the system and how they can evolve the product. With this handbook, every developer will find something to take away. This book will help web developers looking to change projects or work on a new project in understanding the context of the application, along with how some design decisions or patterns fit better in their application’s architecture. It acts as a guide, taking you through different levels of professional growth with a focus on best practices, coding guidelines, business considerations, and soft skills that will help you gain the knowledge to craft a career in web development. Finally, you’ll work with examples and ways of applying the discussed concepts in practical situations. By the end of this book, you’ll have gained valuable insights into what it means to be a web architect, as well as the impact architecture has on a web application.What you will learnUnderstand the context of software architecture, from shaping the product to delivery and beyondBecome well versed in what a web architect’s role meansExplore go-to key concepts for every time you try your hand at app developmentAnalyze the importance of relationships with stakeholdersGet acquainted with the benefits of well-designed architectureDig into and solve myths web developers have come across or created along the wayWho this book is forThis book is for web developers who want to become web architects. Beginner-level web developers will be able to develop a strong technical background, and experienced web developers will learn techniques to become better professionals by understanding the web architect's role and the impact of efficient architecture on their projects.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781803231617},
  url={https://ieeexplore.ieee.org/document/10163018}
}

@BOOK{10559419,
  author={Ayeva, Kamon and Kasampalis, Sakis},
  booktitle={Mastering Python Design Patterns: Craft essential Python patterns by following core design principles},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Explore Python design patterns such as observer, proxy, throttling, dependency injection, and anti-patterns to develop efficient and scalable applications Key FeaturesMaster essential design principles to build robust software architecture with the latest features in Python 3.10Apply proven design patterns to solve complex problems efficientlyUnderstand anti-patterns to avoid common pitfalls in Python programmingPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionAs software systems become increasingly complex, maintaining code quality, scalability, and efficiency can be a daunting challenge. Mastering Python Design Patterns is an essential resource that equips you with the tools you need to overcome these hurdles and create robust, scalable applications. The book delves into design principles and patterns in Python, covering both classic and modern patterns, and showing you how to apply them to solve daily challenges as a Python developer or architect. This new edition covers creational, structural, behavioral, and architectural patterns, including concurrency, asynchronous, and performance patterns. You'll explore how these patterns are relevant to various domains, such as event handling, concurrency, distributed systems, and testing. Whether you're working on user interfaces (UIs), web apps, APIs, data pipelines, or AI models, this book equips you with the knowledge to build robust and maintainable software. The book also presents Python anti-patterns, helping you avoid common pitfalls and ensuring your code remains clean and efficient. By the end of this book, you'll be able to confidently apply classic and modern Python design patterns to build robust, scalable applications.What you will learnMaster fundamental design principles and SOLID conceptsBecome familiar with Gang of Four (GoF) patterns and apply them effectively in PythonExplore architectural design patterns to architect robust systemsDelve into concurrency and performance patterns for optimized codeDiscover distributed systems patterns for scalable applicationsGet up to speed with testing patterns to ensure code reliability and maintainabilityDevelop modular, decoupled systems and manage dependencies efficientlyWho this book is forWith a focus on intermediate and advanced Python programmers, this book offers valuable insights into the best practices for software design, backed by real-world examples and decades of experience. The book is also an excellent resource for software architects and team leaders who want to improve code quality and maintainability across their projects. Prior Python proficiency, including syntax, data structures, and OOP will help you get the most out of this book. },
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781837637652},
  url={https://ieeexplore.ieee.org/document/10559419}
}

@BOOK{10740986,
  author={Yanev, Martin},
  booktitle={Building AI Applications with OpenAI APIs: Leverage ChatGPT, Whisper, and DALL-E APIs to build 10 innovative AI projects},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Improve your app development skills by building a ChatGPT clone, code bug fixer, quiz generator, translation app, email auto-reply, PowerPoint generator, and moreKey FeaturesTransition into an expert AI developer by mastering ChatGPT concepts, including fine-tuning and integrationsGain hands-on experience through real-world projects covering a wide range of AI applicationsImplement payment systems in your applications by integrating the ChatGPT API with StripePurchase of the print or Kindle book includes a free PDF eBookBook DescriptionUnlock the power of AI in your applications with ChatGPT with this practical guide that shows you how to seamlessly integrate OpenAI APIs into your projects, enabling you to navigate complex APIs and ensure seamless functionality with ease. This new edition is updated with key topics such as OpenAI Embeddings, which’ll help you understand the semantic relationships between words and phrases. You’ll find out how to use ChatGPT, Whisper, and DALL-E APIs through 10 AI projects using the latest OpenAI models, GPT-3.5, and GPT-4, with Visual Studio Code as the IDE. Within these projects, you’ll integrate ChatGPT with frameworks and tools such as Flask, Django, Microsoft Office APIs, and PyQt. You’ll get to grips with NLP tasks, build a ChatGPT clone, and create an AI code bug-fixing SaaS app. The chapters will also take you through speech recognition, text-to-speech capabilities, language translation, generating email replies, creating PowerPoint presentations, and fine-tuning ChatGPT, along with adding payment methods by integrating the ChatGPT API with Stripe. By the end of this book, you’ll be able to develop, deploy, and monetize your own groundbreaking applications by harnessing the full potential of ChatGPT APIs.What you will learnDevelop a solid foundation in using the OpenAI API for NLP tasksBuild, deploy, and integrate payments into various desktop and SaaS AI applicationsIntegrate ChatGPT with frameworks such as Flask, Django, and Microsoft Office APIsUnleash your creativity by integrating DALL-E APIs to generate stunning AI art within your desktop appsExperience the power of Whisper API's speech recognition and text-to-speech featuresFind out how to fine-tune ChatGPT models for your specific use caseMaster AI embeddings to measure the relatedness of text stringsWho this book is forThis book is for a diverse range of professionals, including programmers, entrepreneurs, and software enthusiasts. Beginner programmers, Python developers exploring AI applications with ChatGPT, software developers integrating AI technology, and web developers creating AI-powered web applications with ChatGPT will find this book beneficial. Scholars and researchers working on AI projects with ChatGPT will also find it valuable. Basic knowledge of Python and familiarity with APIs is needed to understand the topics covered in this book.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835884010},
  url={https://ieeexplore.ieee.org/document/10740986}
}

@BOOK{10168057,
  author={Amos, Brandon},
  booktitle={Tutorial on Amortized Optimization},
  year={2023},
  volume={},
  number={},
  pages={},
  abstract={Optimization is a ubiquitous modeling tool and is often deployed in settings which repeatedly solve similar instances of the same problem. Amortized optimization methods use learning to predict the solutions to problems in these settings, exploiting the shared structure between similar problem instances. These methods have been crucial in variational inference and reinforcement learning and are capable of solving optimization problems many orders of magnitudes times faster than traditional optimization methods that do not use amortization. In this tutorial, the author presents an introduction to the amortized optimization foundations behind these advancements and overviews their applications in variational inference, sparse coding, gradient-based meta-learning, control, reinforcement learning, convex optimization, optimal transport, and deep equilibrium networks. Of practical use for the reader, is the source code accompanying the Implementation and Software Examples chapter. This tutorial provides the reader with a complete source for understanding the theory behind and implementing amortized optimization in many machine learning applications. It will be of interest to students and practitioners alike.},
  keywords={},
  doi={},
  ISSN={},
  publisher={now},
  isbn={9781638282099},
  url={https://ieeexplore.ieee.org/document/10168057}
}

@BOOK{10162904,
  author={Morley, Sam},
  booktitle={Applying Math with Python: Over 70 practical recipes for solving real-world computational math problems},
  year={2022},
  volume={},
  number={},
  pages={},
  abstract={Discover easy-to-follow solutions and techniques to help you to implement applied mathematical concepts such as probability, calculus, and equations using Python's numeric and scientific librariesKey FeaturesCompute complex mathematical problems using programming logic with the help of step-by-step recipesLearn how to use Python libraries for computation, mathematical modeling, and statisticsDiscover simple yet effective techniques for solving mathematical equations and apply them in real-world statisticsBook DescriptionThe updated edition of Applying Math with Python will help you solve complex problems in a wide variety of mathematical fields in simple and efficient ways. Old recipes have been revised for new libraries and several recipes have been added to demonstrate new tools such as JAX. You'll start by refreshing your knowledge of several core mathematical fields and learn about packages covered in Python's scientific stack, including NumPy, SciPy, and Matplotlib. As you progress, you'll gradually get to grips with more advanced topics of calculus, probability, and networks (graph theory). Once you’ve developed a solid base in these topics, you’ll have the confidence to set out on math adventures with Python as you explore Python's applications in data science and statistics, forecasting, geometry, and optimization. The final chapters will take you through a collection of miscellaneous problems, including working with specific data formats and accelerating code. By the end of this book, you'll have an arsenal of practical coding solutions that can be used and modified to solve a wide range of practical problems in computational mathematics and data science.What you will learnBecome familiar with basic Python packages, tools, and libraries for solving mathematical problemsExplore real-world applications of mathematics to reduce a problem in optimizationUnderstand the core concepts of applied mathematics and their application in computer scienceFind out how to choose the most suitable package, tool, or technique to solve a problemImplement basic mathematical plotting, change plot styles, and add labels to plots using MatplotlibGet to grips with probability theory with the Bayesian inference and Markov Chain Monte Carlo (MCMC) methodsWho this book is forWhether you are a professional programmer or a student looking to solve mathematical problems computationally using Python, this is the book for you. Advanced mathematics proficiency is not a prerequisite, but basic knowledge of mathematics will help you to get the most out of this Python math book. Familiarity with the concepts of data structures in Python is assumed.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781804616802},
  url={https://ieeexplore.ieee.org/document/10162904}
}

@INPROCEEDINGS{10377865,
  author={Kumari, Nupur and Zhang, Bingliang and Wang, Sheng-Yu and Shechtman, Eli and Zhang, Richard and Zhu, Jun-Yan},
  booktitle={2023 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Ablating Concepts in Text-to-Image Diffusion Models}, 
  year={2023},
  volume={},
  number={},
  pages={22634-22645},
  abstract={Large-scale text-to-image diffusion models can generate high-fidelity images with powerful compositional ability. However, these models are typically trained on an enormous amount of Internet data, often containing copyrighted material, licensed images, and personal photos. Furthermore, they have been found to replicate the style of various living artists or memorize exact training samples. How can we remove such copyrighted concepts or images without retraining the model from scratch? To achieve this goal, we propose an efficient method of ablating concepts in the pretrained model, i.e., preventing the generation of a target concept. Our algorithm learns to match the image distribution for a target style, instance, or text prompt we wish to ablate to the distribution corresponding to an anchor concept. This prevents the model from generating target concepts given its text condition. Extensive experiments show that our method can successfully prevent the generation of the ablated concept while preserving closely related concepts in the model.},
  keywords={Training;Computer vision;Computational modeling;Data models;Internet},
  doi={10.1109/ICCV51070.2023.02074},
  ISSN={2380-7504},
  month={Oct}
}

@BOOK{10522538,
  author={Picano, Holly},
  booktitle={Generating Creative Images With DALL-E 3: Create accurate images with effective prompting for real-world applications},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Learn to craft fine art prints, NFTs, and captivating covers for books and magazines with Dall-E 3 and ChatGPTKey FeaturesExplore Dall-E 3's diverse practical applications across art, design, education, and beyondMaster AI-generated art creation through step-by-step tutorials, ranging from basic to advanced projectsEnhance your prompt crafting skills with the exclusive prompt cheat sheetPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionUnveil the extraordinary capabilities of the groundbreaking AI model, DALL-E 3, as it transforms text prompts into accurate images. This book addresses the challenge of creating meaningful images by writing prompts, guiding you step by step through creating stunning visual art regardless of your skill level. Prepare to delve deep into the inner workings of DALL-E 3's architecture and training process. With clear explanations, practical tutorials, and real-world examples that can be easily applied, you’ll unlock secrets to creating awe-inspiring AI-generated art, from fine art prints to digital designs. This book provides comprehensive insights into various lens options, camera angles, lighting techniques, and art movements, helping you integrate AI capabilities with your artistic skills. You’ll also learn to create NFTs that can be monetized and gain invaluable insights into designing compelling covers, all within the ethical boundaries of AI-generated art. And with the invaluable prompt cheat sheet by your side, you’ll hone your skills in formulating captivating prompts for diverse purposes. By the end of this book, you’ll have learned how to produce generative AI art at a rapid pace and relatively low cost and push the boundaries of imagination with DALL-E 3.What you will learnMaster DALL-E 3's architecture and training methodsCreate fine prints and other AI-generated art with precisionSeamlessly blend AI with traditional artistryAddress ethical dilemmas in AI artExplore the future of digital creativityImplement practical optimization techniques for your artistic endeavorsWho this book is forWhether you’re an artist looking to integrate AI into your work, a designer seeking new creative horizons, a tech enthusiast intrigued by the intersection of art and artificial intelligence, an educator in the fields of art and technology, or a curious individual venturing into AI-generated art, this book is for you. For anyone interested in the innovative fusion of creativity and technology, the DALL-E 3 Guide to AI Artistry offers invaluable insights and practical skills that you can apply right away.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835089903},
  url={https://ieeexplore.ieee.org/document/10522538}
}

@INPROCEEDINGS{10849141,
  author={Zhu, Wendi and Wong, KokSheik and Kuribayashi, Minoru},
  booktitle={2024 Asia Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)}, 
  title={A Permutation-based Reversible Data Hiding Method with Zero Visual Distortion}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Recently, several approaches have been designed to hide data in portable document format (PDF) files. These approaches have demonstrated their advantages in different application scenarios, including copyright verification, covert communication/steganography, and content forensics. However, they often suffer from visual distortion or lack universal applicability. In this work, we propose a reversible and transparent method that exploits the coding properties of text objects (i.e., substrings) in a PDF-compliant document to embed data. In particular, the position information of the substrings is adjusted to hide data, where each unique permutation of the substrings encodes a bit sequence. Subsequently, the distance of each substring from the left margin is corrected so that the processed PDF has the exact layout or appearance of the original PDF, hence completely preserving the quality of the original PDF file. In the best-case scenario, to hide one bit of data, 5.88 bits of the PDF file are required, i.e., 1 : 5.88. In addition, this method can be deployed in tandem with conventional data hiding methods to hide more data and to hide data in different ways.},
  keywords={Visualization;Forensics;Layout;Passwords;Information processing;Portable document format;Distortion;Encryption;Multimedia communication;Payloads},
  doi={10.1109/APSIPAASC63619.2025.10849141},
  ISSN={2640-0103},
  month={Dec}
}

@INPROCEEDINGS{10646808,
  author={Zhou, Ruikai and Yang, Kang and Wang, Xiuling and Wang, Wendy Hui and Xu, Jun},
  booktitle={2024 IEEE Symposium on Security and Privacy (SP)}, 
  title={Revisiting Black-box Ownership Verification for Graph Neural Networks}, 
  year={2024},
  volume={},
  number={},
  pages={2478-2496},
  abstract={Graph Neural Networks (GNNs) have emerged as powerful tools for processing graph-structured data, enabling applications in various domains. Yet, GNNs are vulnerable to model extraction attacks, imposing risks to intellectual property. To mitigate model extraction attacks, model ownership verification is considered an effective method. However, throughout a series of empirical studies, we found that the existing GNN ownership verification methods either mandate unrealistic conditions or present unsatisfactory accuracy under the most practical settings—the black-box setting where the verifier only requires access to the final output (e.g., posterior probability) of the target model and the suspect model.Inspired by the studies, we propose a new, black-box GNN ownership verification method that involves local independent models and shadow surrogate models to train a classifier for performing ownership verification. Our method boosts the verification accuracy by exploiting two insights: (1) We consider the overall behaviors of the target model for decision-making, better utilizing its holistic fingerprinting; (2) We enrich the fingerprinting of the target model by masking a subset of features of its training data, injecting extra information to facilitate ownership verification.To assess the effectiveness of our proposed method, we perform an intensive series of evaluations with 5 popular datasets, 5 mainstream GNN architectures, and 16 different settings. Our method achieves nearly perfect accuracy with a marginal impact on the target model in all cases, significantly outperforming the existing methods and enlarging their practicality. We also demonstrate that our method maintains robustness against adversarial attempts to evade the verification.},
  keywords={Privacy;Accuracy;Decision making;Closed box;Training data;Fingerprint recognition;Graph neural networks},
  doi={10.1109/SP54263.2024.00232},
  ISSN={2375-1207},
  month={May}
}

@ARTICLE{9093125,
  author={Quan, Yuhui and Teng, Huan and Chen, Yixin and Ji, Hui},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Watermarking Deep Neural Networks in Image Processing}, 
  year={2021},
  volume={32},
  number={5},
  pages={1852-1865},
  abstract={Publishing/sharing pretrained deep neural network (DNN) models is a common practice in the community of computer vision. The increasing popularity of pretrained models has made it a serious concern: how to protect the intellectual properties of model owners and avert illegal usages by malicious attackers. This article aims at developing a framework for watermarking DNNs, with a particular focus on low-level image processing tasks that map images to images. Using image denoising and superresolution as case studies, we develop a black-box watermarking method for pretrained models, which exploits the overparameterization of the DNNs in image processing. In addition, an auxiliary module for visualizing the watermark information is proposed for further verification. Extensive experiments show that the proposed watermarking framework has no noticeable impact on model performance and enjoys the robustness against the often-seen attacks.},
  keywords={Watermarking;Image processing;Task analysis;Computational modeling;Training;Data models;Manifolds;Black box;deep learning;neural network;watermark},
  doi={10.1109/TNNLS.2020.2991378},
  ISSN={2162-2388},
  month={May}
}

@ARTICLE{9410590,
  author={Wu, Haiwei and Zhou, Jiantao},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={IID-Net: Image Inpainting Detection Network via Neural Architecture Search and Attention}, 
  year={2022},
  volume={32},
  number={3},
  pages={1172-1185},
  abstract={Deep learning (DL) has demonstrated its powerful capabilities in the field of image inpainting, which could produce visually plausible results. Meanwhile, the malicious use of advanced image inpainting tools (e.g. removing key objects to report fake news, erasing visible copyright watermarks, etc.) has led to increasing threats to the reliability of image data. To fight against the inpainting forgeries (not only DL-based but also traditional ones), in this work, we propose a novel end-to-end Image Inpainting Detection Network (IID-Net), to detect the inpainted regions at pixel accuracy. The proposed IID-Net consists of three sub-blocks: the enhancement block, the extraction block and the decision block. Specifically, the enhancement block aims to enhance the inpainting traces by using hierarchically combined special layers. The extraction block, automatically designed by Neural Architecture Search (NAS) algorithm, is targeted to extract features for the actual inpainting detection tasks. To further optimize the extracted latent features, we integrate global and local attention modules in the decision block, where the global attention reduces the intra-class differences by measuring the similarity of global features, while the local attention strengthens the consistency of local features. Furthermore, we thoroughly study the generalizability of our IID-Net, and find that different training data could result in vastly different generalization capability. By carefully examining 10 popular inpainting methods, we identify that the IID-Net trained on only one specific deep inpainting method exhibits desirable generalizability; namely, the obtained IID-Net can accurately detect and localize inpainting manipulations for various unseen inpainting methods as well. Extensive experimental results are presented to validate the superiority of the proposed IID-Net, compared with the state-of-the-art competitors. Our results would suggest that common artifacts are shared across diverse image inpainting methods. Finally, we build a public inpainting dataset of 10K image pairs for future research in this area.},
  keywords={Feature extraction;Forensics;Forgery;Training;Task analysis;Semantics;Computer architecture;Inpainting forensics;generalizability;deep neural networks},
  doi={10.1109/TCSVT.2021.3075039},
  ISSN={1558-2205},
  month={March}
}

@ARTICLE{10380590,
  author={Fields, John and Chovanec, Kevin and Madiraju, Praveen},
  journal={IEEE Access}, 
  title={A Survey of Text Classification With Transformers: How Wide? How Large? How Long? How Accurate? How Expensive? How Safe?}, 
  year={2024},
  volume={12},
  number={},
  pages={6518-6531},
  abstract={Text classification in natural language processing (NLP) is evolving rapidly, particularly with the surge in transformer-based models, including large language models (LLM). This paper presents an in-depth survey of text classification techniques across diverse benchmarks, addressing applications from sentiment analysis to chatbot-driven question-answering. Methodologically, it utilizes NLP-facilitated approaches such as co-citation and bibliographic coupling alongside traditional research techniques. Because new use cases continue to emerge in this dynamic field, the study proposes an expanded taxonomy of text classification applications, extending the focus beyond unimodal (text-only) inputs to explore the emerging field of multimodal classification. While offering a comprehensive review of text classification with LLMs, this review highlights novel questions that arise when approaching the task with transformers: It evaluates the use of multimodal data, including text, numeric, and columnar data, and discusses the evolution of text input lengths (tokens) for long text classification; it covers the historical development of transformer-based models, emphasizing recent advancements in LLMs; it evaluates model accuracy on 358 datasets across 20 applications, with results challenging the assumption that LLMs are universally superior, revealing unexpected findings related to accuracy, cost, and safety; and it explores issues related to cost and access as models become increasingly expensive. Finally, the survey discusses new social and ethical implications raised when using LLMs for text classification, including bias and copyright. Throughout, the review emphasizes the importance of a nuanced understanding of model performance and a holistic approach to deploying transformer-based models in real-world applications.},
  keywords={Text categorization;Transformers;Surveys;Task analysis;Taxonomy;Data models;Chatbots;NLP;text classification;transformers;survey},
  doi={10.1109/ACCESS.2024.3349952},
  ISSN={2169-3536},
  month={}
}

@BOOK{10769209,
  author={Thompson, Adrian},
  booktitle={ChatGPT for Conversational AI and Chatbots: Learn how to automate conversations with the latest large language model technologies},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Explore ChatGPT technologies to create state-of-the-art chatbots and voice assistants, and prepare to lead the AI revolutionKey FeaturesLearn how to leverage ChatGPT to create innovative conversational AI solutions for your organizationHarness LangChain and delve into step-by-step LLM application development for conversational AIGain insights into security, privacy, and the future landscape of large language models and conversational AIPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionChatGPT for Conversational AI and Chatbots is a definitive resource for exploring conversational AI, ChatGPT, and large language models. This book introduces the fundamentals of ChatGPT and conversational AI automation. You’ll explore the application of ChatGPT in conversation design, the use of ChatGPT as a tool to create conversational experiences, and a range of other practical applications. As you progress, you’ll delve into LangChain, a dynamic framework for LLMs, covering topics such as prompt engineering, chatbot memory, using vector stores, and validating responses. Additionally, you’ll learn about creating and using LLM-enabling tools, monitoring and fine tuning, LangChain UI tools such as LangFlow, and the LangChain ecosystem. You’ll also cover popular use cases, such as using ChatGPT in conjunction with your own data. Later, the book focuses on creating a ChatGPT-powered chatbot that can comprehend and respond to queries directly from your unique data sources. The book then guides you through building chatbot UIs with ChatGPT API and some of the tools and best practices available. By the end of this book, you’ll be able to confidently leverage ChatGPT technologies to build conversational AI solutions.What you will learnGain a solid understanding of ChatGPT and its capabilities and limitationsUnderstand how to use ChatGPT for conversation designDiscover how to use advanced LangChain techniques, such as prompting, memory, agents, chains, vector stores, and toolsCreate a ChatGPT chatbot that can answer questions about your own dataDevelop a chatbot powered by ChatGPT APIExplore the future of conversational AI, LLMs, and ChatGPT alternativesWho this book is forThis book is for tech-savvy readers, conversational AI practitioners, engineers, product owners, business analysts, and entrepreneurs wanting to integrate ChatGPT into conversational experiences and explore the possibilities of this game-changing technology. Anyone curious about using internal data with ChatGPT and looking to stay up to date with the developments in large language models will also find this book helpful. Some expertise in coding and standard web design concepts would be useful, along with familiarity with conversational AI terminology, though not essential.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781805122357},
  url={https://ieeexplore.ieee.org/document/10769209}
}
