@ARTICLE{10819347,
  author={Salem, Hamza and Salloum, Hadi and Mazzara, Manuel},
  journal={IEEE Access}, 
  title={Mathematical Model and Algorithm for Accurate Main Content Extraction From News Websites}, 
  year={2025},
  volume={13},
  number={},
  pages={15694-15711},
  abstract={Irrelevant elements like ads, menus, and footers in web pages hinder data extraction and reduce the performance of Retrieval-Augmented Generation (RAG) systems in Large Language Models (LLMs). This paper tackles the challenge of accurately identifying and extracting the main content from web pages to enhance the efficiency of these systems. We present a novel mathematical model and algorithm that leverages the Document Object Model (DOM) structure, effectively isolating relevant content with high accuracy. Our approach is language-neutral and performs well across diverse languages, including those with complex tokenization, such as Arabic. To validate the model, we created a dataset from 500 websites, allowing for comprehensive evaluation and benchmarking. The algorithm’s practical application demonstrates a reduction in token usage for LLM tasks, contributing to cost-effectiveness. This work introduces a robust, open-source tool for the academic and commercial communities, fostering further innovation in web content extraction and information retrieval.},
  keywords={Feature extraction;Data mining;Web pages;Accuracy;Hidden Markov models;Mathematical models;Layout;Heuristic algorithms;Convolutional neural networks;Focusing;Information extraction;document object model (DOM);retrieval-augmented generation (RAG);large language models (LLM);main content detection},
  doi={10.1109/ACCESS.2024.3524656},
  ISSN={2169-3536},
  month={},}@ARTICLE{10061219,
  author={Maskeliunas, Rytis and Damaševičius, Robertas and Vitkute-Adzgauskiene, Daiva and Misra, Sanjay},
  journal={IEEE Access}, 
  title={Pareto Optimized Large Mask Approach for Efficient and Background Humanoid Shape Removal}, 
  year={2023},
  volume={11},
  number={},
  pages={33900-33914},
  abstract={The purpose of automated video object removal is to not only detect and remove the object of interest automatically, but also to utilize background context to inpaint the foreground area. Video inpainting requires to fill spatiotemporal gaps in a video with convincing material, necessitating both temporal and spatial consistency; the inpainted part must seamlessly integrate into the background in a variety of scenes, and it must maintain a consistent appearance in subsequent frames even if its surroundings change noticeably. We introduce deep learning-based methodology for removing unwanted human-like shapes in videos. The method uses Pareto-optimized Generative Adversarial Networks (GANs) technology, which is a novel contribution. The system automatically selects the Region of Interest (ROI) for each humanoid shape and uses a skeleton detection module to determine which humanoid shape to retain. The semantic masks of human like shapes are created using a semantic-aware occlusion-robust model that has four primary components: feature extraction, and local, global, and semantic branches. The global branch encodes occlusion-aware information to make the extracted features resistant to occlusion, while the local branch retrieves fine-grained local characteristics. A modified big mask inpainting approach is employed to eliminate a person from the image, leveraging Fast Fourier convolutions and utilizing polygonal chains and rectangles with unpredictable aspect ratios. The inpainter network takes the input image and the mask to create an output image excluding the background humanoid shapes. The generator uses an encoder-decoder structure with included skip connections to recover spatial information and dilated convolution and squeeze and excitation blocks to make the regions behind the humanoid shapes consistent with their surroundings. The discriminator avoids dissimilar structure at the patch scale, and the refiner network catches features around the boundaries of each background humanoid shape. The efficiency was assessed using the Structural Learned Perceptual Image Patch Similarity, Frechet Inception Distance, and Similarity Index Measure metrics and showed promising results in fully automated background person removal task. The method is evaluated on two video object segmentation datasets (DAVIS indicating respective values of 0.02, FID of 5.01 and SSIM of 0.79 and YouTube-VOS, resulting in 0.03, 6.22, 0.78 respectively) as well a database of 66 distinct video sequences of people behind a desk in an office environment (0.02, 4.01, and 0.78 respectively).},
  keywords={Videos;Shape measurement;Feature extraction;Humanoid robots;Semantics;Computer architecture;Image processing;Semantic segmentation;occlusion-robust network;human shape extraction;background person removal;image inpainting},
  doi={10.1109/ACCESS.2023.3253206},
  ISSN={2169-3536},
  month={},}@ARTICLE{10891427,
  author={Wu, Shaowu and Lu, Wei and Luo, Xiangyang},
  journal={IEEE Transactions on Multimedia}, 
  title={Robust Watermarking Based on Multi-layer Watermark Feature Fusion}, 
  year={2025},
  volume={},
  number={},
  pages={1-14},
  abstract={The purpose of robust image watermarking is to embed a watermark into a carrier image in an invisible form and extract the watermark successfully even under noise interference conditions to achieve copyright confirmation and traceability. Although watermarking methods based on deep learning can improve the robustness by adding a noise simulation layer, few theoretical analyses of the codec structure have been conducted. Theoretical explainability is the theoretical basis for developing a network architecture, which plays a guiding role in network development. On the basis of the interpretability of convolutional networks, this paper analyzes the mathematical process of embedding and extracting watermarks in codecs and proposes a novel watermarking framework based on multi-layer watermark feature fusion. Specifically, the encoder can be a convolutional network structure of arbitrary depth, whereas the decoder needs only to adopt its corresponding deconvolution structure. To improve the quality and robustness of the generated watermarked image, the watermark is associated with an arbitrary layer feature space in the decoder. In the decoder, the network quickly converges to each original encoding feature space through the deconvolution structure, thus decoupling the watermark features. Finally, the watermark is extracted via the automatic fusion of multi-layer watermark features. The experimental results show that the proposed method is suitable for few-shot learning, and its invisibility, robustness and generalization performance on multiple datasets are significantly better than those of other advanced methods.},
  keywords={Watermarking;Decoding;Robustness;Feature extraction;Noise;Convolutional neural networks;Training;Deep learning;Distortion;Convolution;Robust watermarking;convolutional network;watermark feature fusion},
  doi={10.1109/TMM.2025.3543079},
  ISSN={1941-0077},
  month={},}@ARTICLE{10723311,
  author={Koide, Takashi and Nakano, Hiroki and Chiba, Daiki},
  journal={IEEE Access}, 
  title={ChatPhishDetector: Detecting Phishing Sites Using Large Language Models}, 
  year={2024},
  volume={12},
  number={},
  pages={154381-154400},
  abstract={Large Language Models (LLMs), such as ChatGPT, are significantly impacting various fields. While LLMs have been extensively studied for code generation and text synthesis, their application in detecting malicious web content, particularly phishing sites, remains largely unexplored. To counter the increasing cyber-attacks that leverage LLMs for creating more sophisticated and convincing phishing content, it is crucial to automate detection by harnessing LLMs’ advanced capabilities. This paper introduces ChatPhishDetector, a novel system that employs LLMs to identify phishing sites. Our approach involves using a web crawler to collect website information, generating prompts for LLMs based on the gathered data, and extracting detection results from LLM responses. This system enables accurate detection of multilingual phishing sites by identifying impersonated brands and social engineering techniques within the entire website context, without requiring machine learning model training. We evaluated our system’s performance using our own dataset and compared it with baseline systems and several LLMs. Experiments using GPT-4V showed exceptional results, achieving 98.7% precision and 99.6% recall, surpassing the detection performance of other LLMs and existing systems. These findings highlight the potential of LLMs for protecting users from online fraudulent activities and provide crucial insights for strengthening defenses against phishing attacks.},
  keywords={Phishing;Uniform resource locators;Large language models;Crawlers;Codes;Web pages;Security;Accuracy;Visualization;Cognition;Large language models;phishing sites;social engineering},
  doi={10.1109/ACCESS.2024.3483905},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10378495,
  author={Wang, Alex Jinpeng and Lin, Kevin Qinghong and Zhang, David Junhao and Lei, Stan Weixian and Shou, Mike Zheng},
  booktitle={2023 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Too Large; Data Reduction for Vision-Language Pre-Training}, 
  year={2023},
  volume={},
  number={},
  pages={3124-3134},
  abstract={This paper examines the problems of severe image-text misalignment and high redundancy in the widely-used large-scale Vision-Language Pre-Training (VLP) datasets. To address these issues, we propose an efficient and straightforward Vision-Language learning algorithm called ${\color {Purple}{TL;DR}}$, which aims to compress the existing large VLP data into a small, high-quality set. Our approach consists of two major steps. First, a codebook-based encoder-decoder captioner is developed to select representative samples. Second, a new caption is generated to complement the original captions for selected samples, mitigating the text-image misalignment problem while maintaining uniqueness. As the result, ${\color {Purple}{TL;DR}}$ enables us to reduce the large dataset into a small set of high-quality data, which can serve as an alternative pre-training dataset. This algorithm significantly speeds up the time-consuming pretraining process. Specifically, ${\color {Purple}{TL;DR}}$ can compress the mainstream VLP datasets at a high ratio, e.g., reduce well-cleaned CC3M dataset from 2.82M to 0.67M (~24%) and noisy YFCC15M from 15M to 2.5M (~16.7%). Extensive experiments with three popular VLP models over seven downstream tasks show that VLP model trained on the compressed dataset provided by ${\color {Purple}{TL;DR}}$ can perform similar or even better results compared with training on the full-scale dataset1.},
  keywords={Training;Computer vision;Image coding;Computational modeling;Redundancy;Noise measurement;Task analysis},
  doi={10.1109/ICCV51070.2023.00292},
  ISSN={2380-7504},
  month={Oct},}@INPROCEEDINGS{8541769,
  author={},
  booktitle={2018 48th European Microwave Conference (EuMC)}, 
  title={Book of Abstracts}, 
  year={2018},
  volume={},
  number={},
  pages={1-75},
  abstract={Presents abstracts for the articles comprising the conference proceedings.},
  keywords={Microwave filters;Microwave theory and techniques;Microwave communication;Microwave circuits;Microwave photonics;Microwave antenna arrays;Radar antennas},
  doi={10.23919/EuMC.2018.8541769},
  ISSN={},
  month={Sep.},}@ARTICLE{10015581,
  author={Arsenyan, Jbid and Piepenbrink, Anke},
  journal={IEEE Transactions on Engineering Management}, 
  title={Artificial Intelligence Research in Management: A Computational Literature Review}, 
  year={2024},
  volume={71},
  number={},
  pages={5088-5100},
  abstract={Artificial intelligence (AI) spring of the past decade created an increased interest into the topic in business as well as in academia. This resulted in an upward trend in academic publications, not only in computer science but also in management. This article presents a computational literature review with an abstract-based sampling approach to investigate the status of the management literature to take stock of academic research of the past two decades. We analyze 6324 papers from 1990 to 2020 published in five management-related domains and identify 41 distinct topics. We present the evolution of research pre and post AI spring, emerging topics as well as saturated areas. The findings show that the previously disjointed topic network structure is fully connected by early 2010s and the upward trend in management research starts in the period of 2014–2015. The results provide a comprehensive insight into the potential of AI in management versus underdeveloped areas, and presents, for management scholars and practitioners, suggestions about effective adoption of AI practices.},
  keywords={Artificial intelligence;Business;Machine learning;Inspection;Bibliographies;Vocabulary;Computational modeling;Artificial intelligence (AI);computational literature review (CLR);latent Dirichlet allocation (LDA);management research},
  doi={10.1109/TEM.2022.3229821},
  ISSN={1558-0040},
  month={},}@ARTICLE{8402266,
  author={},
  journal={IEEE P11073-10101/D1, June 2018}, 
  title={IEEE Draft Standard for Health Informatics—Point-of-Care Medical Device Communication—Part 10101: Nomenclature}, 
  year={2018},
  volume={},
  number={},
  pages={1-704},
  abstract={Within the context of the ISO/IEEE 11073 family of standards for point-of-care (POC) and personal health devices (PHD) medical device communication (MDC), this standard provides the nomenclature that supports both the domain information model and service model components of the standards family, as well as the semantic content exchanged with medical devices. The nomenclature is specialized for patient vital signs information representation and medical device informatics, with major areas including concepts for electrocardiograph (ECG), haemodynamics, respiration, blood gas, urine, fluid-related metrics, and neurology, as well as specialized units of measurement, general device events, alarms, and body sites. The standard defines both the architecture and major components of the nomenclature, along with extensive definitions for each conceptual area.},
  keywords={IEEE Standards;Medica devices;Point of care;Patient monitoring;Smart healthcare;Terminology;codes;IEEE 11073-10101;IHE PCD-01;independent living;information model;medical device communication;nomenclature;ontology;patient;personal health devices;PHD;POC;point-of-care;semantics;service model;terminology},
  doi={},
  ISSN={},
  month={July},}@ARTICLE{9184351,
  author={},
  journal={ISO/IEEE 11073-10101:2020(E)}, 
  title={ISO/IEEE International Standard - Health informatics-Device interoperability-Part 10101: Point-of-care medical device communication-Nomenclature}, 
  year={2020},
  volume={},
  number={},
  pages={1-1064},
  abstract={Within the context of the ISO/IEEE 11073 family of standards for point-of-care (POC) and personal health devices (PHD) medical device communication (MDC), this standard provides the nomenclature that supports both the domain information model and service model components of the standards family, as well as the semantic content exchanged with medical devices. The nomenclature is specialized for patient vital signs information representation and medical device informatics, with major areas including concepts for electrocardiograph (ECG), haemodynamics, respiration, blood gas, urine, fluid-related metrics, and neurology, as well as specialized units of measurement, general device events, alarms, and body sites. The standard defines both the architecture and major components of the nomenclature, along with extensive definitions for each conceptual area.},
  keywords={IEEE Standards;Medical devices;Biomedical monitoring;Point of care;Bioinformatics;codes;IEEE 11073-10101™;IHE PCD-01;independent living;information model;medical device communication;nomenclature;ontology;patient;personal health devices;PHD;POC;point-of-care;semantics;service model;terminology},
  doi={10.1109/IEEESTD.2020.9184351},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10888762,
  author={Long, Yilin and Yang, Zhongliang and Wang, Zhuang and Zhou, Zhili and Huang, Yongfeng and Zhou, Linna},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={SCF-Stega: Controllable Linguistic Steganography Based on Semantic Communications Framework}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Linguistic steganography is a key information hiding technique but faces challenges like abrupt content shifts, detection risks, and high training resource demands. To address these, this paper introduces SCF-Stega, a controllable method based on Semantic Communications Framework. By using a knowledge graph to guide secret encoding and dynamically adjusting large language model outputs, SCF-Stega enhances text imperceptibility and semantic coherence. Experiments show improved text quality and strong resistance to steganalysis, without needing additional training data.},
  keywords={Training;Resistance;Steganography;Training data;Linguistics;Signal processing;Semantic communication;Encoding;Security;Speech processing;Linguistic steganography;semantic communications;knowledge graph;large language models},
  doi={10.1109/ICASSP49660.2025.10888762},
  ISSN={2379-190X},
  month={April},}@ARTICLE{10413528,
  author={Bezzi, Michele},
  journal={IEEE Security & Privacy}, 
  title={Large Language Models and Security}, 
  year={2024},
  volume={22},
  number={2},
  pages={60-68},
  abstract={We analyze the security implications of large language models (LLMs) from their use as security tools for both attackers and defenders and the security of LLMs. We discuss how LLMs increase the scale of traditional threats such as social engineering and add new ones such as prompt injections.},
  keywords={Security;Phishing;Malware;Fake news;Electronic mail;Costs;Computational modeling;Large language models},
  doi={10.1109/MSEC.2023.3345568},
  ISSN={1558-4046},
  month={March},}@INPROCEEDINGS{10392411,
  author={Liu, Chang and Yang, Lei},
  booktitle={2023 IEEE 3rd International Conference on Data Science and Computer Application (ICDSCA)}, 
  title={Research on English Data Intelligent Retrieval Terminal System Based on Computer 3D Image Vision Technology}, 
  year={2023},
  volume={},
  number={},
  pages={1097-1102},
  abstract={This paper introduces an embedded software for English information query based on ARM single chip microcomputer LPC2290 and Mini GUI. Integrate the Mini GUI with network communication. Remote access to MySQL using C/S architecture. The hardware and software architecture of English data intelligent retrieval terminal system is presented. The graphical interface of the system and the data extraction of the system are completed based on Mini GUI. Several main implementation links of the system are also explained. This paper presents an intelligent query terminal based on English data, which improves the user interface very well. It can not only realize the intelligent search of English data, but also solve the expensive problem of the traditional intelligent search terminal of English data.},
  keywords={Three-dimensional displays;Software architecture;Operating systems;Computer architecture;Search problems;Hardware;Graphical user interfaces;3D image;visual technology;English materials;intelligent retrieval;terminal system},
  doi={10.1109/ICDSCA59871.2023.10392411},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10825103,
  author={Rababah, Baha and Wu, Shang Tommy and Kwiatkowski, Matthew and Leung, Carson K. and Akcora, Cuneyt Gurcan},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={SoK: Prompt Hacking of Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={5392-5401},
  abstract={The safety and robustness of large language models (LLMs) based applications remain critical challenges in artificial intelligence. Among the key threats to these applications are prompt hacking attacks, which can significantly undermine the security and reliability of LLM-based systems. In this work, we offer a comprehensive and systematic overview of three distinct types of prompt hacking: jailbreaking, leaking, and injection, addressing the nuances that differentiate them despite their overlapping characteristics. To enhance the evaluation of LLM-based applications, we propose a novel framework that categorizes LLM responses into five distinct classes, moving beyond the traditional binary classification. This approach provides more granular insights into the AI’s behavior, improving diagnostic precision and enabling more targeted enhancements to the system’s safety and robustness.},
  keywords={Hands;Systematics;Large language models;Refining;Big Data;Robustness;Safety;Security;Computer crime;Usability;LLMs},
  doi={10.1109/BigData62323.2024.10825103},
  ISSN={2573-2978},
  month={Dec},}@INPROCEEDINGS{10387642,
  author={Lofstead, Jay},
  booktitle={2023 Fifth International Conference on Transdisciplinary AI (TransAI)}, 
  title={Economic, Societal, Legal, and Ethical Considerations for Large Language Models}, 
  year={2023},
  volume={},
  number={},
  pages={155-162},
  abstract={Systems like ChatGPT-3 captured the imagination in late 2022. The quality of the systems surprised and delighted many with both a flurry of lawsuits, predictions of the collapse of many white collar careers, and decimation of artist incomes. The potential to have an interactive tool that can work like an interactive textbook is compelling and potentially transformative for the betterment of humanity offering low cost access to something to talk with about just about anything. This can enable learning to whole new audiences. With this potential upside, the current status of these tools in terms of the economics of the tools themselves, how their costs compare to human labor, the impacts on human jobs both white collar and creative, and in the current legal environment must be considered to best see the future these tools may offer. This work examines what these tools are, how they work, and the implications of how they are created through all of these lenses to give a holistic view of the current state and potential future possibilities. While this is a changing landscape, the current status can offer a strong position to talk about these tools and help guide what the future will be like.},
  keywords={Ethics;Art;Costs;Law;Biological system modeling;Training data;Companies;artificial intelligence;machine learning;ethics;society;economics;law},
  doi={10.1109/TransAI60598.2023.00049},
  ISSN={},
  month={Sep.},}@BOOK{10769321,
  author={Rivera, Stephanie and Prokaieva, Anastasia and Baker, Amanda and Horn, Hayley},
  booktitle={Databricks ML in Action: Learn how Databricks supports the entire ML lifecycle end to end from data ingestion to the model deployment},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Get to grips with autogenerating code, deploying ML algorithms, and leveraging various ML lifecycle features on the Databricks Platform, guided by best practices and reusable code for you to try, alter, and build onKey FeaturesBuild machine learning solutions faster than peers only using documentationEnhance or refine your expertise with tribal knowledge and concise explanationsFollow along with code projects provided in GitHub to accelerate your projectsPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionDiscover what makes the Databricks Data Intelligence Platform the go-to choice for top-tier machine learning solutions. Written by a team of industry experts at Databricks with decades of combined experience in big data, machine learning, and data science, Databricks ML in Action presents cloud-agnostic, end-to-end examples with hands-on illustrations of executing data science, machine learning, and generative AI projects on the Databricks Platform. You’ll develop expertise in Databricks' managed MLflow, Vector Search, AutoML, Unity Catalog, and Model Serving as you learn to apply them practically in everyday workflows. This Databricks book not only offers detailed code explanations but also facilitates seamless code importation for practical use. You’ll discover how to leverage the open-source Databricks platform to enhance learning, boost skills, and elevate productivity with supplemental resources. By the end of this book, you'll have mastered the use of Databricks for data science, machine learning, and generative AI, enabling you to deliver outstanding data products.What you will learnSet up a workspace for a data team planning to perform data scienceMonitor data quality and detect driftUse autogenerated code for ML modeling and data explorationOperationalize ML with feature engineering client, AutoML, VectorSearch, Delta Live Tables, AutoLoader, and WorkflowsIntegrate open-source and third-party applications, such as OpenAI's ChatGPT, into your AI projectsCommunicate insights through Databricks SQL dashboards and Delta SharingExplore data and models through the Databricks marketplaceWho this book is forThis book is for machine learning engineers, data scientists, and technical managers seeking hands-on expertise in implementing and leveraging the Databricks Data Intelligence Platform and its Lakehouse architecture to create data products.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781800564008},
  url={https://ieeexplore.ieee.org/document/10769321},}@INPROCEEDINGS{9484363,
  author={Colbois, Laurent and Freitas Pereira, Tiago de and Marcel, Sébastien},
  booktitle={2021 IEEE International Joint Conference on Biometrics (IJCB)}, 
  title={On the use of automatically generated synthetic image datasets for benchmarking face recognition}, 
  year={2021},
  volume={},
  number={},
  pages={1-8},
  abstract={The availability of large-scale face datasets has been key in the progress of face recognition. However, due to licensing issues or copyright infringement, some datasets are not available anymore (e.g. MS-Celeb-1M). Recent advances in Generative Adversarial Networks (GANs), to synthesize realistic face images, provide a pathway to replace real datasets by synthetic datasets, both to train and benchmark face recognition (FR) systems. The work presented in this paper provides a study on benchmarking FR systems using a synthetic dataset. First, we introduce the proposed methodology to generate a synthetic dataset, without the need for human intervention, by exploiting the latent structure of a StyleGAN2 model with multiple controlled factors of variation. Then, we confirm that (i) the generated synthetic identities are not data subjects from the GAN’s training dataset, which is verified on a synthetic dataset with 10K+ identities; (ii) benchmarking results on the synthetic dataset are a good substitution, often providing error rates and system ranking similar to the benchmarking on the real dataset.},
  keywords={Training;Visualization;Databases;Error analysis;Face recognition;Semantics;Benchmark testing},
  doi={10.1109/IJCB52358.2021.9484363},
  ISSN={2474-9699},
  month={Aug},}@BOOK{10460890,
  author={Mizrahi, Gilbert and Serfaty, Daniel},
  booktitle={Unlocking the Secrets of Prompt Engineering: Master the art of creative language generation to accelerate your journey from novice to pro},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Enhance your writing with AI by mastering prompt engineering techniques and become an expert in developing and utilizing LLM prompts across applicationsKey FeaturesMaster prompt engineering techniques to harness AI's writing potentialDiscover diverse LLM applications for content creation and beyondLearn through practical examples, use cases, and hands-on guidancePurchase of the print or Kindle book includes a free PDF eBookBook DescriptionUnlocking the Secrets of Prompt Engineering is your key to mastering the art of AI-driven writing. This book propels you into the world of large language models (LLMs), empowering you to create and apply prompts effectively for diverse applications, from revolutionizing content creation and chatbots to coding assistance. Starting with the fundamentals of prompt engineering, this guide provides a solid foundation in LLM prompts, their components, and applications. Through practical examples and use cases, you'll discover how LLMs can be used for generating product descriptions, personalized emails, social media posts, and even creative writing projects like fiction and poetry. The book covers advanced use cases such as creating and promoting podcasts, integrating LLMs with other tools, and using AI for chatbot development. But that’s not all. You'll also delve into the ethical considerations, best practices, and limitations of using LLM prompts as you experiment and optimize your approach for best results. By the end of this book, you'll have unlocked the full potential of AI in writing and content creation to generate ideas, overcome writer's block, boost productivity, and improve communication skills.What you will learnExplore the different types of prompts, their strengths, and weaknessesUnderstand the AI agent's knowledge and mental modelEnhance your creative writing with AI insights for fiction and poetryDevelop advanced skills in AI chatbot creation and deploymentDiscover how AI will transform industries such as education, legal, and othersIntegrate LLMs with various tools to boost productivityUnderstand AI ethics and best practices, and navigate limitations effectivelyExperiment and optimize AI techniques for best resultsWho this book is forThis book is for a wide audience, including writers, marketing and business professionals, researchers, students, tech enthusiasts, and creative individuals. Anyone looking for strategies and examples for using AI co-writing tools like ChatGPT effectively in domains such as content creation, drafting emails, and inspiring artistic works, will find this book especially useful. If you are interested in AI, NLP, and innovative software for personal or professional use, this is the book for you.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835088265},
  url={https://ieeexplore.ieee.org/document/10460890},}@INPROCEEDINGS{10020431,
  author={Chen, Yao and Gui, Yijie and Lin, Hong and Gan, Wensheng and Wu, Yongdong},
  booktitle={2022 IEEE International Conference on Big Data (Big Data)}, 
  title={Federated Learning Attacks and Defenses: A Survey}, 
  year={2022},
  volume={},
  number={},
  pages={4256-4265},
  abstract={In terms of artificial intelligence, there are several security and privacy deficiencies in the traditional centralized training methods of machine learning models by a server. To address this limitation, federated learning (FL) has been proposed and is known for breaking down "data silos" and protecting the privacy of users. However, FL has not yet gained popularity in the industry, mainly due to its security, privacy, and high cost of communication. For the purpose of advancing the research in this field, building a robust FL system, and realizing the wide application of FL, this paper sorts out the possible attacks and corresponding defenses of the current FL system systematically. Firstly, this paper briefly introduces the basic workflow of FL and related knowledge of attacks and defenses. It reviews a great deal of research about privacy theft and malicious attacks that have been studied in recent years. Most importantly, in view of the current three classification criteria, namely the three stages of machine learning, the three different roles in federated learning, and the CIA (Confidentiality, Integrity, and Availability) guidelines on privacy protection, we divide attack approaches into two categories according to the training stage and the prediction stage in machine learning. Furthermore, we also identify the CIA property violated for each attack method and potential attack role. Various defense mechanisms are then analyzed separately from the level of privacy and security. Finally, we summarize the possible challenges in the application of FL from the aspect of attacks and defenses and discuss the future development direction of FL systems. In this way, the designed FL system has the ability to resist different attacks and is more secure and stable.},
  keywords={Training;Privacy;Pediatrics;Systematics;Costs;Federated learning;Resists;federated learning;attacks;defenses;challenges;opportunities},
  doi={10.1109/BigData55660.2022.10020431},
  ISSN={},
  month={Dec},}@ARTICLE{10706921,
  author={Zainuddin, Zahirah and Akhir, Emelia Akashah P.},
  journal={IEEE Access}, 
  title={Systematic Literature Review of Data Quality in Open Government Data: Trend, Methods, and Applications}, 
  year={2024},
  volume={12},
  number={},
  pages={148466-148487},
  abstract={An open government data (OGD) is an assortment of datasets dumped by government agencies into a portal with the goal of promoting the legitimacy and openness of government operations and processes to citizens. OGD also assist citizens in obtaining other forms of information to aid in decision-making or planning. However, poor data quality (DQ) leads to users losing interest and trust in using the data. DQ is a type of measurement that determines the usefulness of data. It is a vast issue for discussion, with uncertainty arising from the diversity across a range of descriptions and dimensions. Hence, this study explored the concept of DQ and found the completeness dimension as a vital component in OGD. According to an analysis of 37 articles, incomplete, missing, and unknown values all had a direct effect on completeness. This study illustrated recent ways of addressing the issue, as well as real life examples. Finally, this study offers recommendations for novices and other intellectuals for improvement in future research.},
  keywords={Accuracy;Government;Data integrity;Economics;Portals;Open data;Data visualization;Technological innovation;Standards;Metadata;Completeness;data quality;dimension;missing value;open government data},
  doi={10.1109/ACCESS.2024.3475577},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10770985,
  author={Procko, Tyler Thomas and Davidoff, Alexandra and Elvira, Timothy and Ochoa, Omar},
  booktitle={2024 Conference on AI, Science, Engineering, and Technology (AIxSET)}, 
  title={Leveraging Large Language Models on the Traditional Scientific Writing Workflow}, 
  year={2024},
  volume={},
  number={},
  pages={154-161},
  abstract={Technological advances in Natural Language Processing have brought forth language models capable of advanced response delivery. Scientific papers are traditionally written manually by human researchers, but with the advent of mainstream Large Language Models, e.g., OpenAI's ChatGPT, it is of increasing concern to scientists and academics that content in scientific papers may be generated by Artificial Intelligence (AI). Wishing to stop this is a losing attitude, as large-scale generative AI only becomes more powerful and accessible. Taking the more tenable position of cautious adaptation, this paper argues that there exists a taxonomy in the structure of scientific papers, and that language models can be used by scientific researchers to bootstrap scientific writing. Furthermore, AI can augment their own writing workflow to more efficiently traverse the academic publishing pipeline. Despite the shortcomings of language models, e.g., hallucination, when prompted appropriately with sufficient constraints, language models are extremely accurate and efficient content providers. In this work, the canonical scientific paper is broken down into its taxonomy of parts, where it is then considered how each part can benefit from language models, e.g., in generating abstracts and keywords, reformatting sections, theorizing titles, etc. Finally, a call for consensus among the academic and scientific communities regarding the use of language models in the scientific writing workflow is established.},
  keywords={Adaptation models;Generative AI;Publishing;Large language models;Taxonomy;Pipelines;Writing;Horses;Throughput;Automobiles;literature review;metascience;scientific workflow system;language model;scientific writing;academia;GPT},
  doi={10.1109/AIxSET62544.2024.00028},
  ISSN={},
  month={Sep.},}@BOOK{9647706,
  author={Portwood-Stacer, Laura},
  booktitle={The Book Proposal Book: A Guide for Scholarly Authors},
  year={2021},
  volume={},
  number={},
  pages={},
  abstract={A step-by-step guide to crafting a compelling scholarly book proposal—and seeing your book through to successful publicationThe scholarly book proposal may be academia’s most mysterious genre. You have to write one to get published, but most scholars receive no training on how to do so—and you may have never even seen a proposal before you’re expected to produce your own. The Book Proposal Book cuts through the mystery and guides prospective authors step by step through the process of crafting a compelling proposal and pitching it to university presses and other academic publishers.Laura Portwood-Stacer, an experienced developmental editor and publishing consultant for academic authors, shows how to select the right presses to target, identify audiences and competing titles, and write a project description that will grab the attention of editors—breaking the entire process into discrete, manageable tasks. The book features over fifty time-tested tips to make your proposal stand out; sample prospectuses, a letter of inquiry, and a response to reader reports from real authors; optional worksheets and checklists; answers to dozens of the most common questions about the scholarly publishing process; and much, much more.Whether you’re hoping to publish your first book or you’re a seasoned author with an unfinished proposal languishing on your hard drive, The Book Proposal Book provides honest, empathetic, and invaluable advice on how to overcome common sticking points and get your book published. It also shows why, far from being merely a hurdle to clear, a well-conceived proposal can help lead to an outstanding book.},
  keywords={Publishing;Publication;Author;Writing;Academic publishing;Paragraph;Copy editing;Princeton University Press;Suggestion;Guideline;Manuscript;Target audience;Table of contents;Narrative;Marketing;Credential;Handbook;Career;Bibliography;Website;Word count;Finding;Writing style;Understanding;Email;Publicist;Editorial board;Literature review;Article (publishing);Proofreading;Editorial;Case study;Literary agent;Peer review;Copyright;Gaze;Quality assurance;Illustration;First Book;Editing;Rhetorical question;Phenomenon;Passive voice;Writing process;Wildlife conservation;Funding;Academic journal;Citizen science;Technology;Book;Recommendation (European Union);Edition (book);Designer;Developmental editing;Writer;Rhetoric;Environmental protection;Search engine optimization;Ecosystem;Institution;Monograph;Calculation;Marketing plan;Price point;Academic writing;Social media;Publicity;Consideration;Documents (magazine);Sociology;Brand management;Femininity;Librarian;Style guide;Symbolic capital;On Royalty;Neoliberalism;Qualitative research;Verb;Infrastructure;Thesis statement;Routledge;Criticism;Decision-making;Book design;Textbook;Creative director;Methodology;Sensibility;Brand culture;University of Illinois Press;Sentence (linguistics);Newspaper;Hardcover;Description;Public talks;Empowerment;Sexism;Globalization;One Laptop per Child},
  doi={},
  ISSN={},
  publisher={Princeton University Press},
  isbn={9780691216621},
  url={https://ieeexplore.ieee.org/document/9647706},}@ARTICLE{10756226,
  author={Twomey, John and Ching, Didier and Peter Aylett, Matthew and Quayle, Michael and Linehan, Conor and Murphy, Gillian},
  journal={IEEE Transactions on Technology and Society}, 
  title={What Is So Deep About Deepfakes? A Multi-Disciplinary Thematic Analysis of Academic Narratives About Deepfake Technology}, 
  year={2025},
  volume={6},
  number={1},
  pages={64-79},
  abstract={Deepfakes are a form of synthetic media that uses deep-learning technology to create fake images, video, and audio. The emergence of this technology has inspired much commentary and speculation from academics across a range of disciplines, who have contributed expert opinions regarding the implications of deepfake proliferation on fields such as law, politics, and entertainment. A systematic scoping review was carried out to identify, assemble, and critically analyze those academic narratives. The aim is to build on and critique previous attempts at defining the technology and categorizing the harms and benefits of deepfake technology. A range of databases were searched for relevant articles from 2017 to 2023, resulting in a large multi-disciplinary dataset of 102 papers, 181,659 words long, which were analyzed qualitatively through thematic analysis. Implications for future research include questioning the lack of research evidence for the supposed positives of deepfakes, recognizing the role that identity plays in deepfake technology, challenging the perceived accessibility/ believability of deepfakes, and proposing a more nuanced approach to the dichotomous “positive and negatives” of deepfakes. Furthermore, we show how definitional issues around what a deepfake is versus other forms of fake media feeds confusion around the novelty and impacts of deepfakes.},
  keywords={Deepfakes;Reviews;Generative AI;Software;Psychology;Social networking (online);Organizations;Lenses;Law;Internet;Deepfakes;social implications of technology;media},
  doi={10.1109/TTS.2024.3493465},
  ISSN={2637-6415},
  month={March},}@INPROCEEDINGS{10073803,
  author={Pratik, Rishank and Sendhil, R.},
  booktitle={2023 Third International Conference on Artificial Intelligence and Smart Energy (ICAIS)}, 
  title={Privacy Protection Against Reverse Image Search}, 
  year={2023},
  volume={},
  number={},
  pages={1207-1214},
  abstract={The user wants to include their image in their résumé, LinkedIn profile, or any other relevant place and doesn't want their personal life to be viewed using a reverse image search, which can trace back their professional image to their social ID based on facial image. They may not want to be evaluated as social media account may expose sensitive information or personal life. Various techniques such as synthetic modification exist to protect the privacy of an individual but they mostly tend to distort the image to such an extent that figure is not identifiable as a human or some other person is represented.This article provides a technique that enables people to protect their images against the misuse of facial recognition software enabling humans to identify the person but machines fail to recognize the person. The proposed method would help the users to edit their images at the pixel level and removing the metadata before sharing them. These "cloaked" images yield functional models that repeatedly lead to incorrect identification of typical images of the user when used to train facial recognition models. When combined with metadata removal, it highly reduces the possibility of image traceback to a person’s social ID.},
  keywords={Privacy;Image recognition;Social networking (online);Face recognition;Multimedia Web sites;Organizations;Metadata;Privacy protection;image recognition;metadata;cloaking;reverse search;google lens},
  doi={10.1109/ICAIS56108.2023.10073803},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{8494856,
  author={Rahman, M Tanjidur and Shi, Qihang and Tajik, Shahin and Shen, Haoting and Woodard, Damon L. and Tehranipoor, Mark and Asadizanjani, Navid},
  booktitle={2018 IEEE 3rd International Verification and Security Workshop (IVSW)}, 
  title={Physical Inspection & Attacks: New Frontier in Hardware Security}, 
  year={2018},
  volume={},
  number={},
  pages={93-102},
  abstract={Due to globalization, the semiconductor industry is becoming more susceptible to trust and security issues. Hardware Trojans, i.e., malicious modification to integrated circuits (ICs), can violate the root of trust when the devices are fabricated in untrusted facilities. Literature shows as the microscopy and failure analysis tools excel in the resolution and capability, physical inspection methods like reverse engineering and photonic emission become attractive in helping verify such trust issues. On the contrary, such physical inspection methods are opening new capabilities for an adversary to extract sensitive information like secret keys, memory content or intellectual property (IP) from the chip compromising confidentiality and integrity. Different countermeasures have been proposed, however, there are still many unanswered questions. In this paper, we discuss physical inspection/attack methods using failure analysis tools and analyze the existing countermeasures and security/trust issues related to them. Next, we will introduce challenges related to the development of new countermeasures and trust verification. Finally, we present research roadmap for this emerging field.},
  keywords={Reverse engineering;Hardware;Integrated circuits;Trojan horses;Security;Inspection;Tools;Physical Inspection/attacks;Invasive attacks;Reverse Engineering;Probing;Optical Attacks},
  doi={10.1109/IVSW.2018.8494856},
  ISSN={},
  month={July},}@ARTICLE{10810321,
  author={Li, Xuan and Zhang, Guomin and Chen, Weiwei and Cheng, Li and Xie, Yining and Ma, Jiayi},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={An Infrared and Visible Image Fusion Method Based on Semantic-Sensitive Mask Selection and Bidirectional-Collaboration Region Fusion}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  abstract={Mask is considered as an important prior for fusion, which could selectively enhance specific regions to generate ideal fused images. However, masks used in the existing methods exhibit limitations in the precise representation of targets, and more importantly, these masks are generated from a single modality, which restricts the effective integration of multi-modal information. To address this issue, we propose a competitive mask-guidance fusion method for infrared and visible images. A multi-modal semantic-sensitive mask selection network is proposed to generate complementary-mask maps, which organically integrate advantageous target regions of different modalities by competitively comparing the qualities of masks. In this network, a pseudosiamese architecture is designed to obtain respective target masks, and specifically, a spatial-aligned-based feature aggregation module is devised to produce high-quality pseudo-labels which are served as references for the generation of the complementary-mask maps. Furthermore, we propose a bidirectional-collaboration region fusion strategy, which enhances the expression of advantageous target regions from each modality in foreground while suppressing the contribution of corresponding regions from the other modality in background. Compared to methods on public datasets, the results show that our method significantly enhances the description of semantic-sensitive targets in fused images, including the saliency and the integrity of structural information. Code are available at https://github.com/9DunDun9/FusionNet.git.},
  keywords={Feature extraction;Image fusion;Circuits and systems;Deep learning;Generators;Network architecture;Measurement;Image reconstruction;Generative adversarial networks;Visual effects;Image fusion;Semantic-sensitive mask selection;Complementary-mask map;Bidirectional-collaboration fusion},
  doi={10.1109/TCSVT.2024.3520252},
  ISSN={1558-2205},
  month={},}@ARTICLE{10577671,
  author={Fang, Wenji and Lu, Yao and Liu, Shang and Zhang, Qijun and Xu, Ceyu and Wu Wills, Lisa and Zhang, Hongce and Xie, Zhiyao},
  journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems}, 
  title={Transferable Presynthesis PPA Estimation for RTL Designs With Data Augmentation Techniques}, 
  year={2025},
  volume={44},
  number={1},
  pages={200-213},
  abstract={In modern VLSI design flow, evaluating the quality of register-transfer level (RTL) designs involves time-consuming logic synthesis using electronic design automation tools, a process that often slows down early optimization. While recent machine learning (ML) solutions offer some advancements, they typically struggle with maintaining high accuracy across any given RTL design. In this work, we propose an innovative transferable presynthesis power, performance, and area (PPA) estimation framework named MasterRTL. It first converts the hardware description language code to a new bit-level design representation named the simple operator graph (SOG). By only adopting single-bit simple operators, this SOG proves to be a general representation that unifies different design types and styles. The SOG is also more similar to the target gate-level netlist, reducing the gap between the RTL representation and netlist. In addition to the new SOG representation, MasterRTL proposes new ML methods for the RTL-stage modeling of timing, power, and area separately. Compared with the state-of-the-art solutions, the experiment on a comprehensive dataset with 90 different designs shows accuracy improvement by 0.33, 0.22, and 0.15 in correlation for total negative slack (TNS), worst negative slack (WNS), and power, respectively. Besides the prediction of the synthesis results, MasterRTL also excels in accurately predicting layout-stage PPA based on the RTL designs and in adapting across different technology nodes and process corners. Furthermore, we investigate two effective data augmentation techniques: 1) a graph generation method and 2) a large language model (LLM)-based approach. Our results validate the effectiveness of the generated RTL designs in mitigating the data shortage challenges.},
  keywords={Data models;Layout;Timing;Data augmentation;Codes;Predictive models;Logic gates;Data augmentation;power modeling;register-transfer level (RTL);timing analysis},
  doi={10.1109/TCAD.2024.3420904},
  ISSN={1937-4151},
  month={Jan},}@ARTICLE{10539125,
  author={Nanni, Loris and Brahnam, Sheryl and Loreggia, Andrea},
  journal={IEEE Access}, 
  title={An Enhanced Loss Function for Semantic Road Segmentation in Remote Sensing Images}, 
  year={2024},
  volume={12},
  number={},
  pages={74218-74229},
  abstract={The analysis of road continuity in satellite images is a complex challenge. This is due to the difficulty in identifying the directional vector of road sections, especially when the satellite view of roads is obstructed by trees or other structures. Today, most research focuses on optimizing the deep learning network topology, however, the accuracy of segmentation is affected by the loss function used in training; currently, little research has been published on ad-hoc loss functions for road segmentation. To solve this problem, we proposed loss functions based on topological pixel analysis, in which more weight is given to problematic pixels representing non-real road breaks. We report the results of different tests, obtaining state-of-the-art performance among convolution neural network-based approaches. For instance, on the Massachusetts Roads dataset, our method achieved a Dice score of 75.34% and an IoU of 60.44%, compared to the best baseline scores of 74.64% and 59.51% achieved by GapLoss. Similarly, on the DeepGlobe Roads dataset, our method obtained a Dice score of 79.78% and an IoU of 66.36%, outperforming the best baseline scores of 78.62% and 64.47% by GapLoss. Both the code and information for replicating our experiments are available at https://github.com/LorisNanni/An-Enhanced-Loss-Function-for-Semantic-Road-Segmentation-in-Remote-Sensing-Images, so as to enable future reliable comparisons.},
  keywords={Roads;Image segmentation;Remote sensing;Task analysis;Convolution;Feature extraction;Deep learning;Convolutional neural networks;road segmentation;optimization;ensemble},
  doi={10.1109/ACCESS.2024.3405559},
  ISSN={2169-3536},
  month={},}@ARTICLE{10819422,
  author={Kim, Taeheon and Chung, Sangyun and Yeom, Damin and Yu, Youngjoon and Kim, Hak Gu and Ro, Yong Man},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={MSCoTDet: Language-driven Multi-modal Fusion for Improved Multispectral Pedestrian Detection}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  abstract={Multispectral pedestrian detection is attractive for around-the-clock applications due to the complementary information between RGB and thermal modalities. However, current models often fail to detect pedestrians in certain cases (e.g., thermal-obscured pedestrians), particularly due to the modality bias learned from statistically biased datasets. In this paper, we investigate how to mitigate modality bias in multispectral pedestrian detection using a Large Language Model (LLM). Accordingly, we design a Multispectral Chain-of-Thought (MSCoT) prompting strategy, which prompts the LLM to perform multispectral pedestrian detection. Moreover, we propose a novel Multispectral Chain-of-Thought Detection (MSCoTDet) framework that integrates MSCoT prompting into multispectral pedestrian detection. To this end, we design a Language-driven Multi-modal Fusion (LMF) strategy that enables fusing the outputs of MSCoT prompting with the detection results of vision-based multispectral pedestrian detection models. Extensive experiments validate that MSCoTDet effectively mitigates modality biases and improves multispectral pedestrian detection.},
  keywords={Pedestrians;Detectors;Circuits and systems;Training;Feature extraction;Visualization;Large language models;Accuracy;Training data;Reliability;Multispectral Chain-of-Thought Detection;Language-driven Multi-modal Fusion;Multispectral Pedestrian Detection;Large Language Models},
  doi={10.1109/TCSVT.2024.3524645},
  ISSN={1558-2205},
  month={},}@ARTICLE{10584534,
  author={Malik, Jasmita and Muthalagu, Raja and Pawar, Pranav M.},
  journal={IEEE Access}, 
  title={A Systematic Review of Adversarial Machine Learning Attacks, Defensive Controls, and Technologies}, 
  year={2024},
  volume={12},
  number={},
  pages={99382-99421},
  abstract={Adversarial machine learning (AML) attacks have become a major concern for organizations in recent years, as AI has become the industry’s focal point and GenAI applications have grown in popularity around the world. Organizations are eager to invest in GenAI applications and develop their own large language models, but they face numerous security and data privacy issues, particularly AML attacks. AML attacks have jeopardized numerous large-scale machine learning models. If carried out successfully, AML attacks can significantly reduce the efficiency and precision of machine learning models. They have far-reaching negative consequences in the context of critical healthcare and autonomous transportation systems. In this paper, AML attacks are identified, analyzed, and classified using adversarial tactics and techniques. This research also recommends open-source tools for testing AI and ML models against AML attacks. Furthermore, this research suggests specific mitigating measures against each attack. It aims to serve as a guidance for organizations to defend against AML attacks and gain assurance in the security of ML models.},
  keywords={Artificial intelligence;Security;Organizations;Testing;Reviews;Data models;Computational modeling;Adversarial machine learning;Data privacy;Software development management;Life cycle assessment;Adversarial machine learning;AI assurance;cybersecurity;data privacy;secure software development lifecycle},
  doi={10.1109/ACCESS.2024.3423323},
  ISSN={2169-3536},
  month={},}@ARTICLE{10872881,
  author={},
  journal={IEEE P3119/D8, January 2025}, 
  title={IEEE Approved Draft Standard for the Procurement of Artificial Intelligence and Automated Decision Systems}, 
  year={2025},
  volume={},
  number={},
  pages={1-188},
  abstract={The standard helps procurement teams reduce risks in artificial intelligence systems (AIS) by using tailored risk management practices when purchasing AIS. Specific process steps for AIS problem definition, solicitation preparation, vendor and solution evaluation, contract negotiation, and contract monitoring are described. Risk management methodologies that augment customary activities and tasks performed during the procurement life cycle are provided including identifying, analyzing, evaluating, prioritizing, mitigating, and controlling unique AIS risks that can detract from unique AIS benefits. Practical AIS procurement tools and metrics and how procurement teams can use and apply them are also provided. The standard focuses explicitly on AIS risks (when compared to traditional, non-AIS technology) and is designed to address the purchase of commercial AI products and services procured using a formal contract or contract framework. NOTE–AI and ADS are referred to as artificial intelligence systems (AIS) for simplicity.},
  keywords={IEEE Standards;Artificial intelligence;Data governance;Risk management;Sociotechnical systems;artificial intelligence;automated decision systems;data;data governance;systems;responsible procurement;public interest;procurement;technology;solicitation;tender;impact assessment;due diligence;risks;harms;responsible AI;sociotechnical;high-risk;acquisition;human rights;commercial AI products and services},
  doi={},
  ISSN={},
  month={April},}@INPROCEEDINGS{10317971,
  author={Li, Yilin and Li, Shan and Shen, Haihua},
  booktitle={2023 IEEE 32nd Asian Test Symposium (ATS)}, 
  title={HTrans: Transformer-Based Method for Hardware Trojan Detection and Localization}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Hardware Trojan (HT) is a malicious code intentionally inserted into the original circuit design to modify the original function, leak information or decrease the performance. Circuit fabrications have increased Third-Party Intellectual Property (3PIP) usage with market pressure and the increasing global economy. Consequently, hardware may become vulnerable to a wide range of attacks at some stage of the manufacturing process, making detecting HT a necessary procedure. HT detection in the early stage is crucial because removing HT and re-designing the circuit later or after fabrication could be expensive. In this work, we propose a novel Transformer-based Method for pre-silicon HT detection and localization called HTrans. We innovatively use Graph Convolutional Network (GCN) as a preprocessing stage before the Transformer, giving our model the scalability to any design size. Experiments on the Trusthub benchmark show that our model achieves an average of 96.7% Fl score on HT detection and 91.7% accuracy on HT localization. In addition, HTrans can quickly complete the detection on the Register Transfer Level (RTL) within a second.},
  keywords={Location awareness;Fabrication;Knowledge engineering;Manufacturing processes;Scalability;Transformers;Hardware;hardware Trojan detection;security;deep learning},
  doi={10.1109/ATS59501.2023.10317971},
  ISSN={2377-5386},
  month={Oct},}@ARTICLE{10880482,
  author={Li, Na and Zhou, Chunyi and Gao, Yansong and Chen, Hui and Zhang, Zhi and Kuang, Boyu and Fu, Anmin},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Machine Unlearning: Taxonomy, Metrics, Applications, Challenges, and Prospects}, 
  year={2025},
  volume={},
  number={},
  pages={1-21},
  abstract={Personal digital data is a critical asset, and governments worldwide have enforced laws and regulations to protect data privacy. Data users have been endowed with the “right to be forgotten” (RTBF) of their data. In the course of machine learning (ML), the forgotten right requires a model provider to delete user data and its subsequent impact on ML models upon user requests. Machine unlearning (MU) emerges to address this, which has garnered ever-increasing attention from both industry and academia. Specifically, MU allows model providers to eliminate the influence of unlearned data without retraining the model from scratch, ensuring the model behaves as if it never encountered this data. While the area has developed rapidly, there is a lack of comprehensive surveys to capture the latest advancements. Recognizing this shortage, we conduct an extensive exploration to map the landscape of MU including the (fine-grained) taxonomy of unlearning algorithms under centralized and distributed settings, debate on approximate unlearning, verification and evaluation metrics, and challenges and solutions across various applications. We also focus on the motivations, challenges, and specific methods for deploying unlearning in large language models (LLMs), as well as the potential attacks targeting unlearning processes. The survey concludes by outlining potential directions for future research, hoping to serve as a beacon for interested scholars.},
  keywords={Data models;Surveys;Measurement;Training;Electronic mail;Data privacy;Taxonomy;General Data Protection Regulation;Computational modeling;Approximation algorithms;Data privacy;federated learning (FL);large language model (LLM);machine learning (ML);machine unlearning (MU)},
  doi={10.1109/TNNLS.2025.3530988},
  ISSN={2162-2388},
  month={},}@BOOK{10173716,
  author={Tan, Chee Wei and Yu, Pei-Duo},
  booktitle={Contagion Source Detection in Epidemic and Infodemic Outbreaks: Mathematical Analysis and Network Algorithms},
  year={2023},
  volume={},
  number={},
  pages={},
  abstract={The rapid spread of infectious diseases and online rumors share similarities in terms of their speed, scale, and patterns of contagion. Although these two phenomena have historically been studied separately, the COVID-19 pandemic has highlighted the devastating consequences that simultaneous crises of epidemics and misinformation can have on the world. Soon after the outbreak of COVID-19, the World Health Organization launched a campaign against the COVID-19 Infodemic, which refers to the dissemination of pandemic-related false information online that causes widespread panic and hinders recovery efforts. Undoubtedly, nothing spreads faster than fear. Networks serve as a crucial platform for viral spreading, as the actions of highly influential users can quickly render others susceptible to the same. The potential for contagion in epidemics and rumors hinges on the initial source, underscoring the need for rapid and efficient digital contact tracing algorithms to identify super-spreaders or Patient Zero. Similarly, detecting and removing rumor mongers is essential for preventing the proliferation of harmful information in online social networks. Identifying the source of large-scale contagions requires solving complex optimization problems on expansive graphs. Accurate source identification and understanding the dynamic spreading process requires a comprehensive understanding of surveillance in massive networks, including topological structures and spreading veracity. Ultimately, the efficacy of algorithms for digital contact tracing and rumor source detection relies on this understanding. This monograph provides an overview of the mathematical theories and computational algorithm design for contagion source detection in large networks. By leveraging network centrality as a tool for statistical inference, we can accurately identify the source of contagions, trace their spread, and predict future trajectories. This approach provides fundamental insights into surveillance capability and asymptotic behavior of contagion spreading in networks. Mathematical theory and computational algorithms are vital to understanding contagion dynamics, improving surveillance capabilities, and developing effective strategies to prevent the spread of infectious diseases and misinformation.},
  keywords={},
  doi={},
  ISSN={},
  publisher={now},
  isbn={9781638282518},
  url={https://ieeexplore.ieee.org/document/10173716},}@ARTICLE{10330569,
  author={Cooper, Robert G.},
  journal={IEEE Engineering Management Review}, 
  title={The Artificial Intelligence Revolution in New-Product Development}, 
  year={2024},
  volume={52},
  number={1},
  pages={195-211},
  abstract={Artificial Intelligence (AI) is poised to revolutionize all aspects of business, particularly new-product development (NPD). Currently, our approach to NPD has remained largely unchanged for decades, yielding stubbornly poor results: only 30% of NP development projects become commercial successes. However, the AI revolution is set to alter this landscape significantly! Leading early adopter firms demonstrate that AI not only finds many applications in NPD but also offers substantial payoffs, such as 50% reductions in development times. This article provides an outline of the diverse and powerful applications of AI in NPD, offering numerous examples from leading companies. Examples include GE's use of digital models and twins to quickly test product designs in turbine development; BASFs use of AI to identify new molecules for use in customer formulations; and AI to generate new-product ideas, identify new-product opportunities, and even create new-product concepts. Our exploratory journey begins at the idea stage and traverses the entire new-product process to the postlaunch period. While AI might still resemble science fiction to many, that future is no longer fiction—it is here now. AI has arrived in full force! With an adoption window of about 13 years, the time is now to embrace AI in NPD in your business. AI will become a major milestone in NPD, perhaps the most important, within the decade.},
  keywords={Artificial intelligence;Business;Technological innovation;Product development;Prediction algorithms;Software algorithms;Chatbots;AI for new-product development (NPD);artificial intelligence (AI);generative AI;new-product development;new-product process;product innovation},
  doi={10.1109/EMR.2023.3336834},
  ISSN={1937-4178},
  month={Feb},}@INPROCEEDINGS{10852438,
  author={Sowe, Sulayman and Mou, Yongli and Cheng, Du and Kong, Lingxiao and Neumann, Alexander Tobias and Decker, Stefan},
  booktitle={2024 2nd International Conference on Foundation and Large Language Models (FLLM)}, 
  title={Understanding Open Source Large Language Models: An Exploratory Study}, 
  year={2024},
  volume={},
  number={},
  pages={132-140},
  abstract={Prompted by the increasing dominance of proprietary Large Language Models (LLMs), such as OpenAI’s GPT-4 and Google’s Gemini, concerns about data privacy, accessibility and bias have led to a growing advocacy for OSLLMs. This study investigates Open Source Large Language Models (OSLLMs), exploring their characteristics, openness, and community interactions. Our research aims to define OSLLMs (license, openness, community engagement). Utilizing data from the Hugging Face platform, we examine the popularity metrics, license distribution, artefact accessibilities and community engagement of LLM projects. Findings reveal a skewed distribution of model usage, with a few models dominating downloads and likes. Apache 2.0 and MIT are the most common licenses among top models, highlighting a preference for flexible usage terms. However, a significant portion of models lack specified licenses, posing potential legal challenges. Openness analysis shows that nearly half of the examined models share their training code and datasets, with standardized evaluation metrics common across repositories. Community engagement analysis indicates that engineer users are more active than general users, contributing significantly to technical discussions. Sentiment analysis of forum interactions reveals varying user attitudes, with licensed models generally receiving more positive feedback. This study underscores the potential of OSLLMs to democratize AI access and foster innovation, while also highlighting areas for improvement in community engagement and model openness.},
  keywords={Measurement;Training;Analytical models;Technological innovation;Sentiment analysis;Data privacy;Law;Large language models;Licenses;Faces;Artificial intelligence (AI);Open Source Large Language Models (OSLLMs);LLMs Licenses},
  doi={10.1109/FLLM63129.2024.10852438},
  ISSN={},
  month={Nov},}@ARTICLE{10752529,
  author={Hoseini, Seied Veria and Suutala, Jaakko and Partala, Juha and Halunen, Kimmo},
  journal={IEEE Access}, 
  title={Threat Modeling AI/ML With the Attack Tree}, 
  year={2024},
  volume={12},
  number={},
  pages={172610-172637},
  abstract={The pervasive use of AI assistant systems and machine learning-based applications in various fields and everyday life has significantly shifted. However, this shift is not without its challenges. The emergence of security threats, various attacks, and vulnerabilities in this domain has not only questioned their use but also sparked the interest of security experts and researchers, underlining the urgency and importance of this topic. However, a comprehensive and systematic research endeavor is yet to be undertaken on threat modeling based on violating basic tenets of information security on the various components of a machine learning system and evaluating their security risks. This lack of comprehensive threat modeling for each violation of a machine learning system’s confidentiality, integrity, availability, and privacy for various attacks and their risk analysis is a significant gap in the field. This article aims to bridge this gap by proposing a simple, efficient, and time-saving approach to evaluate potential attacks and their security risks by utilizing the attack tree and a risk analysis method in the Adversarial Machine Learning (AML) field. One of the most important steps in determining the overall risk of the attack is evaluating the risk attached to each node in an attack tree. A systematic approach that includes describing the system architecture and identifying its assets under various operational environment scenarios is also outlined in this paper. This approach can also offer crucial insights to security experts, aiding them in understanding and mitigating potential threats and risk analysis in AML systems. To ensure the validity and reliability of our findings, we have conducted a thorough and rigorous review of academic papers, summarizing different threats and attacks and their root cause analysis.},
  keywords={Threat modeling;Root cause analysis;Systematics;Reviews;Roads;Information security;Systems architecture;Vectors;Risk analysis;Reliability;Machine learning;adversarial machine learning;attack tree;security;privacy;integrity;confidentiality;availability},
  doi={10.1109/ACCESS.2024.3497011},
  ISSN={2169-3536},
  month={},}@ARTICLE{10028760,
  author={Zhang, Xu-Yao and Xie, Guo-Sen and Li, Xiuli and Mei, Tao and Liu, Cheng-Lin},
  journal={Proceedings of the IEEE}, 
  title={A Survey on Learning to Reject}, 
  year={2023},
  volume={111},
  number={2},
  pages={185-215},
  abstract={Learning to reject is a special kind of self-awareness (the ability to know what you do not know), which is an essential factor for humans to become smarter. Although machine intelligence has become very accurate nowadays, it lacks such kind of self-awareness and usually acts as omniscient, resulting in overconfident errors. This article presents a comprehensive overview of this topic from three perspectives: confidence, calibration, and discrimination. Confidence is an important measurement for the reliability of model predictions. Rejection can be realized by setting thresholds on confidence. However, most models, especially modern deep neural networks, are usually overconfident. Therefore, calibration is a process to ensure confidence matching the actual likelihood of correctness, including two approaches: post-calibration and self-calibration. Calibration reflects the global characteristic of confidence, and the local distinguishing property of confidence is also important. In light of this, discrimination focuses on the performance of accepting positive samples while rejecting negative samples. As a binary classification problem, the challenge of discrimination comes from the missing and nonrepresentativeness of the negative data. Three discrimination tasks are comprehensively analyzed and discussed: failure rejection, unknown rejection, and fake rejection. By rejecting failures, the risk could be controlled especially for mission-critical applications. By rejecting unknowns, the awareness of the knowledge blind zone would be enhanced. By rejecting fakes, security and privacy could be protected. We provide a general taxonomy, organization, and discussion of the methods for solving these problems, which are studied separately in the literature. The connections between different approaches and future directions that are worth further investigation are also presented. With a discriminative and calibrated confidence, learning to reject will let the decision-making process be more practical, reliable, and secure.},
  keywords={Predictive models;Failure analysis;Estimation;Calibration;Sorting;Predictive methods;Probabilistic logic;Calibration;confidence;discrimination;failure;fake;rejection;unknown},
  doi={10.1109/JPROC.2023.3238024},
  ISSN={1558-2256},
  month={Feb},}@ARTICLE{10570412,
  author={Jiao, Licheng and Shao, Yilin and Sun, Long and Liu, Fang and Yang, Shuyuan and Ma, Wenping and Li, Lingling and Liu, Xu and Hou, Biao and Zhang, Xiangrong and Shang, Ronghua and Li, Yangyang and Wang, Shuang and Tang, Xu and Guo, Yuwei},
  journal={IEEE Access}, 
  title={Advanced Deep Learning Models for 6G: Overview, Opportunities, and Challenges}, 
  year={2024},
  volume={12},
  number={},
  pages={133245-133314},
  abstract={The advent of the sixth generation of mobile communications (6G) ushers in an era of heightened demand for advanced network intelligence to tackle the challenges of an expanding network landscape and increasing service demands. Deep Learning (DL), as a crucial technique for instilling intelligence into 6G, has demonstrated powerful and promising development. This paper provides a comprehensive overview of the pivotal role of DL in 6G, exploring the myriad opportunities and challenges that arise. Firstly, we present a detailed vision for DL in 6G, emphasizing areas such as adaptive resource allocation, intelligent network management, robust signal processing, ubiquitous edge intelligence, and endogenous security. Secondly, this paper reviews how DL models leverage their unique learning capabilities to solve complex service demands in 6G. The models discussed include Convolutional Neural Networks (CNN), Generative Adversarial Networks (GAN), Graph Neural Networks (GNN), Deep Reinforcement Learning (DRL), Transformer, Federated Learning (FL), and Meta Learning. Additionally, we examine the specific challenges each DL model faces within the 6G context. Moreover, we delve into the rapidly evolving field of Artificial Intelligence Generated Content (AIGC), examining its development and impact within the 6G framework. Finally, this paper culminates in a detailed discussion of ten critical open problems in integrating DL with 6G, setting the stage for future research and development in this field.},
  keywords={6G mobile communication;Resource management;Adaptation models;Artificial intelligence;Transformers;Deep learning;Intelligent networks;Content management;Deep learning;6G;network intelligence;artificial intelligence generated content (AIGC);open problems},
  doi={10.1109/ACCESS.2024.3418900},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9023357,
  author={Hu, Jinsen and Yu, Chunyan and Guan, Faqian},
  booktitle={2019 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)}, 
  title={Non-parallel Many-to-many Singing Voice Conversion by Adversarial Learning}, 
  year={2019},
  volume={},
  number={},
  pages={125-132},
  abstract={With the rapid development of deep learning, although speech conversion had made great progress, there are still rare researches in deep learning to model on singing voice conversion, which is mainly based on statistical methods at present and can only achieve one-to-one conversion with parallel training datasets. So far, its application is limited. This paper proposes a generative adversarial learning model, MSVC-GAN, for many-to-many singing voice conversion using non-parallel datasets. First, the generator of our model is concatenated by the singer label, which denotes domain constraint. Furthermore, the model integrates self-attention mechanism to capture long-term dependence on the spectral features. Finally, switchable normalization is employed to stabilize network training. Both the objective and subjective evaluation results show that our model achieves the highest similarity and naturalness not only on the parallel speech dataset but also on the non-parallel singing dataset.},
  keywords={5G mobile communication},
  doi={10.1109/APSIPAASC47483.2019.9023357},
  ISSN={2640-0103},
  month={Nov},}@ARTICLE{10197462,
  author={Pishbin, Hora Saadaat and Bidgoly, Amir Jalaly},
  journal={IEEE Transactions on Dependable and Secure Computing}, 
  title={Exploiting Deep Neural Networks as Covert Channels}, 
  year={2024},
  volume={21},
  number={4},
  pages={2115-2126},
  abstract={With the increasing development of deep learning models, the security of these models has become more important. In this work, for the first time, we have investigated the possibility of abusing the deep model as a covert channel. The concept of a covert channel is to use a channel that is not designed for information exchange for transmitting a covert message. This work studies how a deep model can be used by an adversary as a covert channel. The proposed approach is using an end-to-end training deep model called the covert model to produce artificial data which includes some covert messages. This artificial data is the input of the deep model, which is aimed at being exploited as a covert channel, in such a way that the signal will be covered in the output of this model. To achieve indistinguishability of concealment, generative adversarial networks are used. The results show that it is possible to have a covert channel with an acceptable message transmission power in well-known deep models such as the ResNet and InceptionV3 models. Results of case studies indicate the signal-to-noise ratio (SNR) of 12.67, the bit error rate (BER) of 0.08, and the accuracy of the deep model used to hide the signal reaches 92%.},
  keywords={Data models;Computational modeling;Deep learning;Receivers;Training;Artificial neural networks;Malware;Trustworthy machine learning;deep neural network;covert channel;deep learning attack;concealment},
  doi={10.1109/TDSC.2023.3300072},
  ISSN={1941-0018},
  month={July},}@ARTICLE{10789626,
  author={Rodrigues Perche Mahlow, Felipe and Zanella, André Felipe and Cruz Castañeda, William Alberto and Aparecida Sarzi-Ribeiro, Regilene},
  journal={IEEE Latin America Transactions}, 
  title={Illustrating Classic Brazilian Books using a Text-To-Image Diffusion Model}, 
  year={2024},
  volume={22},
  number={12},
  pages={1000-1008},
  abstract={In recent years, Generative Artificial Intelligence (GenAI) has undergone a profound transformation in addressing intricate tasks involving diverse modalities such as textual, auditory, visual, and pictorial generation. Within this spectrum, text-to-image (TTI) models have emerged as a formidable approach to generating varied and aesthetically appealing compositions, spanning applications from artistic creation to realistic facial synthesis, and demonstrating significant advancements in computer vision, image processing, and multimodal tasks. The advent of Latent Diffusion Models (LDMs) signifies a paradigm shift in the domain of AI capabilities. This article delves into the feasibility of employing the Stable Diffusion LDM to illustrate literary works. For this exploration, seven classic Brazilian books have been selected as case studies. The objective is to ascertain the practicality of this endeavor and to evaluate the potential of Stable Diffusion in producing illustrations that augment and enrich the reader's experience. We will outline the beneficial aspects, such as the capacity to generate distinctive and contextually pertinent images, as well as the drawbacks, including any shortcomings in faithfully capturing the essence of intricate literary depictions. Through this study, we aim to provide a comprehensive assessment of the viability and efficacy of utilizing AI-generated illustrations in literary contexts, elucidating both the prospects and challenges encountered in this pioneering application of technology.},
  keywords={Artificial intelligence;Image synthesis;Diffusion models;Training;Visualization;Text to image;Noise reduction;Computational modeling;Refining;Ethics;image generation;diffusion models;text-to-image;illustration},
  doi={10.1109/TLA.2024.10789626},
  ISSN={1548-0992},
  month={Dec},}@INPROCEEDINGS{10323951,
  author={Fang, Wenji and Lu, Yao and Liu, Shang and Zhang, Qijun and Xu, Ceyu and Wills, Lisa Wu and Zhang, Hongce and Xie, Zhiyao},
  booktitle={2023 IEEE/ACM International Conference on Computer Aided Design (ICCAD)}, 
  title={MasterRTL: A Pre-Synthesis PPA Estimation Framework for Any RTL Design}, 
  year={2023},
  volume={},
  number={},
  pages={1-9},
  abstract={In modern VLSI design flow, the register-transfer level (RTL) stage is a critical point, where designers define precise design behavior with hardware description languages (HDLs) like Verilog. Since the RTL design is in the format of HDL code, the standard way to evaluate its quality requires time-consuming subsequent synthesis steps with EDA tools. This time-consuming process significantly impedes design optimization at the early RTL stage. Despite the emergence of some recent ML-based solutions, they fail to maintain high accuracy for any given RTL design. In this work, we propose an innovative pre-synthesis PPA estimation framework named MasterRTL. It first converts the HDL code to a new bit-level design representation named the simple operator graph (SOG). By only adopting single-bit simple operators, this SOG proves to be a general representation that unifies different design types and styles. The SOG is also more similar to the target gate-level netlist, reducing the gap between RTL representation and netlist. In addition to the new SOG representation, MasterRTL proposes new ML methods for the RTL-stage modeling of timing, power, and area separately. Compared with state-of-the-art solutions, the experiment on a comprehensive dataset with 90 different designs shows accuracy improvement by 0.33, 0.22, and 0.15 in correlation for total negative slack (TNS), worst negative slack (WNS), and power, respectively.},
  keywords={Codes;Design automation;Estimation;Very large scale integration;Logic gates;Hardware;Timing},
  doi={10.1109/ICCAD57390.2023.10323951},
  ISSN={1558-2434},
  month={Oct},}@ARTICLE{10025743,
  author={Oh, Myung Gyo and Hyun Park, Leo and Kim, Jaeuk and Park, Jaewoo and Kwon, Taekyoung},
  journal={IEEE Access}, 
  title={Membership Inference Attacks With Token-Level Deduplication on Korean Language Models}, 
  year={2023},
  volume={11},
  number={},
  pages={10207-10217},
  abstract={The confidentiality threat against training data has become a significant security problem in neural language models. Recent studies have shown that memorized training data can be extracted by injecting well-chosen prompts into generative language models. While these attacks have achieved remarkable success in the English-based Transformer architecture, it is unclear whether they are still effective in other language domains. This paper studies the effectiveness of attacks against Korean models and the potential for attack improvements that might be beneficial for future defense studies. The contribution of this study is two-fold. First, we perform a membership inference attack against the state-of-the-art Korean GPT model. We found approximate training data with 20% to 90% precision in the top-100 samples and confirmed that the proposed attack technique for naive GPT is valid across the language domains. Second, in this process, we observed that the redundancy of the selected sentences could hardly be detected with the existing attack method. Since the information appearing in a few documents is more likely to be meaningful, it is desirable to increase the uniqueness of the sentences to improve the effectiveness of the attack. Thus, we propose a deduplication strategy to replace the traditional word-level similarity metric with the BPE token level. Our proposed strategy reduces 6% to 22% of the underestimated samples among selected ones, thereby improving precision by up to 7%p. As a result, we show that considering both language- and model-specific characteristics is essential to improve the effectiveness of attack strategies. We also discuss possible mitigations against the MI attacks on the general language models.},
  keywords={Training data;Deep learning;Measurement;Natural language processing;Data models;Entropy;Data mining;Confidentiality;deep learning;generative language model;Korean-based GPT;membership inference;training data extraction attack},
  doi={10.1109/ACCESS.2023.3239668},
  ISSN={2169-3536},
  month={},}@ARTICLE{10535494,
  author={Awal Kassim, Mohammed and Viktor, Herna and Michalowski, Wojtek},
  journal={IEEE Access}, 
  title={Multi-Label Lifelong Machine Learning: A Scoping Review of Algorithms, Techniques, and Applications}, 
  year={2024},
  volume={12},
  number={},
  pages={74539-74557},
  abstract={Lifelong machine learning concerns the development of systems that continuously learn from diverse tasks, incorporating new knowledge without forgetting the knowledge they have previously acquired. Multi-label classification is a supervised learning process in which each instance is assigned multiple non-exclusive labels, with each label denoted as a binary value. One of the main challenges within the lifelong learning paradigm is the stability-plasticity dilemma, which entails balancing a model’s adaptability in terms of incorporating new knowledge with its stability in terms of retaining previously acquired knowledge. When faced with multi-label data, the lifelong learning challenge becomes even more pronounced, as it becomes essential to preserve relations between multiple labels across sequential tasks. This scoping review explores the intersection of lifelong learning and multi-label classification, an emerging domain that integrates continual adaptation with intricate multi-label datasets. By analyzing the existing literature, we establish connections, identify gaps in the existing research, and propose new directions for research to improve the efficacy of multi-label lifelong learning algorithms. Our review unearths a growing number of algorithms and underscores the need for specialized evaluation metrics and methodologies for the accurate assessment of their performance. We also highlight the need for strategies that incorporate real-world data from varying contexts into the learning process to fully capture the nuances of real-world environments.},
  keywords={Classification algorithms;Reviews;Machine learning;Training;Object recognition;Continuing education;Algorithm design and analysis;Continual learning;lifelong learning;machine learning;multi-label classification},
  doi={10.1109/ACCESS.2024.3403569},
  ISSN={2169-3536},
  month={},}@ARTICLE{10858399,
  author={Sepúlveda-Torres, Robiert and Martínez-Murillo, Iván and Saquete, Estela and Lloret, Elena and Palomar, Manuel},
  journal={IEEE Transactions on Big Data}, 
  title={To Write or Not to Write as a Machine? That's the Question}, 
  year={2025},
  volume={},
  number={},
  pages={1-12},
  abstract={Considering the potential of tools such as ChatGPT or Gemini to generate texts in a similar way to a human would do, having reliable detectors of AI –AI-generated content (AIGC)– is vital to combat the misuse and the surrounding negative consequences of those tools. Most research on AIGC detection has focused on the English language, often overlooking other languages that also have tools capable of generating human-like texts, such is the case of the Spanish language. This paper proposes a novel multilingual and multi-task approach for detecting machine vs. human-generated text. The first task classifies whether a text is written by a machine or by a human, which is the research objective of this paper. The second task consists in detect the language of the text. To evaluate the results of our approach, this study has framed the scope of the AuTexTification shared task and also we have collected a different dataset in Spanish. The experiments carried out in Spanish and English show that our approach is very competitive concerning the state of the art, as well as it can generalize better, thus being able to detect an AI-generated text in multiple domains.},
  keywords={Multitasking;Multilingual;Text detection;Detectors;Art;Transformers;Reliability;Generative AI;Feature extraction;Chatbots;Multi-task Learning;Multilingual;Natural Language Processing;Large Language Models;AI-Generated Content},
  doi={10.1109/TBDATA.2025.3536938},
  ISSN={2332-7790},
  month={},}@ARTICLE{10433480,
  author={Raiaan, Mohaimenul Azam Khan and Mukta, Md. Saddam Hossain and Fatema, Kaniz and Fahad, Nur Mohammad and Sakib, Sadman and Mim, Most Marufatul Jannat and Ahmad, Jubaer and Ali, Mohammed Eunus and Azam, Sami},
  journal={IEEE Access}, 
  title={A Review on Large Language Models: Architectures, Applications, Taxonomies, Open Issues and Challenges}, 
  year={2024},
  volume={12},
  number={},
  pages={26839-26874},
  abstract={Large Language Models (LLMs) recently demonstrated extraordinary capability in various natural language processing (NLP) tasks including language translation, text generation, question answering, etc. Moreover, LLMs are new and essential part of computerized language processing, having the ability to understand complex verbal patterns and generate coherent and appropriate replies in a given context. Though this success of LLMs has prompted a substantial increase in research contributions, rapid growth has made it difficult to understand the overall impact of these improvements. Since a plethora of research on LLMs have been appeared within a short time, it is quite impossible to track all of these and get an overview of the current state of research in this area. Consequently, the research community would benefit from a short but thorough review of the recent changes in this area. This article thoroughly overviews LLMs, including their history, architectures, transformers, resources, training methods, applications, impacts, challenges, etc. This paper begins by discussing the fundamental concepts of LLMs with its traditional pipeline of the LLMs training phase. Then the paper provides an overview of the existing works, the history of LLMs, their evolution over time, the architecture of transformers in LLMs, the different resources of LLMs, and the different training methods that have been used to train them. The paper also demonstrates the datasets utilized in the studies. After that, the paper discusses the wide range of applications of LLMs, including biomedical and healthcare, education, social, business, and agriculture. The study also illustrates how LLMs create an impact on society and shape the future of AI and how they can be used to solve real-world problems. Finally, the paper also explores open issues and challenges to deploy LLMs in real-world scenario. Our review paper aims to help practitioners, researchers, and experts thoroughly understand the evolution of LLMs, pre-trained architectures, applications, challenges, and future goals.},
  keywords={Cognition;Artificial intelligence;Transformers;Training;Taxonomy;Task analysis;Surveys;Natural language processing;Question answering (information retrieval);Information analysis;Linguistics;Large language models (LLM);natural language processing (NLP);artificial intelligence;transformer;pre-trained models;taxonomy;application},
  doi={10.1109/ACCESS.2024.3365742},
  ISSN={2169-3536},
  month={},}@ARTICLE{9950314,
  author={Hasegawa, Kento and Hidano, Seira and Nozawa, Kohei and Kiyomoto, Shinsaku and Togawa, Nozomu},
  journal={IEEE Transactions on Computers}, 
  title={R-HTDetector: Robust Hardware-Trojan Detection Based on Adversarial Training}, 
  year={2023},
  volume={72},
  number={2},
  pages={333-345},
  abstract={Hardware Trojans (HTs) have become a serious problem, and extermination of them is strongly required for enhancing the security and safety of integrated circuits. An effective solution is to identify HTs at the gate level via machine learning techniques. However, machine learning has specific vulnerabilities, such as adversarial examples. In reality, it has been reported that adversarial modified HTs greatly degrade the performance of a machine learning-based HT detection method. Therefore, we propose a robust HT detection method using adversarial training (R-HTDetector). We formally describe the robustness of R-HTDetector in modifying HTs. Our work gives the world-first adversarial training for HT detection with theoretical backgrounds. We show through experiments with Trust-HUB benchmarks that R-HTDetector overcomes adversarial examples while maintaining its original accuracy.},
  keywords={Logic gates;Integrated circuits;Feature extraction;Trojan horses;Hardware;Training;Machine learning;Adversarial examples;adversarial training;hardware Trojans;machine learning;gate-level netlists},
  doi={10.1109/TC.2022.3222090},
  ISSN={1557-9956},
  month={Feb},}@INPROCEEDINGS{10376050,
  author={Le, Ngoc Tran Khanh and Hadiprodjo, Nadia and El-Alfy, Hazem and Kerimzhanov, Aziz and Teshebaev, Avtandil},
  booktitle={2023 22nd International Symposium on Communications and Information Technologies (ISCIT)}, 
  title={The Recent Large Language Models in NLP}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Over the past few years, Natural Language Processing (NLP) has evolved significantly thanks to the development of large Language Models (LMs). In this paper, we present a survey of four recent language models that we believe have had a significant importance in the NLP field lately: BERT (Google), ELMo (Allen Institute), GPT-3 (OpenAI), and LLaMA (Meta AI). For each model, we analyse its architecture, the dataset on which it was trained, its performance evaluation, as well as the strengths and challenges faced by each. Our paper compares the recent Language Models and their contributions to the field of NLP, and discusses future extensions.},
  keywords={Surveys;Performance evaluation;Training data;Market research;Chatbots;Internet;Information and communication technology;NLP;LLM(s);pre-trained;data;model;architecture;performance;state-of-art;BERT;ELMo;GPT-3;LLaMA;application.},
  doi={10.1109/ISCIT57293.2023.10376050},
  ISSN={2643-6175},
  month={Oct},}@ARTICLE{10602503,
  author={Kalateh, Sepideh and Estrada-Jimenez, Luis A. and Nikghadam-Hojjati, Sanaz and Barata, Jose},
  journal={IEEE Access}, 
  title={A Systematic Review on Multimodal Emotion Recognition: Building Blocks, Current State, Applications, and Challenges}, 
  year={2024},
  volume={12},
  number={},
  pages={103976-104019},
  abstract={Emotion recognition involves accurately interpreting human emotions from various sources and modalities, including questionnaires, verbal, and physiological signals. With its broad applications in affective computing, computational creativity, human-robot interactions, and market research, the field has seen a surge in interest in recent years. This paper presents a systematic review of multimodal emotion recognition (MER) techniques developed from 2014 to 2024, encompassing verbal, physiological signals, facial, body gesture, and speech as well as emerging methods like sketches emotion recognition. The review explores various emotion models, distinguishing between emotions, feelings, sentiments, and moods, along with human emotional expression, categorized in both artistic and non-verbal ways. It also discusses the background of automated emotion recognition systems and introduces seven criteria for evaluating modalities alongside a current state analysis of MER, drawn from the human-centric perspective of this field. By selecting the PRISMA guidelines and carefully analyzing 45 selected articles, this review provides comprehensive perspectives into existing studies, datasets, technical approaches, identified gaps, and future directions in MER. It also highlights existing challenges and current applications of the MER.},
  keywords={Emotion recognition;Physiology;Mood;Feature extraction;Cultural differences;Guidelines;Multimodal sensors;Artificial intelligence;Affective computing;Deep learning;Machine learning;Multimodal emotion recognition;artificial intelligence;affective computing;emotion recognition;deep learning;machine learning;emotion expression},
  doi={10.1109/ACCESS.2024.3430850},
  ISSN={2169-3536},
  month={},}@ARTICLE{10840256,
  author={Taveekitworachai, Pittawat and Dewantoro, Mury F. and Xia, Yi and Suntichaikul, Pratch and Thawonmas, Ruck},
  journal={IEEE Transactions on Games}, 
  title={BenchING: A Benchmark for Evaluating Large Language Models in Following Structured Output Format Instruction in Text-Based Narrative Game Tasks}, 
  year={2025},
  volume={},
  number={},
  pages={1-11},
  abstract={This paper presents BenchING, a new benchmark for evaluating large language models (LLMs) on their ability to follow structured output format instructions in text-based procedural content generation (PCG) tasks. The ability to condition LLMs to output in specified formats proves useful, as downstream components in LLM-integrated games often require structured outputs for exchanging information. However, there is a gap in evaluating this aspect of LLMs, especially in narrative PCG tasks, making it difficult to select LLMs and design games or applications integrating these LLMs. To demonstrate the potential of our benchmark, we evaluate nine LLMs for their ability to generate parseable formatted outputs using five selected text-based PCG tasks. We report on the performance of these LLMs on these tasks. Additionally, we categorize more detailed error types and propose solutions by utilizing LLMs to fix these errors. We also conduct a scaling study, investigating an emergent point of LLMs for their ability to fix malformed formatted content using eight quantized LLMs with varying original sizes from 0.62B to 72.3B. Furthermore, we perform a qualitative study to assess the quality of the generated content. We make our source code and raw data available for future research.},
  keywords={Games;Benchmark testing;XML;Complexity theory;Syntactics;Standards;Large language models;Birds;User interfaces;Servers;Benchmark;JSON;LLMs;XML;YAML},
  doi={10.1109/TG.2025.3529117},
  ISSN={2475-1510},
  month={},}@INPROCEEDINGS{10764812,
  author={Yu, Xiao and Zhang, Zexian and Niu, Feifei and Hu, Xing and Xia, Xin and Grundy, John},
  booktitle={2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={What Makes a High-Quality Training Dataset for Large Language Models: A Practitioners’ Perspective}, 
  year={2024},
  volume={},
  number={},
  pages={656-668},
  abstract={Large Language Models (LLMs) have demonstrated remarkable performance in various application domains, largely due to their self-supervised pre-training on extensive high-quality text datasets. However, despite the importance of constructing such datasets, many leading LLMs lack documentation of their dataset construction and training procedures, leaving LLM practitioners with a limited understanding of what makes a high-quality training dataset for LLMs. To fill this gap, we initially identified 18 characteristics of high-quality LLM training datasets, as well as 10 potential data pre-processing methods and 6 data quality assessment methods, through detailed interviews with 13 experienced LLM professionals. We then surveyed 219 LLM practitioners from 23 countries across 5 continents. We asked our survey respondents to rate the importance of these characteristics, provide a rationale for their ratings, specify the key data pre-processing and data quality assessment methods they used, and highlight the challenges encountered during these processes. From our analysis, we identified 13 crucial characteristics of high-quality LLM datasets that receive a high rating, accompanied by key rationale provided by respondents. We also identified some widely-used data pre-processing and data quality assessment methods, along with 7 challenges encountered during these processes. Based on our findings, we discuss the implications for researchers and practitioners aiming to construct high-quality training datasets for optimizing LLMs.CCS CONCEPTS• Software and its engineering → Software implementation planning.},
  keywords={Training;Surveys;Data integrity;Large language models;Documentation;Software;Planning;Continents;Interviews;Software engineering;Large Language Models;High-Quality Data;Practitioners’ Perspective;Empirical Study},
  doi={},
  ISSN={2643-1572},
  month={Oct},}@INPROCEEDINGS{10903892,
  author={Donvir, Anujkumarsinh and Sharma, Gaurav},
  booktitle={2025 IEEE 15th Annual Computing and Communication Workshop and Conference (CCWC)}, 
  title={Ethical Challenges and Frameworks in AI-Driven Software Development and Testing}, 
  year={2025},
  volume={},
  number={},
  pages={00569-00576},
  abstract={Artificial Intelligence (AI) has revolutionized and transformed the landscape of software development and testing by introducing new efficiencies and capabilities through advancements like Generative AI (GenAI) and Large Language Models (LLMs). While these technologies bring major benefits in terms of productivity, personalization, and innovation, they also raise critical ethical challenges, such as biases, lack of transparency, data privacy concerns, and potential negative societal impacts. This paper examines the ethical considerations involved in developing such advanced AI systems as well using AI systems within software development and testing. It explores existing ethical frameworks and principles provided by leading organizations, emphasizing core concepts like human-centered design, accountability, transparency, fairness, and privacy. Practical strategies for integrating ethical practices throughout the AI development lifecycle are discussed, with a strong emphasis on the need for continuous ethical evaluation. The paper explores the ethical landscape of AI in software development, addressing challenges like algorithmic bias, data security, and broader societal impacts. Real-world case studies presented in the paper demonstrate the consequences of neglecting ethical considerations. Looking forward, the paper suggests future directions, including the development of unified ethical standards, collaborative ethical auditing, regulatory advancements, and higher societal engagement.},
  keywords={Ethics;Technological innovation;Data privacy;Standards organizations;Software algorithms;Collaboration;Stakeholders;Artificial intelligence;Software development management;Testing;Artificial Intelligence (AI);Ethical AI;Software Development;Software Testing;Generative AI (GenAI);Large Language Models (LLMs);Ethical Frameworks;Human-Centered Design;Accountability;Transparency;Fairness and Non-Discrimination;Data Privacy;Responsible AI;Bias Detection;Explainable AI (XAI);Ethical Auditing;Regulatory Frameworks;Societal Engagement;Case Studies in AI Ethics},
  doi={10.1109/CCWC62904.2025.10903892},
  ISSN={},
  month={Jan},}@BOOK{10769374,
  author={Noring, Christoffer and Jain, Anjali and Fernandez, Marina and Mutlu, Ayşe and Jaokar, Ajit},
  booktitle={AI-Assisted Programming for Web and Machine Learning: Improve your development workflow with ChatGPT and GitHub Copilot},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Speed up your development processes and improve your productivity by writing practical and relevant prompts to build web applications and Machine Learning (ML) models Purchase of the print or Kindle book includes a free PDF copyKey FeaturesUtilize prompts to enhance frontend and backend web developmentDevelop prompt strategies to build robust machine learning modelsUse GitHub Copilot for data exploration, maintaining existing code bases, and augmenting ML models into web applicationsBook DescriptionAI-Assisted Programming for Web and Machine Learning shows you how to build applications and machine learning models and automate repetitive tasks. Part 1 focuses on coding, from building a user interface to the backend. You’ll use prompts to create the appearance of an app using HTML, styling with CSS, adding behavior with JavaScript, and working with multiple viewports. Next, you’ll build a web API with Python and Flask and refactor the code to improve code readability. Part 1 ends with using GitHub Copilot to improve the maintainability and performance of existing code. Part 2 provides a prompting toolkit for data science from data checking (inspecting data and creating distribution graphs and correlation matrices) to building and optimizing a neural network. You’ll use different prompt strategies for data preprocessing, feature engineering, model selection, training, hyperparameter optimization, and model evaluation for various machine learning models and use cases. The book closes with chapters on advanced techniques on GitHub Copilot and software agents. There are tips on code generation, debugging, and troubleshooting code. You’ll see how simpler and AI-powered agents work and discover tool calling.What you will learnSpeed up your coding and machine learning workflows with GitHub Copilot and ChatGPTUse an AI-assisted approach across the development lifecycle Implement prompt engineering techniques in the data science lifecycleDevelop the frontend and backend of a web application with AI assistance Build machine learning models with GitHub Copilot and ChatGPT Refactor code and fix faults for better efficiency and readability Improve your codebase with rich documentation and enhanced workflows Who this book is forExperienced developers new to GitHub Copilot and ChatGPT can discover the best strategies to improve productivity and deliver projects quicker than traditional methods. This book is ideal for software engineers working on web or machine learning projects. It is also a useful resource for web developers, data scientists, and analysts who want to improve their efficiency with the help of prompting. This book does not teach web development or how different machine learning models work.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835083895},
  url={https://ieeexplore.ieee.org/document/10769374},}@ARTICLE{10839402,
  author={Che, Zengyang and Zhang, Zheng and Wu, Yaping and Wang, Meiyun},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Disentangle and Then Fuse: A Cross-Modal Network for Synthesizing Gadolinium-Enhanced Brain MR Images}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Despite the widespread use of gadolinium-based contrast agents in clinical MRI examinations due to their significant advantages in structural localization and tumor identification, there is a risk of brain deposition and nephrogenic systemic fibrosis. Cross-modal image synthesis methods offer a new alternative, yet lesion synthesis remains challenging. On one hand, brain lesions vary significantly in location, shape, and size. On the other hand, the high background ratio associated with brain lesions makes their synthesis more difficult. To address these issues, we first introduce a Multi-Objective Local Perception Module (M-OLPM), which utilizes edge generation and lesion segmentation tasks to prioritize local lesions from the disentangled local perceptual feature subspaces. To better extend to multi-objective local perception, we propose a ’Disentangle and Then Fuse’ learning strategy, including a Feature Disentanglement Module (FDM) and a Global Fusion Module (GFM). The FDM decouples multimodal deep features into low-frequency semantic features and high-frequency edge features, alleviating feature conflicts from weakly related perception tasks. To enhance feature interaction among multiple perception tasks, the GFM progressively integrates these local perceptual features and underlying detail features through an attention mechanism, further refining the global image quality. Evaluated on the publicly available BRaTS2020, BRaTS2021 datasets, and the private HPPH dataset, our method significantly outperforms the existing technology in both visual and quantitative assessments of gadolinium-enhanced MRI images in global and localized lesion areas, providing a safe alternative to gadolinium enhancement. The source code is publicly available at https://github.com/zengyangche/DTF-Net.},
  keywords={Lesions;Magnetic resonance imaging;Image edge detection;Semantics;Image synthesis;Biomedical imaging;Frequency division multiplexing;Feature extraction;Shape;Interference;medical image synthesis;cross-modal;MRI;GAN;gadolinium-enhanced},
  doi={10.1109/TCSVT.2025.3528981},
  ISSN={1558-2205},
  month={},}@ARTICLE{8373692,
  author={Mohammadi, Mehdi and Al-Fuqaha, Ala and Sorour, Sameh and Guizani, Mohsen},
  journal={IEEE Communications Surveys & Tutorials}, 
  title={Deep Learning for IoT Big Data and Streaming Analytics: A Survey}, 
  year={2018},
  volume={20},
  number={4},
  pages={2923-2960},
  abstract={In the era of the Internet of Things (IoT), an enormous amount of sensing devices collect and/or generate various sensory data over time for a wide range of fields and applications. Based on the nature of the application, these devices will result in big or fast/real-time data streams. Applying analytics over such data streams to discover new information, predict future insights, and make control decisions is a crucial process that makes IoT a worthy paradigm for businesses and a quality-of-life improving technology. In this paper, we provide a thorough overview on using a class of advanced machine learning techniques, namely deep learning (DL), to facilitate the analytics and learning in the IoT domain. We start by articulating IoT data characteristics and identifying two major treatments for IoT data from a machine learning perspective, namely IoT big data analytics and IoT streaming data analytics. We also discuss why DL is a promising approach to achieve the desired analytics in these types of data and applications. The potential of using emerging DL techniques for IoT data analytics are then discussed, and its promises and challenges are introduced. We present a comprehensive background on different DL architectures and algorithms. We also analyze and summarize major reported research attempts that leveraged DL in the IoT domain. The smart IoT devices that have incorporated DL in their intelligence background are also discussed. DL implementation approaches on the fog and cloud centers in support of IoT applications are also surveyed. Finally, we shed light on some challenges and potential directions for future research. At the end of each section, we highlight the lessons learned based on our experiments and review of the recent literature.},
  keywords={Machine learning;Big Data;Data analysis;Economics;Internet of Things;Data mining;Tutorials;Deep learning;deep neural network;Internet of Things;on-device intelligence;IoT big data;fast data analytics;cloud-based analytics},
  doi={10.1109/COMST.2018.2844341},
  ISSN={1553-877X},
  month={Fourthquarter},}@ARTICLE{10540566,
  author={Dietz, Katharina and Mühlhauser, Michael and Kögel, Jochen and Schwinger, Stephan and Sichermann, Marleen and Seufert, Michael and Herrmann, Dominik and Hoßfeld, Tobias},
  journal={IEEE Access}, 
  title={The Missing Link in Network Intrusion Detection: Taking AI/ML Research Efforts to Users}, 
  year={2024},
  volume={12},
  number={},
  pages={79815-79837},
  abstract={Intrusion Detection Systems (IDS) tackle the challenging task of detecting network attacks as fast as possible. As this is getting more complex in modern enterprise networks, Artificial Intelligence (AI) and Machine Learning (ML) have gained substantial popularity in research. However, their adoption into real-world IDS solutions remains poor. Academic research often overlooks the interconnection of users and technical aspects. This leads to less explainable AI/ML models that hinder trust among AI/ML non-experts. Additionally, research often neglects secondary concerns such as usability and privacy. If IDS approaches conflict with current regulations or if administrators cannot deal with attacks more effectively, enterprises will not adopt the IDS in practice. To identify those problems systematically, our literature survey takes a user-centric approach; we examine IDS research from the perspective of stakeholders by applying the concept of personas. Further, we investigate multiple factors limiting the adoption of AI/ML in security and suggest technical, non-technical, and user-related considerations to enhance the adoption in practice. Our key contributions are threefold. (i) We derive personas from realistic enterprise scenarios, (ii) we provide a set of relevant hypotheses in the form of a review template, and (iii), based on our reviews, we derive design guidelines for practical implementations. To the best of our knowledge, this is the first paper that analyzes practical adoption barriers of AI/ML-based intrusion detection solutions concerning appropriateness of data, reproducibility, explainability, practicability, usability, and privacy. Our guidelines may help researchers to holistically evaluate their AI/ML-based IDS approaches to increase practical adoption.},
  keywords={Surveys;Security;Monitoring;Network intrusion detection;Usability;Privacy;Anomaly detection;Artificial intelligence;Intrusion detection;Machine learning;Anomaly detection;artificial intelligence;intrusion detection;machine learning;network monitoring;privacy;security;usability},
  doi={10.1109/ACCESS.2024.3406939},
  ISSN={2169-3536},
  month={},}@ARTICLE{10897482,
  author={Zeng, Xiaoxing and Wu, Zhelun and Peng, Xiaojiang and Qiao, Yu},
  journal={Computational Visual Media}, 
  title={Joint 3D facial shape reconstruction and texture completion from a single image}, 
  year={2022},
  volume={8},
  number={2},
  pages={239-256},
  abstract={Recent years have witnessed significant progress in image-based 3D face reconstruction using deep convolutional neural networks. However, current reconstruction methods often perform improperly in self-occluded regions and can lead to inaccurate correspondences between a 2D input image and a 3D face template, hindering use in real applications. To address these problems, we propose a deep shape reconstruction and texture completion network, SRTC-Net, which jointly reconstructs 3D facial geometry and completes texture with correspondences from a single input face image. In SRTC-Net, we leverage the geometric cues from completed 3D texture to reconstruct detailed structures of 3D shapes. The SRTC-Net pipeline has three stages. The first introduces a correspondence network to identify pixel-wise correspondence between the input 2D image and a 3D template model, and transfers the input 2D image to a U-V texture map. Then we complete the invisible and occluded areas in the U-V texture map using an inpainting network. To get the 3D facial geometries, we predict coarse shape (U-V position maps) from the segmented face from the correspondence network using a shape network, and then refine the 3D coarse shape by regressing the U-V displacement map from the completed U-V texture map in a pixel-to-pixel way. We examine our methods on 3D reconstruction tasks as well as face frontalization and pose invariant face recognition tasks, using both in-the-lab datasets (MICC, MultiPIE) and in-the-wild datasets (CFP). The qualitative and quantitative results demonstrate the effectiveness of our methods on inferring 3D facial geometry and complete texture; they outperform or are comparable to the state-of-the-art.},
  keywords={Three-dimensional displays;Face recognition;Image reconstruction;Shape;Solid modeling;Faces;Image segmentation;Geometry;Pipelines;Predictive models;3D face reconstruction;U-V completion;pose invariant face recognition;deep learning},
  doi={10.1007/s41095-021-0238-4},
  ISSN={2096-0662},
  month={June},}@ARTICLE{10740285,
  author={Lin, Dongjie},
  journal={IEEE Access}, 
  title={Key Considerations to be Applied While Leveraging Machine Learning for Financial Statement Fraud Detection: A Review}, 
  year={2024},
  volume={12},
  number={},
  pages={168213-168228},
  abstract={Financial statement fraud (FSF) is a challenging issue in capital markets and severely affects their overall health and stability. The effective prediction of FSF has become an urgent need for investors. In recent years, scholars have developed several machine learning-based FSF prediction models. This study conducted a systematic review of such models to facilitate an understanding of the latest developments in this field. First, sample and data preprocessing were analyzed, focusing on key aspects such as data sources, splitting training and testing sets, imbalanced samples, cross-period FSF, and handling of zero and missing values. Second, existing research on FSF prediction models was reviewed considering structured and unstructured data. The existing studies exhibited two significant characteristics: expansion if data from structured to unstructured formats and the evolution of methodologies from traditional machine learning to deep learning approaches. Third, the effectiveness of FSF prediction models was evaluated. Indiscriminately pursuing higher recall rates is not advisable. Rather, the effectiveness of the model in terms of predicting FSF must be scientific assessed. Finally, the challenges and opportunities in current research were summarized. The core challenges were identified as the development of robust prediction models and the incorporation of unstructured data into these models. Moreover, leveraging diverse data, deep learning, and large language models can significantly enhance the performance of prediction models. Furthermore, to advance research in this field, this study advocates the construction of a shared and open FSF database.},
  keywords={Fraud;Predictive models;Data models;Biological system modeling;Training;Companies;Deep learning;Databases;Testing;Data preprocessing;Financial management;Deep learning;Financial statement fraud;machine learning;deep learning;literature review},
  doi={10.1109/ACCESS.2024.3488832},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10218142,
  author={Zaman, Kimia Tuz and Hasan, Wordh Ul and Li, Juan and Tao, Cui},
  booktitle={2023 IEEE Symposium on Computers and Communications (ISCC)}, 
  title={Empowering Caregivers of Alzheimer's Disease and Related Dementias (ADRD) with a GPT-Powered Voice Assistant: Leveraging Peer Insights from Social Media}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={Caring for individuals with Alzheimer's Disease and Related Dementias (ADRD) is a complex and challenging task, especially for unprofessional caregivers who often lack the necessary training and resources. While online peer support groups have been shown to be useful in providing caregivers with information and emotional support, many caregivers are unable to benefit from them due to time constraints and limited knowledge of social media platforms. To address this issue, we propose the development of a voice assistant app that can collect relevant information and discussions from online peer support groups on social media. This app will use the collected information as a knowledge base and fine-tune a Generative Pre-trained Transformers (GPT) model to facilitate caregivers in accessing shared experiences and practical tips from peers. Initial evaluation of the app has shown promising results in terms of feasibility and potential impact on caregivers.},
  keywords={Training;Computers;Social networking (online);Knowledge based systems;Transformers;User experience;Question answering (information retrieval);Alzheimer's Disease and Related Dementias (ADRD);voice assistant;caregiving;Generative Pre-trained Transformers (GPT);natural language processing},
  doi={10.1109/ISCC58397.2023.10218142},
  ISSN={2642-7389},
  month={July},}@INPROCEEDINGS{10645456,
  author={Li, Rui and Wei, Yifan and Lu, Haopeng and Ma, Siwei and Liu, Zhenyu and Liu, Hui and Wang, Qianying and Wu, Yaqiang and Tan, Jianrong},
  booktitle={2024 IEEE International Conference on Multimedia and Expo Workshops (ICMEW)}, 
  title={Chinese Ancient Painting Figure Face Restoration and its Application in a Q&A Interaction System}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={We design a complete technical chain for developing a Q&A interaction system between Chinese ancient figures and modern users. The system is built on end-cloud collaboration, and all the users need to do is uploading a Chinese ancient painting figure face image. The interactive ability is realized by a large language model. Chinese ancient paintings often emphasize vivid expression and lack realism. Therefore, to enhance the time-travel experience, we restore the Chinese ancient painting figure faces as modern faces with realistic style, which is also the most critical and challenging part in the entire technical chain. We solve this problem by the StyleGAN2 generator in the encoder4editing (e4e) algorithm. Our system is very expected to be deployed in application scenarios such as museums.},
  keywords={Humanities;Large language models;Multimedia systems;Conferences;Collaboration;Museums;Generators;Talking face animation;ancient painting;StyleGAN;face restoration;large language model},
  doi={10.1109/ICMEW63481.2024.10645456},
  ISSN={2995-1429},
  month={July},}@ARTICLE{10798108,
  author={Guo, Shaolong and Wang, Yuntao and Zhang, Ning and Su, Zhou and Luan, Tom H. and Tian, Zhiyi and Shen, Xuemin},
  journal={IEEE Communications Surveys & Tutorials}, 
  title={A Survey on Semantic Communication Networks: Architecture, Security, and Privacy}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  abstract={With the rapid advancement and deployment of intelligent agents and artificial general intelligence (AGI), a fundamental challenge for future networks is enabling efficient communications among agents. Unlike traditional human-centric, data-driven communication networks, the primary goal of agent-based communication is to facilitate coordination among agents. Therefore, task comprehension and collaboration become the key objectives of communications, rather than data synchronization. Semantic communication (SemCom) aims to align information and knowledge among agents to expedite task comprehension. While significant research has been conducted on SemCom for two-agent systems, the development of semantic communication networks (SemComNet) for multi-agent systems remains largely unexplored. In this paper, we provide a comprehensive and up-to-date survey of SemComNet, focusing on their fundamentals, security, and privacy aspects. We introduce a novel three-layer architecture for multi-agent interaction, comprising the control layer, semantic transmission layer, and cognitive sensing layer. We explore working modes and enabling technologies, and present a taxonomy of security and privacy threats, along with state-of-the-art defense mechanisms. Finally, we outline future research directions, paving the way toward intelligent, robust, and energy-efficient SemComNet. This survey represents the first comprehensive analysis of SemComNet, offering detailed insights into its core principles as well as associated security and privacy challenges.},
  keywords={Security;Surveys;Privacy;Artificial intelligence;Knowledge based systems;Collaboration;Training;Sensors;Wireless communication;Computer hacking;Semantic communication;artificial intelligence;security;privacy;trust},
  doi={10.1109/COMST.2024.3516819},
  ISSN={1553-877X},
  month={},}@BOOK{10109623,
  author={Yang, Yibo and Mandt, Stephan and Theis, Lucas},
  booktitle={An Introduction to Neural Data Compression},
  year={2023},
  volume={},
  number={},
  pages={},
  abstract={The goal of data compression is to reduce the number of bits needed to represent useful information. Neural, or learned compression, is the application of neural networks and related machine learning techniques to this task. This monograph aims to serve as an entry point for machine learning researchers interested in compression by reviewing the prerequisite background and representative methods in neural compression. Neural compression is the application of neural networks and other machine learning methods to data compression. Recent advances in statistical machine learning have opened up new possibilities for data compression, allowing compression algorithms to be learned end-to-end from data using powerful generative models such as normalizing flows, variational autoencoders, diffusion probabilistic models, and generative adversarial networks. This monograph introduces this field of research to a broader machine learning audience by reviewing the necessary background in information theory (e.g., entropy coding, rate-distortion theory) and computer vision (e.g., image quality assessment, perceptual metrics), and providing a curated guide through the essential ideas and methods in the literature thus far. Instead of surveying the vast literature, essential concepts and methods in neural compression are covered, with a reader in mind who is versed in machine learning but not necessarily data compression.},
  keywords={},
  doi={},
  ISSN={},
  publisher={now},
  isbn={9781638281757},
  url={https://ieeexplore.ieee.org/document/10109623},}@BOOK{10162968,
  author={Tsourakis, Nikos},
  booktitle={Machine Learning Techniques for Text: Apply modern techniques with Python for text processing, dimensionality reduction, classification, and evaluation},
  year={2022},
  volume={},
  number={},
  pages={},
  abstract={Take your Python text processing skills to another level by learning about the latest natural language processing and machine learning techniques with this full color guideKey FeaturesLearn how to acquire and process textual data and visualize the key findingsObtain deeper insight into the most commonly used algorithms and techniques and understand their tradeoffsImplement models for solving real-world problems and evaluate their performanceBook DescriptionWith the ever-increasing demand for machine learning and programming professionals, it's prime time to invest in the field. This book will help you in this endeavor, focusing specifically on text data and human language by steering a middle path among the various textbooks that present complicated theoretical concepts or focus disproportionately on Python code. A good metaphor this work builds upon is the relationship between an experienced craftsperson and their trainee. Based on the current problem, the former picks a tool from the toolbox, explains its utility, and puts it into action. This approach will help you to identify at least one practical use for each method or technique presented. The content unfolds in ten chapters, each discussing one specific case study. For this reason, the book is solution-oriented. It's accompanied by Python code in the form of Jupyter notebooks to help you obtain hands-on experience. A recurring pattern in the chapters of this book is helping you get some intuition on the data and then implement and contrast various solutions. By the end of this book, you'll be able to understand and apply various techniques with Python for text preprocessing, text representation, dimensionality reduction, machine learning, language modeling, visualization, and evaluation.What you will learnUnderstand fundamental concepts of machine learning for textDiscover how text data can be represented and build language modelsPerform exploratory data analysis on text corporaUse text preprocessing techniques and understand their trade-offsApply dimensionality reduction for visualization and classificationIncorporate and fine-tune algorithms and models for machine learningEvaluate the performance of the implemented systemsKnow the tools for retrieving text data and visualizing the machine learning workflowWho this book is forThis book is for professionals in the area of computer science, programming, data science, informatics, business analytics, statistics, language technology, and more who aim for a gentle career shift in machine learning for text. Students in relevant disciplines that seek a textbook in the field will benefit from the practical aspects of the content and how the theory is presented. Finally, professors teaching a similar course will be able to pick pertinent topics in terms of content and difficulty. Beginner-level knowledge of Python programming is needed to get started with this book.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781803236292},
  url={https://ieeexplore.ieee.org/document/10162968},}@ARTICLE{10943240,
  author={Kang, Jingdan and Yang, Haoxin and Cai, Yan and Zhang, Huaidong and Xu, Xuemiao and Du, Yong and He, Shengfeng},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={SITA: Structurally Imperceptible and Transferable Adversarial Attacks for Stylized Image Generation}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Image generation technology has brought significant advancements across various fields but has also raised concerns about data misuse and potential rights infringements, particularly with respect to creating visual artworks. Current methods aimed at safeguarding artworks often employ adversarial attacks. However, these methods face challenges such as poor transferability, high computational costs, and the introduction of noticeable noise, which compromises the aesthetic quality of the original artwork. To address these limitations, we propose a Structurally Imperceptible and Transferable Adversarial (SITA) attacks. SITA leverages a CLIP-based destylization loss, which decouples and disrupts the robust style representation of the image. This disruption hinders style extraction during stylized image generation, thereby impairing the overall stylization process. Importantly, SITA eliminates the need for a surrogate diffusion model, leading to significantly reduced computational overhead. The method’s robust style feature disruption ensures high transferability across diverse models. Moreover, SITA introduces perturbations by embedding noise within the imperceptible structural details of the image. This approach effectively protects against style extraction without compromising the visual quality of the artwork. Extensive experiments demonstrate that SITA offers superior protection for artworks against unauthorized use in stylized generation. It significantly outperforms existing methods in terms of transferability, computational efficiency, and noise imperceptibility.},
  keywords={Noise;Diffusion models;Image synthesis;Computational modeling;Computational efficiency;Visualization;Optimization;Feature extraction;Noise reduction;Perturbation methods;Adversarial Attack;Stylized Generation;Transferable Adversarial Example;Imperceptible Adversarial Example},
  doi={10.1109/TIFS.2025.3555552},
  ISSN={1556-6021},
  month={},}@ARTICLE{10507779,
  author={},
  journal={IEEE Std 2986-2023}, 
  title={IEEE Recommended Practice for Privacy and Security for Federated Machine Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-57},
  abstract={Privacy and security issues pose great challenges to the federated machine leaning (FML) community. A general view on privacy and security risks while meeting applicable privacy and security requirements in FML is provided. This recommended practice is provided in four parts: malicious failure and non-malicious failure in FML, privacy and security requirements from the perspective of system and FML participants, defensive methods and fault recovery methods, and the privacy and security risks evaluation. It also provides some guidance for typical FML scenarios in different industry areas, which can facilitate practitioners to use FML in a better way.},
  keywords={IEEE Standards;Federated learning;Machine learning;Privacy;Security;federated machine learning;FML;IEEE 2986™;machine learning;privacy;security},
  doi={10.1109/IEEESTD.2024.10507779},
  ISSN={},
  month={April},}@INPROCEEDINGS{10549272,
  author={Abdalwahid, Shadan M.J.a and Hashim, Wassan Adnan and Saeed, Mohammed Ganim and Altaie, Sarmad A. and Kareem, Shahab Wahhab},
  booktitle={2024 21st International Multi-Conference on Systems, Signals & Devices (SSD)}, 
  title={Investigating the Effectiveness of Artificial Intelligence in Watermarking and Steganography for Digital Media Security}, 
  year={2024},
  volume={},
  number={},
  pages={552-561},
  abstract={Watermarking and Steganography are methods of embedding digital information within images or other media, such as text or audio, for the purpose of Copyright Protection or covert communication. This field of study is not recent and has been ongoing for several years, culminating in its current advanced stage. The utilization of Artificial Intelligence algorithms has played a pivotal role in revolutionizing various aspects, including security concerns and the precision of outcomes, as compared to traditional methods. This paper focuses on doing an in-depth analysis of cutting-edge research, techniques, and methodologies employed in the domain of Watermarking and Steganography, specifically in conjunction with Artificial Intelligence. By thoroughly examining and evaluating a collection of recent studies in this domain, we have scrutinized the outcomes of each study with respect to its research goal, the acquired results, the employed algorithm, and the research's robustness in terms of susceptibility to various forms of attacks and the technique of data embedding. Our findings indicate that the use of Artificial Intelligence algorithms has a substantial influence on enhancing result precision, system resilience, and establishing data ownership. Deep Neural Networks (DNN) are essential in Watermarking and Steganography due to their robustness, effectiveness, and accuracy. Novel methodologies and systems improve security, incorporation rates, precision of detection, and speed of convergence. Deep learning is being investigated in techniques such as data concealment, information hiding, and steganography to improve security.},
  keywords={Deep learning;Steganography;Fault tolerance;Reviews;Measurement standards;Watermarking;Artificial neural networks;Watermarking;Steganography;Artificial intelligence;Key Embedding},
  doi={10.1109/SSD61670.2024.10549272},
  ISSN={2474-0446},
  month={April},}@ARTICLE{9241509,
  author={Evans, James},
  journal={Journal of Social Computing}, 
  title={Social Computing Unhinged}, 
  year={2020},
  volume={1},
  number={1},
  pages={1-13},
  abstract={Social computing is ubiquitous and intensifying in the 21st Century. Originally used to reference computational augmentation of social interaction through collaborative filtering, social media, wikis, and crowdsourcing, here I propose to expand the concept to cover the complete dynamic interface between social interaction and computation, including computationally enhanced sociality and social science, socially enhanced computing and computer science, and their increasingly complex combination for mutual enhancement. This recommends that we reimagine Computational Social Science as Social Computing, not merely using computational tools to make sense of the contemporary explosion of social data, but also recognizing societies as emergent computers of more or less collective intelligence, innovation and flourishing. It further proposes we imagine a socially inspired computer science that takes these insights into account as we build machines not merely to substitute for human cognition, but radically complement it. This leads to a vision of social computing as an extreme form of human computer interaction, whereby machines and persons recursively combine to augment one another in generating collective intelligence, enhanced knowledge, and other social goods unattainable without each other. Using the example of science and technology, I illustrate how progress in each of these areas unleash advances in the others and the beneficial relationship between the technology and science of social computing, which reveals limits of sociality and computation, and stimulates our imagination about how they can reach past those limits together.},
  keywords={Social computing;Cognition;Collaboration;Social networking (online);Artificial intelligence;Encyclopedias;social computing;complex systems;computer supported cooperative work;computational social science;artificial intelligence;human computer interaction;human-centered computing},
  doi={10.23919/JSC.2020.0002},
  ISSN={2688-5255},
  month={Sep.},}@ARTICLE{10788671,
  author={Li, Wenhao and Manickam, Selvakumar and Chong, Yung-Wey and Leng, Weilan and Nanda, Priyadarsi},
  journal={IEEE Access}, 
  title={A State-of-the-Art Review on Phishing Website Detection Techniques}, 
  year={2024},
  volume={12},
  number={},
  pages={187976-188012},
  abstract={Phishing attacks remain a significant cybersecurity threat, with phishing websites serving as a primary tool for attackers to deceive users and steal sensitive information. The rapid evolution of phishing tactics has spurred the development of increasingly sophisticated detection mechanisms. This paper provides a comprehensive review of state-of-the-art techniques for phishing website detection, highlighting recent advancements in the field. In particular, it addresses emerging methods for detection, such as graph-based, large language model (LLM)-based approaches and phishing kit-based detection methods, which have not been extensively covered in previous surveys. By critically reviewing recent works from reliable databases, this study constructs a new taxonomy for phishing detection techniques. This review offers a comparison of these techniques, highlighting their strengths and limitations, and explores the challenges of real-world applications of these detection systems. Furthermore, the role of artificial intelligence (AI) in phishing website detection is discussed, and future research directions to improve detection capabilities are suggested. This work addresses emerging and uncovered phishing website detection methods in previous review papers and provides valuable insights for both researchers and practitioners working to develop more robust phishing website detection systems.},
  keywords={Phishing;Reviews;Surveys;Feature extraction;Visualization;Uniform resource locators;Convolutional neural networks;Blocklists;Analytical models;Organizations;Cybersecurity;deep learning;machine learning;phishing website detection},
  doi={10.1109/ACCESS.2024.3514972},
  ISSN={2169-3536},
  month={},}@ARTICLE{10041168,
  author={Karnati, Mohan and Seal, Ayan and Bhattacharjee, Debotosh and Yazidi, Anis and Krejcar, Ondrej},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={Understanding Deep Learning Techniques for Recognition of Human Emotions Using Facial Expressions: A Comprehensive Survey}, 
  year={2023},
  volume={72},
  number={},
  pages={1-31},
  abstract={Emotion recognition plays a significant role in cognitive psychology research. However, measuring emotions is a challenging task. Thus, several approaches have been designed for facial expression recognition (FER). Although, the challenges increase further as the data transit from the laboratory-controlled environment to in-the-wild circumstances, nowadays, applications are overwhelmed by a profusion of deep learning (DL) techniques in real-world problems. DL networks have steadily led to a better understanding of low-dimensional discriminative features from high-dimensional complex face patterns for automatic FER. The modern FER systems based on deep neural networks mainly suffer from two problems: overfitting due to the inadequate availability of training data and complications unassociated with the expressions, such as occlusion, posture, illumination, and identity bias. This study aims to provide a comprehensive survey of the significant DL-based methods that have made a notable contribution to the field of FER. Different components of the methods, such as preprocessing, feature extraction, and classification of facial expressions, are described systematically. Moreover, the discussed approaches are analyzed to compare their performance along with their advantages and limitations. Furthermore, different databases relevant to FER are also explored in this study. Essentially, the main aim of this survey is twofold. The former is to discuss the current scenario of FER approaches and the latter is to present some thoughts on the future directions of facial emotion recognition by machines: what are the obstacles and prospects for FER researchers?},
  keywords={Face recognition;Databases;Feature extraction;Emotion recognition;Task analysis;Lighting;Deep learning;Deep learning (DL);facial expression databases;facial expression recognition (FER);FER challenges;FER future directions;overfitting;survey},
  doi={10.1109/TIM.2023.3243661},
  ISSN={1557-9662},
  month={},}@ARTICLE{10516690,
  author={Hoenig, Amber and Roy, Kaushik and Acquaah, Yaa Takyiwaa and Yi, Sun and Desai, Salil S.},
  journal={IEEE Access}, 
  title={Explainable AI for Cyber-Physical Systems: Issues and Challenges}, 
  year={2024},
  volume={12},
  number={},
  pages={73113-73140},
  abstract={Artificial intelligence and cyber-physical systems (CPS) are two of the key technologies of the future that are enabling major global shifts. However, most of the current implementations of AI in CPS are not explainable, which creates serious problems in ethical, legal, regulatory, and other domains. Therefore, it is necessary for explainable artificial intelligence (XAI) to be integrated with cyber-physical systems to meet the vital needs for control, fairness, accountability, safety, cyber-resilience, and cybersecurity. The goal of this review is to demonstrate the need, benefits, challenges, and implementation of XAI for CPS. We review the existing literature about XAI and CPS, discuss the current state of the art, examine applications in different domains, and make recommendations for future research directions. To the best of our knowledge, this is the first peer-reviewed academic article to provide a comprehensive review of general XAI for CPS. We also contribute new research ideas including development of multisensory explanations and outputs for these systems, application of XAI to CPS to decrease occupational burnout and increase employee engagement, and enumeration of the multidisciplinary goals and benefits of XAI as applied to cyber-physical systems.},
  keywords={Artificial intelligence;Cyber-physical systems;Explainable AI;Biological system modeling;Reviews;Safety;Computer security;Fifth Industrial Revolution;Cyber-physical systems (CPS);cyber-resilience;cybersecurity;explainable artificial intelligence (XAI);industrial CPS;Industry 5.0},
  doi={10.1109/ACCESS.2024.3395444},
  ISSN={2169-3536},
  month={},}@ARTICLE{10620685,
  author={Senevirathna, Thulitha and La, Vinh Hoa and Marchal, Samuel and Siniarski, Bartlomiej and Liyanage, Madhusanka and Wang, Shen},
  journal={IEEE Communications Surveys & Tutorials}, 
  title={A Survey on XAI for 5G and Beyond Security: Technical Aspects, Challenges and Research Directions}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  abstract={With the advent of 5G commercialization, the need for more reliable, faster, and intelligent telecommunication systems is envisaged for the next generation beyond 5G (B5G) radio access technologies. Artificial Intelligence (AI) and Machine Learning (ML) are immensely popular in service layer applications and have been proposed as essential enablers in many aspects of 5G and beyond networks, from IoT devices and edge computing to cloud-based infrastructures. However, existing 5G ML-based security surveys tend to emphasize AI/ML model performance and accuracy more than the models’ accountability and trustworthiness. In contrast, this paper explores the potential of Explainable AI (XAI) methods, which would allow stakeholders in 5G and beyond to inspect intelligent black-box systems used to secure next-generation networks. The goal of using XAI in the security domain of 5G and beyond is to allow the decision-making processes of ML-based security systems to be transparent and comprehensible to 5G and beyond stakeholders, making the systems accountable for automated actions. In every facet of the forthcoming B5G era, including B5G technologies such as ORAN, zero-touch network management, and end-to-end slicing, this survey emphasizes the role of XAI in them that the general users would ultimately enjoy. Furthermore, we presented the lessons from recent efforts and future research directions on top of the currently conducted projects involving XAI.},
  keywords={Artificial intelligence;5G mobile communication;Explainable AI;Security;Surveys;6G mobile communication;Wireless sensor networks;B5G;5G;XAI;AI security;cyber-security;6G mobile communication;Accountability;Trustworthy AI;Explainable security},
  doi={10.1109/COMST.2024.3437248},
  ISSN={1553-877X},
  month={},}@ARTICLE{10005178,
  author={Chang, Ching-Chun and Wang, Xu and Chen, Sisheng and Echizen, Isao and Sanchez, Victor and Li, Chang-Tsun},
  journal={IEEE Access}, 
  title={Deep Learning for Predictive Analytics in Reversible Steganography}, 
  year={2023},
  volume={11},
  number={},
  pages={3494-3510},
  abstract={Deep learning is regarded as a promising solution for reversible steganography. There is an accelerating trend of representing a reversible steo-system by monolithic neural networks, which bypass intermediate operations in traditional pipelines of reversible steganography. This end-to-end paradigm, however, suffers from imperfect reversibility. By contrast, the modular paradigm that incorporates neural networks into modules of traditional pipelines can stably guarantee reversibility with mathematical explainability. Prediction-error modulation is a well-established reversible steganography pipeline for digital images. It consists of a predictive analytics module and a reversible coding module. Given that reversibility is governed independently by the coding module, we narrow our focus to the incorporation of neural networks into the analytics module, which serves the purpose of predicting pixel intensities and a pivotal role in determining capacity and imperceptibility. The objective of this study is to evaluate the impacts of different training configurations upon predictive accuracy of neural networks and provide practical insights. In particular, we investigate how different initialisation strategies for input images may affect the learning process and how different training strategies for dual-layer prediction respond to the problem of distributional shift. Furthermore, we compare steganographic performance of various model architectures with different loss functions.},
  keywords={Neural networks;Deep learning;Steganography;Training data;Distortion;Encoding;Watermarking;Predictive models;Deep learning;modularity;predictive analytics;reversible steganography},
  doi={10.1109/ACCESS.2023.3233976},
  ISSN={2169-3536},
  month={},}@ARTICLE{10922145,
  author={Luo, Ziyuan and Rocha, Anderson and Shi, Boxin and Guo, Qing and Li, Haoliang and Wan, Renjie},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={The NeRF Signature: Codebook-Aided Watermarking for Neural Radiance Fields}, 
  year={2025},
  volume={},
  number={},
  pages={1-16},
  abstract={Neural Radiance Fields (NeRF) have been gaining attention as a significant form of 3D content representation. With the proliferation of NeRF-based creations, the need for copyright protection has emerged as a critical issue. Although some approaches have been proposed to embed digital watermarks into NeRF, they often neglect essential model-level considerations and incur substantial time overheads, resulting in reduced imperceptibility and robustness, along with user inconvenience. In this paper, we extend the previous criteria for image watermarking to the model level and propose NeRF Signature, a novel watermarking method for NeRF. We employ a Codebook-aided Signature Embedding (CSE) that does not alter the model structure, thereby maintaining imperceptibility and enhancing robustness at the model level. Furthermore, after optimization, any desired signatures can be embedded through the CSE, and no fine-tuning is required when NeRF owners want to use new binary signatures. Then, we introduce a joint pose-patch encryption watermarking strategy to hide signatures into patches rendered from a specific viewpoint for higher robustness. In addition, we explore a Complexity-Aware Key Selection (CAKS) scheme to embed signatures in high visual complexity patches to enhance imperceptibility. The experimental results demonstrate that our method outperforms other baseline methods in terms of imperceptibility and robustness.},
  keywords={Neural radiance field;Watermarking;Three-dimensional displays;Training;Robustness;Pipelines;Computational modeling;Visualization;Solid modeling;Rendering (computer graphics);3D reconstruction;digital watermarking;neural radiance fields},
  doi={10.1109/TPAMI.2025.3550166},
  ISSN={1939-3539},
  month={},}@ARTICLE{8312469,
  author={AlRegib, Ghassan and Deriche, Mohamed and Long, Zhiling and Di, Haibin and Wang, Zhen and Alaudah, Yazeed and Shafiq, Muhammad Amir and Alfarraj, Motaz},
  journal={IEEE Signal Processing Magazine}, 
  title={Subsurface Structure Analysis Using Computational Interpretation and Learning: A Visual Signal Processing Perspective}, 
  year={2018},
  volume={35},
  number={2},
  pages={82-98},
  abstract={Understanding Earth's subsurface structures has been and continues to be an essential component of various applications such as environmental monitoring, carbon sequestration, and oil and gas exploration. By viewing the seismic volumes that are generated through the processing of recorded seismic traces, researchers were able to learn from applying advanced image processing and computer vision algorithms to effectively analyze and understand Earth's subsurface structures. In this article, we first summarize the recent advances in this direction that relied heavily on the fields of image processing and computer vision. Second, we discuss the challenges in seismic interpretation and provide insights and some directions to address such challenges using emerging machine-learning algorithms.},
  keywords={Earth;Image processing;Computer vision;Environmental monitoring;Carbon;Oil drilling;Gas industry},
  doi={10.1109/MSP.2017.2785979},
  ISSN={1558-0792},
  month={March},}@ARTICLE{10664537,
  author={Vyas, Abhishek and Lin, Po-Ching and Hwang, Ren-Hung and Tripathi, Meenakshi},
  journal={IEEE Access}, 
  title={Privacy-Preserving Federated Learning for Intrusion Detection in IoT Environments: A Survey}, 
  year={2024},
  volume={12},
  number={},
  pages={127018-127050},
  abstract={With the rapid development of artificial intelligence and a new generation of network technologies, the Internet of Things (IoT) is expanding worldwide. Malicious agents consistently exploit new technical vulnerabilities to access the various IoT systems used in critical industries, medical diagnosis, military, and defense systems. To mitigate these threats, IoT networks should be equipped with intrusion detection systems capable of detecting threat vectors in an attempt to compromise the systems. Moreover, many researchers have integrated privacy-preserving technologies such as homomorphic encryption, differential privacy, and secure multiparty computation with machine learning algorithms. Furthermore, federated learning, which shares only model parameters rather than data, provides distributed privacy-preserving learning; therefore, federated learning is secure and reliable for the implementation of intrusion detection systems in IoT environments. This survey examined the utilization and applications of privacy-preserving mechanisms, explicitly focusing on privacy-preserving federated learning for intrusion detection systems in IoT environments. This survey also highlights future research directions and open research questions. Privacy-preserving federated learning can significantly contribute to the rapid and efficient detection and prevention of various threat vectors that target IoT ecosystems.},
  keywords={Surveys;Internet of Things;Intrusion detection;Federated learning;Vectors;Privacy;Data privacy;Privacy preservation;federated learning;intrusion detection system;Internet of Things},
  doi={10.1109/ACCESS.2024.3454211},
  ISSN={2169-3536},
  month={},}@ARTICLE{10535119,
  author={Gong, Lina and Zhang, Haoxiang},
  journal={IEEE Transactions on Software Engineering}, 
  title={MR${}^{2}$ 2-KG: A Multi-Relation Multi-Rationale Knowledge Graph for Modeling Software Engineering Knowledge on Stack Overflow}, 
  year={2024},
  volume={50},
  number={7},
  pages={1867-1887},
  abstract={Stack Overflow is a knowledge sharing platform where its users create and share informative content from both inside and outside the site. Prior studies have leveraged the relation across Stack Overflow posts through internal links to build services and applications to enhance the accessibility of knowledge. However, they focused on studying a knowledge unit that consists of a question post and all the associated answer posts to represent the relation. It is unknown whether such representation of knowledge on Stack Overflow could comprehensively model various complex relations among webpages, such as questions, answers, internal and external links. In addition, the rationales behind sharing knowledge on Stack Overflow have yet to be explored among distinct user groups, such as askers, answerers, readers who wish to learn. Thus, in this study, we first investigate the real-world characteristics of Stack Overflow knowledge by abstracting the complex knowledge representation into relations among its building blocks. We observe that a question thread includes three basic knowledge relations to reassemble into complex knowledge, that is, the hierarchy relation within the associated answers in a question, the coupling relation between knowledge artifacts (i.e., question or answer posts) through internal links, and the complimentary relation between Stack Overflow posts and external websites. All these three basic knowledge relations are informative and could be caused by different rationales when the crowdsourced knowledge is shared on Stack Overflow. Our findings highlight that it is necessary to propose a comprehensive knowledge graph to represent the real-world knowledge on Stack Overflow. Therefore, we further propose a Multi-Relation Multi-Rationale Knowledge Graph (MR${}^{2}$ 2-KG), whose nodes represent questions, answers, and external webpages. Edges in the MR${}^{2}$ 2-KG represent the rationales included in the three structures (i.e., question answering, duplicate, priori, posterior, parallelism, containment, and working examples knowledge). In addition, we develop an automated approach to model the nodes and edges to represent Stack Overflow knowledge associated with a question thread. Our case study shows that the automated knowledge representation generation can achieve an ROC AUC of 96% and MCC of 89% to identify edges in the MR${}^{2}$ 2-KG. To further evaluate the applicability of MR${}^{2}$ 2-KG, we develop an answer generator to help developers efficiently identify the answers that meet their intent. Our user study of 100 real-world Java questions indicates the usefulness of MR${}^{2}$ 2-KG. Finally, we discuss the implications of our findings for developers, researchers, and Stack Overflow moderators.},
  keywords={Knowledge graphs;Message systems;Java;Couplings;Question answering (information retrieval);Software engineering;Parallel processing;Empirical software engineering;stack overflow;crowdsourced knowledge sharing;knowledge graph},
  doi={10.1109/TSE.2024.3403108},
  ISSN={1939-3520},
  month={July},}@ARTICLE{9233366,
  author={Tjoa, Erico and Guan, Cuntai},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={A Survey on Explainable Artificial Intelligence (XAI): Toward Medical XAI}, 
  year={2021},
  volume={32},
  number={11},
  pages={4793-4813},
  abstract={Recently, artificial intelligence and machine learning in general have demonstrated remarkable performances in many tasks, from image processing to natural language processing, especially with the advent of deep learning (DL). Along with research progress, they have encroached upon many different fields and disciplines. Some of them require high level of accountability and thus transparency, for example, the medical sector. Explanations for machine decisions and predictions are thus needed to justify their reliability. This requires greater interpretability, which often means we need to understand the mechanism underlying the algorithms. Unfortunately, the blackbox nature of the DL is still unresolved, and many machine decisions are still poorly understood. We provide a review on interpretabilities suggested by different research works and categorize them. The different categories show different dimensions in interpretability research, from approaches that provide “obviously” interpretable information to the studies of complex patterns. By applying the same categorization to interpretability in medical research, it is hoped that: 1) clinicians and practitioners can subsequently approach these methods with caution; 2) insight into interpretability will be born with more considerations for medical practices; and 3) initiatives to push forward data-based, mathematically grounded, and technically grounded medical education are encouraged.},
  keywords={Artificial intelligence;Machine learning;Medical information systems;Machine learning algorithms;Explainable artificial intelligence (XAI);interpretability;machine learning (ML);medical information system;survey},
  doi={10.1109/TNNLS.2020.3027314},
  ISSN={2162-2388},
  month={Nov},}@ARTICLE{9380482,
  author={Fan, Feng-Lei and Xiong, Jinjun and Li, Mengzhou and Wang, Ge},
  journal={IEEE Transactions on Radiation and Plasma Medical Sciences}, 
  title={On Interpretability of Artificial Neural Networks: A Survey}, 
  year={2021},
  volume={5},
  number={6},
  pages={741-760},
  abstract={Deep learning as performed by artificial deep neural networks (DNNs) has achieved great successes recently in many important areas that deal with text, images, videos, graphs, and so on. However, the black-box nature of DNNs has become one of the primary obstacles for their wide adoption in mission-critical applications such as medical diagnosis and therapy. Because of the huge potentials of deep learning, the interpretability of DNNs has recently attracted much research attention. In this article, we propose a simple but comprehensive taxonomy for interpretability, systematically review recent studies on interpretability of neural networks, describe applications of interpretability in medicine, and discuss future research directions, such as in relation to fuzzy logic and brain science.},
  keywords={Deep learning;Neural networks;Taxonomy;Data models;Training;Deep learning;interpretability;neural networks;survey},
  doi={10.1109/TRPMS.2021.3066428},
  ISSN={2469-7303},
  month={Nov},}@ARTICLE{9899708,
  author={Wazid, Mohammad and Kumar Das, Ashok and Shetty, Sachin},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={BSFR-SH: Blockchain-Enabled Security Framework Against Ransomware Attacks for Smart Healthcare}, 
  year={2023},
  volume={69},
  number={1},
  pages={18-28},
  abstract={Ransomware is a type of malicious program or software that encrypts the contents on a hard disc and prevents the users from accessing them unless they pay an amount (called a ransom). Most of the organizations, such as financial institutes and healthcare sectors (i.e., smart healthcare) are targeted by ransomware attacks. Ransomware assaults are among the most frightening types of cyber-attacks, and they are not confined to a specific sector or the countries. Blockchain is a tamper-proof technology, which is more secure, robust and decentralized in nature. Features of blockchain can add more security for detection and mitigation of ransomware more effectively. In this paper, we propose a new blockchain-enabled security framework to detect and defend the ransomware attacks for smart healthcare (in short, BSFR-SH). The conducted security analysis proves the security of the proposed BSFR-SH against the ransomware attacks. The performance of BSFR-SH is significantly better than the other similar existing mechanisms as it achieves better accuracy and F1-score than other compared mechanisms. Furthermore, the practical demonstration of BSFR-SH is provided to estimate the impact on important performance parameters.},
  keywords={Ransomware;Medical services;Blockchains;Malware;Smart healthcare;Intrusion detection;Machine learning;Ransomware;smart healthcare;intrusion detection;machine learning;blockchain},
  doi={10.1109/TCE.2022.3208795},
  ISSN={1558-4127},
  month={Feb},}@ARTICLE{10337612,
  author={Soliman, Hazem M. and Sovilj, Dušan and Salmon, Geoff and Rao, Mohan and Mayya, Niranjan},
  journal={IEEE Transactions on Dependable and Secure Computing}, 
  title={RANK: AI-Assisted End-to-End Architecture for Detecting Persistent Attacks in Enterprise Networks}, 
  year={2024},
  volume={21},
  number={4},
  pages={3834-3850},
  abstract={Modern government and enterprise networks are the target of sophisticated multi-step attacks called Advanced Persistent Threats (APTs), designed and carried out by expert adversaries. The prolonged nature of APTs results in overwhelming the analyst with an increasingly impractical number of alerts. As a result, the challenge of APT detection is ideal for automation through artificial intelligence (AI). In this paper, we propose the first, up to our knowledge, end-to-end AI-assisted architecture for detecting APTs – RANK. We propose advanced algorithms and solutions for four consecutive sub-problems: 1) alert templating and merging, 2) alert graph construction, 3) alert graph partitioning into incidents, and 4) incident scoring and prioritization. Additionally, we discuss the necessary optimizations and techniques enabling the system to operate in a real-time fashion. We evaluate our architecture against the 2000 DARPA, Mordor, as well as a large number of real-world datasets from enterprise networks. Extensive results are provided showing four orders-of-magnitude reduction in the amount of data to be reviewed, innovative extraction and security-aware scoring of incidents. The extracted incidents can be further used for downstream tasks. In our experiments where we have access to a portion of alert labels, we are able achieve 87% balanced accuracy.},
  keywords={Security;Detectors;Buildings;Correlation;Computer architecture;Merging;Deep learning;Advanced persistent threats;enterprise networks;intrusion detection;machine learning;mathematical optimization;security management architecture},
  doi={10.1109/TDSC.2023.3338136},
  ISSN={1941-0018},
  month={July},}@ARTICLE{10780997,
  author={},
  journal={IEEE P3350/D3, November 2024}, 
  title={IEEE Approved Draft Recommended Practice for Improving Generalizability of Artificial Intelligence for Medical Imaging}, 
  year={2025},
  volume={},
  number={},
  pages={1-38},
  abstract={This recommended practice delineates an architecture and offers suggestions for enhancing the generalizability of artificial intelligence (AI) models in medical imaging.},
  keywords={IEEE Standards;Data models;Training;Biomedical imaging;Artificial intelligence;Performance evaluation;Medical services;Generalizability;dataset;modeling;training;evaluation},
  doi={},
  ISSN={},
  month={Feb},}@ARTICLE{10694768,
  author={},
  journal={IEEE P3350/D1, March 2023}, 
  title={Draft Recommended Practice for Improving Generalizability of Artificial Intelligence for Medical Imaging}, 
  year={2024},
  volume={},
  number={},
  pages={1-43},
  abstract={This recommended practice delineates an architecture and offers suggestions for enhancing the generalizability of artificial intelligence (AI) models in medical imaging.},
  keywords={IEEE Standards;Biomedical imaging;Artificial intelligence;Data models;Training data;Performance evaluation;Generalizability;dataset;modeling;training;evaluation},
  doi={},
  ISSN={},
  month={Sep.},}@ARTICLE{10756189,
  author={},
  journal={IEEE P3350/D2, November 2024}, 
  title={IEEE Draft Recommended Practice for Improving Generalizability of Artificial Intelligence for Medical Imaging}, 
  year={2024},
  volume={},
  number={},
  pages={1-38},
  abstract={This recommended practice delineates an architecture and offers suggestions for enhancing the generalizability of artificial intelligence (AI) models in medical imaging.},
  keywords={IEEE Standards;Artificial intelligence;Biomedical monitoring;Data models;Training;Performance evaluation;Generalizability;dataset;modeling;training;evaluation},
  doi={},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10219901,
  author={Luo, Shiya and Chen, Defang and Wang, Can},
  booktitle={2023 IEEE International Conference on Multimedia and Expo (ICME)}, 
  title={Customizing Synthetic Data for Data-Free Student Learning}, 
  year={2023},
  volume={},
  number={},
  pages={1817-1822},
  abstract={Data-free knowledge distillation (DFKD) aims to obtain a lightweight student model without original training data. Existing works generally synthesize data from the pretrained teacher model to replace the original training data for student learning. To more effectively train the student model, the synthetic data shall be customized to the current student learning ability. However, this is ignored in the existing DFKD methods and thus negatively affects the student training. To address this issue, we propose Customizing Synthetic Data for Data-Free Student Learning (CSD) in this paper, which achieves adaptive data synthesis using a self-supervised augmented auxiliary task to estimate the student learning ability. That is, data synthesis is dynamically adjusted to enlarge the cross entropy between the labels and the predictions from the self-supervised augmented task, thus generating the hard samples for the student model. The experiments on various datasets and teacher-student models show the effectiveness of our proposed method. Code is available at: https://github.com/luoshiya/CSD},
  keywords={Training;Adaptation models;Codes;Training data;Predictive models;Data models;Entropy;data-free knowledge distillation;self-supervision;model compression},
  doi={10.1109/ICME55011.2023.00312},
  ISSN={1945-788X},
  month={July},}@ARTICLE{10113601,
  author={Wu, Tianyu and He, Shizhu and Liu, Jingping and Sun, Siqi and Liu, Kang and Han, Qing-Long and Tang, Yang},
  journal={IEEE/CAA Journal of Automatica Sinica}, 
  title={A Brief Overview of ChatGPT: The History, Status Quo and Potential Future Development}, 
  year={2023},
  volume={10},
  number={5},
  pages={1122-1136},
  abstract={ChatGPT, an artificial intelligence generated content (AIGC) model developed by OpenAI, has attracted world-wide attention for its capability of dealing with challenging language understanding and generation tasks in the form of conversations. This paper briefly provides an overview on the history, status quo and potential future development of ChatGPT, helping to provide an entry point to think about ChatGPT. Specifically, from the limited open-accessed resources, we conclude the core techniques of ChatGPT, mainly including large-scale language models, in-context learning, reinforcement learning from human feedback and the key technical steps for developing Chat-GPT. We further analyze the pros and cons of ChatGPT and we rethink the duality of ChatGPT in various fields. Although it has been widely acknowledged that ChatGPT brings plenty of opportunities for various fields, mankind should still treat and use ChatGPT properly to avoid the potential threat, e.g., academic integrity and safety challenge. Finally, we discuss several open problems as the potential development of ChatGPT.},
  keywords={Three-dimensional displays;Web and internet services;Reinforcement learning;Chatbots;Robot sensing systems;Transformers;History;AIGC;ChatGPT;GPT-3;GPT-4;human feedback;large language models},
  doi={10.1109/JAS.2023.123618},
  ISSN={2329-9274},
  month={May},}@ARTICLE{10278413,
  author={Afzal, Muhammad Usman and Abdellatif, Alaa Awad and Zubair, Muhammad and Mehmood, Muhammad Qasim and Massoud, Yehia},
  journal={IEEE Access}, 
  title={Privacy and Security in Distributed Learning: A Review of Challenges, Solutions, and Open Research Issues}, 
  year={2023},
  volume={11},
  number={},
  pages={114562-114581},
  abstract={In recent years, the way that machine learning is used has undergone a paradigm shift driven by distributed and collaborative learning. Several approaches have emerged to enable pervasive computing and distributed learning in ubiquitous Internet of Things (IoT) systems. Numerous decentralized strategies have been proposed to deal with the limitations of centralized learning, including privacy and latency due to sharing local data, while utilizing distributed computations as a promising substitute to centralized learning. However, such distributed learning schemes come with new security and privacy concerns that should be addressed. Thus, in this paper, we first provide an overview for the emerging paradigms developed for distributed learning. Then, we performed a comprehensive survey for the privacy and security challenges associated with distributed learning along with the presented solutions to overcome them. Furthermore, we highlight key challenges and open future research directions toward implementing more robust distributed systems.},
  keywords={Distance learning;Computer aided instruction;Security;Privacy;Artificial intelligence;Data privacy;Servers;Internet of Things;Adversarial machine learning;Data privacy and security;Internet of Things (IoT);deep learning;adversarial attacks},
  doi={10.1109/ACCESS.2023.3323932},
  ISSN={2169-3536},
  month={},}@ARTICLE{10906583,
  author={El-Rahman, Sahar A. and Mansour, Ahmed E. and Jamel, Leila and Abdullah Alohali, Manal and Seifeldin, Mohamed and Alkady, Yasmin},
  journal={IEEE Access}, 
  title={C-HIDE: A Steganographic Framework for Robust Data Hiding and Advanced Security Using Coverless Hybrid Image Encryption With AES and ECC}, 
  year={2025},
  volume={13},
  number={},
  pages={41367-41381},
  abstract={Coverless image steganography conceals information without modifying the carrier image, addressing vulnerabilities in traditional methods. However, existing approaches often require transmitting metadata, raising suspicion and security risks. To overcome these limitations, we propose Coverless Hybrid Image Data Encryption (C-HIDE), a robust steganographic method integrating Advanced Encryption Standard (AES) for data confidentiality and Elliptic Curve Cryptography (ECC) for secure key exchange. The system ensures secure transmission without altering cover images, making embedded data harder to detect. C-HIDE eliminates metadata transmission by enabling both sender and receiver to independently generate synchronized coverless image datasets (CIDs) using random seeds. Encrypted secret data is mapped to images whose hash sequences correspond to segments of the message, with Speeded-Up Robust Features (SURF) ensuring reliable image matching. At the receiver’s end, ECC-decrypted AES keys recover the original message while SURF retrieves relevant images. Experimental results demonstrate that C-HIDE achieves an embedding capacity of 574 bits per image, significantly surpassing DCT (256 bits) and DWT (128 bits) techniques. The system maintains 98.5% accuracy under attacks such as noise addition, cropping, and geometric transformations. Furthermore, it enhances security by eliminating metadata transmission, achieving a zero additional information ratio, unlike conventional methods requiring up to 25% extra data. By integrating encryption, minimizing detection, and removing metadata transmission, C-HIDE provides a secure, efficient, and scalable solution for covert communication in real-world applications.},
  keywords={Steganography;Security;Robustness;Encryption;Feature extraction;Metadata;Convolutional neural networks;Receivers;Elliptic curve cryptography;Discrete cosine transforms;Steganography;coverless image steganography;information hiding;information security;concealed communications;cryptography;embedding;encryption technique},
  doi={10.1109/ACCESS.2025.3546255},
  ISSN={2169-3536},
  month={},}@BOOK{10769272,
  author={Plotnikovs, Aleksejs},
  booktitle={Data Management Strategy at Microsoft: Best practices from a tech giant's decade-long data transformation journey},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Leverage your data as a business asset, from readiness to actionable insights, and drive exceptional performanceKey FeaturesLearn strategies to create a data-driven culture and align data initiatives with business goalsNavigate the ever-evolving business landscape with a modern data platform and unique Data IPSurpass competitors by harnessing the true value of data and fostering data literacy in your organizationPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionMicrosoft pioneered data innovation and investment ahead of many in the industry, setting a remarkable standard for data maturity. Written by a data leader with over 15 years of experience following Microsoft’s data journey, this book delves into every crucial aspect of this journey, including change management, aligning with business needs, enhancing data value, and cultivating a data-driven culture. This book emphasizes that success in a data-driven enterprise goes beyond relying solely on modern technology and highlights the importance of prioritizing genuine business needs to propel necessary modernizations through change management practices. You’ll see how data-driven innovation does not solely reside within central IT engineering teams but also among the data's business owners who rely on data daily for their operational needs. This guide empower these professionals with clean, easily discoverable, and business-ready data, marking a significant breakthrough in how data is perceived and utilized throughout an enterprise. You’ll also discover advanced techniques to nurture the value of data as unique intellectual property, and differentiate your organization with the power of data. Its storytelling approach and summary of essential insights at the end of each chapter make this book invaluable for business and data leaders to advocate for crucial data investments.What you will learnDevelop a data-driven roadmap to achieve significant and quantifiable business goalsDiscover the ties between data management and change managementExplore the data maturity curve with essential technology investmentsBuild, safeguard, and amplify your organization's unique Data Intellectual PropertyEquip business leaders with trustworthy and high value data for informed decision-makingUnleash the value of data management and data governance to uplift your data investmentsWho this book is forThis book is for data leaders, CDOs, CDAOs, data practitioners, data stewards, and enthusiasts, as well as modern business leaders intrigued by the transformative potential of data. While a technical background isn't essential, a basic understanding of data management and quality concepts will be helpful. The book avoids twisted technical, engineering, or data science aspects, making it accessible and insightful for data engineers and data scientists to gain a wider understanding of enterprise data needs and challenges.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835466933},
  url={https://ieeexplore.ieee.org/document/10769272},}@ARTICLE{10716791,
  author={Singh, Himanshu Kumar and Singh, Kedar Nath and Singh, Amit Kumar},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={FedMark: Privacy-Preserving Federated Learning-Based Watermarking for Large-Scale Image Datasets}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  abstract={With the accelerated advancement of consumer devices and multimedia editing software, the manipulation and sharing of digital images have become ubiquitous. While these functions enhance user convenience in image editing, they also face more threats, such as data leakage and information theft. Deep learning-based watermarking provides a unique method of digital-image protection. However, it is challenging for existing approaches to provide an effective solution for privacy, generalisation, and scalability at the same time. This study proposes a federated learning-based watermarking framework, called FedMark, to improve the robustness and imperceptibility of watermarks in large-scale image datasets. It enables collaborative model training across distributed consumer devices while maintaining data privacy and model generalisation and scalability across diverse datasets. Empirical validation across multiple datasets shows that FedMark consistently outperforms existing methods with significantly improvement of 36.8 % in terms of robustness and 48.2 % in terms of imperceptibility while ensuring reversibility and maintaining stringent security standards. With its combination of federated learning and advanced watermarking techniques, FedMark is a promising step towards a secure, privacy-preserving future for digital-image watermarking.},
  keywords={Watermarking;Training;Feature extraction;Data models;Computational modeling;Robustness;Servers;Consumer electronics;Data privacy;Scalability;Privacy;Digital watermarking;Federated Learning;Robustness;Consumers electronics},
  doi={10.1109/TCE.2024.3481043},
  ISSN={1558-4127},
  month={},}@INPROCEEDINGS{9283867,
  author={Siva Kumar, Ram Shankar and Nyström, Magnus and Lambert, John and Marshall, Andrew and Goertzel, Mario and Comissoneru, Andi and Swann, Matt and Xia, Sharon},
  booktitle={2020 IEEE Security and Privacy Workshops (SPW)}, 
  title={Adversarial Machine Learning-Industry Perspectives}, 
  year={2020},
  volume={},
  number={},
  pages={69-75},
  abstract={Based on interviews with 28 organizations, we found that industry practitioners are not equipped with tactical and strategic tools to protect, detect and respond to attacks on their Machine Learning (ML) systems. We leverage the insights from the interviews and enumerate the gaps in securing machine learning systems when viewed in the context of traditional software security development. We write this paper from the perspective of two personas: developers/ML engineers and security incident responders. The goal of this paper is to layout the research agenda to amend the Security Development Lifecycle for industrial-grade software in the adversarial ML era.},
  keywords={Organizations;Machine learning;Tools;Software;Software reliability;Security;Interviews;adversarial machine learning;software security;engineering},
  doi={10.1109/SPW50608.2020.00028},
  ISSN={},
  month={May},}@ARTICLE{10255769,
  author={Wang, Yuntao and Su, Zhou and Yan, Miao},
  journal={IEEE Internet of Things Magazine}, 
  title={Social Metaverse: Challenges and Solutions}, 
  year={2023},
  volume={6},
  number={3},
  pages={144-150},
  abstract={Social metaverse is a shared digital space combining a series of interconnected virtual worlds for users to play, shop, work, and socialize. In parallel with the advances of artificial intelligence (AI) and growing awareness of data privacy concerns, federated learning (FL) is promoted as a paradigm shift towards privacy-preserving AI-empowered social metaverse. However, challenges including privacy-utility tradeoff, learning reliability, and AI model thefts hinder the deployment of FL in real metaverse applications. In this article, we exploit the pervasive social ties among users/avatars to advance a social-aware hierarchical FL framework, i.e., SocialFL for a better privacy-utility tradeoff in the social metaverse. Then, an aggregator-free robust FL mechanism based on blockchain is devised with a new block structure and an improved consensus protocol featured with on/off-chain collaboration. Furthermore, based on digital watermarks, an automatic federated AI (FedAI) model ownership provenance mechanism is designed to prevent AI model thefts and collusive avatars in social metaverse. Experimental findings validate the feasibility and effectiveness of proposed framework. Finally, we envision promising future research directions in this emerging area.},
  keywords={Training;Privacy;Metaverse;Collaboration;Watermarking;Reliability engineering;Robustness},
  doi={10.1109/IOTM.001.2200266},
  ISSN={2576-3199},
  month={Sep.},}@BOOK{10614682,
  author={Harding, Verity},
  booktitle={AI Needs You: How We Can Change AI's Future and Save Our Own},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={A humanist manifesto for the age of AIArtificial intelligence may be the most transformative technology of our time. As AI’s power grows, so does the need to figure out what—and who—this technology is really for. AI Needs You argues that it is critical for society to take the lead in answering this urgent question and ensuring that AI fulfills its promise.Verity Harding draws inspiring lessons from the histories of three twentieth-century tech revolutions—the space race, in vitro fertilization, and the internet—to empower each of us to join the conversation about AI and its possible futures. Sharing her perspective as a leading insider in technology and politics, she rejects the dominant narrative, which often likens AI’s advent to that of the atomic bomb. History points the way to an achievable future in which democratically determined values guide AI to be peaceful in its intent; to embrace limitations; to serve purpose, not profit; and to be firmly rooted in societal trust.AI Needs You gives us hope that we, the people, can imbue AI with a deep intentionality that reflects our best values, ideals, and interests, and that serves the public good. AI will permeate our lives in unforeseeable ways, but it is clear that the shape of AI’s future—and of our own—cannot be left only to those building it. It is up to us to guide this technology away from our worst fears and toward a future that we can trust and believe in.},
  keywords={Artificial intelligence;science;technology;history;space race;satellites;biotech;life sciences;politics;history of science;internet;AI governance;AI ethics;democracy geopolitics;chatgpt;generative ai;AI Needs You: How We Can Change AI's Future and Save Our Own;verity harding;Times 100 AI;how we can safeguard AI’s future for the public good;safe AI: is AI good: is AI bad;how can AI help: AI policy;AI education: AI public good;AI fear: Artificial intelligence;transformative technology;AI’s power grows;technology;society;critical;urgent: social responsibility;better society;harmful;better education;future of AI;societal trust;Silicon Valley;Large Language Models (LLMs);ChatGPT;Bing;Google;Space Race;United Nations Outer Space Treaty 1967;Cold War;IVF (in vitro fertilization);Louise Joy Brown;Roe V. Wade;Embryo research/human embryology;Chatbot;DeepMind;Online security;OpenAI;Atomic Bomb;Oppenheimer;AI Bill of Rights;Warnock Commission;AI regulation},
  doi={},
  ISSN={},
  publisher={Princeton University Press},
  isbn={9780691244907},
  url={https://ieeexplore.ieee.org/document/10614682},}@ARTICLE{10757345,
  author={Imani, Hassan and Islam, Md Baharul},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={Spatial-Temporal Coherence in Extreme Video Retargeting for Consumer Screening Devices}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  abstract={The accessibility of diverse display devices and their aspect ratios has drawn much research attention to video retargeting. Non-consistent video retargeting can significantly affect a video’s spatial and temporal quality, particularly in extreme retargeting cases. Since there are no perfectly annotated datasets for video retargeting, deep learning-based techniques are rarely utilized. This paper proposes a method that learns to retarget videos by detecting the salient areas and shifting them to the appropriate location. First, we segment the salient objects using a unified Transformer model. Using convolutional layers and a shifting strategy, we shift and warp objects to the appropriate size and location in the frame. We use 1D convolution to move the salient items in the scene. Additionally, we employ a frame interpolation technique to preserve temporal information. To train the network, we feed the retargeted frames to a variational auto-encoder network to map the retargeted frames back to the input frames. Furthermore, we design perceptual and wavelet-based loss functions to train our model. Thus, we train the network unsupervised. Extensive qualitative and quantitative experiments on the DAVIS dataset show the superiority of the proposed method over existing image and video-based methods.},
  keywords={Distortion;Image segmentation;Visualization;Consumer electronics;Coherence;Transformers;Strips;Shape;Object detection;Media;Salient objects;Spatial and temporal coherence;Segmentation;Video retargeting},
  doi={10.1109/TCE.2024.3502422},
  ISSN={1558-4127},
  month={},}@INPROCEEDINGS{10778711,
  author={Gyimah, Frank Offei and Ofori-Mensah, Ernest and Boowuo, Henrietta and Aggrawal, Sakhi},
  booktitle={2024 Cyber Awareness and Research Symposium (CARS)}, 
  title={Friend or Foe? AI and the Evolving Landscape of Ransomware-as-a-Service (RaaS)}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper examines Ransomware-as-a-Service (RaaS) and its impact on cybercrime. RaaS has made sophisticated attacks accessible to a wider range of criminals, increasing the number of ransomware attacks. The paper explores how Artificial Intelligence (AI) is being used by both attackers and defenders in this evolving landscape. AI empowers RaaS attackers by improving target selection, vulnerability identification, and social engineering tactics. It also automates attack processes, making them more efficient. For defenders, AI offers potential in threat detection, vulnerability assessment, and incident response through real-time data analysis. However, challenges like model development complexity, false positives, and the need for explainable AI models exist for both sides. The paper concludes that AI use by both attackers and defenders creates an "AI arms race" in cybersecurity. It further aim(s) to illuminate future cybersecurity strategies and equip defenders with proactive measures against evolving cyber threats.},
  keywords={Data analysis;Explainable AI;Weapons;Fasteners;Threat assessment;Real-time systems;Ransomware;Artificial intelligence;Computer crime;Research and development;Ransomware;AI in Cybersecurity;Artificial Intelligence;Cybersecurity;Ransomware-as-a-Service;RaaS;Attackers;Defenders;Cybercrime},
  doi={10.1109/CARS61786.2024.10778711},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10205003,
  author={Smith, James Seale and Cascante-Bonilla, Paola and Arbelle, Assaf and Kim, Donghyun and Panda, Rameswar and Cox, David and Yang, Diyi and Kira, Zsolt and Feris, Rogerio and Karlinsky, Leonid},
  booktitle={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={ConStruct-VL: Data-Free Continual Structured VL Concepts Learning*}, 
  year={2023},
  volume={},
  number={},
  pages={14994-15004},
  abstract={Recently, large-scale pre-trained Vision-and-Language (VL) foundation models have demonstrated remarkable capabilities in many zero-shot downstream tasks, achieving competitive results for recognizing objects defined by as little as short text prompts. However, it has also been shown that VL models are still brittle in Structured VL Concept (SVLC) reasoning, such as the ability to recognize object attributes, states, and inter-object relations. This leads to reasoning mistakes, which need to be corrected as they occur by teaching VL models the missing SVLC skills; often this must be done using private data where the issue was found, which naturally leads to a data-free continual (no task-id) VL learning setting. In this work, we introduce the first Continual Data-Free Structured VL Concepts Learning (ConStruct-VL) benchmark11Our code is publicly available at https://github.com/jamessealesmith/ConStruct-VL and show it is challenging for many existing data-free CL strategies. We, therefore, propose a data-free method comprised of a new approach of Adversarial Pseudo-Replay (APR) which generates adversarial reminders of past tasks from past task models. To use this method efficiently, we also propose a continual parameter-efficient Layered-LoRA (LaLo) neural architecture allowing no-memory-cost access to all past models at train time. We show this approach outperforms all data-free methods by as much as ~ 7% while even matching some levels of experience-replay (prohibitive for applications where data-privacy must be preserved).},
  keywords={Computer vision;Codes;Text recognition;Education;Computer architecture;Benchmark testing;Cognition;Transfer;meta;low-shot;continual;or long-tail learning},
  doi={10.1109/CVPR52729.2023.01440},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{10765055,
  author={Yan, Chuan and Ren, Ruomai and Meng, Mark Huasong and Wan, Liuhuo and Ooi, Tian Yang and Bai, Guangdong},
  booktitle={2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={Exploring ChatGPT App Ecosystem: Distribution, Deployment and Security}, 
  year={2024},
  volume={},
  number={},
  pages={1370-1382},
  abstract={ChatGPT has enabled third-party developers to create plugins to expand ChatGPT’s capabilities. These plugins are distributed through OpenAI’s plugin store, making them easily accessible to users. With ChatGPT as the backbone, this app ecosystem has illustrated great business potential by offering users personalized services in a conversational manner. Nonetheless, many crucial aspects regarding app development, deployment, and security of this ecosystem have yet to be thoroughly studied in the research community, potentially hindering a broader adoption by both developers and users. In this work, we conduct the first comprehensive study of the Chat-GPT app ecosystem, aiming to illuminate its landscape for our research community. Our study examines the distribution and deployment models in the integration of LLMs and third-party apps, and assesses their security and privacy implications. We uncover an uneven distribution of functionality among ChatGPT plugins, highlighting prevalent and emerging topics. We also identify severe flaws in the authentication and user data protection for third-party app APIs integrated within LLMs, revealing a concerning status quo of security and privacy in this app ecosystem. Our work provides insights for the secure and sustainable development of this rapidly evolving ecosystem.CCS CONCEPTS• Security and privacy → Software and application security.},
  keywords={Privacy;Biological system modeling;Source coding;Ecosystems;Reverse engineering;Chatbots;Software;Security;Sustainable development;Software engineering;Large Language Model;Testing;Security;Deployment},
  doi={},
  ISSN={2643-1572},
  month={Oct},}@INPROCEEDINGS{10021112,
  author={Chen, Zefeng and Wu, Jiayang and Gan, Wensheng and Qi, Zhenlian},
  booktitle={2022 IEEE International Conference on Big Data (Big Data)}, 
  title={Metaverse Security and Privacy: An Overview}, 
  year={2022},
  volume={},
  number={},
  pages={2950-2959},
  abstract={Metaverse is a living space and cyberspace that realizes the process of virtualizing and digitizing the real world. It integrates a plethora of existing technologies with the goal of being able to map the real world, even beyond the real world. Metaverse has a bright future and is expected to have many applications in various scenarios. The support of the Metaverse is based on numerous related technologies becoming mature. Hence, there is no doubt that the security risks of the development of the Metaverse may be more prominent and more complex. We present some Metaverse-related technologies and some potential security and privacy issues in the Metaverse. We present current solutions for Metaverse security and privacy derived from these technologies. In addition, we also raise some unresolved questions about the potential Metaverse. To summarize, this survey provides an in-depth review of the security and privacy issues raised by key technologies in Metaverse applications. We hope that this survey will provide insightful research directions and prospects for the Metaverse's development, particularly in terms of security and privacy protection in the Metaverse.},
  keywords={Industries;Privacy;Metaverse;Cyberspace;Big Data;Internet;Security;Metaverse;cyber;security;privacy;overview},
  doi={10.1109/BigData55660.2022.10021112},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9523015,
  author={Kim, Minha and Tariq, Shahroz and Woo, Simon S.},
  booktitle={2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
  title={FReTAL: Generalizing Deepfake Detection using Knowledge Distillation and Representation Learning}, 
  year={2021},
  volume={},
  number={},
  pages={1001-1012},
  abstract={As GAN-based video and image manipulation technologies become more sophisticated and easily accessible, there is an urgent need for effective deepfake detection technologies. Moreover, various deepfake generation techniques have emerged over the past few years. While many deepfake detection methods have been proposed, their performance suffers from new types of deepfake methods on which they are not sufficiently trained. To detect new types of deepfakes, the model should learn from additional data without losing its prior knowledge about deepfakes (catastrophic forgetting), especially when new deepfakes are significantly different. In this work, we employ the Representation Learning (ReL) and Knowledge Distillation (KD) paradigms to introduce a transfer learning-based Feature Representation Transfer Adaptation Learning (FReTAL) method. We use FReTAL to perform domain adaptation tasks on new deepfake datasets, while minimizing the catastrophic forgetting. Our student model can quickly adapt to new types of deepfake by distilling knowledge from a pre-trained teacher model and applying transfer learning without using source domain data during domain adaptation. Through experiments on FaceForensics++ datasets, we demonstrate that FReTAL outperforms all baselines on the domain adaptation task with up to 86.97% accuracy on low-quality deepfakes.},
  keywords={Adaptation models;Computer vision;Conferences;Computational modeling;Transfer learning;Data models;Pattern recognition},
  doi={10.1109/CVPRW53098.2021.00111},
  ISSN={2160-7516},
  month={June},}@ARTICLE{10086041,
  author={Luo, Xiyang and Li, Yinxiao and Chang, Huiwen and Liu, Ce and Milanfar, Peyman and Yang, Feng},
  journal={IEEE Transactions on Image Processing}, 
  title={DVMark: A Deep Multiscale Framework for Video Watermarking}, 
  year={2023},
  volume={},
  number={},
  pages={1-1},
  abstract={Video watermarking embeds a message into a cover video in an imperceptible manner, which can be retrieved even if the video undergoes certain modifications or distortions. Traditional watermarking methods are often manually designed for particular types of distortions and thus cannot simultaneously handle a broad spectrum of distortions. To this end, we propose a robust deep learning-based solution for video watermarking that is end-to-end trainable. Our model consists of a novel multiscale design where the watermarks are distributed across multiple spatial-temporal scales. Extensive evaluations on a wide variety of distortions show that our method outperforms traditional video watermarking methods as well as deep image watermarking models by a large margin. We further demonstrate the practicality of our method on a realistic video-editing application.},
  keywords={Watermarking;Distortion;Transforms;Decoding;Deep learning;Robustness;Training},
  doi={10.1109/TIP.2023.3251737},
  ISSN={1941-0042},
  month={},}@INPROCEEDINGS{9093568,
  author={Banerjee, Sandipan and Scheirer, Walter J. and Bowyer, Kevin W. and Flynn, Patrick J.},
  booktitle={2020 IEEE Winter Conference on Applications of Computer Vision (WACV)}, 
  title={On Hallucinating Context and Background Pixels from a Face Mask using Multi-scale GANs}, 
  year={2020},
  volume={},
  number={},
  pages={289-298},
  abstract={We propose a multi-scale GAN model to hallucinate realistic context (forehead, hair, neck, clothes) and background pixels automatically from a single input face mask, without any user supervision. Instead of swapping a face on to an existing picture, our model directly generates realistic context and background pixels based on the features of the provided face mask. Unlike facial inpainting algorithms, it can generate realistic hallucinations even for a large number of missing pixels. Our model is composed of a cascaded network of GAN blocks, each tasked with hallucination of missing pixels at a particular resolution while guiding the synthesis process of the next GAN block. The hallucinated full face image is made photo-realistic by using a combination of reconstruction, perceptual, adversarial and identity preserving losses at each block of the network. With a set of extensive experiments, we demonstrate the effectiveness of our model in hallucinating context and background pixels from face masks varying in facial pose, expression and lighting, collected from multiple datasets subject disjoint with our training data. We also compare our method with popular face inpainting and face swapping models in terms of visual quality, realism and identity preservation. Additionally, we analyze our cascaded pipeline and compare it with the progressive growing of GANs, and explore its usage as a data augmentation module for training CNNs.},
  keywords={Face;Gallium nitride;Training;Context modeling;Image resolution;Data models;Image reconstruction},
  doi={10.1109/WACV45572.2020.9093568},
  ISSN={2642-9381},
  month={March},}
