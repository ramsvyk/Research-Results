@ARTICLE{10931854,
  author={Gao, Haoyu and Treude, Christoph and Zahedi, Mansooreh},
  journal={IEEE Transactions on Software Engineering}, 
  title={Adapting Installation Instructions in Rapidly Evolving Software Ecosystems}, 
  year={2025},
  volume={},
  number={},
  pages={1-24},
  abstract={README files play an important role in providing installation-related instructions to software users and are widely used in open source software systems on platforms such as GitHub. Software projects evolve rapidly alongside their dependencies in dynamic software ecosystems, requiring frequent updates to installation instructions. These instructions are crucial for users to start with a software project. Despite their significance, there is a lack of systematic understanding regarding the documentation efforts invested in README files and the triggers behind them. To fill the research gap, we conducted a qualitative study, investigating 400 GitHub repositories with 1,163 README commits that focused on updates in installation-related sections. Our research revealed six major categories of changes in the README commits, namely pre-installation instructions, installation instructions, post-installation instructions, help information updates, document presentation, and external resource management. We further provide detailed insights into modification behaviours and offer examples of these updates. We also studied the triggers for the documentation updates, which led to three categories including errors in the previous documentation, changes in the codebase, and need for documentation improvement. Based on our findings, we proposed a README template tailored to cover the installation-related sections for documentation maintainers to reference when updating documents. We further validated this template by conducting an online survey and a pull request study, identifying that documentation readers find the augmented documents based on our template to be generally of better quality, and documentation maintainers find it useful. We further provide recommendations to practitioners for maintaining their README files, as well as motivations for future research directions. These recommendations encompass completeness, correctness and up-to-dateness, and information presentation considerations. The proposed research directions include the development of automated tools, in particular for documentation updates, and conducting empirical studies to enhance comprehension of the needs of documentation users.},
  keywords={Documentation;Software;Software development management;Ecosystems;Codes;Taxonomy;Surveys;Open source software;Data mining;Training;Software Documentation;README Files;Qualitative Analysis;Open Source Software;Installation Instructions;Software Ecosystem},
  doi={10.1109/TSE.2025.3552614},
  ISSN={1939-3520},
  month={}
}

@ARTICLE{10902504,
  author={Li, Xiao and Chen, Liquan and Fu, Tong and Fu, Zhangjie and Gao, Yuan},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Coverless Image Steganography based on Semantic-Controlled Text-to-Image Generation}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Artificial Intelligence Generated Content (AIGC) has created a fertile ground for image steganography. Existing Coverless Image Steganography (CIS) methods rely on image semantics to encode secrets, transmitting stego images without embedding, inherently resisting steganalysis. However, constructing CIS Datasets (CISDs) for these methods demands excessive resources, making them impractical for communication. Moreover, achieving low cost and high security is unattainable under these conditions. Therefore, we propose a CIS method based on semantic-controlled text-to-image generation. Our method disguises users as typical AIGC community members utilizing mainstream black-box text-to-image generation with Stable Diffusion (SD). During pre-processing, plain prompts, derived from dialogues with a large language model, are divided into coded and uncoded prompts through our encryption process, where a secret key determines coded prompts. In communication, confusion prompts are selected from uncoded and coded prompts, excluding those determined by secrets. Subsequently, our stego shuffling process combines topic, secret, and confusion prompts to produce stego prompt sets. Diverse stego images maintaining visual topic consistency are generated from these sets using SD with generation seeds indicating transmission order. By introducing confusion prompts, our method is secure from recognition when revealing stego prompts. Experimental results demonstrate our method achieves low communication costs and enhances communication security.},
  keywords={Semantics;Text to image;Steganography;Security;Costs;Artificial intelligence;Visualization;Receivers;Image recognition;Electronic mail;Coverless Image Steganography (CIS);Image Steganography;Text-to-Image Generation;Artificial Intelligence Generated Content (AIGC)},
  doi={10.1109/TCSVT.2025.3545067},
  ISSN={1558-2205},
  month={}
}

@INPROCEEDINGS{10673401,
  author={Anthony, Celia and Patel, Savan},
  booktitle={2024 7th International Conference on Circuit Power and Computing Technologies (ICCPCT)}, 
  title={Deep Convolutional Q-Learning system and VGG-16 steganalysis detector for image Steganography}, 
  year={2024},
  volume={1},
  number={},
  pages={924-930},
  abstract={Image steganography is the concealment of data (text, image, or video) within a cover image. The confidential information is concealed so that human eyes cannot see it. In recent years, deep learning has garnered popularity as a potent tool for various applications, including image steganography. Image steganography techniques are increasingly used for covert communication and information concealment because of the accelerated development of digital technology. This paper uses Deep Convolutional Generative Adversarial Networks (DCGANs) to incorporate classified data within cover images. Our proposed steganography method employs DCGANs to generate realistic-looking stego images invisible to the human eye while effectively concealing sensitive information. Moreover, we present a novel Deep Convolutional Q-Learning (DCQL) method for optimizing the embedding procedure, ensuring the utmost imperceptibility while preserving data integrity. We use a cutting-edge VGG-16-based steganalysis detector that employs deep learning algorithms to scrutinize suspicious images for hidden content to uncover these hidden signals. The VGG-16 architecture, with its established image classification abilities, is ideally adapted for the challenging task of steganalysis, which involves locating even the most subtly concealed information. Our experimental results demonstrate that the proposed method effectively conceals and detects steganography content. We evaluate the system's efficacy using various steganography techniques and cover image datasets, highlighting its robustness and adaptability. In addition, the DCQL procedure increases the invisibility of stego-images while preserving the integrity of the hidden data. The combination of DCGANs, DCQL, and VGG-16-based steganalysis detectors results in a comprehensive framework that improves the security and detection of image steganography, with promising applications in cyber security and digital forensics.},
  keywords={Deep learning;Steganography;Q-learning;Program processors;Convolution;Detectors;Robustness;Image steganography;Deep learning;confidential information;Deep Convolutional Generative Adversarial Networks;Deep Convolutional Q-Learning;Steganalysis},
  doi={10.1109/ICCPCT61902.2024.10673401},
  ISSN={},
  month={Aug}
}

@ARTICLE{10721229,
  author={Qiang Wang, Zhi and Wang, Haopeng and El Saddik, Abdulmotaleb},
  journal={IEEE Access}, 
  title={FedITD: A Federated Parameter-Efficient Tuning With Pre-Trained Large Language Models and Transfer Learning Framework for Insider Threat Detection}, 
  year={2024},
  volume={12},
  number={},
  pages={160396-160417},
  abstract={Insider threats cause greater losses than external attacks, prompting organizations to invest in detection systems. However, there exist challenges: 1) Security and privacy concerns prevent data sharing, making it difficult to train robust models and identify new attacks. 2) The diversity and uniqueness of organizations require localized models, as a universal solution could be more effective. 3) High resource costs, delays, and data security concerns complicate building effective detection systems. This paper introduces FedITD, a flexible, hierarchy, and federated framework with local real-time detection systems, combining Large Language Models (LLM), Federated Learning (FL), Parameter Efficient Tuning (PETuning), and Transfer Learning (TF) for insider threat detection. FedITD uses FL to protect privacy while indirect integrating client information and employs PETuning methods (Adapter, BitFit, LoRA) with LLMs (BERT, RoBERTa, XLNet, DistilBERT) to reduce resource use and time delay. FedITD customizes client models and optimizes performance via transfer learning without central data transfer, further enhancing the detection of new attacks. FedITD outperforms other federated learning methods and its performance is very close to the best centrally trained method. Extensive experiment results show FedITD’s superior performance, adaptability to varied data, and reduction of resource costs, achieving an optimal balance in detection capabilities across source data, unlabeled local data, and global data. Alternative PETuning implementations are also explored in this paper.},
  keywords={Data models;Adaptation models;Threat assessment;Tuning;Security;Organizations;Costs;Computational modeling;Transfer learning;Deep learning;Computer security;Data augmentation;Artificial intelligence;Machine learning;Cybersecurity;insider threat;deep learning;transformer;BERT;RoBERTa;XLNet;DistilBERT;GPT;data augmentation;artificial intelligence;machine learning;pre-trained LLM;PETuning;adapter;LoRA;BitFit;LLM;NLP},
  doi={10.1109/ACCESS.2024.3482988},
  ISSN={2169-3536},
  month={}
}

@INPROCEEDINGS{10794405,
  author={Lupi, Francesco and Rocha, Andre Dionisio and Maffei, Antonio and Ferreira, Pedro and Barata, Josè and Lanzetta, Michele},
  booktitle={2024 IEEE International Conference on Engineering, Technology, and Innovation (ICE/ITMC)}, 
  title={A Survey on Trends in Visual Inspection Systems Toward Industry 5.0 – A Systematic Mapping Study}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={Over the past decades, significant developments have occurred in the manufacturing domain, culminating in the contemporary landscape of Industry 5.0 (I5.0). This era is defined by three primary dimensions: technical aspects, sustainability concerns, and human-centricity. Although the broader manufacturing field features a dispersed array of scientific literature reviews amidst this multidisciplinary transition, a focused examination of Visual Inspection Systems (VIS) within this context appears absent. This study aims to provide a comprehensive mapping study that navigates this complex and emerging area of research for VIS, incorporating both scientific publications and Intellectual Property (IP). Employing a systematic methodology for mapping review, an initial exploratory search was conducted, retrieving 264 documents. Following a systematic screening process, 46 documents were identified as relevant, underscoring the preliminary findings and prevailing trends in the field. Results shows that three main clusters emerged with rising interest in technological solutions. Additionally, this study offers a procedural approach to further investigate these promising exploratory findings and expand upon the current review.},
  keywords={Surveys;Visualization;Technological innovation;Systematics;Reviews;Inspection;Market research;Manufacturing;Fifth Industrial Revolution;Sustainable development;Visual inspection;Industry 5.0;Sustainability;Human-centricity;Technological evolution},
  doi={10.1109/ICE/ITMC61926.2024.10794405},
  ISSN={2693-8855},
  month={June}
}

@INPROCEEDINGS{10893115,
  author={Kalaigian, Maddy and Thompson, Michael S. and VanLone, Janet and Nickel, Robert},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Using Generative AI to Implement UDL Principles in Traditional STEM Classrooms}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This innovative practice full paper presents a guided approach to integrating universal design for learning (UDL) principles into an Explicit Instruction classroom. To address the common challenges of scope and additional time requirements of integrating UDL, we are using generative artificial intelligence (GAI) tools like ChatGPT because they have reached a level of functionality that allows a GAI tool to replace multiple specialized tools. This paper provides specific guidelines of where UDL interventions can be included in an explicit instruction lesson and how to use GAI to support them. This paper has multiple goals. First, we are focused on an approach that can help embed modern, best practices in traditional, higher ed STEM classes that use an approach that is typically close to the explicit instruction model. Second, we want to show how GAI can be used to implement UDL principles in classes in a way that does not require much additional instructor time and can help UDL adoption scale to larger classes. Example GAI prompts and “real” responses are provided for those who are unfamiliar with GAI tools, in order to help demonstrate the capabilities of the tools.},
  keywords={Generative AI;Chatbots;Best practices;Guidelines},
  doi={10.1109/FIE61694.2024.10893115},
  ISSN={2377-634X},
  month={Oct}
}

@BOOK{10251277,
  author={Kreiling, Kelsey Gilbert and Ulaszek, Mallory},
  booktitle={Squarespace from Signup to Launch: Build, customize, and launch robust and user-friendly Squarespace websites with a no-code approach},
  year={2023},
  volume={},
  number={},
  pages={},
  abstract={Packed with expert insights, practical tools, and a library of resources, this book teaches everything you need to know to build design focused, professional websites that deliver inspiring user experiences from signup to launch. Purchase of the print or Kindle book includes a free PDF eBookKey FeaturesUse a hands-on approach and professional insights to design a custom website on Squarespace 7.1 and Fluid EngineLaunch a website on your domain with features like commerce, member areas, blogging and schedulingGrow your audience with a mobile-optimized website you can own, edit, and updateBook DescriptionYou've heard about Squarespace; maybe you've even started a trial site, but you haven't gotten around to actually launching it yet. It looks simple enough and feels like it should be easy, so why is it such a challenge? Author and Squarespace expert Kelsey Gilbert-Kreiling is here to help. Squarespace from Signup to Launch a comprehensive guide to customizing the most design-focused and user-friendly website builder in the no-code world. More than a technical manual, the book will help you prepare to build a website, explain the foundational knowledge behind Squarespace 7.1 and Fluid Engine, and introduce you to a professional designer's mindset. Readers will learn how to build forms, use content blocks, optimize websites for mobile, build an online store, and become comfortable with Squarespace's built-in SEO, marketing, and analytics tools. Learn from Squarespace experts Christy Price, Will Myers, David Iskander, Kristine Neil, Kathryn Joachim, Beatriz Caraballo, Justin Mabee, Shelly Price and more, with professional insights and resources in each chapter. By the end of the book, you will have gained the confidence needed to build professional Squarespace websites with the developer's technical knowledge, project organization, and design intuition. You won’t just launch your site; you’ll be proud to share it with the world.What you will learnBuild a website on Squarespace, step by step, with expert insights and practical tipsPlan your site content with an easy-to-understand outline Source and create the visual elements needed for a professional siteGo beyond pre-set templates to create a polished design from navigation to footerUse advanced tools such as commerce, scheduling, member areas, blogging and email campaignsIntegrate custom code to enhance the design and functionality of your projectOptimize your website for mobile view and search engine visibilityMarket your site and grow your audience after launchWho this book is forIf you are interested in building a website on the Squarespace platform, including its newest versions, 7.1 and Fluid Engine, then this book is for you. Maybe you’re a brand designer with little or no code experience or perhaps you’re an entrepreneur who needs a website you can own and use. You could even be a website designer versed in other platforms looking to expand your skills to a new tool. No matter your entry point, this book will offer an understanding of the why and how of Squarespace, preparing you to use it as a go-to practical guide.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781801818797},
  url={https://ieeexplore.ieee.org/document/10251277}
}

@INPROCEEDINGS{10378568,
  author={Gandikota, Rohit and Materzyńska, Joanna and Fiotto-Kaufman, Jaden and Bau, David},
  booktitle={2023 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Erasing Concepts from Diffusion Models}, 
  year={2023},
  volume={},
  number={},
  pages={2426-2436},
  abstract={Motivated by concerns that large-scale diffusion models can produce undesirable output such as sexually explicit content or copyrighted artistic styles, we study erasure of specific concepts from diffusion model weights. We propose a fine-tuning method that can erase a visual concept from a pre-trained diffusion model, given only the name of the style and using negative guidance as a teacher. We benchmark our method against previous approaches that remove sexually explicit content and demonstrate its effectiveness, performing on par with Safe Latent Diffusion and censored training. To evaluate artistic style removal, we conduct experiments erasing five modern artists from the network and conduct a user study to assess the human perception of the removed styles. Unlike previous methods, our approach can remove concepts from a diffusion model permanently rather than modifying the output at the inference time, so it cannot be circumvented even if a user has access to model weights. Our code, data, and results are available at erasing.baulab.info.},
  keywords={Training;Visualization;Computer vision;Codes;Filtering;Interference;Benchmark testing},
  doi={10.1109/ICCV51070.2023.00230},
  ISSN={2380-7504},
  month={Oct}
}

@ARTICLE{10648691,
  author={Derner, Erik and Batistič, Kristina and Zahálka, Jan and Babuška, Robert},
  journal={IEEE Access}, 
  title={A Security Risk Taxonomy for Prompt-Based Interaction With Large Language Models}, 
  year={2024},
  volume={12},
  number={},
  pages={126176-126187},
  abstract={As large language models (LLMs) permeate more and more applications, an assessment of their associated security risks becomes increasingly necessary. The potential for exploitation by malicious actors, ranging from disinformation to data breaches and reputation damage, is substantial. This paper addresses a gap in current research by specifically focusing on security risks posed by LLMs within the prompt-based interaction scheme, which extends beyond the widely covered ethical and societal implications. Our work proposes a taxonomy of security risks along the user-model communication pipeline and categorizes the attacks by target and attack type alongside the commonly used confidentiality, integrity, and availability (CIA) triad. The taxonomy is reinforced with specific attack examples to showcase the real-world impact of these risks. Through this taxonomy, we aim to inform the development of robust and secure LLM applications, enhancing their safety and trustworthiness.},
  keywords={Security;Taxonomy;Chatbots;Large language models;Data models;Codes;Privacy;Natural language processing;Risk analysis;Large language models;security;jailbreak;natural language processing},
  doi={10.1109/ACCESS.2024.3450388},
  ISSN={2169-3536},
  month={}
}

@INPROCEEDINGS{10881463,
  author={Pariki, Manohar and Katakam, Srinivas and Srimathi, Marella},
  booktitle={2024 International Conference on Modeling, Simulation & Intelligent Computing (MoSICom)}, 
  title={An Experimental Analysis of Forensics and Deepfakes}, 
  year={2024},
  volume={},
  number={},
  pages={473-478},
  abstract={The growing popularity of smartphones with high-resolution digital cameras, the development of deep learning AI platforms, and the accessibility of a large selection of software programs for shooting, editing, and sharing photos and videos have all contributed to the emergence of a new phenomenon known as “Deepfake.” In response, we have developed and put into use a deep-fake detection model (DFT-MF) that is centred on mouth features. Our algorithm examines and verifies lip/mouth motions in order to detect Deepfake films using deep learning techniques. Our DFT-MF model performed well in classification, according to experiments conducted on datasets containing both actual and fraudulent videos. This was especially true when compared to other methods that have been used in this domain previously.},
  keywords={Deep learning;Performance evaluation;Deepfakes;Films;Computational modeling;Biological system modeling;Software algorithms;Teeth;Software;Smart phones;Digital Forensics;Manipulation;Detection;Classification;Segmentation;Python;Deep Learning;Videos;Deepfake},
  doi={10.1109/MoSICom63082.2024.10881463},
  ISSN={},
  month={Dec}
}

@INPROCEEDINGS{10917955,
  author={Zhang, Zhaoxi and Zhang, Xiaomei and Zhang, Yanjun and Zhang, Leo Yu and Chen, Chao and Hu, Shengshan and Gill, Asif and Pan, Shirui},
  booktitle={2024 Annual Computer Security Applications Conference (ACSAC)}, 
  title={Stealing Watermarks of Large Language Models via Mixed Integer Programming}, 
  year={2024},
  volume={},
  number={},
  pages={46-60},
  abstract={The Large Language Model (LLM) watermark is a newly emerging technique that shows promise in addressing concerns surrounding LLM copyright, monitoring AI-generated text, and preventing its misuse. The LLM watermark scheme commonly includes generating secret keys to partition the vocabulary into green and red lists, applying a perturbation to the logits of tokens in the green list to increase their sampling likelihood, thus facilitating watermark detection to identify AI-generated text if the proportion of green tokens exceeds a threshold. However, recent research indicates that watermarking methods using numerous keys are susceptible to removal attacks, such as token editing, synonym substitution, and paraphrasing, with robustness declining as the number of keys increases. Therefore, the state-of-the-art watermark schemes that employ fewer or single keys have been demonstrated to be more robust against text editing and paraphrasing. In this paper, we propose a novel green list stealing attack against the state-of-the-art LLM watermark scheme and systematically examine its vulnerability to this attack. We formalize the attack as a mixed integer programming problem with constraints. We evaluate our attack under a comprehensive threat model, including an extreme scenario where the attacker has no prior knowledge, lacks access to the watermark detector API, and possesses no information about the LLM’s parameter settings or watermark injection/detection scheme. Extensive experiments on LLMs, such as OPT and LLaMA, demonstrate that our attack can successfully steal the green list and remove the watermark across all settings.},
  keywords={Integer programming;Threat modeling;Vocabulary;Privacy;Large language models;Perturbation methods;Watermarking;Detectors;Programming;Robustness;Large Language Model;LLM Security;Watermarking;Security and Privacy},
  doi={10.1109/ACSAC63791.2024.00021},
  ISSN={2576-9103},
  month={Dec}
}

@ARTICLE{10898040,
  author={Gao, Guangyong and Chen, Xiaoan and Li, Li and Xia, Zhihua and Fei, Jianwei and Shi, Yun-Qing},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={Screen-Shooting Robust Watermark Based on Style Transfer and Structural Re-Parameterization}, 
  year={2025},
  volume={20},
  number={},
  pages={2648-2663},
  abstract={In real-world applications, screen capturing represents a significant scenario where this process can induce substantial distortion to the original image. Previous methods for simulating screen-shooting distortion often involved combining different formulas. We found that these simulation methods still have a significant gap compared to real distortions, making it urgently necessary to develop a realistic and credible comprehensive noise layer to achieve robustness against screen-shooting distortion. This paper presents a watermarking scheme capable of withstanding severe screen-shooting distortion. First, a dataset is constructed to train a screen-shooting distortion simulation network based on style transfer. Subsequently, a comprehensive noise layer is built upon this network to achieve robustness against severe screen-shooting distortion. Additionally, this paper incorporates structural re-parameterization techniques into the traditional U-shaped encoder to improve the quality of encoded images. Extensive experiments demonstrate the proposed scheme’s superior performance in terms of robustness and generalization, especially under severe screen-shooting distortion conditions.},
  keywords={Watermarking;Distortion;Noise;Robustness;Image edge detection;Decoding;Visualization;Training;Image coding;Electronic mail;Data hiding;robust watermark;screen-shooting simulation network;adversarial training;visual image codes},
  doi={10.1109/TIFS.2025.3542992},
  ISSN={1556-6021},
  month={}
}

@INPROCEEDINGS{10903912,
  author={Rathod, Vishal and Nabavirazavi, Seyedsina and Zad, Samira and Iyengar, Sundararaja Sitharama},
  booktitle={2025 IEEE 15th Annual Computing and Communication Workshop and Conference (CCWC)}, 
  title={Privacy and Security Challenges in Large Language Models}, 
  year={2025},
  volume={},
  number={},
  pages={00746-00752},
  abstract={Large Language Models (LLMs) are at the forefront of artificial intelligence advancements, demonstrating exceptional capabilities in natural language understanding and generation across diverse domains such as healthcare, finance, and customer service. However, their deployment introduces substantial secu-rity and privacy risks, including prompt injection, data leakage, and unauthorized data disclosures. These vulnerabilities highlight the need for robust frameworks to safeguard sensitive data and prevent misuse. This paper provides a comprehensive analysis of the security and privacy challenges in LLMs, examines existing mitigation strategies such as intelligent LLM firewalls, differen-tial privacy, and OW ASP-based security principles, and discusses future directions for ethical and secure LLM deployment. By addressing these challenges in detail, we identify gaps in current practices and propose a roadmap for the secure and responsible deployment of LLMs in high-stakes applications. Our findings underscore the importance of tailored security frameworks and privacy-preserving techniques to ensure the ethical and reliable use of LLMs in sensitive environments. Additionally, this pa-per emphasizes the significance of a human-in-the-loop (HITL) approach to ensure accountability and accuracy, particularly in critical domains. The discussion extends to emerging technologies such as retrieval-augmented generation (RAG) and adaptive threat detection systems, which hold promise for enhancing the security and ethical deployment of LLMs.},
  keywords={Industries;Ethics;Privacy;Technological innovation;Firewalls (computing);Large language models;Computational modeling;Medical services;Threat assessment;Security;Artificial intelligence;Natural language processing;Large language models (LLM);Privacy;OWASP;Data Protection;AI Ethics;Firewall;Threat Modeling;Data Leakage;Ethical Bias Mitigation;Federated Learning;Healthcare AI;Human-in-the-Loop (HITL);Adaptive Security Frameworks;Privacy-Preserving Computation},
  doi={10.1109/CCWC62904.2025.10903912},
  ISSN={},
  month={Jan}
}

@INPROCEEDINGS{10663055,
  author={Pereira, Juanan and López, Juan-Miguel and Garmendia, Xabier and Azanza, Maider},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={Leveraging Open Source LLMs for Software Engineering Education and Training}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={Generative AI, particularly Large Language Models (LLMs), presents innovative opportunities to enhance software engineering education. Open source LLMs such as LLaMA and Mistral leverage the potential of generative AI offering distinct advantages over proprietary options including transparency, customizability, collaboration, and cost savings. This paper de-velops a catalog of LLM prompt examples tailored for software engineering training, mapped to knowledge areas from the Soft-ware Engineering Body of Knowledge (SWEBoK) framework. Example prompts demonstrate LLMs' capabilities in eliciting requirements, diagram generation, API simulation, effort esti-mation through role-playing, and other areas. The methodology involves evaluating prompt responses from ChatGPT, Mistral, and LLaMA on representative tasks. Quantitative and qualitative analysis assesses quality, usefulness, and correctness. Findings show ChatGPT and Mistral outperforming LLaMA overall, but no model perfectly executes complex interactions. We examine implications and challenges of integrating open source LLMs into classrooms, emphasizing the need for oversight, verification, and prompt design aligned with pedagogical objectives.},
  keywords={Training;Knowledge engineering;Costs;Generative AI;Large language models;Collaboration;Chatbots;Software Engineering Education;Open Source AI Models;Large Language Models;Prompt Engineering},
  doi={10.1109/CSEET62301.2024.10663055},
  ISSN={2377-570X},
  month={July}
}

@INPROCEEDINGS{10131890,
  author={Kataria, Mohak and Jain, Kurunandan and Subramanian, Narayanan},
  booktitle={2023 11th International Symposium on Digital Forensics and Security (ISDFS)}, 
  title={Exploring Advanced Encryption and Steganography Techniques for Image Security}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper investigates the use of modern steganography techniques for secure image transmission, utilizing four encryption algorithms: AES, DES, RSA, and ChaCha20. Two steganography techniques, LSB and Spread Spectrum, are used to encrypt and embed ciphertext into five different images. The security of the created images is evaluated using metrics such as PSNR, runtime, MSE, histogram, and information entropy. Our analysis reveals that DES is less effective than AES and ChaCha20 for encryption. Furthermore, Spread Spectrum outperforms LSB in terms of security, although LSB produces better stego-image quality. Combining different steganography and encryption techniques enhances the capacity to send photos with a high level of security and robustness. This study provides insightful knowledge on the effective use of steganography and encryption for secure image transmission in various industries, including military and healthcare imaging applications},
  keywords={Measurement;Industries;Steganography;Runtime;Image communication;Imaging;Medical services;Steganography;AES;DES;RSA;ChaCha20;LSB;Spread Spectrum;PSNR;MSE;histogram;information entropy},
  doi={10.1109/ISDFS58141.2023.10131890},
  ISSN={},
  month={May}
}

@ARTICLE{10423747,
  author={Liu, Yong and Zhang, Li and Wu, Hanzhou and Wang, Zichi and Zhang, Xinpeng},
  journal={IEEE Internet of Things Journal}, 
  title={Reducing High-Frequency Artifacts for Generative Model Watermarking via Wavelet Transform}, 
  year={2024},
  volume={11},
  number={10},
  pages={18503-18515},
  abstract={As generative models find broader applications in Internet of Things (IoT) image processing tasks, safeguarding the copyright of these models assumes increasing significance. Embedding watermarks on the output images generated by such models has been proposed by some researchers as a means of protecting intellectual property. However, prevailing methods for generating model watermarks inadvertently introduce significant high-frequency artifacts in high-frequency regions, compromising the imperceptibility and security of the watermarking system. In pursuit of enhancing the imperceptibility of generative model watermarking, we propose a framework based on discrete wavelet transform. This framework effectively mitigates the high-frequency artifact issue and enhances the frequency-domain concealment of watermarking. Specifically, we introduce an embedded watermarking network, a frequency separation layer, and a watermark extraction network after the output of the target model. We construct a wavelet frequency domain separation layer by wavelet decomposition to decompose the image generated by the embedding network into different frequency components, and embed the watermark into the low-frequency region of the target model output image through joint training and joint loss optimization of the embedding and extraction networks. Extensive experiments conducted on two image processing tasks, i.e., painting transfer and de-raining, demonstrate that our method exhibits no discernible traces of high-frequency artifacts in the frequency domain of the image in both cases, thus boasting superior invisibility. Furthermore, our method demonstrates robustness against preprocessing attacks, such as noise addition, resizing, and image cropping.},
  keywords={Watermarking;Internet of Things;Frequency-domain analysis;Data models;Task analysis;Image processing;Glass box;High-frequency artifacts;imperceptibility;model watermarking;security;wavelet transform},
  doi={10.1109/JIOT.2024.3363613},
  ISSN={2327-4662},
  month={May}
}

@INPROCEEDINGS{9914343,
  author={R, Abirami and C, Malathy},
  booktitle={2022 International Conference on Innovative Computing, Intelligent Communication and Smart Electrical Systems (ICSES)}, 
  title={Watermarking Techniques Performance Analysis in Medical Images for Secure Communication}, 
  year={2022},
  volume={},
  number={},
  pages={1-9},
  abstract={Over the past few years, most medical diagnostics and treatments have shifted to digital content. COVID-19 is a viral disease first identified in Wuhan, China 2019. Its pandemic caused a dramatic loss in human health, work, and food systems worldwide. WHO recommended social distancing as a preventive measure to protect ourselves from corona viral infections. Hence, now many avail hospitals facilities are online. It enables telemedicine where patients, doctors, and medical research units can easily share their digital medical information through various communication channels. At the receiver’s end, the patient’s record must not be lost or altered during transmission. As medical imaging contains many fine features, even small changes cause confusion among medical staff for diagnosis. One of the best techniques for image authentication is digital image watermarking. When developing an effective watermark method, it’s necessary to have a balanced trade-off among imperceptibility, capacity, and robustness. The work gives a comprehensive survey of cryptography, biometrics, and blockchain-based on various watermarking schemes in medical images that gives new ideas to improve the already existing techniques.},
  keywords={Pandemics;Telemedicine;Watermarking;Human factors;Social factors;Robustness;Performance analysis;image authentication;watermarking;capacity;robustness;imperceptibility},
  doi={10.1109/ICSES55317.2022.9914343},
  ISSN={},
  month={July}
}

@ARTICLE{10304125,
  author={Montalvo-Romero, Nayeli and Montiel-Rosales, Aarón and Purroy-Vásquez, Rubén and Quechulpa-Pérez, Pompeyo},
  journal={IEEE Access}, 
  title={Agro-Technological Systems in Traditional Agriculture Assistance: A Systematic Review}, 
  year={2023},
  volume={11},
  number={},
  pages={123047-123069},
  abstract={Guaranteeing food security from agriculture in an uncertain context, derived from the effects of multiple factors, is a challenge. Traditional agricultural production is the one that faces the greatest challenges, derived from the scarce evolution in agricultural practices, despite being the one that contributes the most to the availability of food, at 80%. This systematic review aims to identify and analyze agrotechnological systems belonging to precision agriculture, which may be potentially adaptable to traditional rural agriculture. Contributions that improved crop yields from scientific and technological studies were analyzed. The PRISMA statement was used as a formal outline to collect and analyze 114 studies from the period 2018-2023. From the review, it was identified that there is a growing trend in the adoption of intelligent systems that help producers in the management of crops, accentuated in the increase of crop yield, in the determination of product quality, and in the management of water resources, mainly. Likewise, it was identified that the preponderant approach is the monitoring and control of crop development. This is achieved through emerging technologies, such as the Internet of Things, artificial intelligence, and machine learning, with information mainly collected by sensors embedded in drones, algorithms, decision support systems, sensors, and Arduino technology systems. Finally, this review shows that there are five viable systems that can be adapted to traditional agriculture to strengthen agricultural production. Therefore, the adoption of scientific-technological contributions from precision agriculture contributes to ensuring food security.},
  keywords={Production;Statistics;Sociology;Systematics;Food security;Smart agriculture;Precision engineering;Agricultural applications;food security;precision agriculture},
  doi={10.1109/ACCESS.2023.3329087},
  ISSN={2169-3536},
  month={}
}

@ARTICLE{10935704,
  author={Ali, Abdelhay and Abdelrahman, Amr N. and Celik, Abdulkadir and Fouda, Mohammed E. and Eltawil, Ahmed M.},
  journal={IEEE Sensors Journal}, 
  title={A Robust Auto-Encoder HBC Transceiver with CGAN-Based Channel Modeling}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Human body communication (HBC) offers a promising alternative for efficient and secure data transmission in wearable healthcare systems by leveraging the body’s conductive properties. By utilizing the conductive properties of the human body, HBC offers significant advantages over conventional radio frequency wireless communication methods, including ultra-low power consumption and minimal interference. However, HBC systems face key challenges in energy efficiency, data rate optimization, channel adaptability, and accurate body channel modeling. In this paper, we present a novel dual-mode HBC transceiver architecture designed to overcome these challenges by integrating autoencoder-based signal processing with Generative adversarial networks (GANs)-driven channel modeling framework to enhance communication reliability. Operating in both broadband and narrowband modes, the transceiver dynamically adjusts its data rate and power efficiency based on application-specific demands. The design process involves first developing a CGAN-based channel model from real HBC measurements, then using this model to train an autoencoder-based transceiver architecture. Our CGAN framework generates realistic synthetic channel responses for training, enabling the autoencoder to learn optimal encoding and decoding strategies that are robust to channel variations. Subsequently, we developed a low-power hardware architecture that supports flexible data rates of the proposed design while ensuring robust performance in diverse scenarios. This systematic approach provides key advantages: improved channel modeling accuracy achieving a 0.9 correlation coefficient between generated and real channels and mean squared error of 0.0071, reduced hardware complexity through elimination of DAC/ADC, and flexible operation with dual-mode support. Operating at a clock speed of 42 MHz in the narrowband mode, the transceiver achieves an energy efficiency of 349 pJ/bit at a data rate of 262.5 kbps with sensitivity of -64 dBm, appealing for long-range and low-power applications. In broadband mode, the transceiver achieves an energy efficiency of 16 pJ/bit at a data rate of 5.25 Mbps, suitable for applications demanding high data rates over shorter distances.},
  keywords={Transceivers;Autoencoders;Electrodes;Biosensors;Energy efficiency;Training;Narrowband;Hardware;Broadband communication;Wireless communication;Internet of Bodies (IoB);Human Body Communication;End-to-End communication;CGAN channel modeling;Deep Learning},
  doi={10.1109/JSEN.2025.3551539},
  ISSN={1558-1748},
  month={}
}

@ARTICLE{10813359,
  author={Abdelgadir Mohamed, Yasir and Mohamed, Abdul Hakim H. M. and Khanan, Akbar and Bashir, Mohamed and Adiel, Mousab A. E. and Elsadig, Muawia A.},
  journal={IEEE Access}, 
  title={Navigating the Ethical Terrain of AI-Generated Text Tools: A Review}, 
  year={2024},
  volume={12},
  number={},
  pages={197061-197120},
  abstract={This review examines the ethical, social, and technical challenges posed by AI-generated text tools, focusing on their rapid advancement and widespread adoption. An exhaustive literature search across many databases, strict inclusion/exclusion criteria, and a rigorous analysis procedure are all parts of our systematic review technique. This guarantees an impartial and complete study of the current status of AI-generated text tools. The study analyzes prominent language models, including GPT-3, GPT-4, LaMDA, PaLM, Claude, Jasper, and Llama 2, evaluating their capabilities in natural language processing and generation. The analysis reveals significant advancements, with GPT-3 demonstrating a 92% accuracy rate on standard natural language understanding benchmarks, outperforming LaMDA (88%) and PaLM (85%). To illustrate real-world implications, the review presents a case study of ChatGPT’s application in healthcare, where it achieved 80% consistency with expert opinions in assessing acute ulcerative colitis. This case highlights both the potential benefits and ethical concerns of AI in critical domains. Quantitative bias analysis shows that GPT-3 generated biased content in 15% of test cases involving sensitive topics, a higher rate than LaMDA (12%) and PaLM (10%). We provide an in-depth analysis of fairness and bias issues, particularly in image generation tasks depicting professional roles. Our research synthesizes insights from technical advancements, ethical considerations, and real-world applications across healthcare, education, and creative sectors. We address critical privacy concerns and data protection challenges, noting struggles in AI-generated text detection and investigating AI’s potential in enabling cyberattacks. We underscore the need for comprehensive governance systems and multidisciplinary cooperation. To provide a cohesive analysis of the ethical considerations surrounding AI-generated text tools, we employ a multifaceted ethical framework drawing on established theories. Utilitarianism, which seeks to maximize happiness for everyone; deontology, which places an emphasis on right and wrong; and Virtue Ethics, which analyzes the moral nature of deeds and actors, are all included in this framework. In this article, we use this approach to investigate AI ethics from a variety of angles, including privacy, prejudice, and social implications, as well as concerns of justice and fairness. Moreover, the study critically examines existing and proposed legal frameworks addressing AI ethics, identifying regulatory gaps and proposing adaptive policy recommendations to address the unique challenges posed by AI-generated text tools. Our review contributes a critical analysis of AI-generated text tools, their impacts, and the need for responsible innovation. The study provides precise guidelines for the ethical development and implementation of AI, highlighting the need to strike a balance between technical progress and ethical concerns to guarantee that AI technologies have a beneficial effect on society while protecting human values. The emergence of generative artificial intelligence (AI) signifies a substantial revolution in our methods of interacting with language and information.},
  keywords={Ethics;Artificial intelligence;Reviews;Generative AI;Analytical models;Privacy;Object recognition;Technological innovation;Search problems;Industries;Generative AI;text generation;ethics},
  doi={10.1109/ACCESS.2024.3521945},
  ISSN={2169-3536},
  month={}
}

@INPROCEEDINGS{10254960,
  author={Al Azad, Md Washik and Sarwar, Shifat and Taki, Sifat Ut and Mastorakis, Spyridon},
  booktitle={2023 IEEE 16th International Conference on Cloud Computing (CLOUD)}, 
  title={The Case for the Anonymization of Offloaded Computation}, 
  year={2023},
  volume={},
  number={},
  pages={84-95},
  abstract={Computation offloading (often to external computing resources over a network) has become a necessity for modern applications. At the same time, the proliferation of machine learning techniques has empowered malicious actors to use such techniques in order to breach the privacy of the execution process for offloaded computations. This can enable malicious actors to identify offloaded computations and infer their nature based on computation characteristics that they may have access to even if they do not have direct access to the computation code. In this paper, we first demonstrate that even non-sophisticated machine learning algorithms can accurately identify offloaded computations. We then explore the design space of anonymizing offloaded computations through the realization of a framework, called Camouflage. Camouflage features practical mechanisms to conceal characteristics related to the execution of computations, which can be used by malicious actors to identify computations and orchestrate further attacks based on identified computations. Our evaluation demonstrated that Camouflage can impede the ability of malicious actors to identify executed computations by up to 60%, while incurring modest overheads for the anonymization of computations.},
  keywords={Data privacy;Cloud computing;Privacy;Machine learning algorithms;Codes;Machine learning;Space exploration;Computation Anonymization;Machine Learning;Computation Offloading;Cloud Computing;Computation Graphs},
  doi={10.1109/CLOUD60044.2023.00019},
  ISSN={2159-6190},
  month={July}
}

@INPROCEEDINGS{10889776,
  author={Pan, Zibin and Zhang, Shuwen and Zheng, Yuesheng and Li, Chi and Cheng, Yuheng and Zhao, Junhua},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Multi-Objective Large Language Model Unlearning}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Machine unlearning in the domain of large language models (LLMs) has attracted great attention recently, which aims to effectively eliminate undesirable behaviors from LLMs without full retraining from scratch. In this paper, we explore the Gradient Ascent (GA) approach in LLM unlearning, which is a proactive way to decrease the prediction probability of the model on the target data in order to remove their influence. We analyze two challenges that render the process impractical: gradient explosion and catastrophic forgetting. To address these issues, we propose Multi-Objective Large Language Model Unlearning (MOLLM) algorithm. We first formulate LLM unlearning as a multi-objective optimization problem, in which the cross-entropy loss is modified to the unlearning version to overcome the gradient explosion issue. A common descent update direction is then calculated, which enables the model to forget the target data while preserving the utility of the LLM. Our empirical results verify that MoLLM outperforms the SOTA GA-based LLM unlearning methods in terms of unlearning effect and model utility preservation. The source code is available at https://github.com/zibinpan/MOLLM.},
  keywords={Large language models;Source coding;Signal processing algorithms;Signal processing;Predictive models;Prediction algorithms;Explosions;Data models;Speech processing;Optimization;large language model;machine unlearning;multi-objective optimization},
  doi={10.1109/ICASSP49660.2025.10889776},
  ISSN={2379-190X},
  month={April}
}

@INBOOK{10897091,
  author={Islam, Mohammad Rubyet},
  booktitle={Generative AI, Cybersecurity, and Ethics}, 
  title={Understanding GenAI}, 
  year={2025},
  volume={},
  number={},
  pages={47-81},
  abstract={Summary <p>Generative artificial intelligence (GenAI) is an innovative subset of artificial intelligence (AI) focused on creating original content, simulating human creativity. Unlike traditional AI, which excels in tasks such as classification and prediction, GenAI generates various data types using advanced machine learning techniques. By analyzing existing datasets to identify patterns, GenAI produces novel outputs such as realistic images, videos, music, text, and designs. This chapter explores the core elements, tools, frameworks, and models of GenAI, along with their diverse applications across industries like art, entertainment, marketing, and virtual environments. Additionally, it addresses the technological landscape, validation methodologies, and ethical considerations surrounding GenAI, providing a comprehensive overview of this groundbreaking technology.</p>},
  keywords={Solid modeling;Data models;Predictive models;Machine learning;Image synthesis;Context modeling;Virtual environments;Video games;Transformers;Synthetic data},
  doi={10.1002/9781394279326.ch3},
  ISSN={},
  publisher={Wiley},
  isbn={9781394279319},
  url={https://ieeexplore.ieee.org/document/10897091}
}

@ARTICLE{10903675,
  author={Zhou, Yang and Li, Shengshu and Huang, Hui},
  journal={Computational Visual Media}, 
  title={Deformable few-shot face cartoonization via local to global translation}, 
  year={2025},
  volume={},
  number={},
  pages={1-19},
  abstract={Cartoonizing portrait images is a stylish and eye-catching application in both computer vision and graphics. We aimed to train a face cartoonization model using very few (e.g., 5-10) style examples. The main difficulty in this challenging task lies in producing stylizations of high quality while preserving the identity of the input, particularly when the style examples contain strong exaggerations. To address this, we propose a novel cross-domain center loss for few-shot generative adversarial network (GAN) adaptation, which forces the distribution of the target domain to be similar to that of the source. We then employ it to solve this few-shot problem along with a two-stage strategy. Stage I generates an intermediate cartoonization for the input, where we first stylize the individual facial components locally and then deform them to mimic the desired exaggeration under the guidance of landmarks. Stage II focuses on global refinement of the intermediate image. First, we adapt a pretrained StyleGAN model using the proposed cross-domain center loss to the target domain defined by a few examples. Subsequently, the intermediate cartoonization from Stage I can be holistically refined through GAN inversion. The generative power of StyleGAN guarantees high image quality, while the local translation and landmark-guided deformation applied to facial components provide high identity fidelity. Experiments show that the proposed method outperforms state-of-the-art few-shot stylization approaches both qualitatively and quantitatively.},
  keywords={Translation;Faces;Generative adversarial networks;Deformation;Shape;Feature extraction;Visualization;Neural style transfer;Generators;Adaptation models;face stylization;cartoonization;few-shot learning;domain adaptation},
  doi={10.26599/CVM.2025.9450348},
  ISSN={2096-0662},
  month={}
}

@ARTICLE{10855423,
  author={Zhang, Junbin and Wang, Yixiao and Reza Tohidypour, Hamid and Nasiopoulos, Panos},
  journal={IEEE Access}, 
  title={An Efficient Frequency Domain Based Attribution and Detection Network}, 
  year={2025},
  volume={13},
  number={},
  pages={19909-19921},
  abstract={People nowadays can easily synthesize high fidelity fake images with different types of image content due to the rapid advances of deep learning technologies. Detecting such images and attributing them to their generative models (GMs) is crucial. Existing deep learning methods attempt to identify and classify GM-specific artifacts but often struggle with content-independence and generalizability. In this paper, we observe that while GMs leave unique artifacts in the frequency domain, they are coupled with the image content. Based on this observation, we propose a novel deep learning-based solution that learns input-adaptive masks to highlight GMs’ artifacts and achieve high accuracy on the synthesized image attribution task. In addition, we observed that GMs’ artifacts in the frequency domain remain intact in sub-images of the original image, and they are even retained when the images are distorted. To further improve the accuracy of the proposed solution, we leverage the characteristics of GMs artifacts in sub-images and distorted images to make our network perform more effectively. Our evaluation results show that our proposed solution outperforms other state-of-the-art methods on unseen image types, showing great generalizability.},
  keywords={Discrete cosine transforms;Fingerprint recognition;Frequency-domain analysis;Training;Accuracy;Frequency synthesizers;Visualization;Generative adversarial networks;Faces;Distortion;Synthesized image;attribution;detection;frequency domain},
  doi={10.1109/ACCESS.2025.3534829},
  ISSN={2169-3536},
  month={}
}

@INPROCEEDINGS{10597991,
  author={Liu, Yilun and Tao, Shimin and Zhao, Xiaofeng and Zhu, Ming and Ma, Wenbing and Zhu, Junhao and Su, Chang and Hou, Yutai and Zhang, Miao and Zhang, Min and Ma, Hongxia and Zhang, Li and Yang, Hao and Jiang, Yanfei},
  booktitle={2024 IEEE 40th International Conference on Data Engineering (ICDE)}, 
  title={CoachLM: Automatic Instruction Revisions Improve the Data Quality in LLM Instruction Tuning}, 
  year={2024},
  volume={},
  number={},
  pages={5184-5197},
  abstract={Instruction tuning is crucial for enabling Language Learning Models (LLMs) in responding to human instructions. The quality of instruction pairs used for tuning greatly affects the performance of LLMs. However, the manual creation of high-quality instruction datasets is costly, leading to the adoption of automatic generation of instruction pairs by LLMs as a popular alternative. To ensure the high quality of LLM-generated instruction datasets, several approaches have been proposed. Nevertheless, existing methods either compromise dataset integrity by filtering a large proportion of samples, or are unsuitable for industrial applications. In this paper, instead of discarding low-quality samples, we propose CoachLM, a novel approach to enhance the quality of instruction datasets through automatic revisions on samples in the dataset. CoachLM is trained from the samples revised by human experts and significantly increases the proportion of high-quality samples in the dataset from 17.7% to 78.9%. The effectiveness of CoachLM is further assessed on various real-world instruction test sets. The results show that CoachLM improves the instruction-following capabilities of the instruction-tuned LLM by an average of 29.9%, which even surpasses larger LLMs with nearly twice the number of parameters. Furthermore, CoachLM is successfully deployed in a data management system for LLMs at Huawei, resulting in an efficiency improvement of up to 20% in the cleaning of 40k real-world instruction pairs. We release various assets of CoachLM, including the training data, code and test set11https://github.com/lunyiliu/CoachLM.},
  keywords={Training;Filtering;Data integrity;Pipelines;Training data;Manuals;Cleaning;large language model;instruction tuning;data quality;instruction revision},
  doi={10.1109/ICDE60146.2024.00390},
  ISSN={2375-026X},
  month={May}
}

@INPROCEEDINGS{10781374,
  author={Wang, Peng and Liu, Yu and Han, Kai and Liu, Ziqi and Liu, Ke and Wang, Mingyang and Zhou, Ke and Huang, Zhihai},
  booktitle={2024 International Conference on Networking, Architecture and Storage (NAS)}, 
  title={CGHit: A Content-Oriented Generative-Hit Framework for Content Delivery Networks}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={The service provided by content delivery networks (CDNs) may overlook content locality, leaving the potential to improve performance. In this study, we explore the feasibility of leveraging generated data as a replacement for fetching data in missing scenarios based on content locality. Due to sufficient local computing resources and reliable generation efficiency, we propose a content-oriented generative-hit framework (CGHit) for CDNs. CGHit utilizes idle computing resources on edge nodes to generate requested data based on similar or related cached data, achieving hits. Extensive experiments in a real-world system demonstrate that CGHit reduces the average access latency by half. In addition, experiments conducted on a simulator confirm that CGHit can enhance current caching algorithms, leading to lower latency and reduced bandwidth usage.},
  keywords={Content distribution networks;Large language models;Computational modeling;Computer architecture;Bandwidth;Data collection;Data models;Reliability;Quality of experience;Decision trees;generative-hit;content locality;content delivery network},
  doi={10.1109/NAS63802.2024.10781374},
  ISSN={2835-3323},
  month={Nov}
}

@ARTICLE{10816667,
  author={Liu, Ying and Yin, Jianhui and Zhang, Weiting and An, Changming and Xia, Yu and Zhang, Hongke},
  journal={IEEE Communications Surveys & Tutorials}, 
  title={Integration of Federated Learning and AI-Generated Content: A Survey of Overview, Opportunities, Challenges, and Solutions}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  abstract={Artificial intelligence generated content (AIGC) relies on advanced AI algorithms supported by extensive datasets and substantial computing power to generate precise and pertinent content. Federated learning (FL) enables the aggregation of large volumes of data and computing resources from various sources, all while safeguarding privacy. As a result, FL has emerged as a critical enabler in the realm of AIGC. This survey paper provides a comprehensive overview of the integration of FL and AIGC, namely federated AIGC models. First, we introduce the fundamental concepts of FL and AIGC. Next, we summarize four typical types of federated AIGC models. Subsequently, We highlight the threats to centralized federated AIGC models regarding data confidentiality, integrity, and availability and discuss the unique advantages of blockchain technology in decentralized federated AIGC models in addressing these issues. Finally, we look at potential emerging application scenarios and explore open issues and future directions for federated AIGC models.},
  keywords={Data models;Training;Computational modeling;Artificial intelligence;Surveys;Data privacy;Blockchains;Bandwidth;Servers;Security;Federated learning;AI-generated content;Data Privacy;Blockchain},
  doi={10.1109/COMST.2024.3523350},
  ISSN={1553-877X},
  month={}
}

@ARTICLE{10431786,
  author={Karim, Shahid and Tong, Geng and Yu, Yiting and Laghari, Asif Ali and Khan, Abdullah Ayub and Ibrar, Muhammad and Mehmood, Faisal},
  journal={IEEE Access}, 
  title={Developments in Brain Tumor Segmentation Using MRI: Deep Learning Insights and Future Perspectives}, 
  year={2024},
  volume={12},
  number={},
  pages={26875-26896},
  abstract={The human brain is an incredible and wonderful organ that governs all body actions. Due to its great importance, any defect in the shape of its regions should be reported quickly to reduce the death rate. The abnormal region segmentation helps to plan and monitor the treatment. The most critical procedure is isolating normal and abnormal tissues from each other. So far, remarkable imaging modalities are being used to diagnose abnormalities at their early stages, and magnetic resonance imaging (MRI) is renowned and noninvasive among those modalities. This paper investigates the current landscape of brain tumor segmentation (BTS) by exploring emerging deep learning (DL) methods for brain MRI analysis. The findings offer a comprehensive comparison of recent DL approaches, emphasizing their effectiveness in handling diverse tumor types while addressing limitations associated with data scarcity and robust validation. DL has shown a vital improvement for BTS, so our primary focus is to include significant DL robust models to analyze the brain MRI. However, DL outperforms traditional methods; still, there are several limitations, especially related to the diverse tumor types, lack of datasets, and weak validations. The future perspectives of DL-based BTS present significant potential for revolutionizing the diagnosis and treatment of brain tumors.},
  keywords={Tumors;Image segmentation;Medical diagnostic imaging;Magnetic resonance imaging;Surgery;Medical services;Feature extraction;Brain cancer;Deep learning;Biomedical imaging;Brain tumor segmentation;deep learning;medical imaging;MRI},
  doi={10.1109/ACCESS.2024.3365048},
  ISSN={2169-3536},
  month={}
}

@INBOOK{10897017,
  author={Islam, Mohammad Rubyet},
  booktitle={Generative AI, Cybersecurity, and Ethics}, 
  title={GenAI in Cybersecurity}, 
  year={2025},
  volume={},
  number={},
  pages={83-109},
  abstract={Summary <p>This chapter explores the dual&#x2010;use nature of generative artificial intelligence (GenAI) in cybersecurity, highlighting both its beneficial and potentially malicious applications. GenAI can enhance cybersecurity by developing advanced models for anomaly detection, predictive modeling, and incident response. However, it also poses significant risks, including the creation of sophisticated phishing attacks, malware, and deepfakes. Effective mitigation strategies include the implementation of advanced defensive artificial intelligence technologies, adversarial machine learning, and continuous learning. The chapter emphasizes the importance of ethical and legal frameworks, public awareness campaigns, and the development of comprehensive training programs for cybersecurity professionals. Additionally, it outlines the technical and organizational infrastructure required to incorporate GenAI into cybersecurity frameworks, ensuring a scalable and secure environment for its application.</p>},
  keywords={Computer security;Phishing;Artificial intelligence;Electronic mail;Predictive models;Ethics;Anomaly detection;Analytical models;Threat modeling;Testing},
  doi={10.1002/9781394279326.ch4},
  ISSN={},
  publisher={Wiley},
  isbn={9781394279319},
  url={https://ieeexplore.ieee.org/document/10897017}
}

@ARTICLE{9349088,
  author={Kong, Chenqi and Chen, Baoliang and Yang, Wenhan and Li, Haoliang and Chen, Peilin and Wang, Shiqi},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Appearance Matters, So Does Audio: Revealing the Hidden Face via Cross-Modality Transfer}, 
  year={2022},
  volume={32},
  number={1},
  pages={423-436},
  abstract={Recently, there has been an exponential increase in the security concerns raised by faking face (e.g., deepfake), which automatically changes the identity with a specifically learned deep generative model. With numerous approaches proposed to identify the fake content, much less work has been dedicated to automatically revealing the authentic one that is originally acquired. Here, we propose a new paradigm that seeks to reveal the authentic face hidden behind the fake one by leveraging the joint information of face and audio. More specifically, given the fake face as well as the audio segment, the cross-modality transferable capability is exploited by learning to generate the feature of the authentic face, based on the underlying clues from the audio as well as the fake face appearance. The effectiveness of the proposed scheme is validated through a series of evaluations, and experimental results show that the proposed model achieves promising face reconstruction performance in revealing the hidden faces, in terms of reconstruction quality, as well as identity and face attribute inference accuracy.},
  keywords={Faces;Videos;Information integrity;Face recognition;Training;Generative adversarial networks;Testing;Deepfake;cross modality;face reconstruction;face revealing;fake face},
  doi={10.1109/TCSVT.2021.3057457},
  ISSN={1558-2205},
  month={Jan}
}

@ARTICLE{10886956,
  author={Chen, Xiaojiao and Wang, Jing and Huang, Jingxuan and Zeng, Ming and Zheng, Zhong and Fei, Zesong},
  journal={IEEE Internet of Things Journal}, 
  title={Low-Bitrate High-Quality Digital Semantic Communication Based on RVQGAN}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Digital semantic communication has attracted considerable attention attributed to its potential for integration with modern digital communication systems, which has demonstrated significant performance gains. However, despite its ability to save transmission bandwidth, digital semantic communication can degrade the performance of tasks at the receiver, particularly in low-bitrate scenarios. In this paper, we propose a novel low-bitrate digital semantic communication method based on a generative model for speech transmission to achieve high-quality reconstructed speech at low-bitrate transmission. In particular, we first investigate a multi-scale semantic codec based on residual vector quantization with a generative adversary network (RVQGAN) model for extracting semantic information and obtaining high speech reconstruction quality while transmitting at a low bitrate. We then design a channel noise suppression module based on U-Net to alleviate the channel effect at low signal-to-noise ratio (SNR) by restoring high-quality semantic features, which is capable of improving the performance of the proposed method under challenging channel conditions. Moreover, a Transformer-based code predictor is utilized to further improve the robustness of the proposed method by accounting for both the channel impact and reconstruction quality. Finally, a three-stage training strategy is also presented in this paper to ensure the effective operation of the proposed multi-scale semantic codec, channel noise suppression module, and code predictor module. Experimental results demonstrate that the proposed method operating at 3 kbps can save at least 50% of bandwidth while achieving higher speech restoration quality than the baseline method.},
  keywords={Semantic communication;Receivers;Internet of Things;Codecs;Bandwidth;Decoding;Data mining;Bit rate;Speech coding;Image reconstruction;Digital semantic communication;generative model;low-bitrate;speech transmission},
  doi={10.1109/JIOT.2025.3534462},
  ISSN={2327-4662},
  month={}
}

@ARTICLE{10929000,
  author={Huang, Ting-Feng and Lin, Yu-Hsun},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Drop2Sparse: Improving Dataset Distillation via Sparse Model}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={The success of modern deep learning algorithms requires large amounts of training data, which leads to high computational and storage costs. Dataset Distillation (DD) is a rising research field that resolves this issue by synthesizing a compact training dataset from a large one. Recent gradient matching DD methods have achieved remarkable results. However, these methods typically utilize weak models for DD performance improvement, while well-trained models are often considered inferior choices due to their lower performance. Conversely, our study provides new insights into the role of well-trained models in DD, particularly under high-storage budget scenarios. We identify a previously overlooked design principle—a positive correlation between model capability and storage budget. Based on this principle, we propose Drop2Sparse, an approach that randomly sparsifies well-trained models to create efficient models for various storage budget scenarios. Drop2Sparse concurrently infuses significant model diversity and regularization effects into DD, outperforming previous state-of-the-art methods by up to 3.8% on CIFAR and 3.6% on ImageNet-subset. Moreover, our method exhibits remarkable cross-architecture generalization and achieves promising results even under challenging scenarios, such as using an extremely reduced model pool or highly accelerated training.},
  keywords={Training;Synthetic data;Accuracy;Image coding;Computational modeling;Integrated circuit modeling;Runtime;Circuits and systems;Buildings;Adaptation models;Dataset Compression;Dataset Distillation;Gradient Matching;Model Sparsification},
  doi={10.1109/TCSVT.2025.3552047},
  ISSN={1558-2205},
  month={}
}

@INBOOK{10897112,
  author={Islam, Mohammad Rubyet},
  booktitle={Generative AI, Cybersecurity, and Ethics}, 
  title={Cybersecurity: Understanding the Digital Fortress}, 
  year={2025},
  volume={},
  number={},
  pages={17-46},
  abstract={Summary <p>Cybersecurity is vital in safeguarding computers, networks, programs, and data against unauthorized access and damage. As digital systems become increasingly integral to modern life, cybersecurity ensures the protection of sensitive information and maintains operational continuity. This chapter explores the fundamental types of cybersecurity, including network security, application security, information security, and operational security. It dives into the significant financial impact of cybercrime globally and regionally, highlighting the unique challenges faced by different industries such as financial services, health care, government, e&#x2010;commerce, and critical infrastructure. The chapter also examines the role of artificial intelligence (AI) and generative AI (GenAI) in enhancing cybersecurity measures, addressing ethical considerations, and navigating the global regulatory landscape to fortify digital defenses.</p>},
  keywords={Security;Firewalls (computing);Computer crime;Training;Structured Query Language;Encryption;Regulation;Personnel;Network security;NIST},
  doi={10.1002/9781394279326.ch2},
  ISSN={},
  publisher={Wiley},
  isbn={9781394279319},
  url={https://ieeexplore.ieee.org/document/10897112}
}

@ARTICLE{10453556,
  author={Otsubo, Yuhei and Otsuka, Akira and Mimura, Mamoru},
  journal={IEEE Access}, 
  title={Compiler Provenance Recovery for Multi-CPU Architectures Using a Centrifuge Mechanism}, 
  year={2024},
  volume={12},
  number={},
  pages={34477-34488},
  abstract={Bit-stream recognition (BSR) has a wide range of applications, including forensic investigations, detecting copyright infringement, and analyzing malware. In order to analyze file fragments recovered by digital forensics, it is necessary to use a BSR method that can accurately classify classes while addressing various domains without preprocessing the raw input bitstream. For example, it is important to note that in the case of compiler provenance recovery, a type of BSR, the same bit sequence can have different meanings for different CPU architectures. As a result, traditional methods that rely heavily on disassembly tools, such as IDA Pro, may have limited in applicaballity scope to programs designed for specific CPU architecture. To address the aforementioned limitation, we proposed a novel learning method. Our method involves the upstream layers (sub-net) capturing global features and instructing the downstream layers (main-net) to shift focus, even when a portion of the input bit-stream has identical values. Through our experiments, we utilized a model that was less than 1/300 the size of the state-of-the-art model. Despite its smaller size, our method achieved the highest classification performance of 99.54 on a multi-CPU architecture, outperforming existing methods.},
  keywords={Transfer learning;Vectors;Computer architecture;Task analysis;Optimization;Mathematical models;Learning systems;Binary sequences;Program processors;Machine learning;Binary analysis;compiler provenance recovery;machine learning;transfer learning;fine-tuning},
  doi={10.1109/ACCESS.2024.3371499},
  ISSN={2169-3536},
  month={}
}

@ARTICLE{10703091,
  author={Yang, Fan and Abedin, Mohammad Zoynul and Qiao, Yanan and Ye, Lvyang},
  journal={IEEE Transactions on Engineering Management}, 
  title={Toward Trustworthy Governance of AI-Generated Content (AIGC): A Blockchain-Driven Regulatory Framework for Secure Digital Ecosystems}, 
  year={2024},
  volume={71},
  number={},
  pages={14945-14962},
  abstract={Digital platforms are experiencing a growing presence of generative artificial intelligence (AI) content, raising concerns due to the prevalence of misinformation that disrupts market integrity. Consequently, the development of effective regulatory measures for overseeing generative AI content becomes imperative. This necessitates the establishment of mechanisms to detect and filter out inaccuracies, ensuring compliance with regulatory requirements. In addition, collaboration among experts, regulators, and AI developers is essential to encourage responsible AI deployment on digital platforms. Successful governance hinges on principles of transparency, accountability, and proactive risk management to navigate the evolving generative AI on digital platforms. Therefore, in order to address the security issues currently faced by artificial intelligence generated content (AIGC), this article first proposes a method of efficient cache mechanism for AIGC content. The secure method of determining the identity of AIGC content owners is proposed based on blockchain technology. Subsequently, it suggests mechanisms for access control and data encryption for generated content within a blockchain environment. Finally, it presents an efficient data supervision mechanism tailored to the AIGC environment. The methods outlined in this article aim to enhance security from three perspectives: protection of content creators' identities, safeguarding data security, and ensuring effective data supervision within the AIGC framework. The experimental results further confirm that our proposed method not only ensures the security of the AIGC framework but also provides an efficient data analysis and supervision solution for digital platforms.},
  keywords={Security;Generative AI;Artificial intelligence;Regulation;Data privacy;Blockchains;Engineering management;Data security;Data models;Reliability;Artificial intelligence generated content (AIGC) regulation;blockchain governance;consensus mechanism;data security;data traceability},
  doi={10.1109/TEM.2024.3472292},
  ISSN={1558-0040},
  month={}
}

@BOOK{10460884,
  author={Ozdemir, Sinan},
  booktitle={Principles of Data Science: A beginner's guide to essential math and coding skills for data fluency and machine learning},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Transform your data into insights with must-know techniques and mathematical concepts to unravel the secrets hidden within your dataKey FeaturesLearn practical data science combined with data theory to gain maximum insights from dataDiscover methods for deploying actionable machine learning pipelines while mitigating biases in data and modelsExplore actionable case studies to put your new skills to use immediatelyPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionPrinciples of Data Science bridges mathematics, programming, and business analysis, empowering you to confidently pose and address complex data questions and construct effective machine learning pipelines. This book will equip you with the tools to transform abstract concepts and raw statistics into actionable insights. Starting with cleaning and preparation, you’ll explore effective data mining strategies and techniques before moving on to building a holistic picture of how every piece of the data science puzzle fits together. Throughout the book, you’ll discover statistical models with which you can control and navigate even the densest or the sparsest of datasets and learn how to create powerful visualizations that communicate the stories hidden in your data. With a focus on application, this edition covers advanced transfer learning and pre-trained models for NLP and vision tasks. You’ll get to grips with advanced techniques for mitigating algorithmic bias in data as well as models and addressing model and data drift. Finally, you’ll explore medium-level data governance, including data provenance, privacy, and deletion request handling. By the end of this data science book, you'll have learned the fundamentals of computational mathematics and statistics, all while navigating the intricacies of modern ML and large pre-trained models like GPT and BERT.What you will learnMaster the fundamentals steps of data science through practical examplesBridge the gap between math and programming using advanced statistics and MLHarness probability, calculus, and models for effective data controlExplore transformative modern ML with large language modelsEvaluate ML success with impactful metrics and MLOpsCreate compelling visuals that convey actionable insightsQuantify and mitigate biases in data and ML modelsWho this book is forIf you are an aspiring novice data scientist eager to expand your knowledge, this book is for you. Whether you have basic math skills and want to apply them in the field of data science, or you excel in programming but lack the necessary mathematical foundations, you’ll find this book useful. Familiarity with Python programming will further enhance your learning experience.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781837636006},
  url={https://ieeexplore.ieee.org/document/10460884}
}

@INPROCEEDINGS{10765104,
  author={Wu, Liangxuan and Zhao, Yanjie and Wang, Chao and Liu, Tianming and Wang, Haoyu},
  booktitle={2024 39th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW)}, 
  title={A First Look at LLM-powered Smartphones}, 
  year={2024},
  volume={},
  number={},
  pages={208-217},
  abstract={The integration of Large Language Models (LLMs) into edge devices such as smartphones represents a significant leap in mobile technology, promising enhanced user experiences and novel functionalities. This paper presents a first look at LLM-powered smartphones, addressing four key aspects: the current market landscape, core functions enabled by integrated LLMs, potential security risks, and user perceptions. The findings reveal a rapidly evolving market with major manufacturers competing to integrate LLMs, innovative features that improve user interaction, significant security challenges, and mixed user perceptions that balance enthusiasm for new capabilities with privacy concerns. This study contributes to understanding LLM integration in mobile devices and its implications for users, manufacturers, and the broader technological landscape.},
  keywords={Industries;Privacy;Technological innovation;Ethics;Large language models;Conferences;User experience;Security;Smart phones;Software engineering},
  doi={},
  ISSN={2151-0849},
  month={Oct}
}

@INPROCEEDINGS{10577842,
  author={Chekira, Chaimae and Fadili, Hakim El and Lakhliai, Zakia},
  booktitle={2024 IEEE 12th International Symposium on Signal, Image, Video and Communications (ISIVC)}, 
  title={Medical Image Watermarking in Machine Learning Environments: A review}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Ensuring healthcare data protection is becoming necessary, given the vast current attempts of data unauthorized manipulation via the Internet. Hence, this paper aims to present a comprehensive overview of Medical Image Watermarking using advanced Machine Learning approaches. Our work was carried out by analyzing 16 deeply selected articles from well-known digital libraries according to specified watermarking characteristics. Research results are presented and discussed, and recommendations are made for further exploration.},
  keywords={Reviews;Data protection;Watermarking;Machine learning;Medical services;Libraries;Internet;Medical Image Watermarking;Optimization;Machine Learning;Transform domain},
  doi={10.1109/ISIVC61350.2024.10577842},
  ISSN={2832-8337},
  month={May}
}

@BOOK{10769315,
  author={Świdziński, Rafał and Kushnir, Alexander},
  booktitle={Modern CMake for C++: Effortlessly build cutting-edge C++ code and deliver high-quality solutions},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Gain proficiency in CMake and unlock the complete potential of C++ to develop exceptional projects Purchase of the print or Kindle book includes a free eBook in the PDF formatKey FeaturesGet to grips with CMake and take your C++ development skills to enterprise standardsUse hands-on exercises and self-assessment questions to lock-in your learningUnderstand how to build in an array of quality checks and tests for robust codeBook DescriptionModern CMake for C++ isn't just another reference book, or a repackaging of the documentation, but a blueprint to bridging the gap between learning C++ and being able to use it in a professional setting. It's an end-to-end guide to the automation of complex tasks, including building, testing, and packaging software. This second edition is significantly rewritten, restructured and refreshed with latest additions to CMake, such as support of C++20 Modules. In this book, you'll not only learn how to use the CMake language in CMake projects but also discover how to make those projects maintainable, elegant, and clean. As you progress, you'll dive into the structure of source directories, building targets, and packages, all while learning how to compile and link executables and libraries. You'll also gain a deeper understanding of how those processes work and how to optimize builds in CMake for the best results. You'll discover how to use external dependencies in your project – third-party libraries, testing frameworks, program analysis tools, and documentation generators. Finally, you'll gain profi ciency in exporting, installing, and packaging for internal and external purposes. By the end of this book, you'll be able to use CMake confi dently at a professional level.What you will learnUnderstand best practices to build ++ codeGain practical knowledge of the CMake languageGuarantee code quality with tests and static and dynamic analysisDiscover how to manage, discover, download, and link dependencies with CMakeBuild solutions that can be reused and maintained in the long termUnderstand how to optimize build artifacts and the build processProgram modern CMake and manage your build processesAcquire expertise in complex subjects such as CMake presetsWho this book is forThe book is for build engineers and software developers with knowledge of C/C++ programming who are looking to learn CMake to automate the process of building small and large software solutions. If you’re just getting started with CMake, a long-time GNU Make user, or simply looking to brush up on the latest best practices, this book is for you.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781805123361},
  url={https://ieeexplore.ieee.org/document/10769315}
}

@ARTICLE{10772463,
  author={Ocal, Ayse},
  journal={IEEE Access}, 
  title={Perceptions of the Future of Artificial Intelligence on Social Media: A Topic Modeling and Sentiment Analysis Approach}, 
  year={2024},
  volume={12},
  number={},
  pages={182386-182409},
  abstract={Today’s AI technology has various applications in many fields, thus creating opportunities to improve different aspects of daily life and optimize business operations. However, there are also societal expectations and concerns regarding AI and its future impacts. Investigating such societal opinions and feelings is essential for social acceptance, further development and distribution of such technology, regulation, and adaptation to changes and policies. Despite this situation, such an exploration has not been sufficiently conducted in the existing literature and the most appropriate methods for such an exploration have not been sufficiently investigated. To contribute to addressing this limitation in literature, this study applies topic modeling and sentiment analysis approaches to investigate societal opinions and feelings about the future of AI on social media, which includes conversations from various segments of society. A corpus consisting of 16,611 comments and 998 unique Reddit post titles was analyzed with a customized BERTopic model for topic modeling and a BERT sentiment classification model. This study highlights the significant advantages of using BERTopic and BERT models in analyzing a large sample of social media discussions. The results of this study can help realize the potential of text analytics methods through transformer-based language models to derive empirical findings from large-scale data samples.},
  keywords={Analytical models;Artificial intelligence;Social networking (online);Sentiment analysis;Data models;Computational modeling;Surveys;Interviews;Encoding;Content management;Artificial intelligence;BERT;BERTopic;sentiment analysis;topic modeling},
  doi={10.1109/ACCESS.2024.3510526},
  ISSN={2169-3536},
  month={}
}

@ARTICLE{10930890,
  author={Ren, Chao and Yu, Han and Peng, Hongyi and Tang, Xiaoli and Zhao, Bo and Yi, Liping and Tan, Alysa Ziying and Gao, Yulan and Li, Anran and Li, Xiaoxiao and Li, Zengxiang and Yang, Qiang},
  journal={IEEE Communications Surveys & Tutorials}, 
  title={Advances and Open Challenges in Federated Foundation Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={The integration of Foundation Models (FMs) with Federated Learning (FL) presents a transformative paradigm in Artificial Intelligence (AI). This integration offers enhanced capabilities, while addressing concerns of privacy, data decentralization and computational efficiency. This paper provides a comprehensive survey of the emerging field of Federated Foundation Models (FedFM), elucidating their synergistic relationship and exploring novel methodologies, challenges, and future directions that the FL research field needs to focus on in order to thrive in the age of FMs. A systematic multi-tiered taxonomy is proposed, categorizing existing FedFM approaches for model training, aggregation, trustworthiness, and incentivization. Key challenges, including how to enable FL to deal with high complexity of computational demands, privacy considerations, contribution evaluation, and communication efficiency, are thoroughly discussed. Moreover, this paper explores the intricate challenges of communication, scalability and security inherent in training/fine-tuning FMs via FL. It highlights the potential of quantum computing to revolutionize the processes of training, inference, optimization and security. This survey also introduces the implementation requirement of FedFM and some practical FedFM applications. It highlights lessons learned with a clear understanding of our findings for FedFM. Finally, this survey not only provides insights into the current state and challenges of FedFM, but also offers a blueprint for future research directions, emphasizing the need for developing trustworthy solutions. It serves as a foundational guide for researchers and practitioners interested in contributing to this interdisciplinary and rapidly advancing field.},
  keywords={Frequency modulation;Surveys;Training;Artificial intelligence;Adaptation models;Computational modeling;Foundation models;Data privacy;Reviews;Security;Federated learning;foundation models;federated foundation models;large language models;efficient training/aggregation;trustworthiness;incentivization;evaluation;quantum computing},
  doi={10.1109/COMST.2025.3552524},
  ISSN={1553-877X},
  month={}
}

@ARTICLE{10947002,
  author={Tiwari, Abhinav and Farag, Hany E. Z.},
  journal={IEEE Access}, 
  title={Responsible AI Framework for Autonomous Vehicles: Addressing Bias and Fairness Risks}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Autonomous Vehicles (AVs) hold immense potential to revolutionize transportation, yet their deployment raises significant concerns regarding safety, security, and ethical considerations. Furthermore, the increased use of automation, edge computing, and Artificial Intelligence (AI), fueled by generative AI technology, has increasingly elevated the risks of AI. Most of the existing research only covers ethical components and lacks the breadth of Responsible AI (RAI), while some have presented components such as justice and solidarity but do not provide an approach or mechanism to implement those in an AI-based system. This paper addresses these gaps by proposing a comprehensive RAI framework for AVs with four key contributions. First, it provides an in-depth analysis of AI risks in AVs, encompassing safety, security, ethical, and legal domains, offering a structured classification to guide developers and regulators. Second, it introduces a holistic RAI framework that spans the AI lifecycle, identifying and mitigating risks at each AV system development and deployment stage. Third, the paper focuses on bias and fairness within AV systems, outlining precise techniques for bias detection and mitigation across data collection, algorithm design, and real-time decision-making. Lastly, the research presents bias removal simulations using publicly available AV datasets, evaluating mitigation strategies such as synthetic data generation and algorithmic fairness analysis. The proposed framework and simulations provide a practical foundation for integrating RAI principles into AV development, ensuring safer, fairer, and more accountable AI-driven mobility solutions.},
  keywords={Artificial intelligence;Ethics;Safety;Security;Prevention and mitigation;Data privacy;Roads;ISO Standards;Decision making;Synthetic data;Responsible Artificial Intelligence;Ethical Artificial Intelligence;Autonomous Electric Vehicles;Generative Artificial Intelligence;Synthetic Data},
  doi={10.1109/ACCESS.2025.3556781},
  ISSN={2169-3536},
  month={}
}

@ARTICLE{10904905,
  author={Zeng, Pinxian and Zeng, Xinyi and Wang, Yan and Zhou, Luping and Zu, Chen and Wu, Xi and Zhou, Jiliu and Shen, Dinggang},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Multi-modal Long-Short Distance Attention-based Transformer-GAN for PET Reconstruction with Auxiliary MRI}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={To obtain high-quality PET scans while minimizing potential radiation hazards for patients, various GAN-based methods have been developed to reconstruct high-quality standard-count PET (SPET) images from low-count PET (LPET) ones. While recent efforts try to integrate MRI or CT to enhance reconstruction in a multi-modal way, current architectures mainly face two limitations: (1) CNN backbones or simple Transformer bottleneck layers are insufficient for robust semantic understanding, and (2) the identical strategies for multi-modal feature extraction and fusion overlook each modality’s respective importance for the reconstruction task. In this work, we propose the Multi-modal Long-Short Distance Attention-based Transformer-GAN (MLSDA-GAN), a novel network combining 3D transformer and CNN architecture for PET image reconstruction. Specifically, to extract fine-grained features with a small number of parameters, our MLSDA-GAN integrates multi-scale convolution into the embedding part of the transformer. As for our multi-modal design, given the strong correlation between LPET and SPET in structural characteristics, we treat MRI as an auxiliary modality to LPET and achieve effective multi-modal extraction and fusion strategies. These strategies include (1) a PET-specific Self-attention Extraction (PSE) block for comprehensive feature extraction of the primary LPET and (2) a Multi-modality Cross-attention Fusion (MCF) block for effective multi-modal interaction and fusion, enabling us to more efficiently model both long- and short-range relationships in the corresponding feature extraction and fusion processes. Experiments demonstrate superiority of our method quantitatively and qualitatively. Code is available at https://github.com/Aru321/MLSDA-GAN.},
  keywords={Image reconstruction;Feature extraction;Transformers;Magnetic resonance imaging;Three-dimensional displays;Convolutional neural networks;Convolution;Generative adversarial networks;Solid modeling;Positron emission tomography;Attention Mechanism;Feature Extraction and Fusion;Multi-modal PET Reconstruction},
  doi={10.1109/TCSVT.2025.3545911},
  ISSN={1558-2205},
  month={}
}

@ARTICLE{10947580,
  author={Xu, Yifei and Wu, Zaiqiang and Li, Li and Li, Siqi and Li, Wenlong and Li, Mingqi and Rao, Yuan and Deng, Shuiguang},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Hybrid Siamese Masked Autoencoders as Unsupervised Video Summarizer}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Video summarization aims to seek the most important information from a source video while still retaining its primary content. In practical application, unsupervised video summarizers are acknowledged for their flexibility and superiority without requiring annotated data. However, they are looking for the determined rules on how much each frame is essential enough to be selected as a summary. Unlike conventional frame-based scoring methods, we propose a shot-level unsupervised video summarizer termed Hybrid Siamese Masked Autoencoders (H-SMAE) from a higher semantic perspective. Specifically, our method consists of Multi-view Siamese Masked Autoencoders (MV-SMAE) and Shot Diversity Enhancer (SDE). MV-SMAE tries to recover the masked shots from original frame feature and three unmasked shot subsets with elaborate Siamese masked autoencoders. Inspired by the masking idea in MAE, MV-SMAE introduces a Siamese architecture to model prior references to guide the reconstruction of masked shots. Besides, SDE improves the diversity of generated summary by minimizing the repelling loss among selected shots. Afterward, these two modules are fused followed by 0-1 knapsack algorithm to produce a video summary. Experiments on two challenging and diverse datasets demonstrate that our approach outperforms other state-of- the-art unsupervised and weakly-supervised methods, and even generates comparable results with several excellent supervised methods. The source code of H-SMAE is available at https://github.com/wzq0214/H-SMAE.},
  keywords={Feature extraction;Autoencoders;Transformers;Visualization;Semantics;Data mining;Training;Computational modeling;Generative adversarial networks;Computational efficiency;Unsupervised Video Summarizer;Siamese Masked Autoencoder;Shot Diversity Enhancer;Repelling Loss},
  doi={10.1109/TCSVT.2025.3557254},
  ISSN={1558-2205},
  month={}
}

@ARTICLE{7911210,
  author={Petke, Justyna and Haraldsson, Saemundur O. and Harman, Mark and Langdon, William B. and White, David R. and Woodward, John R.},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={Genetic Improvement of Software: A Comprehensive Survey}, 
  year={2018},
  volume={22},
  number={3},
  pages={415-432},
  abstract={Genetic improvement (GI) uses automated search to find improved versions of existing software. We present a comprehensive survey of this nascent field of research with a focus on the core papers in the area published between 1995 and 2015. We identified core publications including empirical studies, 96% of which use evolutionary algorithms (genetic programming in particular). Although we can trace the foundations of GI back to the origins of computer science itself, our analysis reveals a significant upsurge in activity since 2012. GI has resulted in dramatic performance improvements for a diverse set of properties such as execution time, energy and memory consumption, as well as results for fixing and extending existing system functionality. Moreover, we present examples of research work that lies on the boundary between GI and other areas, such as program transformation, approximate computing, and software repair, with the intention of encouraging further exchange of ideas between researchers in these fields.},
  keywords={Genetic programming;Software;Software testing;History;Software engineering;Genetic improvement (GI);survey},
  doi={10.1109/TEVC.2017.2693219},
  ISSN={1941-0026},
  month={June}
}

@ARTICLE{10287345,
  author={Niu, Yanmin and Xue, Han},
  journal={IEEE Access}, 
  title={Exercise Generation and Student Cognitive Ability Research Based on ChatGPT and Rasch Model}, 
  year={2023},
  volume={11},
  number={},
  pages={116695-116705},
  abstract={In the context of generative artificial intelligence (AI), AIGCP (content generation-based AI products), represented by ChatGPT, have attracted extensive attention in the field of education. This study focuses on the discipline of university operating systems and adopts the Rasch model as the theoretical foundation. By combining ChatGPT with existing question banks and using the bidirectional fine-grained table method, it compiles questions that match the corresponding abilities for three different levels of student groups. This aims to explore personalized question matching and student cognitive ability analysis methods to support personalized teaching. The research findings indicate that ChatGPT is capable of matching exercises of similar difficulty under the Rasch model, but its accuracy in generating exercise content is relatively low, and the variety of exercise content is limited. Students’ performance in overall competency requires improvement. This study aims to leverage the combined strengths of ChatGPT and traditional educational assessment methods to introduce an innovative approach to support personalized instruction. It aims to establish the routine utilization of exercise creation by ChatGPT and personalized analysis of student cognitive abilities, thereby better fulfilling the demands of education within the classroom setting.},
  keywords={Computational modeling;Chatbots;Mathematical models;Education;Analytical models;Testing;Operating systems;Generative adversarial networks;Artificial intelligence;Question answering (information retrieval);Generative artificial intelligence;Rasch model;personalized question matching;cognitive ability;operating system exercises},
  doi={10.1109/ACCESS.2023.3325741},
  ISSN={2169-3536},
  month={}
}

@ARTICLE{10876163,
  author={Wu, Gang and Hu, Liang and Hu, Yuxiao and Xiong, Xingbo and Wang, Feng},
  journal={IEEE Internet of Things Journal}, 
  title={LLM4TAP: LLM-Enhanced TAP Rule Recommendation}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Trigger-action programming (TAP) is an Internet of Things (IoT) paradigm that enables non-professional end-users to automate smart devices by formulating rules such as “IF you leave home, THEN turn off lights". As the number of possible rules increases, manually browsing these rules becomes increasingly time-consuming for users. Recently, graph-based recommendation systems have shown promise in automatically suggesting rules, yet they face two issues. First, these studies struggle to identify and differentiate users’ demands (e.g., turning off lights) and intentions (e.g., energy saving). Second, they overlook the issue of sparse user-rule interactions. In this article, we propose LLM4TAP, a large language model (LLM) enhanced TAP rule recommendation framework, to address these issues. Prior to LLM4TAP, a user-rule graph is constructed to represent the interactions between users and rules. Within LLM4TAP, singular value decomposition is first employed to generate an augmented graph, strengthening global structural relationships between users and rules. Next, the reasoning capabilities of LLMs are utilized to infer users’ demands and intentions from the textual descriptions of rules and user-rule interactions, producing representations of these inferred demands and intentions. Finally, a dual representation alignment method is introduced, integrating user demands and intentions derived from LLMs with the global structural information from the augmentation graph within a contrastive learning framework to enhance representation performance. Extensive experiments demonstrate the effectiveness of LLM4TAP, achieving the maximum improvements of 8.96% and 4.72% over the strongest compared methods on the IFTTT and Wyze datasets, respectively.},
  keywords={Internet of Things;Programming;Recommender systems;Contrastive learning;Smart devices;Performance evaluation;Accuracy;Cognition;Automation;Turning;Internet of Things;trigger-action programming;rule recommendation;large language models;contrastive Learning},
  doi={10.1109/JIOT.2025.3532977},
  ISSN={2327-4662},
  month={}
}

@ARTICLE{10705025,
  author={Hosonuma, Eri and Yamazaki, Taku and Miyoshi, Takumi and Taya, Akihito and Nishiyama, Yuuki and Sezaki, Kaoru},
  journal={IEICE Transactions on Communications}, 
  title={Image Generative Semantic Communication with Multi-Modal Similarity Estimation for Resource-Limited Networks}, 
  year={2025},
  volume={E108-B},
  number={3},
  pages={260-273},
  abstract={To reduce network traffic and support environments with limited resources, a method for transmitting images with minimal transmission data is required. Several machine learning-based image compression methods, which compress the data size of images while maintaining their features, have been proposed. However, in certain situations, reconstructing only the semantic information of images at the receiver end may be sufficient. To realize this concept, semantic-information-based communication, called semantic communication, has been proposed, along with an image transmission method using semantic communication. This method transmits only the semantic information of an image, and the receiver reconstructs it using an image-generation model. This method utilizes a single type of semantic information for image reconstruction, but reconstructing images similar to the original image using only this information is challenging. This study proposes a multimodal image transmission method that leverages various types of semantic information for efficient semantic communication. The proposed method extracts multimodal semantic information from an original image and transmits only that to a receiver. Subsequently, the receiver generates multiple images using an image-generation model and selects an output image based on semantic similarity. The receiver must select the result based only on the received features; however, evaluating semantic similarity using conventional metrics is challenging. Therefore, this study explores new metrics to evaluate the similarity between semantic features of images and proposes two scoring procedures for evaluating semantic similarity between images based on multiple semantic features. The results indicate that the proposed procedures can compare semantic similarities, such as position and composition, between the semantic features of the original and generated images.},
  keywords={Semantics;Receivers;Image reconstruction;Feature extraction;Image coding;Image communication;Measurement;Monitoring;Data mining;Transmitters;semantic communication;image generation;image transmission;image captioning;semantic segmentation},
  doi={10.23919/transcom.2024EBP3056},
  ISSN={1745-1345},
  month={March}
}

@ARTICLE{8314138,
  author={Chen, Yu-Chieh and Chang, Hsin-Chi and Chen, Hsin},
  journal={IEEE Access}, 
  title={Two-Dimensional Multiply-Accumulator for Classification of Neural Signals}, 
  year={2018},
  volume={6},
  number={},
  pages={19714-19725},
  abstract={Automatic spike detection and classification have been used for a neuroelectronic interface to reduce data amount or even to interact with neurons in a closed loop. While conventional neuroelectronic interfaces employ voltage-mode circuits to amplify neural signals and convert the signals into binary data, the dynamic range and signal-to-noise ratio of these circuits are directly limited by the supply voltage. To release this constraint, this paper proposes an analog-to-time converter (ATC), which uses positive feedback to convert analog neural signals into a sequence of pulse trains. Custom-designed digital circuits, including two types of time-to-digital converters (TDCs) and a 2-D multiply-accumulator (2-D-MAC), are further proposed for processing such time-mode signals. The ATC is implemented with the standard 0.35-μm CMOS technology and proved able to convert analog voltages into pulse-width-modulated signals with a resolution of 6 bits. The TDCs and 2-D-MAC are realized in FPGA and compared to the standard digital IPs. The comparison indicates that the TDC based on dual counters minimizes area consumption and the other based on delayed clocks minimizes power consumption. The 2-D-MAC further facilitates parallel computation of partial products and allows data to be classified without summing up all partial products. Finally, the application of the proposed time-mode system is demonstrated as classifying neuronal spikes.},
  keywords={Clocks;Field programmable gate arrays;Delays;Signal resolution;Dynamic range;Delay lines;Sorting;Analog-to-time converter (ATC);multiply-accumulate (MAC) operation;time-mode signal processing},
  doi={10.1109/ACCESS.2018.2814625},
  ISSN={2169-3536},
  month={}
}

@ARTICLE{10937768,
  author={Ge, Huilin and Wang, Ze and Liu, Runbang and Qiu, Zhiwen and Xia, Jie and Chen, Ting and Zhu, Hongzi},
  journal={IEEE Internet of Things Journal}, 
  title={Adapting Large Language Models for Smart Contract Defects Detection in The Open Network Blockchain}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Smart contracts on The Open Network (TON) have become vital in IoT applications due to their low latency and high scalability. However, the unique architectural features of TON introduce specialized vulnerabilities that existing tools fail to address comprehensively. In this paper, we propose a novel defect detection framework that combines Large Language Models (LLMs) for automated defect discovery with a locatable call graph for precise and efficient code analysis. Our method identifies four new types of TON-specific defects: Ignore Errors Mode Usage, Premature Acceptance, Pseudo Deletion, and Improper Jetton Refund. Evaluated on 1640 real-world smart contracts written in FunC and Tact, the framework uncovers 669 defects, with an average of one defect every 2.45 code segments. The detection achieves an average F1 score of 99.75% for FunC and 100% for Tact contracts. Additionally, our approach demonstrates lightweight computational overhead, consuming only 12.6MB of memory and achieving a mean response time of 0.05s. These results highlight the accuracy, efficiency, and practicality of our framework for securing TON-based smart contracts in IoT ecosystems.},
  keywords={Defect detection;Blockchains;Smart contracts;Internet of Things;Codes;Accuracy;Detectors;Data mining;Source coding;Flow graphs;TON;FunC;static analysis},
  doi={10.1109/JIOT.2025.3553917},
  ISSN={2327-4662},
  month={}
}

@INPROCEEDINGS{10884256,
  author={Liang, Fei-Yao and Xi, Wu-Dong and Xing, Xing-Xing and Wan, Wei and Wang, Chang-Dong and Chen, Min and Guizani, Mohsen},
  booktitle={2024 IEEE International Conference on Data Mining (ICDM)}, 
  title={Contrastive Learning for Adapting Language Model to Sequential Recommendation}, 
  year={2024},
  volume={},
  number={},
  pages={251-260},
  abstract={With the explosive growth of information, recommendation systems have emerged to alleviate the problem of information overload. In order to improve the performance of recommendation systems, many existing methods introduce Large Language Models to extract textual information from description text. However, Large Language Models are trained on large-scale generic textual data and may face a semantic gap for downstream recommendation tasks. To address the above issues, we propose Contrastive Learning for Adapting Language Model to Sequential Recommendation (CLA-Rec). In CLA-Rec, we first extract text embeddings from description text using Large Language Models and align the text embeddings learned by Large Language Models with the collaborative information through contrastive learning to obtain high-quality item representations. Through semantic alignment, we bridge the semantic gap between Large Language Models and the recommendation task. To map textual information and collaborative information into user representations, we utilize a Transformer model to learn user representations and capture user preferences by combining the semantically aligned item representations. Extensive experiments on three public datasets demonstrate that our method outperforms state-of-the-art approaches on multiple evaluation metrics, illustrating the effectiveness of the CLA-Rec model in adapting Large Language Models to recommendation tasks.},
  keywords={Measurement;Adaptation models;Large language models;Semantics;Collaboration;Contrastive learning;Transformers;Data models;Data mining;Recommender systems;sequential recommendation;large language model;contrastive learning},
  doi={10.1109/ICDM59182.2024.00032},
  ISSN={2374-8486},
  month={Dec}
}

@ARTICLE{10897676,
  author={Fu, Qian and Liu, Linlin and Hou, Fei and He, Ying},
  journal={Computational Visual Media}, 
  title={Hierarchical vectorization for facial images}, 
  year={2024},
  volume={10},
  number={1},
  pages={97-118},
  abstract={The explosive growth of social media means portrait editing and retouching are in high demand. While portraits are commonly captured and stored as raster images, editing raster images is non-trivial and requires the user to be highly skilled. Aiming at developing intuitive and easy-to-use portrait editing tools, we propose a novel vectorization method that can automatically convert raster images into a 3-tier hierarchical representation. The base layer consists of a set of sparse diffusion curves (DCs) which characterize salient geometric features and low-frequency colors, providing a means for semantic color transfer and facial expression editing. The middle level encodes specular highlights and shadows as large, editable Poisson regions (PRs) and allows the user to directly adjust illumination by tuning the strength and changing the shapes of PRs. The top level contains two types of pixel-sized PRs for high-frequency residuals and fine details such as pimples and pigmentation. We train a deep generative model that can produce high-frequency residuals automatically. Thanks to the inherent meaning in vector primitives, editing portraits becomes easy and intuitive. In particular, our method supports color transfer, facial expression editing, highlight and shadow editing, and automatic retouching. To quantitatively evaluate the results, we extend the commonly used FLIP metric (which measures color and feature differences between two images) to consider illumination. The new metric, illumination-sensitive FLIP, can effectively capture salient changes in color transfer results, and is more consistent with human perception than FLIP and other quality measures for portrait images. We evaluate our method on the FFHQR dataset and show it to be effective for common portrait editing tasks, such as retouching, light editing, color transfer, and expression editing.},
  keywords={Image color analysis;Vectors;Lighting;Laplace equations;Geometry;Faces;Videos;Shape;Image edge detection;Feature extraction;face editing;vectorization;Poisson editing;color transfer;illumination editing;expression editing},
  doi={10.1007/s41095-022-0314-4},
  ISSN={2096-0662},
  month={Feb}
}

@ARTICLE{10942340,
  author={Marian Pasca, Emil and Delinschi, Daniela and Erdei, Rudolf and Matei, Oliviu},
  journal={IEEE Access}, 
  title={LLM-Driven, Self-Improving Framework for Security Test Automation: Leveraging Karate DSL for Augmented API Resilience}, 
  year={2025},
  volume={13},
  number={},
  pages={56861-56886},
  abstract={Modern software architectures heavily rely on APIs, yet face significant security challenges, particularly with Broken Object Level Authorization (BOLA) vulnerabilities, which remain the most critical API security risk according to OWASP. This paper introduces Karate-BOLA-Guard, an innovative framework leveraging Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) techniques to automate security-focused test case generation for APIs. Our approach integrates vector databases for context retrieval, multiple LLM models for test generation, and observability tools for process monitoring. Initial experiments were carried out on three deliberately vulnerable APIs (VAmPI, Crapi, and OWASP Juice Shop), with subsequent validation on fifteen additional production APIs spanning diverse domains including social media, version control systems, financial services, and transportation services. Our evaluation metrics show Llama 3 8B achieving consistent performance (Accuracy: 3.1-3.4, Interoperability: 3.7-4.3) with an average processing time of 143.76 seconds on GPU. Performance analysis revealed significant GPU acceleration benefits, with 20-25x improvement over CPU processing times. Smaller models demonstrated efficient processing, with Phi-3 Mini averaging 69.58 seconds and Mistral 72.14 seconds, while maintaining acceptable accuracy scores. Token utilization patterns showed Llama 3 8B using an average of 36,591 tokens per session, compared to Mistral’s 25,225 and Phi-3 Mini’s 31,007. Our framework’s effectiveness varied across APIs, with notably strong performance in complex platforms (Instagram: A = 4.3, I = 4.4) while maintaining consistent functionality in simpler implementations (VAmPI: A = 3.6, I = 4.3). The iterative refinement process, evaluated through comprehensive metrics including Accuracy (A), Complexity (C), and Interoperability (I), represents a significant advancement in automated API security testing, offering an efficient, accurate, and adaptable approach to detecting BOLA vulnerabilities across diverse API architectures.},
  keywords={Security;Testing;Retrieval augmented generation;Test pattern generators;Application programming interfaces;Accuracy;Software testing;Automation;Systematics;Computer architecture;API security;automation testing tools;cybersecurity;restful API;software testing},
  doi={10.1109/ACCESS.2025.3554960},
  ISSN={2169-3536},
  month={}
}

@ARTICLE{8425302,
  author={Chang, Shan and Li, Chao},
  journal={IEEE Network}, 
  title={Privacy in Neural Network Learning: Threats and Countermeasures}, 
  year={2018},
  volume={32},
  number={4},
  pages={61-67},
  abstract={Algorithmic breakthroughs, the feasibility of collecting huge amount of data, and increasing computational power, contribute to the remarkable achievements of NNs. In particular, since Deep Neural Network (DNN) learning presents astonishing results in speech and image recognition, the amount of sophisticated applications based on it has exploded. However, the increasing number of instances of privacy leakage has been reported, and the corresponding severe consequences have caused great worry in this area. In this article, we focus on privacy issues in NN learning. First, we identify the privacy threats during NN training, and present privacy-preserving training schemes in terms of using centralized and distributed approaches. Second, we consider the privacy of prediction requests, and discuss the privacy-preserving protocols for NN prediction. We also analyze the privacy vulnerabilities of trained models. Three types of attacks on private information embedded in trained NN models are discussed, and a differential privacy-based solution is introduced.},
  keywords={Training;Artificial neural networks;Privacy;Predictive models;Servers;Computational modeling},
  doi={10.1109/MNET.2018.1700447},
  ISSN={1558-156X},
  month={July}
}

@INPROCEEDINGS{9684603,
  author={Jaber, Aws Naser and Fritsch, Lothar},
  booktitle={2021 25th International Computer Science and Engineering Conference (ICSEC)}, 
  title={COVID-19 and Global Increases in Cybersecurity Attacks: Review of Possible Adverse Artificial Intelligence Attacks}, 
  year={2021},
  volume={},
  number={},
  pages={434-442},
  abstract={The World Health Organization's (WHO) coronavirus disease dashboard has recorded over 207 million confirmed infections and over 4 million deaths. There has been an increasing vulnerability in cybersecurity amongst businesses, gov- ernments and individuals worldwide because the COVID-19 pandemic has led to additional online activities. Accordingly, many people have turned to online work whilst the world is locked down. Thus, warnings have been issued by cybersecurity agencies that the number of cyber threat actors is increasing, and that they are improving in terms of stealing money, personal information and intellectual property. Opportunities for cybercrimes have increased, and COVID-19 is an effective lure. New methods for adverse artificial intelligence (AI)-empowered cyberattacks have been developed, or will be in the near future, using various weaponisations of AI under the COVID-19 umbrella. For this reason, this study reviewed and summarised how and when the most recent cyberattack trends can successfully exploit COVID-19 as a context for attack. Additionally, a summary of the state of knowledge of adverse AI is given, and its potential within the COVID-themed security threats, including defenses, is discussed.},
  keywords={COVID-19;Uniform resource locators;Pandemics;Phishing;Weapons;Malware;Servers;computer security;artificial intelligence;cyber-attack;COVID-19},
  doi={10.1109/ICSEC53205.2021.9684603},
  ISSN={},
  month={Nov}
}

@INPROCEEDINGS{10569691,
  author={Jovanić, Mislav and Čarapina, Mia},
  booktitle={2024 47th MIPRO ICT and Electronics Convention (MIPRO)}, 
  title={Application of Artificial Intelligence in the Creation of Web Content}, 
  year={2024},
  volume={},
  number={},
  pages={2063-2068},
  abstract={This paper delves into the application of artificial intelligence (AI) technology in the creation of web content, with a special emphasis on A/B testing as an optimization strategy. It analyses the way technical tools like Prisma, Next.js, Tailwind, and Clickhouse contribute to the development and analysis of web applications. The importance of Large Language Models (LLM) in developing interactive interfaces and providing application performance insights is also assessed, with a focus on user behavior analysis. The paper explores how AI, specifically tools like GPT-3.5-turbo, might enhance the process of creating content for the web. The usefulness and potential of AI in generating text are looked into in the context of the continued development of digital communication strategies. Methods such as A/B testing and performance monitoring have significance in evaluating the effectiveness of AI-generated content communicating with users. The work aims to provide an understanding of how the integration of AI and present-day technologies may increase user efficiency and satisfaction in web application development. The paper demonstrates the potential and constraints of applying AI in digital communication through theoretical and empirical research, emphasizing its relevance in shaping the future of web content.},
  keywords={Productivity;Ethics;Law;Transforms;Writing;Digital communication;Artificial intelligence;artificial intelligence;content generation;web application development;A/B testing;LLM},
  doi={10.1109/MIPRO60963.2024.10569691},
  ISSN={2623-8764},
  month={May}
}

@INPROCEEDINGS{10548213,
  author={Liang, Jenny T. and Yang, Chenyang and Myers, Brad A.},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE)}, 
  title={A Large-Scale Survey on the Usability of AI Programming Assistants: Successes and Challenges}, 
  year={2024},
  volume={},
  number={},
  pages={616-628},
  abstract={The software engineering community recently has witnessed widespread deployment of AI programming assistants, such as GitHub Copilot. However, in practice, developers do not accept AI programming assistants' initial suggestions at a high frequency. This leaves a number of open questions related to the usability of these tools. To understand developers' practices while using these tools and the important usability challenges they face, we administered a survey to a large population of developers and received responses from a diverse set of 410 developers. Through a mix of qualitative and quantitative analyses, we found that developers are most motivated to use AI programming assistants because they help developers reduce key-strokes, finish programming tasks quickly, and recall syntax, but resonate less with using them to help brainstorm potential solutions. We also found the most important reasons why developers do not use these tools are because these tools do not output code that addresses certain functional or non-functional requirements and because developers have trouble controlling the tool to generate the desired output. Our findings have implications for both creators and users of AI programming assistants, such as designing minimal cognitive effort interactions with these tools to reduce distractions for users while they are programming.},
  keywords={Surveys;Programming;Syntactics;Software;Artificial intelligence;Usability;Task analysis;Software and its engineering → Software notations and tools;• Human-centered computing → Empirical studies in HCI;• Computing methodologies → Natural language processing;AI programming assistants;usability study},
  doi={},
  ISSN={1558-1225},
  month={April}
}

@ARTICLE{10722034,
  author={Singh, Gopendra Vikram and Mamta and Verma, Atul and Ekbal, Asif},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={MultiSEAO-Mix: A Multimodal Multitask Framework for Sentiment, Emotion, Support, and Offensive Analysis in Code-Mixed Setting}, 
  year={2025},
  volume={12},
  number={1},
  pages={101-112},
  abstract={Social media platforms have become an open door for users to share their views, resulting in a growing trend of offensive content being shared on social media. Detecting and addressing offensive content is crucial due to its significant impact on society. Although there has been extensive research on the detection of offensive content in the English language, there is a notable gap in detecting offensive content in multimodal settings involving code-mixed languages. In this article, we propose a large scale multimodal code-mixed dataset for Hinglish (Hindi+English) MultiSEAO-Mix focusing on women and children. The MultiSEAO-Mix is annotated with offensiveness, sentiment, emotion, and their respective intensities. Additionally, it is also annotated with author support. A multimodal, multitask framework is proposed that considers offensive detection, intensity prediction, and author support as the primary tasks and improves their performance using sentiment, emotion, and corresponding intensities as the auxiliary tasks. Further, we propose a fusion technique that captures the enhanced multimodal representation to improve the performance of our model. Experimental results demonstrate that the proposed multitask framework improves the model performance by more than 4.5 points compared to multitask system without sentiment and emotion as the auxiliary tasks.},
  keywords={Social networking (online);Sentiment analysis;Annotations;Media;Hate speech;Feature extraction;Visualization;Vectors;Transformers;Stars;Code-mixing;emotion;multitask;multimodal;offensive;sentiment},
  doi={10.1109/TCSS.2024.3430821},
  ISSN={2329-924X},
  month={Feb}
}

@INPROCEEDINGS{10657140,
  author={Asnani, Vishal and Collomosse, John and Bui, Tu and Liu, Xiaoming and Agarwal, Shruti},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={ProMark: Proactive Diffusion Watermarking for Causal Attribution}, 
  year={2024},
  volume={},
  number={},
  pages={10802-10811},
  abstract={Generative AI (GenAI) is transforming creative work-flows through the capability to synthesize and manipulate images via high-level prompts. Yet creatives are not well supported to receive recognition or reward for the use of their content in GenAI training. To this end, we propose ProMark, a causal attribution technique to attribute a synthetically generated image to its training data concepts like objects, motifs, templates, artists, or styles. The concept information is proactively embedded into the input training images using imperceptible watermarks, and the diffusion models (unconditional or conditional) are trained to retain the corresponding watermarks in generated images. We show that we can embed as many as 216 unique water-marks into the training data, and each training image can contain more than one watermark. ProMark can maintain image quality whilst outperforming correlation-based attribution. Finally, several qualitative examples are presented, providing the confidence that the presence of the watermark conveys a causative relationship between training data and synthetic images.},
  keywords={Training;Image quality;Accuracy;PSNR;Sensitivity;Generative AI;Training data;watermarking;proactive learning;causal attribution;concept attribution;GenAI defense},
  doi={10.1109/CVPR52733.2024.01027},
  ISSN={2575-7075},
  month={June}
}

@ARTICLE{10121428,
  author={Babar, Mohammad Fakhruddin and Hasan, Monowar},
  journal={IEEE Access}, 
  title={Trusted Deep Neural Execution—A Survey}, 
  year={2023},
  volume={11},
  number={},
  pages={45736-45748},
  abstract={The growing use of deep neural networks (DNNs) in various applications has raised concerns about the security and privacy of model parameters and runtime execution. To address these concerns, researchers have proposed using trusted execution environments (TEEs) to build trustworthy neural network execution. This paper comprehensively surveys the literature on trusted neural networks, viz., answering how to efficiently execute neural models inside trusted enclaves. We review the various TEE architectures and techniques employed to achieve secure neural network execution and provide a classification of existing work. Additionally, we discuss the challenges and present a few open issues. We intend that this review will assist researchers and practitioners in understanding the state-of-the-art and identifying research problems.},
  keywords={Neural networks;Program processors;Codes;Surveys;Computational modeling;Data models;Trust computing;Neural network;DNN;trusted execution;TEE;TrustZone;SGX},
  doi={10.1109/ACCESS.2023.3274190},
  ISSN={2169-3536},
  month={}
}

@BOOK{10745358,
  author={Raschka, Sebastian},
  booktitle={Build a Large Language Model (From Scratch)},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Learn how to create, train, and tweak large language models (LLMs) by building one from the ground up! In Build a Large Language Model (from Scratch) bestselling author Sebastian Raschka guides you step by step through creating your own LLM. Each stage is explained with clear text, diagrams, and examples. You’ll go from the initial design and creation, to pretraining on a general corpus, and on to fine-tuning for specific tasks. Build a Large Language Model (from Scratch) teaches you how to:  Plan and code all the parts of an LLM Prepare a dataset suitable for LLM training Fine-tune LLMs for text classification and with your own data Use human feedback to ensure your LLM follows instructions Load pretrained weights into an LLM  Build a Large Language Model (from Scratch) takes you inside the AI black box to tinker with the internal systems that power generative AI. As you work through each key stage of LLM creation, you’ll develop an in-depth understanding of how LLMs work, their limitations, and their customization methods. Your LLM can be developed on an ordinary laptop, and used as your own personal assistant.},
  keywords={GPT;LLM;personal assistant;text classification;chatbot;train;pretrained weights;Python;fine-tune;human feedback;embeddings;attention mechanisms;generative;AI;Top-k},
  doi={},
  ISSN={},
  publisher={Manning},
  isbn={9781633437166},
  url={https://ieeexplore.ieee.org/document/10745358}
}

@INPROCEEDINGS{10589960,
  author={Dong, Bingyu and Bai, Jie and Xu, Tao and Zhou, Yun},
  booktitle={2024 6th International Conference on Computer Science and Technologies in Education (CSTE)}, 
  title={Large Language Models in Education: A Systematic Review}, 
  year={2024},
  volume={},
  number={},
  pages={131-134},
  abstract={Large Language Models (LLMs) refer to a type of generative artificial intelligence model that produces responses to natural language input. The purpose of this study is to analyze the current application status of LLMs in the field of education through a systematic review of the literature. Data were sourced from three databases: Web of Science, ERIC, and Google Scholar. The study includes 94 documents, analyzed from both qualitative and quantitative perspectives. The results show that large language models have great potential in the field of education, specifically in generating medical content, serving as an English learning assistant, assisting academic research, and evaluating the quality of tests, etc. However, there are still potential dangers such as hindering the development of critical thinking, creating academic integrity crises, and ethical and moral challenges. These findings showed the current application status of LLMs in education, laying the groundwork to inspire future research.},
  keywords={Ethics;Systematics;Reviews;Generative AI;Large language models;Education;Natural languages;large language model;ChatGPT;artificial intelligence;education;systematic review},
  doi={10.1109/CSTE62025.2024.00031},
  ISSN={},
  month={April}
}

@INPROCEEDINGS{10771097,
  author={Lee, Seongmin and Hoover, Benjamin and Strobelt, Hendrik and Wang, Zijie J. and Peng, ShengYun and Wright, Austin and Li, Kevin and Park, Haekyu and Yang, Haoyang and Chau, Duen Horng Polo},
  booktitle={2024 IEEE Visualization and Visual Analytics (VIS)}, 
  title={Diffusion Explainer: Visual Explanation for Text-to-image Stable Diffusion}, 
  year={2024},
  volume={},
  number={},
  pages={96-100},
  abstract={Diffusion-based generative models’ impressive ability to create convincing images has garnered global attention. However, their complex structures and operations often pose challenges for non-experts to grasp. We present Diffusion Explainer, the first interactive visualization tool that explains how Stable Diffusion transforms text prompts into images. Diffusion Explainer tightly integrates a visual overview of Stable Diffusion’s complex structure with explanations of the underlying operations. By comparing image generation of prompt variants, users can discover the impact of keyword changes on image generation. A 56-participant user study demonstrates that Diffusion Explainer offers substantial learning benefits to non-experts. Our tool has been used by over 10,300 users from 124 countries at https://poloclub.github.io/diffusion-explainer/.},
  keywords={Visualization;Image synthesis;Visual analytics;Blogs;Text to image;Transforms;Animation;Generative AI;Machine Learning;Interactive visualization;Text-to-image generative AI;Artificial Intelligence;User study},
  doi={10.1109/VIS55277.2024.00027},
  ISSN={2771-9553},
  month={Oct}
}

@INPROCEEDINGS{10370117,
  author={Sundaram, Srinidhi and Somasundaram, Kamalakkannan and Jothilakshmi, S. and Jayaraman, Sasikala and Dhanalakshmi, P.},
  booktitle={2023 International Conference on Sustainable Communication Networks and Application (ICSCNA)}, 
  title={Modelling of Firefly Algorithm with Densely Connected Networks for Near-Duplicate Image Detection System}, 
  year={2023},
  volume={},
  number={},
  pages={66-72},
  abstract={Near-duplicate image detection is the way of detecting and flagging images that are highly similar to each other but not identical. It is a crucial task in different fields, including search engines, content management, and copyright enforcement, as it helps in content and organization de duplication. To achieve this, techniques and algorithms are employed that calculate similarity metrics, compare features, or analyze image content to define the degree of resemblance between images. Near-duplicate image detection can include approaches such as feature extraction, machine learning, and perceptual hashing to effectively manage and identify similar images in large datasets, which offer benefits in content retrieval and storage optimization. Therefore, this study presents a new firefly algorithm with deep learning-based near-duplicate image detection (FFADL-NDID) technique. Initially, median filtering (MF) approach is used to preprocess the input images. The proposed FFADL-NDID technique exploits the robust feature extraction abilities of DenseNet, a pre-trained DL model for capturing complex visual patterns from database and query images. In addition, the FFA is applied to carry out the hyperparameter tuning, optimizing the system for superior performance. This synergistic fusion enhances the overall efficiency of near-duplicate image detection by successfully searching the hyperparameter space for optimal configurations. Finally, the FFADL-NDID framework applies Euclidean distance-based similarity matching processes, which detects the near-duplicate images significantly. The simulation analysis of the FFADL-NDID method is tested on multiple datasets and the outcomes show its promising performance over other DL models in terms of different measures.},
  keywords={Measurement;Visualization;Machine learning algorithms;Organizations;Search engines;Feature extraction;Visual databases;Near duplicate image detection;Computer vision;Deep learning;Firefly algorithm;Hyperparameter tuning},
  doi={10.1109/ICSCNA58489.2023.10370117},
  ISSN={},
  month={Nov}
}

@ARTICLE{9721612,
  author={Zhang, Lan and Liu, Peng and Choi, Yoon-Ho and Chen, Ping},
  journal={IEEE Transactions on Dependable and Secure Computing}, 
  title={Semantics-Preserving Reinforcement Learning Attack Against Graph Neural Networks for Malware Detection}, 
  year={2023},
  volume={20},
  number={2},
  pages={1390-1402},
  abstract={As an increasing number of deep-learning-based malware scanners have been proposed, the existing evasion techniques, including code obfuscation and polymorphic malware, are found to be less effective. In this work, we propose a reinforcement learning based semantics-preserving (i.e. functionality-preserving) attack against black-box GNNs (Graph Neural Networks) for malware detection. The key factor of adversarial malware generation via semantic Nops insertion is to select the appropriate semantic Nops and their corresponding basic blocks. The proposed attack uses reinforcement learning to automatically make these “how to select” decisions. To evaluate the attack, we have trained two kinds of GNNs with three types (e.g., Backdoor, Trojan, and Virus) of Windows malware samples and various benign Windows programs. The evaluation results have shown that the proposed attack can achieve a significantly higher evasion rate than four baseline attacks, namely the binary diversification attack, the semantics-preserving random instruction insertion attack, the semantics-preserving accumulative instruction insertion attack, and the semantics-preserving gradient-based instruction insertion attack.},
  keywords={Malware;Feature extraction;Codes;Semantics;Reinforcement learning;Graph neural networks;Viruses (medical);Adversarial samples generation;graph neural networks;malware detection;reinforcement learning},
  doi={10.1109/TDSC.2022.3153844},
  ISSN={1941-0018},
  month={March}
}

@INPROCEEDINGS{9565508,
  author={Temmermans, Frederik and Bhowmik, Deepayan and Pereira, Fernando and Ebrahimi, Touradj},
  booktitle={2021 IEEE 4th International Conference on Multimedia Information Processing and Retrieval (MIPR)}, 
  title={An Introduction to the JPEG Fake Media Initiative}, 
  year={2021},
  volume={},
  number={},
  pages={406-411},
  abstract={Recent advances in media creation and modification allow to produce near realistic media assets that are almost indistinguishable from original assets to the human eye. These developments open opportunities for creative production of new media in the entertainment and art industry. However, the intentional or unintentional spread of manipulated media, i.e., modified media with the intention to induce misinterpretation, also imposes risks such as social unrest, spread of rumours for political gain or encouraging hate crimes. The clear and transparent annotation of media modifications is considered to be a crucial element in many usage scenarios bringing trust to the users. This has already triggered various organizations to develop mechanisms that can detect and annotate modified media assets when they are shared. However, these annotations should be attached to the media in a secure way to prevent them of being compromised. In addition, to achieve a wide adoption of such an annotation ecosystem, interoperability is essential and this clearly calls for a standard. This paper presents an initiative by the JPEG Committee called JPEG Fake Media. The scope of JPEG Fake Media is the creation of a standard that can facilitate the secure and reliable annotation of media asset creation and modifications. The standard shall support usage scenarios that are in good faith as well as those with malicious intent. This paper gives an overview of the current state of this initiative and introduces already identified use cases and requirements.},
  keywords={Annotations;Conferences;Standards organizations;Transform coding;Production;Media;Reliability;JPEG;fake media;standardisation;media creation and modification;deepfake;authenticity;media forensics},
  doi={10.1109/MIPR51284.2021.00075},
  ISSN={},
  month={Sep.}
}

@ARTICLE{10275116,
  author={Yu, Ruonan and Liu, Songhua and Wang, Xinchao},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Dataset Distillation: A Comprehensive Review}, 
  year={2024},
  volume={46},
  number={1},
  pages={150-170},
  abstract={Recent success of deep learning is largely attributed to the sheer amount of data used for training deep neural networks. Despite the unprecedented success, the massive data, unfortunately, significantly increases the burden on storage and transmission and further gives rise to a cumbersome model training process. Besides, relying on the raw data for training per se yields concerns about privacy and copyright. To alleviate these shortcomings, dataset distillation (DD), also known as dataset condensation (DC), was introduced and has recently attracted much research attention in the community. Given an original dataset, DD aims to derive a much smaller dataset containing synthetic samples, based on which the trained models yield performance comparable with those trained on the original dataset. In this paper, we give a comprehensive review and summary of recent advances in DD and its application. We first introduce the task formally and propose an overall algorithmic framework followed by all existing DD methods. Next, we provide a systematic taxonomy of current methodologies in this area, and discuss their theoretical interconnections. We also present current challenges in DD through extensive empirical studies and envision possible directions for future works.},
  keywords={Training;Synthetic data;Data models;Optimization;Data privacy;Knowledge engineering;Computer architecture;Dataset distillation;dataset condensation;data compression;efficient learning},
  doi={10.1109/TPAMI.2023.3323376},
  ISSN={1939-3539},
  month={Jan}
}

@INPROCEEDINGS{10132120,
  author={Feng, Yunhe and Poralla, Pradhyumna and Dash, Swagatika and Li, Kaicheng and Desai, Vrushabh and Qiu, Meikang},
  booktitle={2023 IEEE 9th Intl Conference on Big Data Security on Cloud (BigDataSecurity), IEEE Intl Conference on High Performance and Smart Computing, (HPSC) and IEEE Intl Conference on Intelligent Data and Security (IDS)}, 
  title={The Impact of ChatGPT on Streaming Media: A Crowdsourced and Data-Driven Analysis using Twitter and Reddit}, 
  year={2023},
  volume={},
  number={},
  pages={222-227},
  abstract={ChatGPT, a general-purpose text generation AI model, is reshaping various domains ranging from education and software development to legal defense and novel writing. Despite its potential impact, there is a lack of research on how ChatGPT might influence streaming media, which is an essential part of everyday entertainment. As a result, it remains unclear how ChatGPT is changing the future of streaming media. To bridge such a research gap, in this paper, we propose a crowdsourced, data-driven framework that leverages two social media platforms, Twitter and Reddit, to explore the impact of ChatGPT on streaming media. Through extensive analysis of social media data collected from Twitter and Reddit, we reveal how ChatGPT is transforming streaming media from diverse perspectives. Our data analytics demonstrates that ChatGPT is sparking both fear and excitement in the context of the streaming media and enhancing the downstream visual generative models, such as DALLE-2 and Stable Diffusion Videos. To the best of our knowledge, this study is the first large-scale and systematical investigation into the effects of ChatGPT on streaming media. Hope our findings will inspire further research and discussions on this topic across academia and industry.},
  keywords={Analytical models;Visualization;Social networking (online);Blogs;Streaming media;Media;Writing;ChatGPT;social networks;streaming media;data analysis;Twitter;Reddit},
  doi={10.1109/BigDataSecurity-HPSC-IDS58521.2023.00046},
  ISSN={},
  month={May}
}

@ARTICLE{10261341,
  author={Jia, Ju and Ma, Siqi and Wang, Lina and Liu, Yang and Deng, Robert H.},
  journal={IEEE Transactions on Computers}, 
  title={A Secure and Robust Knowledge Transfer Framework via Stratified-Causality Distribution Adjustment in Intelligent Collaborative Services}, 
  year={2024},
  volume={73},
  number={1},
  pages={58-72},
  abstract={The rapid development of device-edge-cloud collaborative computing techniques has actively contributed to the popularization and application of intelligent service models. The intensity of knowledge transfer plays a vital role in enhancing the performance of intelligent services. However, the existing knowledge transfer methods are mainly implemented through data fine-tuning and model distillation, which may cause the leakage of data privacy or model copyright in intelligent collaborative systems. To address this issue, we propose a secure and robust knowledge transfer framework through stratified-causality distribution adjustment (SCDA) for device-edge-cloud collaborative services. Specifically, a simple yet effective density-based estimation is first employed to obtain uncertainty scores that guide the space stratification, which is conducive to reconstructing low-density distribution regions from high-density distribution regions more adaptively and accurately. Subsequently, we devise a novel causality-aware generative model to generate synthetic features for the out-of-distribution domain by exploring the relationship between factors and variables. Ultimately, we introduce a cycle-consistent minimax optimization mechanism to ensure the effectiveness and dependability of knowledge transfer through the influence minimization and the diversity maximization. Furthermore, extensive experiments demonstrate that our scheme can protect the security of data privacy and model copyright in intelligent collaborative services through adaptive distribution adjustment.},
  keywords={Knowledge transfer;Collaboration;Task analysis;Data models;Adaptation models;Artificial intelligence;Robustness;Intelligent collaborative service;knowledge transfer;privacy preservation;copyright protection;adaptive distribution adjustment},
  doi={10.1109/TC.2023.3318403},
  ISSN={1557-9956},
  month={Jan}
}

@ARTICLE{8606923,
  author={Ratasich, Denise and Khalid, Faiq and Geissler, Florian and Grosu, Radu and Shafique, Muhammad and Bartocci, Ezio},
  journal={IEEE Access}, 
  title={A Roadmap Toward the Resilient Internet of Things for Cyber-Physical Systems}, 
  year={2019},
  volume={7},
  number={},
  pages={13260-13283},
  abstract={The Internet of Things (IoT) is a ubiquitous system connecting many different devices - the things - which can be accessed from the distance. The cyber-physical systems (CPSs) monitor and control the things from the distance. As a result, the concepts of dependability and security get deeply intertwined. The increasing level of dynamicity, heterogeneity, and complexity adds to the system's vulnerability, and challenges its ability to react to faults. This paper summarizes the state of the art of existing work on anomaly detection, fault-tolerance, and self-healing, and adds a number of other methods applicable to achieve resilience in an IoT. We particularly focus on non-intrusive methods ensuring data integrity in the network. Furthermore, this paper presents the main challenges in building a resilient IoT for the CPS, which is crucial in the era of smart CPS with enhanced connectivity (an excellent example of such a system is connected autonomous vehicles). It further summarizes our solutions, work-in-progress and future work to this topic to enable “Trustworthy IoT for CPS”. Finally, this framework is illustrated on a selected use case: a smart sensor infrastructure in the transport domain.},
  keywords={Resilience;Security;Internet of Things;Cyber-physical systems;Robustness;Safety;Monitoring;Anomaly detection;cyber-physical systems (CPS);Internet of Things (IoT);monitoring;resilience;long-term dependability and security;self-adaptation;self-healing},
  doi={10.1109/ACCESS.2019.2891969},
  ISSN={2169-3536},
  month={}
}

@ARTICLE{10371310,
  author={Khatun, Mirza Akhi and Memon, Sanober Farheen and Eising, Ciarán and Dhirani, Lubna Luxmi},
  journal={IEEE Access}, 
  title={Machine Learning for Healthcare-IoT Security: A Review and Risk Mitigation}, 
  year={2023},
  volume={11},
  number={},
  pages={145869-145896},
  abstract={The Healthcare Internet-of-Things (H-IoT), commonly known as Digital Healthcare, is a data-driven infrastructure that highly relies on smart sensing devices (i.e., blood pressure monitors, temperature sensors, etc.) for faster response time, treatments, and diagnosis. However, with the evolving cyber threat landscape, IoT devices have become more vulnerable to the broader risk surface (e.g., risks associated with generative AI, 5G-IoT, etc.), which, if exploited, may lead to data breaches, unauthorized access, and lack of command and control and potential harm. This paper reviews the fundamentals of healthcare IoT, its privacy, and data security challenges associated with machine learning and H-IoT devices. The paper further emphasizes the importance of monitoring healthcare IoT layers such as perception, network, cloud, and application. Detecting and responding to anomalies involves various cyber-attacks and protocols such as Wi-Fi 6, Narrowband Internet of Things (NB-IoT), Bluetooth, ZigBee, LoRa, and 5G New Radio (5G NR). A robust authentication mechanism based on machine learning and deep learning techniques is required to protect and mitigate H-IoT devices from increasing cybersecurity vulnerabilities. Hence, in this review paper, security and privacy challenges and risk mitigation strategies for building resilience in H-IoT are explored and reported.},
  keywords={Medical services;Internet of Things;Security;Sensors;Machine learning;Temperature sensors;Monitoring;Healthcare-IoT;generative AI;5G-IoT;security and privacy challenges;cybersecurity;attacks;anomaly detection;machine learning;deep learning;mitigation techniques;5G NR},
  doi={10.1109/ACCESS.2023.3346320},
  ISSN={2169-3536},
  month={}
}

@ARTICLE{8430508,
  author={Jalby, William and Kuck, David and Malony, Allen D. and Masella, Michel and Mazouz, Abdelhafid and Popov, Mihail},
  journal={Proceedings of the IEEE}, 
  title={The Long and Winding Road Toward Efficient High-Performance Computing}, 
  year={2018},
  volume={106},
  number={11},
  pages={1985-2003},
  abstract={The major challenge to Exaflop computing, and more generally, efficient high-end computing, is in finding the best “matches” between advanced hardware capabilities and the software used to program applications, so that top performance will be achieved. Several benchmarks show very disappointing performance progress over the last decade, clearly indicating a mismatch between hardware and software. To remedy this problem, it is important that key performance enablers at the software level-autotuning, performance analysis tools, full application optimization-are understood. For each area, we highlight major limitations and most promising approaches to reaching better performance and energy levels. Finally, we conclude by analyzing hardware and software design, trying to pave the way for more tightly integrated hardware and software codesign.},
  keywords={Benchmark testing;High performance computing;Performance evaluation;Hardware design languages;Program processors;Molecular computing;Autotuning;benchmarking;hardware design;molecular dynamics;performance evaluation tools},
  doi={10.1109/JPROC.2018.2851190},
  ISSN={1558-2256},
  month={Nov}
}

@INPROCEEDINGS{10657770,
  author={Lu, Shilin and Wang, Zilan and Li, Leyang and Liu, Yanzhu and Kong, Adams Wai-Kin},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={MACE: Mass Concept Erasure in Diffusion Models}, 
  year={2024},
  volume={},
  number={},
  pages={6430-6440},
  abstract={The rapid expansion of large-scale text-to-image diffusion models has raised growing concerns regarding their potential misuse in creating harmful or misleading content. In this paper, we introduce MACE, a finetuning framework for the task of MAss Concept Erasure. This task aims to prevent models from generating images that embody unwanted concepts when prompted. Existing concept erasure methods are typically restricted to handling fewer than five concepts simultaneously and struggle to find a balance between erasing concept synonyms (generality) and maintaining unrelated concepts (specificity). In contrast, MACE differs by successfully scaling the erasure scope up to 100 concepts and by achieving an effective balance between generality and specificity. This is achieved by leveraging closed-form cross-attention refinement along with LoRA finetuning, collectively eliminating the information of undesirable concepts. Furthermore, MACE integrates multiple LoRAs without mutual interference. We conduct extensive evaluations of MACE against prior methods across four different tasks: object erasure, celebrity erasure, explicit content erasure, and artistic style erasure. Our results reveal that MACE surpasses prior methods in all evaluated tasks. Code is available at https://github.com/Shilin-LU/MACE.},
  keywords={Computer vision;Codes;Text to image;Interference;Diffusion models;Pattern recognition;Generative AI;AI security;diffusion model;concept editing},
  doi={10.1109/CVPR52733.2024.00615},
  ISSN={2575-7075},
  month={June}
}

@ARTICLE{10885014,
  author={Wang, Yue and Li, Yuke and Elder, James H. and Wu, Runmin and Lu, Huchuan},
  journal={Computational Visual Media}, 
  title={Class-conditional domain adaptation for semantic segmentation}, 
  year={2024},
  volume={10},
  number={5},
  pages={1013-1030},
  abstract={Semantic segmentation is an important sub-task for many applications. However, pixel-level ground-truth labeling is costly, and there is a tendency to overfit to training data, thereby limiting the generalization ability. Unsupervised domain adaptation can potentially address these problems by allowing systems trained on labelled datasets from the source domain (including less expensive synthetic domain) to be adapted to a novel target domain. The conventional approach involves automatic extraction and alignment of the representations of source and target domains globally. One limitation of this approach is that it tends to neglect the differences between classes: representations of certain classes can be more easily extracted and aligned between the source and target domains than others, limiting the adaptation over all classes. Here, we address this problem by introducing a Class-Conditional Domain Adaptation (CCDA) method. This incorporates a class-conditional multi-scale discriminator and class-conditional losses for both segmentation and adaptation. Together, they measure the segmentation, shift the domain in a class-conditional manner, and equalize the loss over classes. Experimental results demonstrate that the performance of our CCDA method matches, and in some cases, surpasses that of state-of-the-art methods.},
  keywords={Semantic segmentation;Loss measurement;Training;Semantics;Feature extraction;Decoding;Translation;Adversarial machine learning;Visualization;Limiting;domain adaptation;generative adversarial networks;semantic segmentation;cityscapes},
  doi={10.1007/s41095-023-0362-4},
  ISSN={2096-0662},
  month={Oct}
}

@ARTICLE{10750803,
  author={Guo, Jie and Wang, Meiting and Yin, Hang and Song, Bin and Chi, Yuhao and Yu, Fei Richard and Yuen, Chau},
  journal={IEEE Internet of Things Journal}, 
  title={Large Language Models and Artificial Intelligence Generated Content Technologies Meet Communication Networks}, 
  year={2025},
  volume={12},
  number={2},
  pages={1529-1553},
  abstract={Artificial intelligence generated content (AIGC) technologies, with a predominance of large language models (LLMs), have demonstrated remarkable performance improvements in various applications, which have attracted great interests from both academia and industry. Although some noteworthy advancements have been made in this area, a comprehensive exploration of the intricate relationship between AIGC and communication networks remains relatively limited. To address this issue, this article conducts an exhaustive survey from dual standpoints: first, it scrutinizes the integration of LLMs and AIGC technologies within the domain of communication networks and second, it investigates how the communication networks can further bolster the capabilities of LLMs and AIGC. Additionally, this research explores the promising applications along with the challenges encountered during the incorporation of these AI technologies into communication networks. Through these detailed analyses, our work aims to deepen the understanding of how LLMs and AIGC can synergize with and enhance the development of advanced intelligent communication networks, contributing to a more profound comprehension of next-generation intelligent communication networks.},
  keywords={Communication networks;Training;Surveys;6G mobile communication;Noise;Data models;Chatbots;Adaptation models;Security;Reviews;Artificial intelligence generated content (AIGC);communication networks;generative models;large language models (LLMs);novel network architecture},
  doi={10.1109/JIOT.2024.3496491},
  ISSN={2327-4662},
  month={Jan}
}

@ARTICLE{10794530,
  author={Luo, Ting and Zhou, Yuhang and He, Zhouyan and Jiang, Gangyi and Xu, Haiyong and Qi, Shuren and Zhang, Yushu},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={StegMamba: Distortion-free Immune-Cover for Multi-Image Steganography with State Space Model}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  abstract={Multi-image steganography ensures privacy protection while avoiding suspicion from third parties by embedding multiple secret images within a cover image. However, existing multi-image steganographic methods fail to model global spatial correlations to reduce image damage at the low computation cost. Moreover, they do not account for the anti-distortion capability of the cover image, which is crucial for achieving imperceptible and ensuring security. To overcome these limitations, we propose StegMamba, a distortion-free immune-cover for multi-image steganography architecture with a state space model. Specifically, we first explore the potential of the linear computational cost model Mamba for data hiding tasks through a steganography Mamba block (SMB), whose efficiency makes it suitable for real-time applications. Subsequently, considering that images with distortion resistance reduce embedding damage, the original cover image is reconstructed through immune-cover construction module (ICCM) and associated with the steganography task. Moreover, well-coupled features facilitate fusion, and thus a wavelet-based interaction module (WIM) is designed for effective communication between the immune-cover and the secret images. Compared with the state-of-the-art global attention-based methods, the proposed StegMamba obtains PSNR gains of 3.30 dB, 1.37 dB, and 1.92 dB for the stego image, and two secret recovery images, respectively, and the reduction of 2.87% in detection accuracy for anti-steganalysis. This code is available at https://github.com/YuhangZhouCJY/StegMamba.},
  keywords={Steganography;Distortion;Immune system;Feature extraction;Optimization;Computational modeling;Circuits and systems;Resistance;Couplings;Image color analysis;Image steganography;State space model;Immune-cover;Distortion resistance},
  doi={10.1109/TCSVT.2024.3515652},
  ISSN={1558-2205},
  month={}
}

@INPROCEEDINGS{10771198,
  author={Dasgupta, Dipankar and Roy, Arunava},
  booktitle={2024 Artificial Intelligence for Business (AIxB)}, 
  title={Issues with Generic Large Language Models (GLLMs)}, 
  year={2024},
  volume={},
  number={},
  pages={47-50},
  abstract={Generic Large Language Models (GLLMs) are continuously being released with enhanced size and capabilities, promoting the abilities of these tools for different use. GLLMs excel in text, image, and video generation (assembling, summarizing, translating) with proper queries and prompts. However, the reliability of GLLMs’ responses is questionable in critical applications due to factual inaccuracies, and inappropriate or unrelated responses. Also there remain many open questions on the data collection-privacy, legal and ethical issues. This short report emphasizes the reliability and security aspects of GLLMs while recognizing significant benefits in a wide variety of applications.},
  keywords={Ethics;Law;Large language models;Data models;Reliability;Security;Business;Generative AI;Large Language Models (LLMs);Generative Pre-Trained Models (GPTs);Small Parameterized Data Models (SPDM)},
  doi={10.1109/AIxB62249.2024.00015},
  ISSN={},
  month={Dec}
}

@INPROCEEDINGS{10208817,
  author={Bui, Tu and Agarwal, Shruti and Yu, Ning and Collomosse, John},
  booktitle={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
  title={RoSteALS: Robust Steganography using Autoencoder Latent Space}, 
  year={2023},
  volume={},
  number={},
  pages={933-942},
  abstract={Data hiding such as steganography and invisible watermarking has important applications in copyright protection, privacy-preserved communication and content provenance. Existing works often fall short in either preserving image quality, or robustness against perturbations or are too complex to train. We propose RoSteALS, a practical steganography technique leveraging frozen pretrained autoencoders to free the payload embedding from learning the distribution of cover images. RoSteALS has a lightweight secret encoder of just 300k parameters, is easy to train, has perfect secret recovery performance and comparable image quality on three benchmarks. Additionally, RoSteALS can be adapted for novel cover-less steganography applications in which the cover image can be sampled from noise or conditioned on text prompts via a denoising diffusion process. Our model and code are available at https://github.com/TuBui/RoSteALS.},
  keywords={Image quality;Measurement;Steganography;Adaptation models;Perturbation methods;Watermarking;Robustness},
  doi={10.1109/CVPRW59228.2023.00100},
  ISSN={2160-7516},
  month={June}
}

@INPROCEEDINGS{10449668,
  author={Lo, David},
  booktitle={2023 IEEE/ACM International Conference on Software Engineering: Future of Software Engineering (ICSE-FoSE)}, 
  title={Trustworthy and Synergistic Artificial Intelligence for Software Engineering: Vision and Roadmaps}, 
  year={2023},
  volume={},
  number={},
  pages={69-85},
  abstract={For decades, much software engineering research has been dedicated to devising automated solutions aimed at enhancing developer productivity and elevating software quality. The past two decades have witnessed an unparalleled surge in the development of intelligent solutions tailored for software engineering tasks. This momentum established the Artificial Intelligence for Software Engineering (AI4SE) area, which has swiftly become one of the most active and popular areas within the software engiueering field. This Future of Software Engineering (FoSE) paper navigates through several focal points. It commences with a succinct introduction and history of AI4SE. Thereafter, it underscores the core challenges inherent to AI4SE, particularly highlighting the need to realize trustworthy and synergistic AI4SE. Progressing, the paper paints a vision for the potential leaps achievable if AI4SE's key challenges are surmounted, suggesting a transition toward Software Engineering 2.0. Two strategic roadmaps are then laid out: one centered on realizing trustworthy AI4SE, and the other on fostering synergistic AI4SE. While this paper may not serve as a conclusive guide, its intent is to catalyze further progress. The ultimate aspiration is to position AI4SE as a linchpin in redefining the horizons of software engineering, propelling us toward Software Engineering 2.0.},
  keywords={Productivity;Navigation;Software quality;Propulsion;History;Artificial intelligence;Task analysis;AI4SE;Trustworthy AI;Human-AI Collaboration;Software Engineering 2.0;Vision;Roadmaps},
  doi={10.1109/ICSE-FoSE59343.2023.00010},
  ISSN={},
  month={May}
}

@ARTICLE{8718661,
  author={Reinel, Tabares-Soto and Raúl, Ramos-Pollán and Gustavo, Isaza},
  journal={IEEE Access}, 
  title={Deep Learning Applied to Steganalysis of Digital Images: A Systematic Review}, 
  year={2019},
  volume={7},
  number={},
  pages={68970-68990},
  abstract={Steganography consists of hiding messages inside some object known as a carrier in order to establish a covert communication channel so that the act of communication itself goes unnoticed by observers who have access to that channel. The steganalysis is dedicated to the detection of hidden messages using steganography; these messages can be implicit in different types of media, such as digital images, video files, audio files or plain text. Traditionally, steganalysis has been divided into two separate stages, the first stage consists of manual extraction of sophisticated features and the second stage is classification using Ensemble Classifiers or Support Vector Machines. In recent years, the development of Deep Learning has made it possible to unify and automate the two traditional stages into an end to end approach with promising results. This paper shows the evolution of steganalysis in recent years using the Deep Learning techniques. The results of these techniques have surpassed those obtained with conventional methods - Rich Models with Ensemble Classifiers - both in the spatial and frequency (JPEG) domains. Since 2014, researchers have used The Convolutional Neural Networks to solve this problem generating diverse architectures and strategies to improve the detection percentages of steganographic images on the last generation algorithms (WOW, S-UNIWARD, HUGO, J-UNIWARD, among others). The Deep Learning, being applied to steganalysis, is now in the process of construction and results so far are encouraging for researchers that are interested in the topic.},
  keywords={Feature extraction;Transform coding;Deep learning;Databases;Frequency-domain analysis;Payloads;Manuals;Convolutional neural network;deep learning;steganalysis;steganography},
  doi={10.1109/ACCESS.2019.2918086},
  ISSN={2169-3536},
  month={}
}

@INPROCEEDINGS{9137011,
  author={Liu, Yuntao and Mondal, Ankit and Chakraborty, Abhishek and Zuzak, Michael and Jacobsen, Nina and Xing, Daniel and Srivastava, Ankur},
  booktitle={2020 21st International Symposium on Quality Electronic Design (ISQED)}, 
  title={A Survey on Neural Trojans}, 
  year={2020},
  volume={},
  number={},
  pages={33-39},
  abstract={Neural networks have become increasingly prevalent in many real-world applications including security critical ones. Due to the high hardware requirement and time consumption to train high-performance neural network models, users often outsource training to a machine-learning-as-a-service (MLaaS) provider. This puts the integrity of the trained model at risk. In 2017, Liu et al. found that, by mixing the training data with a few malicious samples of a certain trigger pattern, hidden functionality can be embedded in the trained network which can be evoked by the trigger pattern [33]. We refer to this kind of hidden malicious functionality as neural Trojans. In this paper, we survey a myriad of neural Trojan attack and defense techniques that have been proposed over the last few years. In a neural Trojan insertion attack, the attacker can be the MLaaS provider itself or a third party capable of adding or tampering with training data. In most research on attacks, the attacker selects the Trojan's functionality and a set of input patterns that will trigger the Trojan. Training data poisoning is the most common way to make the neural network acquire the Trojan functionality. Trojan embedding methods that modify the training algorithm or directly interfere with the neural network's execution at the binary level have also been studied. Defense techniques include detecting neural Trojans in the model and/or Trojan trigger patterns, erasing the Trojan's functionality from the neural network model, and bypassing the Trojan. It was also shown that carefully crafted neural Trojans can be used to mitigate other types of attacks. We systematize the above attack and defense approaches in this paper.},
  keywords={Training;Neural networks;Training data;Hardware;Trojan horses;Security},
  doi={10.1109/ISQED48828.2020.9137011},
  ISSN={1948-3287},
  month={March}
}

@INPROCEEDINGS{10578820,
  author={He, Zhangying and Nguyen, Thomas and Miari, Tahereh and Aliasgari, Mehrdad and Rafatirad, Setareh and Sayadi, Hossein},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={The AI Companion in Education: Analyzing the Pedagogical Potential of ChatGPT in Computer Science and Engineering}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={Artificial Intelligence (AI), with ChatGPT as a prominent example, has recently taken center stage in various domains including higher education, particularly in Computer Science and Engineering (CSE). The AI revolution brings both convenience and controversy, offering substantial benefits while lacking formal guidance on their application. The primary objective of this work is to comprehensively analyze the pedagogical potential of ChatGPT in CSE education, understanding its strengths and limitations from the perspectives of educators and learners. We employ a systematic approach, creating a diverse range of educational practice problems within CSE field, focusing on various subjects such as data science, programming, AI, machine learning, networks, and more. According to our examinations, certain question types, like conceptual knowledge queries, typically do not pose significant challenges to ChatGPT, and thus, are excluded from our analysis. Alternatively, we focus our efforts on developing more in-depth and personalized questions and project-based tasks. These questions are presented to ChatGPT, followed by interactions to assess its effectiveness in delivering complete and meaningful responses. To this end, we propose a comprehensive five-factor reliability analysis framework to evaluate the responses. This assessment aims to identify when ChatGPT excels and when it faces challenges. Our study concludes with a correlation analysis, delving into the relationships among subjects, task types, and limiting factors. This analysis offers valuable insights to enhance ChatGPT's utility in CSE education, providing guidance to educators and students regarding its reliability and efficacy.},
  keywords={Systematics;Limiting;Focusing;Machine learning;Chatbots;Reliability;Task analysis;ChatGPT;Computer Science and Engineering;Education;Generative Artificial Intelligence;Reliability Analysis},
  doi={10.1109/EDUCON60312.2024.10578820},
  ISSN={2165-9567},
  month={May}
}

@INPROCEEDINGS{10263906,
  author={Nikita and Rana, Dipti P. and Mehta, Rupa G.},
  booktitle={2023 IEEE World Conference on Applied Intelligence and Computing (AIC)}, 
  title={Research Challenges for Legal Document Summarization}, 
  year={2023},
  volume={},
  number={},
  pages={307-312},
  abstract={Legal judgment documents are detailed and contains legal terms and codes. These characteristics of legal documents makes it complex to read and analyze, which makes processing legal documents a challenging task. This raises a need for generating automatic summaries. Several techniques have been used by researchers to summarize legal documents such as traditional methods, legal specific approaches and transformer models based approaches. This research focuses on role of summarization in legal domain and various methods for summary generation. We summarize Indian judgment documents with various state of art methods for comparative study. The analysis opened various research challenges.},
  keywords={Codes;Art;Law;Transformers;Task analysis;Text processing;text summarization;legal documents;legal text processing},
  doi={10.1109/AIC57670.2023.10263906},
  ISSN={},
  month={July}
}

@ARTICLE{10783027,
  author={Khan, Hammad Ahmed and Khan, Haibat and Ghafoor, Salman and Khan, Mansoor Ahmed},
  journal={IEEE Communications Surveys & Tutorials}, 
  title={A Survey on Security of Automatic Dependent Surveillance -Broadcast (ADS-B) Protocol: Challenges, Potential Solutions and Future Directions}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  abstract={This work delves into critical examination of the broadcast data safety of Automatic Dependent Surveillance-Broadcast (ADS-B) system, an essential protocol for aircraft identification and navigation. Globally mandated by civil aviation regulatory bodies, ADS-B plays a pivotal role in shaping the future of Air Traffic Management initiatives. This study thoroughly investigates the vulnerabilities inherent in the open and un-encrypted nature of ADS-B data transmission. Given the widespread availability of Software-Defined Radios (SDRs), these security threats pose significant risks to Air Traffic Services and passenger safety. In light of these challenges, the paper scrutinises existing research and industry documents to comprehensively understand ADS-B vulnerabilities and assess threat levels and potential attacks. We also review recent developments and analyze proposed countermeasures aimed at enhancing the security of ADS-B data, possibly through protocol modifications or infrastructure enhancements.},
  keywords={Security;Surveys;Jamming;Aircraft;Air traffic control;Protocols;Tutorials;Authentication;Surveillance;Kalman filters;ADS-B;Air Traffic Control;Authentication;Aviation;broadcast;data security;encryption;privacy;Private Key;transponders;wireless},
  doi={10.1109/COMST.2024.3513213},
  ISSN={1553-877X},
  month={}
}

@ARTICLE{10858368,
  author={Sugunaraj, Niroop and Balaji, Shree Ram Abayankar and Chandar, Barathwaja Subash and Rajagopalan, Prashanth and Kose, Utku and Loper, David Charles and Mahfuz, Tanzim and Chakraborty, Prabuddha and Ahmad, Seerin and Kim, Taesic and Apruzzese, Giovanni and Dubey, Anamika and Strezoski, Luka and Blakely, Benjamin and Ghosh, Subhojit and Reddy, Maddikara Jaya Bharata and Padullaparti, Harsha Vardhan and Ranganathan, Prakash},
  journal={IEEE Communications Surveys & Tutorials}, 
  title={Distributed Energy Resource Management System (DERMS) Cybersecurity Scenarios, Trends, and Potential Technologies: A Review}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Critical infrastructures like the power grid are at risk from increasing cyber threats due to high penetration of interconnected distributed energy resources (DER). Compromised DER endpoints can cause events, data breaches, communication loss, intentional device failures, and even cascading outages. To address these challenges, this paper explores cybersecurity issues in DER management systems (DERMS), including state-of-the-art reviews on architectures, communication protocols, access control privileges, data breaches, identity management policies, attacks such as false data injection, denial of service, distributed denial of service, malware, threats affecting data integrity, and network vulnerabilities. Realistic threat scenarios are outlined, followed by discussions on futuristic solutions like the zero trust framework. The paper presents new architectural patterns for recently released multi-level hierarchical framework as per IEEE 1547.3 standard to handle DERMS data and assets. The paper also discusses potential threats compromising the Confidentiality, Integrity, Availability, and Accountability (CIAA) properties at each level of the IEEE 1547.3 framework. This review is unique and comprehensive, as it covers existing research on cybersecurity challenges in DER-related assets and outlines the necessary capabilities to equip Intrusion Diagnostic Units (IDUs) in future DERMS technologies, all while ensuring compliance with IEEE 1547.3 standard requirements.},
  keywords={Computer architecture;Distributed power generation;Protocols;Computer security;Tutorials;Surveys;Malware;Power system stability;Distributed databases;Data privacy;advanced distribution management systems;cybersecurity;distributed energy resources;distributed energy resource management systems},
  doi={10.1109/COMST.2025.3534828},
  ISSN={1553-877X},
  month={}
}

@INPROCEEDINGS{10628478,
  author={Nouri, Ali and Cabrero-Daniel, Beatriz and Törner, Fredrik and Sivencrona, Håkan and Berger, Christian},
  booktitle={2024 IEEE 32nd International Requirements Engineering Conference (RE)}, 
  title={Engineering Safety Requirements for Autonomous Driving with Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={218-228},
  abstract={Changes and updates in the requirement artifacts, which can be frequent in the automotive domain, are a challenge for SafetyOps. Large Language Models (LLMs), with their impressive natural language understanding and generating capabilities, can play a key role in automatically refining and decomposing requirements after each update. In this study, we propose a prototype of a pipeline of prompts and LLMs that receives an item definition and outputs solutions in the form of safety requirements. This pipeline also performs a review of the requirement dataset and identifies redundant or contradictory requirements. We first identified the necessary characteristics for performing HARA and then defined tests to assess an LLM's capability in meeting these criteria. We used design science with multiple iterations and let experts from different companies evaluate each cycle quantitatively and qualitatively. Finally, the prototype was implemented at a case company and the responsible team evaluated its efficiency.},
  keywords={Reviews;Large language models;Pipelines;Refining;Prototypes;Companies;Natural language processing;Requirement Engineering;Hazard Analysis Risk Assessment;Autonomous Vehicles;DevOps;Safety;Large Language Model;Prompt Engineering;LLM;ChatGPT},
  doi={10.1109/RE59067.2024.00029},
  ISSN={2332-6441},
  month={June}
}

@INPROCEEDINGS{10657312,
  author={Li, Hong and Feng, Yutang and Xue, Song and Liu, Xuhui and Zeng, Bohan and Li, Shanglin and Liu, Boyu and Liu, Jianzhuang and Han, Shumin and Zhang, Baochang},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={UV-IDM: Identity-Conditioned Latent Diffusion Model for Face UV-Texture Generation}, 
  year={2024},
  volume={},
  number={},
  pages={10585-10595},
  abstract={3D face reconstruction aims at generating high-fidelity 3D face shapes and textures from single-view or multi-view images. However, current prevailing facial texture generation methods generally suffer from low-quality texture, identity information loss, and inadequate handling of occlusions. To solve these problems, we introduce an Identity-Conditioned Latent Diffusion Model for face UV-texture generation (UV-IDM) to generate photo-realistic textures based on the Basel Face Model (BFM). UV-IDM leverages the powerful texture generation capacity of a latent diffusion model (LDM) to obtain detailed facial textures. To preserve the identity during the reconstruction procedure, we design an identity-conditioned module that can utilize any in-the-wild image as a robust condition for the LDM to guide texture generation. UV-IDM can be easily adapted to different BFM-based methods as a high-fidelity texture generator. Furthermore, in light of the limited accessibility of most existing UV-texture datasets, we build a large-scale and publicly available UV-texture dataset based on BFM, termed BFM-UV. Extensive experiments show that our UV-IDM can generate high-fidelity textures in 3D face reconstruction within seconds while maintaining image consistency, bringing new state-of-the-art performance in facial texture generation.},
  keywords={Hair;Three-dimensional displays;Shape;Face recognition;Diffusion models;Generators;Robustness;3D face reconstruction;Diffusion Model;UV-Texture},
  doi={10.1109/CVPR52733.2024.01007},
  ISSN={2575-7075},
  month={June}
}

@ARTICLE{10891605,
  author={Feng, Yan and Xu, Longting and Lu, Xiaochen and Zhang, Guanglin and Rao, Wei},
  journal={IEEE Transactions on Multimedia}, 
  title={A Robust Coverless Audio Steganography Based on Differential Privacy Clustering}, 
  year={2025},
  volume={},
  number={},
  pages={1-16},
  abstract={Conventional audio steganography methods typically require embedding secret information into the carrier, making them vulnerable to steganalysis. To address this issue, we propose a novel coverless audio steganography method that hides information by generating carriers and establishing mapping rules rather than embedding data directly. Our approach leverages a differential privacy clustering algorithm to cluster audio data and select representative audio files, thereby enhancing the security of the steganography. Additionally, we introduce an improved audio feature extraction method that combines traditional Mel-frequency cepstral coefficients (MFCC) with global statistical information, significantly boosting the robustness of the secret information against common audio attacks, particularly time-stretching attacks. Experimental results show that our method achieves a robustness rate of up to 95% against time-stretching and maintains an average security accuracy rate exceeding 97% across various attack scenarios. The proposed method ensures that the audio carrier remains unaltered, thus effectively resisting detection by steganalysis tools. This innovative approach provides a practical and efficient solution for the secure transmission of information in the digital era.},
  keywords={Steganography;Security;Robustness;Differential privacy;Feature extraction;Privacy;Clustering algorithms;Noise;Sensitivity;Payloads;Coverless audio steganography;differential privacy clustering;robustness;information security},
  doi={10.1109/TMM.2025.3543107},
  ISSN={1941-0077},
  month={}
}

@ARTICLE{10812863,
  author={Guo, Bobiao and Ping, Ping and Xu, Feng},
  journal={IEEE Transactions on Dependable and Secure Computing}, 
  title={Highly Robust and Diverse Coverless Image Steganography Against Passive and Active Steganalysis}, 
  year={2024},
  volume={},
  number={},
  pages={1-17},
  abstract={To avoid the pixel modification traces left by steganography from being detected by passive steganalysis, and to prevent the hidden data from being destroyed by active steganalysis attacks, Coverless Image Steganography (CIS) that does not modify pixels has attracted widespread attention. However, most existing CIS methods are limited in their maximum capacity due to insufficient diversity in their hash sequences. In addition, these methods struggle to maintain high robustness against both geometric and non-geometric attacks simultaneously. To address these two issues, a new coverless image steganography method is proposed to enhance CIS methods' applicability, security, and robustness in highly insecure networks. During the hiding process, hash sequences are generated by a SHA-256 algorithm that integrates inter-block and inter-channel fusion, providing higher diversity than other CIS methods. Consequently, the proposed CIS method achieves higher capacity on publicly available datasets. During the extraction process, an evaluation metric that combines visual and histogram similarity is designed to improve the accuracy of inverse image retrieval. The experimental results demonstrate that the proposed CIS method achieves capacity increases of 26.73% and 38.34% over other CIS methods on the VOC and COCO datasets, respectively. Moreover, this method exhibits nearly 100% robustness against common active steganalysis.},
  keywords={Steganography;Robustness;Feature extraction;Data mining;Image retrieval;Visualization;Accuracy;Software;Indexes;Histograms;Coverless image steganography;hash generation algorithm;inverse image retrieval;steganalysis},
  doi={10.1109/TDSC.2024.3521424},
  ISSN={1941-0018},
  month={}
}

@ARTICLE{9761245,
  author={Chaurasiya, Himanshu},
  journal={IEEE Transactions on Cognitive and Developmental Systems}, 
  title={Cognitive Hexagon-Controlled Intelligent Speech Interaction System}, 
  year={2022},
  volume={14},
  number={4},
  pages={1413-1439},
  abstract={Several intelligent speech interaction (ISI) systems have emerged over the past four decades that have served the human community. The research papers show that these systems are very well connected to the cognitive hexagon and the six hybrid approaches. Where this hexagon reveals six distinct cognitive areas, one of the six hybrid perspectives gives rise to the dimensions of speech quality. This survey has been undertaken to reveal the dimensions of speech quality and to discuss the role of cognitive hexagonal regions on these dimensions with hybrid approaches. Here, ISI systems support this discussion and follow them as cognitive machines. An overview of the state of the art related to ISI systems is also described here. Techniques, such as processing [natural language (NL)], speech synthesis [speech-to-text (STT) or text-to-speech (TTS)], computing (voice/mobile), and audio mining are presented in this overview. These are contributing well with technologies, such as the Internet of Things (IoT), Voice over Internet Protocol (VoIP), and cloud-based systems (CBSs). In addition, stochastic components, such as reliability, availability, and failure rate were discussed to analyze whether the Quality of Service (QoS) of these ISI systems is described. Additionally, after the discussion, some aspects of the applications are also discussed along with the essential advantages and significant drawbacks.},
  keywords={Philosophical considerations;Psychology;Artificial intelligence;Linguistics;Cognitive systems;Quality of service;Cloud computing;Speech recognition;Cognitive;hexagon;hybrid;intelligent speech interaction (ISI);system},
  doi={10.1109/TCDS.2022.3168807},
  ISSN={2379-8939},
  month={Dec}
}

@INPROCEEDINGS{10661116,
  author={Jin, Zeying and Yang, Zhaoyong and Tang, Gongbo and Liu, Tingchao and Xun, Endong},
  booktitle={2024 International Conference on Asian Language Processing (IALP)}, 
  title={Research on Keyword-Based Element Extraction for Chinese Patent Retrieval}, 
  year={2024},
  volume={},
  number={},
  pages={67-73},
  abstract={Patent retrieval is a critical step in patent analysis. Retrievable elements play a key role in constructing search queries and performing accurate searches, and most retrievable elements are created manually. However, the increment of patent applications each year has brought a huge burden on manual extraction of retrievable elements and patent examination, raising the urgent need of automated solutions. As keywords serve as an effective way of expressing retrievable elements in patent retrieval, we explore the automatic extraction of keyword-based retrievable elements from Chinese patent application texts in this study. We employ various keyword extraction methods, including large language model based methods, to identify retrievable elements within these texts. Our experimental results have shown that these methods can effectively extract keywords as retrievable elements from Chinese patent applications, which benefits to manual patent searching and patent examinations.},
  keywords={Patents;Accuracy;Large language models;Manuals;Complexity theory;Iterative methods;patent retrieval;retrievable elements;keyword extraction},
  doi={10.1109/IALP63756.2024.10661116},
  ISSN={2159-1970},
  month={Aug}
}

@ARTICLE{10937774,
  author={Ma, Yakun and Chai, Xiuli and Long, Guoqiang and Gan, Zhihua and Zhang, Yushu},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={TPE for JPEG images with Dynamic M-ary Decomposition and Adaptive Threshold Constraints}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Traditional JPEG image encryption that prioritizes solely confidentiality fails to account for the pressing usability requirements of cloud-based environments, thus boosting the boom in thumbnail-preserving encryption (TPE) to balance image privacy and usability. However, existing TPE schemes for JPEG images face numerous challenges, such as insufficient security, inability to achieve lossless decryption, and high file extension. To address these challenges, we propose a TPE scheme based on dynamic M-ary decomposition and adaptive threshold constraints (TPE-MDTC). First, the valid ranges of quantized DC coefficients for JPEG images are determined. Then, a sum-preserving encryption method for quantized DC coefficients with compliance threshold constraints is designed using the bit-plane permutation to preserve thumbnails with high accuracy. Next, the introduction of dynamic M-ary decomposition effectively changes bit statistical characteristics preserved by bit-plane permutation, enhancing the ciphertext security. Finally, a quantized AC encryption method with RV (Run/Value) pair global permutation is proposed, effectively modifying the unit block features, thereby significantly improving the security and attack resistance of encrypted images. Experimental results show that the proposed TPE-MDTC scheme can reconstruct the original JPEG images without loss, and the generated ciphertext images exhibit significant advantages over previous schemes regarding file extension and security.},
  keywords={Encryption;Transform coding;Cryptography;Usability;Privacy;Image coding;Encoding;Visualization;Image resolution;Image quality;Privacy and usability;JPEG image encryption;thumbnail-preserving;sum-preserving;block features},
  doi={10.1109/TCSVT.2025.3553962},
  ISSN={1558-2205},
  month={}
}

@ARTICLE{10669285,
  author={},
  journal={IEEE P1012/D22, August 2024}, 
  title={IEEE Approved Draft Standard for System, Software, and Hardware Verification and Validation}, 
  year={2024},
  volume={},
  number={},
  pages={1-324},
  abstract={Verification and validation (V&V) processes are used to determine whether the development products of a given activity conform to the requirements of that activity and whether the product satisfies its intended use and user needs. V&V life cycle process requirements are specified for different integrity levels. The scope of V&V processes encompasses systems, software, and hardware, and it includes their interfaces. This standard applies to systems, software, and hardware being developed, maintained, or reused [legacy, commercial off-the-shelf (COTS), non-developmental items]. The term software also includes firmware and microcode, and each of the terms system, software, and hardware includes related information or documentation. V&V processes include the analysis, evaluation, review, inspection, assessment, and testing of product},
  keywords={IEEE Standards;Artificial intelligence;Testing;Performance evaluation;Hazards;Formal verification;Field programmable gate arrays;Microprogramming;Hardware;Life cycle assessment;acceptance testing;architecture evaluation;adaptive;Agile;AI;artificial intelligence;component testing;concept documentation evaluation;COTS;criticality;criticality analysis;design evaluation;disposal plan evaluation;environmental verification and validation (V&V) factors;field programmable gate array;firmware;FPGA;hardware life cycle;hardware V&V;hardware verification and validation;hazard analysis;IEEE 1012;implementation evaluation;independent V&V;integration testing;integrity level;interface analysis;IV&V;machine learning;microcode;minimum V&V tasks;ML;nth of a kind;objective evidence;operating procedure evaluation;qualification testing;quality assurance;regression analysis;regression testing;requirements allocation analysis;requirements evaluation;reuse software;risk analysis;security analysis;software as a service;SaaS software life cycle;software quality assurance;software V&V;software verification and validation;source code documentation evaluation;source code evaluation;SQA;stakeholder needs and requirements evaluation;system element interaction analysis;system life cycle;system maintenance strategy assessment;system of interest;system requirements evaluation;system V&V;system verification and validation;testing;traceability analysis;V&V;V&V measures;validation;verification;vignette},
  doi={},
  ISSN={},
  month={Nov}
}

@ARTICLE{10409615,
  author={Zhang, Huan and Zheng, Dongsheng and Zhang, Yun and Cao, Jiangzhong and Lin, Weisi and Ling, Wing-Kuen},
  journal={IEEE Transactions on Multimedia}, 
  title={Quality Assessment for DIBR-Synthesized Views Based on Wavelet Transform and Gradient Magnitude Similarity}, 
  year={2024},
  volume={26},
  number={},
  pages={6834-6847},
  abstract={To drive upgrades of Depth-Image-Based Rendering (DIBR) algorithms, depth image refinement, etc., quality assessment models for DIBR-synthesized images in 3D video systems are developed. However, most of these models could not effectively evaluate distortion due to irregular stretching (e.g., crumbling), which is more complex and common than black holes and regular stretching (e.g., horizontal stretching) in synthesized images. To make an attempt at this issue, a new quality assessment method is proposed for DIBR views. First, feature point matching and affine transformation are adopted to remove and compensate for the global object shift between reference and synthesized view images. Second, multi-scale discrete wavelet transform is utilized to extract multi-scale structure distortion; gradient magnitude similarity is further integrated to highlight the distortion features; morphological open operation and median filtering are adopted to exclude perceptually unimportant features. Third, scores are obtained by standard deviation pooling on distortion feature maps for each wavelet scale and sub-band. Experimental results demonstrate that our proposed model outperforms the state-of-the-art handcrafted feature-based DIBR-synthesized image quality assessment models on IETR database, and performs the best on average on IETR and IRCCyN/IVC databases.},
  keywords={Distortion;Feature extraction;Measurement;Three-dimensional displays;Databases;Image quality;Visualization;Depth image-based rendering (DIBR);synthesized views;image quality assessment;quality of experience (QoE);local distortion},
  doi={10.1109/TMM.2024.3356029},
  ISSN={1941-0077},
  month={}
}

@ARTICLE{10850911,
  author={Siino, Marco and Falco, Mariana and Croce, Daniele and Rosso, Paolo},
  journal={IEEE Access}, 
  title={Exploring LLMs Applications in Law: A Literature Review on Current Legal NLP Approaches}, 
  year={2025},
  volume={13},
  number={},
  pages={18253-18276},
  abstract={Artificial Intelligence (AI) is reshaping the legal landscape, with software tools now impacting various aspects of legal work. The intersection of Natural Language Processing (NLP) and law holds potential to transform how legal professionals, including lawyers and judges, operate, resolve disputes, and retrieve case information to formulate their decisions. To identify the current state of the applications of Transformers (also known as Large Language Models or LLMs) in the legal domain, we analysed the existing literature from 2017 to 2023 through a database search and snowballing method. From 61 selected publications, we identified key application categories such as legal document analysis, case prediction, and contract review, along with their main characteristics. We observed a discernible upsurge in the volume of scholarly publications, a diversification of tasks undertaken (e.g., legal research, contract analysis, and regulatory compliance), and an increased range of languages considered. There has been a notable enhancement in the methodological sophistication employed by researchers in practical applications. The performance of models grounded in the Generative Pre-trained Transformer (GPT) architecture has consistently improved across various legal domains, including contract review, legal document summarization, and case outcome prediction. This paper makes several significant contributions to the field. Firstly, it identifies emerging trends in the application of LLMs within the legal domain, highlighting the growing interest and investment in this area. Secondly, it pinpoints methodological gaps in current research, suggesting areas where further development and refinement are needed. Lastly, it discusses the broader implications of these advancements for real-world legal tasks, offering insights into how LLM-based AI can enhance legal practice while addressing the associated challenges.},
  keywords={Law;Artificial intelligence;Transformers;Systematic literature review;Contracts;Attention mechanisms;Databases;Reliability;Question answering (information retrieval);Quality assessment;Natural language processing;law;AI for law;legal NLP;legal tech;GPT;transformers;literature review},
  doi={10.1109/ACCESS.2025.3533217},
  ISSN={2169-3536},
  month={}
}

@ARTICLE{10539079,
  author={},
  journal={IEEE P1012/D20, May 2024}, 
  title={IEEE Draft Standard for System, Software, and Hardware Verification and Validation}, 
  year={2024},
  volume={},
  number={},
  pages={1-327},
  abstract={Verification and validation (V&V) processes are used to determine whether the development products of a given activity conform to the requirements of that activity and whether the product satisfies its intended use and user needs. V&V life cycle process requirements are specified for different integrity levels. The scope of V&V processes encompasses systems, software, and hardware, and it includes their interfaces. This standard applies to systems, software, and hardware being developed, maintained, or reused [legacy, commercial off-the-shelf (COTS), non-developmental items]. The term software also includes firmware and microcode, and each of the terms system, software, and hardware includes related information or documentation. V&V processes include the analysis, evaluation, review, inspection, assessment, and testing of product},
  keywords={IEEE Standards;Hardware design languages;Software testing;Artificial intelligence;Software performance;Formal verification;Software reliability;Performance evaluation;acceptance testing;architecture evaluation;adaptive;Agile;AI;artificial intelligence;component testing;concept documentation evaluation;COTS;criticality;criticality analysis;design evaluation;disposal plan evaluation;environmental verification and validation (V&V) factors;field programmable gate array;firmware;FPGA;hardware life cycle;hardware V&V;hardware verification and validation;hazard analysis;IEEE 1012;implementation evaluation;independent V&V;integration testing;integrity level;interface analysis;IV&V;machine learning;microcode;minimum V&V tasks;ML;nth of a kind;objective evidence;operating procedure evaluation;qualification testing;quality assurance;regression analysis;regression testing;requirements allocation analysis;requirements evaluation;reuse software;risk analysis;security analysis;software as a service;SaaS software life cycle;software quality assurance;software V&V;software verification and validation;source code documentation evaluation;source code evaluation;SQA;stakeholder needs and requirements evaluation;system element interaction analysis;system life cycle;system maintenance strategy assessment;system of interest;system requirements evaluation;system V&V;system verification and validation;testing;traceability analysis;V&V;V&V measures;validation;verification;vignette},
  doi={},
  ISSN={},
  month={May}
}

@ARTICLE{10488899,
  author={Hatton, Les},
  journal={Computer}, 
  title={Dependability Improvement Depends on Dependable Measurement}, 
  year={2024},
  volume={57},
  number={4},
  pages={57-67},
  abstract={If computing is ever to be considered dependable by all its stakeholders, both computer scientists and computer users, we must address the most fundamental aspect of process improvement, that of measurement. As currently practiced, it is wholly and demonstrably inadequate.},
  keywords={Stakeholders},
  doi={10.1109/MC.2023.3326947},
  ISSN={1558-0814},
  month={April}
}

@ARTICLE{10869359,
  author={Wu, Sifan and Zhang, Hongzhe and Liu, Zhenguang and Chen, Haipeng and Jiao, Yingying},
  journal={IEEE Internet of Things Journal}, 
  title={Enhancing Human Pose Estimation in the Internet of Things via Diffusion Generative Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={With the ongoing development of public video surveillance technology, accurate human pose estimation is becoming increasingly important in urban administration and law enforcement. However, existing methods rely on large-scale dense annotations, which are labor-intensive and time-consuming. To tackle this, we propose SparsePose which leverages training videos with sparse annotations (labeled every k frames) to learn to propagate temporal poses that help to estimate the poses in unlabeled frames. Technically, we engage in a novel dual-branch architecture that combines 1) pose forecasting of the consecutive neighboring frames with 2) visual clues of the current frame and the nearest labeled frames. We theoretically derive the intra-branch and inter-branch mutual information loss to supervise that maximized pose-relevant features are extracted from the current frame and different branches complement each other to approach precise pose estimation. Additionally, we propose a diffusion generative enhancement, which improves the robustness of the model to challenging scenes from the perspective of diversity. Empirical results show that our method significantly outperforms the state-of-the-art methods in sparsely labeled pose estimation on three benchmark datasets.},
  keywords={Pose estimation;Internet of Things;Heating systems;Annotations;Mutual information;Cameras;Visualization;Streaming media;Behavioral sciences;Accuracy;Human pose estimation;multi-person;sparsely-labeled;mutual information},
  doi={10.1109/JIOT.2025.3529917},
  ISSN={2327-4662},
  month={}
}

@INPROCEEDINGS{10825802,
  author={Rababah, Baha and Wu, Shang Tommy and Kwiatkowski, Matthew and Leung, Carson K. and Akcora, Cuneyt Gurcan},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={Are Existing Large Language Models Robust Against Jailbreak Attacks?}, 
  year={2024},
  volume={},
  number={},
  pages={5383-5391},
  abstract={The safety and robustness of Large Language Models (LLMs) are major challenges in developing generative AI applications. One key issue is the vulnerability to prompt jailbreak attacks, which pose a significant threat to building secure and resilient LLM-based applications. In this work, we present a framework for understanding and evaluating the behaviors of popular LLMs by categorizing their responses into five distinct exposure levels. Additionally, we introduce a novel language attack that circumvents LLMs’ defenses by translating jailbreak prompts into languages such as Arabic, Chinese, and Greek. Despite ongoing efforts to enhance LLMs’ safety, we find that nearly all popular LLMs can be jailbroken. Our findings offer detailed insights into LLMs’ behavior, improve diagnostic capabilities, and support targeted safety improvements.},
  keywords={Translation;Accuracy;Generative AI;Large language models;Buildings;Big Data;Robustness;Safety;Multilingual;LLMs;Prompt Jailbreak;Multilingual Jailbreak},
  doi={10.1109/BigData62323.2024.10825802},
  ISSN={2573-2978},
  month={Dec}
}
