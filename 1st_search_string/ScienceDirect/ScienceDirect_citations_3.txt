Usman Amjad, Asif Raza, Muhammad Fahad, Doaa Farid, Adnan Akhunzada, Muhammad Abubakar, Hira Beenish,
Context aware machine learning techniques for brain tumor classification and detection – A review,
Heliyon,
Volume 11, Issue 2,
2025,
e41835,
ISSN 2405-8440,
https://doi.org/10.1016/j.heliyon.2025.e41835.
(https://www.sciencedirect.com/science/article/pii/S2405844025002154)
Abstract: Background
Machine learning has tremendous potential in acute medical care, particularly in the field of precise medical diagnosis, prediction, and classification of brain tumors. Malignant gliomas, due to their aggressive growth and dismal prognosis, stand out among various brain tumor types. Recent advancements in understanding the genetic abnormalities that underlie these tumors have shed light on their histo-pathological and biological characteristics, which support in better classification and prognosis.
Objectives
This review aims to predict gene alterations and establish structured correlations among various tumor types, extending the prediction of genetic mutations and structures using the latest machine learning techniques. Specifically, it focuses on multi-modalities of Magnetic Resonance Imaging (MRI) and histopathology, utilizing Convolutional Neural Networks (CNN) for image processing and analysis.
Methods
The review encompasses the most recent developments in MRI, and histology image processing methods across multiple tumor classes, including Glioma, Meningioma, Pituitary, Oligodendroglioma, and Astrocytoma. It identifies challenges in tumor classification, segmentation, datasets, and modalities, employing various neural network architectures. A competitive analysis assesses the performance of CNN. Furthermore it also implies K-MEANS clustering to predict Genetic structure, Genes Clusters prediction and Molecular Alteration of various types and grades of tumors e.g. Glioma, Meningioma, Pituitary, Oligodendroglioma, and Astrocytoma.
Results
CNN and KNN structures, with their ability to extract highlights in image-based information, prove effective in tumor classification and segmentation, surmounting challenges in image analysis. Competitive analysis reveals that CNN and outperform others algorithms on publicly available datasets, suggesting their potential for precise tumor diagnosis and treatment planning.
Conclusion
Machine learning, especially through CNN and SVM algorithms, demonstrates significant potential in the accurate diagnosis and classification of brain tumors based on imaging and histo-pathological data. Further advancements in this area hold promise for improving the accuracy and efficiency of intra-operative tumor diagnosis and treatment.
Keywords: CNN; MRI; Survival prediction; Tumor segmentation; Histology; Deep learning; Machine learning; K-MEANS clustering

Helisa Dhamo, Keisuke Tateno, Iro Laina, Nassir Navab, Federico Tombari,
Peeking behind objects: Layered depth prediction from a single image,
Pattern Recognition Letters,
Volume 125,
2019,
Pages 333-340,
ISSN 0167-8655,
https://doi.org/10.1016/j.patrec.2019.05.007.
(https://www.sciencedirect.com/science/article/pii/S0167865518307062)
Abstract: While conventional depth estimation can infer the geometry of a scene from a single RGB image, it fails to estimate scene regions that are occluded by foreground objects. This limits the use of depth prediction in augmented and virtual reality applications, that aim at scene exploration by synthesizing the scene from a different vantage point, or at diminished reality. To address this issue, we shift the focus from conventional depth map prediction to the regression of a specific data representation called Layered Depth Image (LDI), which contains information about the occluded regions in the reference frame and can fill in occlusion gaps in case of small view changes. We propose a novel approach based on Convolutional Neural Networks (CNNs) to jointly predict depth maps and foreground separation masks used to condition Generative Adversarial Networks (GANs) for hallucinating plausible color and depths in the initially occluded areas. We demonstrate the effectiveness of our approach for novel scene view synthesis from a single image.
Keywords: Layered depth image; RGB-D inpainting; Generative adversarial networks; Occlusion

Linda Nene, Brian Thabile Flepisi, Sarel Jacobus Brand, Charlise Basson, Marissa Balmith,
Evolution of Drug Development and Regulatory Affairs: The Demonstrated Power of Artificial Intelligence,
Clinical Therapeutics,
Volume 46, Issue 8,
2024,
Pages e6-e14,
ISSN 0149-2918,
https://doi.org/10.1016/j.clinthera.2024.05.012.
(https://www.sciencedirect.com/science/article/pii/S0149291824001383)
Abstract: Purpose
Artificial intelligence (AI) refers to technology capable of mimicking human cognitive functions and has important applications across all sectors and industries, including drug development. This has considerable implications for the regulation of drug development processes, as it is expected to transform both the way drugs are brought to market and the systems through which this process is controlled. There is currently insufficient evidence in published literature of the real-world applications of AI. Therefore, this narrative review investigated, collated, and elucidated the applications of AI in drug development and its regulatory processes.
Methods
A narrative review was conducted to ascertain the role of AI in streamlining drug development and regulatory processes.
Findings
The findings of this review revealed that machine learning or deep learning, natural language processing, and robotic process automation were favored applications of AI. Each of them had considerable implications on the operations they were intended to support. Overall, the AI tools facilitated access and provided manageability of information for decision-making across the drug development lifecycle. However, the findings also indicate that additional work is required by regulatory authorities to set out appropriate guidance on applications of the technology, which has critical implications for safety, regulatory process workflow and product development costs.
Implications
AI has adequately proven its utility in drug development, prompting further investigations into the translational value of its utility based on cost and time saved for the delivery of essential drugs.
Keywords: Artificial intelligence; Drug development; Regulatory affairs; Machine learning; Natural language processing; Deep learning

Narendra Singh, Somanath Tripathy,
Unveiling the veiled: An early stage detection of fileless malware,
Computers & Security,
Volume 150,
2025,
104231,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.104231.
(https://www.sciencedirect.com/science/article/pii/S0167404824005376)
Abstract: The threat actors continuously evolve their tactics and techniques in a novel form to evade traditional security solutions. Fileless malware attacks are one such advancement, which operates directly within system memory, leaving no footprint on the disk, so became challenging to detect. Meanwhile, the current state-of-the-art approaches detect fileless attacks at the final (post-infection) stage, although, detecting attacks at an early-stage is crucial to prevent potential damage and data breaches. In this work, we propose an early-stage detection system named Argus to detect fileless malware at early-stage. Argus extracts key features from acquired memory dumps of suspicious processes in real-time and generates explained features. It then correlates the explained features with the MITRE ATT&CK (Adversarial Tactics, Techniques, and Common Knowledge) framework to identify fileless malware attacks before their operational stage. The experimental results show that Argus could successfully identify, 4356 fileless malware samples (out of 5026 samples) during the operational stage. Specifically, 2978 samples are detected in the pre-operational phase, while 1378 samples are detected in the operational phase.
Keywords: Fileless malware attack; Memory analysis; Early stage detection; MITRE ATT&CK enterprise matrix

Elena Ancona, Diego Guerra, Steven Armstrong, Henrique Oliveira da Mata, Claudia Medeiros, Jaime Silva, Eric Dahlstrom,
Technical Aspects of an International Space Traffic Management Framework,
Acta Astronautica,
2025,
,
ISSN 0094-5765,
https://doi.org/10.1016/j.actaastro.2025.02.028.
(https://www.sciencedirect.com/science/article/pii/S0094576525001092)
Abstract: As part of the International Space University (ISU) Space Studies Program (SSP) 2023 Team Project on Space Situational Awareness (SSA), a group of students, researchers, and professionals with a very diverse background, focused on proposing a global framework for Space Traffic Management (STM) [1, 2]. Present statistics indicate that more than 7,000 operational satellites coexist within the same orbital regime, together with more than 36,500 medium-sized trackable fragments of space debris. Following the last few years big constellations' deployment, and considering the ones that are scheduled for launch soon, the way satellites operations were carried out is rapidly becoming obsolete. This situation substantially increases the threat of potential collisions, emphasizing the necessity for an open and internationally coordinated STM framework. This paper introduces an international framework derived from the research conducted by Murakami et al. in 2019 [3]. It offers a comprehensive approach to addressing the STM challenges, with a particular emphasis on fostering precise data exchange, establishing channels for clear and direct communication, and encouraging international collaboration. In the current work, after some considerations on the policy and legal aspects of our proposed international framework, we present the technical features and provide a broader perspective on the reasons that led to its definition. In our analysis, we considered the vibrant scenario involving new commercial actors offering Space Surveillance and Tracking (SST) services, collision risk prediction, recommendations for Collision Avoidance (CA) manoeuvres, and autonomous CA systems. The authors of this work believe that the variety and complexity of this ecosystem can only be beneficial, and by no means is the proposed framework intended to substitute those players. Instead, its goal is to fill the gaps where the current system would be incomplete. As multiple entities offer insights into space traffic and predict potential collisions among space objects, determining the most dependable source becomes a challenge when significant inconsistencies arise. Still being aware of these challenges, we want to foster collaboration within the evolving New Space landscape. Our proposed framework is designed to integrate existing suppliers rather than replace them, allowing for the seamless inclusion of their data within our system. These suppliers can continue to run their independent analysis and operations while also be contributing to, and benefiting from, the enhanced functionality within our unified system.
Keywords: Space Traffic Management; Collision Avoidance; International Framework; Space Situational Awareness

Courtney L. Wilt, Subini A. Annamma, Jennifer M. Wilmot, Sylvia N. Nyegenye, Amanda L. Miller, Elizabeth E. Jackson,
Performing color-evasiveness: A DisCrit analysis of educators’ discourse in the U.S.,
Teaching and Teacher Education,
Volume 117,
2022,
103761,
ISSN 0742-051X,
https://doi.org/10.1016/j.tate.2022.103761.
(https://www.sciencedirect.com/science/article/pii/S0742051X22001354)
Abstract: This study explores how an ideology of color-evasive racism (i.e., color evasiveness; Annamma et al., 2017) imbued white educators' discourse surrounding intersectional inequities in schools for Girls of Color in the U.S. Our analysis of interview and focus group data addresses a gap in educational research identifying color-evasive racism in discourse by in-service educators, specifically for white educators making sense of inequities in schools. We draw from Bonilla-Silva's (2018) application of color-blindness to discourse to identify three specific discursive frames that white educators employ, namely 1) centering self, 2) claiming white racial innocence, and 3) employing progressive notions, and the discursive tools within each. This focus on white educators' discourse expands understandings of how color-evasivene racism is employed, (re)producing intersectional inequities in education. Given that each of these educators was nominated because of their strengths working with Girls of Color, we believe this paper's significance captures the complexities of teaching in a system of white supremacy and identifies underlying ideologies animating discourse that can be disrupted through a Disability Critical Race Theory (DisCrit) lens.
Keywords: DisCrit; Discourse; White educators; Color-blindness; Color-evasive racism

Jun Wang, Xingyu Yan,
The role of trademark rights expansion in the formation and abuse of market power,
International Review of Economics & Finance,
Volume 95,
2024,
103496,
ISSN 1059-0560,
https://doi.org/10.1016/j.iref.2024.103496.
(https://www.sciencedirect.com/science/article/pii/S105905602400488X)
Abstract: Trademarks play a critical role in the creation and abuse of market power, in the sense that when expansively protected, trademark rights yield legal advantages that can be leveraged to lock in consumers and raise entry barriers. But this role has long been underestimated or even overlooked. Based on empirical research and qualitative case analysis, we find that the legal advantages created by the expansion of trademark rights are a key factor in the formation of firms’ market power in product domains with a high degree of information asymmetry. In situations where firms have market power, the geographical and cross-category expansion of trademark rights can enable and rationalize the implementation of abusive practices such as price discrimination and tying. Limiting the anti-competitive effects of the expansion of trademark rights requires the combined efforts of ex post antitrust and ex ante regulation.
Keywords: Expansion of trademark rights; Market power; Antitrust; Differential treatment; Tied sales

Matthias Brucklacher, Giovanni Pezzulo, Francesco Mannella, Gaspare Galati, Cyriel M.A. Pennartz,
Learning to segment self-generated from externally caused optic flow through sensorimotor mismatch circuits,
Neural Networks,
Volume 181,
2025,
106716,
ISSN 0893-6080,
https://doi.org/10.1016/j.neunet.2024.106716.
(https://www.sciencedirect.com/science/article/pii/S0893608024006403)
Abstract: Efficient sensory detection requires the capacity to ignore task-irrelevant information, for example when optic flow patterns created by egomotion need to be disentangled from object perception. To investigate how this is achieved in the visual system, predictive coding with sensorimotor mismatch detection is an attractive starting point. Indeed, experimental evidence for sensorimotor mismatch signals in early visual areas exists, but it is not understood how they are integrated into cortical networks that perform input segmentation and categorization. Our model advances a biologically plausible solution by extending predictive coding models with the ability to distinguish self-generated from externally caused optic flow. We first show that a simple three neuron circuit produces experience-dependent sensorimotor mismatch responses, in agreement with calcium imaging data from mice. This microcircuit is then integrated into a neural network with two generative streams. The motor-to-visual stream consists of parallel microcircuits between motor and visual areas and learns to spatially predict optic flow resulting from self-motion. The second stream bidirectionally connects a motion-selective higher visual area (mHVA) to V1, assigning a crucial role to the abundant feedback connections to V1: the maintenance of a generative model of externally caused optic flow. In the model, area mHVA learns to segment moving objects from the background, and facilitates object categorization. Based on shared neurocomputational principles across species, the model also maps onto primate visual cortex. Our work extends Hebbian predictive coding to sensorimotor settings, in which the agent actively moves - and learns to predict the consequences of its own movements.
Keywords: Generative model; Object segmentation; Predictive coding; Optic flow; Sensorimotor

Chiara Braghin, Marco Cremonini,
Chapter 53 - Online Privacy,
Editor(s): John R. Vacca,
Computer and Information Security Handbook (Fourth Edition),
Morgan Kaufmann,
2025,
Pages 871-890,
ISBN 9780443132230,
https://doi.org/10.1016/B978-0-443-13223-0.00053-9.
(https://www.sciencedirect.com/science/article/pii/B9780443132230000539)
Abstract: Privacy is fading away from the online world, with powerful actors that have worked to invade everyone's privacy for commercial and surveillance purposes. However, limiting the analysis on the role of those actors is overly simplistic because the state of online privacy is the result of many different contributions and an historical trend. In this chapter, we analyze several facets of the lack of online privacy, some idiosyncrasies exhibited by privacy advocates, together with characteristics of the industry mostly responsible of massive data collecting. An issue not sufficiently debated is the asserted effectiveness of data-centered predictive technologies, which should be openly inquired. We also introduce the prevalent market-oriented assumption and individualistic approach at the base of online privacy. The regulatory approach to online privacy is also considered. EU's GDPR is commonly considered the reference case of modern privacy regulations, but its success hinders critical aspects that require a close examination, from the quirks of the institutional decision process, to the flaws of the informed consent principle. A glimpse on the likely problematic future is provided with a discussion on privacy related aspects of European Union, United Kingdom, and China's proposed generative AI policies. The last part of this chapter is dedicated to discuss some privacy technologies, their ambitious goals, the actual effectiveness, and the limitations, which often have been severely underestimated. There is no technical silver bullet for privacy and it seems highly unlikely that it could ever exist, because it is too multifaceted as a problem, often contradictory, strained between contrasting interests.
Keywords: Cookies; Data protection; Generative AI; Informed consent; Online privacy; Predictive technology; Regulations; Surveillance; Web tracking

Natali Helberger,
The rise of technology courts, or: How technology companies re-invent adjudication for a digital world,
Computer Law & Security Review,
Volume 56,
2025,
106118,
ISSN 2212-473X,
https://doi.org/10.1016/j.clsr.2025.106118.
(https://www.sciencedirect.com/science/article/pii/S0267364925000135)
Abstract: The article “The Rise of Technology Courts” explores the evolving role of courts in the digital world, where technological advancements and artificial intelligence (AI) are transforming traditional adjudication processes. It argues that traditional courts are undergoing a significant transition due to digitization and the increasing influence of technology companies. The paper frames this transformation through the concept of the “sphere of the digital,” which explains how digital technology and AI redefine societal expectations of what courts should be and how they function. The article highlights that technology is not only changing the materiality of courts—moving from physical buildings to digital portals—but also affecting their symbolic function as public institutions. It discusses the emergence of AI-powered judicial services, online dispute resolution (ODR), and technology-driven alternative adjudication bodies like the Meta Oversight Board. These developments challenge the traditional notions of judicial authority, jurisdiction, and legal expertise. The paper concludes that while these technology-driven solutions offer increased efficiency and accessibility, they also raise fundamental questions about the legitimacy, transparency, and independence of adjudicatory bodies. As technology companies continue to shape digital justice, the article also argues that there are lessons to learn for the role and structure of traditional courts to ensure that human rights and public values are upheld.
Keywords: Digitisation; AI; Justice; Courts; Big Tech; Digital transformation; Values

Olena Golembovska, Vyacheslav Kharchenko,
Technologies of Interactive Art,
Editor(s): David Baker, Lucy Ellis,
Encyclopedia of Libraries, Librarianship, and Information Science (First Edition),
Academic Press,
2025,
Pages 506-527,
ISBN 9780323956901,
https://doi.org/10.1016/B978-0-323-95689-5.00152-8.
(https://www.sciencedirect.com/science/article/pii/B9780323956895001528)
Abstract: The entry is devoted to interactive art and information technologies, the role of IT in creating new types of art, the authors of which are not only artists or creators, but also viewers. This becomes a new and important trend of modern types of interactive art, making it more democratic and insightful, accessible, and independent, flexible, and unpredictable, which is life itself. The entry provides a detailed definition of the main concepts for IT supported interactive art and its varieties and presents the types of IT used to create art objects. Cases of using IT in interactive art are presented on the example of the "Smart Gallery of Abstract Painting" project demonstrating the possibilities of using AR in abstract painting to create interactive paintings. New challenges and possibilities of Aritificial Intelligence and Augmented Reaility technologies application for development interactive art are discussed.
Keywords: Abstract painting; Artificial intelligence; Augmented and virtual reality; Big Data; Digital media; Information technologies; Interactive art; Internet of Things

Kamran Niroomand, Noori M. Cata Saady, Carlos Bazan, Sohrab Zendehboudi, Amilcar Soares, Talib M. Albayati,
Smart investigation of artificial intelligence in renewable energy system technologies by natural language processing: Insightful pattern for decision-makers,
Engineering Applications of Artificial Intelligence,
Volume 126, Part A,
2023,
106848,
ISSN 0952-1976,
https://doi.org/10.1016/j.engappai.2023.106848.
(https://www.sciencedirect.com/science/article/pii/S0952197623010321)
Abstract: This study aims to provide a framework which enables decision-makers and researchers to identify AI technology patterns in renewable energy systems from a massive data set of textual data. However, the study was challenged by the Scopus database limitation that allows users to retrieve only 2000 documents per query. Therefore, we developed a search engine based on the Scopus Application Programming Interface (API) that enables us to download an unlimited number of documents per query based on our desirable settings. We extracted 5661 renewable energy systems-related publications from Scopus database and leveraged Natural Language Processing (NLP) and unsupervised algorithms to identify the most frequent computational science models and dense meta-topics and investigate their evolution throughout the period 2000-2021. Our findings showed 7 meta-topics based on the class-based Term Frequency-Inverse Document Frequency (c-TD-IDF) score and term score decline graph. Emerging advanced algorithms, such as different deep learning architectures, directly impacted growing meta-topics involving problems with uncertainty and dynamic conditions.
Keywords: Natural language processing; Artificial intelligence; Text mining; Topic modeling; Pattern identification; Renewable energy

Celso Cancela-Outeda,
The EU's AI act: A framework for collaborative governance,
Internet of Things,
Volume 27,
2024,
101291,
ISSN 2542-6605,
https://doi.org/10.1016/j.iot.2024.101291.
(https://www.sciencedirect.com/science/article/pii/S2542660524002324)
Abstract: In February 2024, the Council and the European Parliament (EP) agreed on the Artificial Intelligence Regulation (usually known as AI Act, AIA) .22We use the AI Act version P9_TA(2024)0138 Artificial Intelligence Act European Parliament legislative resolution of 13 March 2024 on the proposal for a regulation of the European Parliament and of the Council on laying down harmonised rules on Artificial Intelligence (Artificial Intelligence Act) and amending certain Union Legislative Acts (COM(2021)0206–C9-0146/2021–2021/0106(COD)). https://www.europarl.europa.eu/doceo/document/TA-9-2024-0138_EN.pdf This regulation evaluates AI applications to ensure they are used ethically and responsibly, promoting the development of safe and lawful AI across the EU's single market. It establishes a comprehensive legal framework with a risk-based approach, aiming to achieve a balance between protecting the health, safety, and fundamental rights of European citizens and ensuring that the growing AI industry in Europe remains competitive and continues to innovate. The AIA also includes governance mechanisms oriented towards achieving effective implementation throughout the EU. For this purpose, a European Artificial Intelligence Office has already been established. In accordance with the provisions of the forthcoming AIA, it will establish a European Artificial Intelligence Board, an advisory forum, and a scientific panel. Furthermore, it will be set up at the national level the so-called national competent authorities. In this way, a single European governance system for AI is emerging, inspired by collaborative governance, which is essential for achieving fair and effective implementation of AI regulations across the EU. The main objective of this text is to critically examine the governance system established by the AIA. Using the contents of the current version of the AIA (April 2024), this analysis delves into the mechanisms and structures designed to implement AI across the EU. As a conclusion, it offers a critical perspective on the collaborative governance, highlighting its strengths and potential areas for improvement.
Keywords: Popularization; Civil society; Stakeholders; Governance; “black box”; Collaborative logic

Djavan De Clercq, Zongguo Wen, Qingbin Song,
Innovation hotspots in food waste treatment, biogas, and anaerobic digestion technology: A natural language processing approach,
Science of The Total Environment,
Volume 673,
2019,
Pages 402-413,
ISSN 0048-9697,
https://doi.org/10.1016/j.scitotenv.2019.04.051.
(https://www.sciencedirect.com/science/article/pii/S0048969719315700)
Abstract: The objective of this study is to apply natural language processing to identifying innovative technology trends related to food waste treatment, biogas, and anaerobic digestion. The methodology used involved analyzing large volumes of text data mined from 3186 patents related to these three fields. Latent Dirichlet Allocation and the perplexity method were used to identify the main topics which the patent corpora were comprised of and which technological concepts were most associated with each topic. In addition, term frequency-inverse document frequency (TF-IDF) was used to gauge the “emergingness” of certain technical concepts across the patent corpora in various years. The key results were as follows: (1) perplexity computations showed that a 20 topic models were feasible for these patent corpora; (2) topics were identified, providing an accurate picture of the patenting landscape in the analyzed fields; (3) TF-IDF analysis on unigrams, bigrams, and trigrams, supplemented with network graph analysis, revealed emerging technology trends in each year. This study has important implications for governments who need to decide where to invest resources in anaerobic food waste treatment.
Keywords: Natural language processing; Latent Dirichlet Allocation; TF-IDF; Food waste; Biogas; Anaerobic digestion

Ruadan Geraghty, Jasper Graham-Jones, Richard Pemberton, John Summerscales, Simon Bray,
Sustainability considerations for end-of-life fibre-reinforced plastic boats,
Regional Studies in Marine Science,
Volume 83,
2025,
104054,
ISSN 2352-4855,
https://doi.org/10.1016/j.rsma.2025.104054.
(https://www.sciencedirect.com/science/article/pii/S2352485525000453)
Abstract: In the 1950s, glass fibre-reinforced polyester resin (GRP, also known as fibreglass or glassfibre) composites replaced wood and metal as the material for small recreational and work boats. The changes resulted from relative ease of manufacture, durability, and low maintenance. New fibres and resins then became available to create a wider range of Fibre-Reinforced Plastics (FRP). Vessels remain serviceable beyond design life: 10 years for inflatables, 20 years for motorboats and 30 years plus for sailboats. Many vessels have now reached end-of-life (EoL) and become Abandoned or Derelict Vessels (ADV). Given that thermosetting resin is not easy to recycle, these boats exist as slowly rotting hulks. There is a growing cohort of stakeholders from various backgrounds becoming concerned about this issue. This review defines sustainability as the balance of Technical, Economic, Environmental Social and Governance (TEESG) and discusses the TEESG considerations for this waste stream.
Keywords: Boats; Disposal; End-of-life; Fibre-reinforced plastic; FRP; GRP; Sustainability

Benjamin Phipps, Xavier Hadoux, Bin Sheng, J. Peter Campbell, T.Y.Alvin Liu, Pearse A. Keane, Carol Y. Cheung, Tham Yih Chung, Tien Y. Wong, Peter van Wijngaarden,
AI Image Generation Technology in Ophthalmology: Use, Misuse and Future Applications,
Progress in Retinal and Eye Research,
2025,
101353,
ISSN 1350-9462,
https://doi.org/10.1016/j.preteyeres.2025.101353.
(https://www.sciencedirect.com/science/article/pii/S1350946225000266)
Abstract: Background
AI-powered image generation technology holds the potential to dramatically reshape clinical ophthalmic practice. The adoption of this technology relies on clinician acceptance, yet it is an unfamiliar technology for both ophthalmic researchers and clinicians. In this work we present a literature review on the application of image generation technology in ophthalmology to discuss its theoretical applications and future role.
Methods
First, we explore the key model designs used for image synthesis, including generative adversarial networks, autoencoders, and diffusion models. We then perform a survey of the literature for image generation technology in ophthalmology prior to September 2024, collecting the type of model used, as well as its clinical application, for each study. Finally, we discuss the limitations of this technology, the risks of its misuse and the future directions of research in this field.
Results
Applications of this technology include improving diagnostic model performance, inter-modality image transformation, treatment and disease prognosis, image denoising, and education. Key challenges for integration of this technology into ophthalmic clinical practice include bias in generative models, risk to patient data security, computational and logistical barriers to model development, challenges with model explainability, inconsistent use of validation metrics between studies and misuse of synthetic images. Looking forward, researchers are placing a further emphasis on clinically grounded metrics, the development of image generation foundation models and the implementation of methods to ensure data provenance.
Conclusion
It is evident image generation technology has the potential to benefit the field of ophthalmology for many tasks, however, compared to other medical applications of AI, it is still in its infancy. This review aims to enable ophthalmic researchers to identify the optimal model and methodology to best take advantage of this technology.
Keywords: Generative AI; Artificial Intelligence; Deep Learning; Ophthalmology; Image Generation; Deep-fake; Generative Adversarial Networks; GAN; Autoencoders; Diffusion Models; Multimodal Ocular Imaging; AI diagnostic models; Data augmentation; Image Denoising; Bias in AI; Patient Data Security; Blockchain Authenticatiobn

Yisroel Mirsky, Ambra Demontis, Jaidip Kotak, Ram Shankar, Deng Gelei, Liu Yang, Xiangyu Zhang, Maura Pintor, Wenke Lee, Yuval Elovici, Battista Biggio,
The Threat of Offensive AI to Organizations,
Computers & Security,
Volume 124,
2023,
103006,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.103006.
(https://www.sciencedirect.com/science/article/pii/S0167404822003984)
Abstract: AI has provided us with the ability to automate tasks, extract information from vast amounts of data, and synthesize media that is nearly indistinguishable from the real thing. However, positive tools can also be used for negative purposes. In particular, cyber adversaries can use AI to enhance their attacks and expand their campaigns. Although offensive AI has been discussed in the past, there is a need to analyze and understand the threat in the context of organizations. For example, how does an AI-capable adversary impact the cyber kill chain? Does AI benefit the attacker more than the defender? What are the most significant AI threats facing organizations today and what will be their impact on the future? In this study, we explore the threat of offensive AI on organizations. First, we present the background and discuss how AI changes the adversary’s methods, strategies, goals, and overall attack model. Then, through a literature review, we identify 32 offensive AI capabilities which adversaries can use to enhance their attacks. Finally, through a panel survey spanning industry, government and academia, we rank the AI threats and provide insights on the adversaries.
Keywords: Offensive AI; APT; Cyber security; Organization security; Adversarial machine learning; Deepfake; AI-Capable adversary

Alexander Yevsikov, Trivikram Muralidharan, Tomer Panker, Nir Nissim,
CADefender: Detection of unknown malicious AutoLISP computer-aided design files using designated feature extraction and machine learning methods,
Engineering Applications of Artificial Intelligence,
Volume 138, Part B,
2024,
109414,
ISSN 0952-1976,
https://doi.org/10.1016/j.engappai.2024.109414.
(https://www.sciencedirect.com/science/article/pii/S0952197624015720)
Abstract: Computer-aided design (CAD) files are used to create digital designs for various structures – from the smallest chips in the high-tech industry to large-scale buildings and bridges in the civil engineering space. We found that most exploits and malicious payloads are deployed through Auto List Processing (AutoLISP) source code (LSP) or Fast Load AutoLISP (FAS) files, which are non-executable files (NEFs) containing scripts in the AutoLISP language that are native to AutoCAD; While antivirus software is capable of detecting many malicious CAD files, the potential to improve protection by using a dedicated machine learning (ML) based detection solution remains, especially against unknown and sophisticated CAD malware. In this study, we are the first to propose designated feature extraction methods and a robust framework aimed at the detection of known and unknown AutoLISP malware using ML algorithms. To accomplish this, we examined the structure, functionality, and ecosystems of AutoLISP files and collected the largest known representative collection of LSP files consisting of 6418 malicious and benign files (labeled and verified). We then explored the use of two novel static-analysis-based feature extraction methods (knowledge-based and structural) designated for LSP files to extract a discriminative set of informative features, which can subsequently be used by ML models to detect malicious LSP files. These two feature extraction methods serve as the basis of the proposed detection framework, whose performance we comprehensively compare to both widely used antiviruses and baseline ML models based on existing feature extraction methods, including MinHash, Bidirectional Encoder Representations from Transformers (BERT), and n-gram. Our results highlight our methods' contributions to the detection of unknown AutoLISP malware and demonstrate their ability to outperform existing methods. The best performance in the task of unknown malicious LSP file detection was obtained by the Artificial Neural Networks (ANN) model trained on 100 knowledge-based features, which obtained a true positive rate (TPR) of 99.49% with a false positive rate (FPR) of 0.57%. Our framework's role in explainability is also highlighted, as we also present the prominent features that contribute most to the model's detection capabilities; this information can be used for explainability purposes. We conclude by evaluating the proposed framework's ability to detect a malicious file from an unknown AutoLISP malware family and by evaluating our framework on an additional independent test set that originated from another source, scenarios that are often faced by malware detection solutions.
Keywords: Computer-aided design; Auto list processing; Machine learning; Malware detection; Feature extraction

R.N. Weerasinghe, A.K.W. Jayawardane, Qiubo Huang,
Critical inquiry on National Innovation System: Does NIS fit with developing countries?,
Sustainable Technology and Entrepreneurship,
Volume 3, Issue 1,
2024,
100052,
ISSN 2773-0328,
https://doi.org/10.1016/j.stae.2023.100052.
(https://www.sciencedirect.com/science/article/pii/S2773032823000159)
Abstract: Innovation is not only a random or accidental process. It requires a deliberate and systematic approach to enhance the innovation performance of a country. The concept of the National Innovation System (NIS) has provided a valuable framework for organizing and fostering innovation efforts across individuals, groups, and organizations within a country. While numerous studies on NIS have been carried out in developed countries, contributing to their socioeconomic progress and shaping effective policies, there is a significant disparity between developed and developing countries. Researchers have recognized the importance of studying NISs in developing countries and have highlighted the need for in-depth investigations into system configurations to generate valuable insights for policy formulation. This paper presents a conceptual model for conducting NIS studies in developing countries, derived from a critical review of existing literature. The proposed model serves as a guide for conducting comprehensive studies within the unique contexts of developing countries, focusing on the central core of NIS. Moreover, this study opens opportunities for future NIS-related research by identifying specific subsections of the overall NIS that warrant attention, while acknowledging the limitations faced by researchers. By adopting this conceptual model, researchers can delve into various aspects of the NIS in developing countries, facilitating a holistic understanding, and enabling the generation of impactful policy recommendations.
Keywords: National innovation system; Developing counties; Networking relationships; Innovation performance

Samradhi Singh, Mona Kriti, Anamika K.S, Poonam Sharma, Namarata Pal, Devojit Kumar Sarma, Rajnarayan Tiwari, Manoj Kumar,
A One Health Approach Addressing Poultry-Associated Antimicrobial Resistance: Human, Animal and Environmental Perspectives,
The Microbe,
2025,
100309,
ISSN 2950-1946,
https://doi.org/10.1016/j.microb.2025.100309.
(https://www.sciencedirect.com/science/article/pii/S2950194625000779)
Abstract: Antibiotics, often viewed as a solution, are now recognized as a double-edged sword due to their widespread and improper use. As the global demand for poultry products rises, antibiotics have become a seemingly indispensable tool to meet this need. However, while this practice addresses production demands, it leaves significant health concerns. The emergence of antibiotic-resistant bacteria (ARBs) and antibiotic-resistant genes (ARGs) marks the beginning of a series of unpredictable and potentially undefendable diseases. The topic of zoonosis has gained considerable attention recently, highlighting the intricate connections between humans, animals, and the environment. This review explores the specific impacts of antibiotics—particularly ARGs and ARBs—within the poultry industry, examining the driving factors behind their rise. By delving into the One Health concept, which underscores the interconnectedness of these three domains, the review also discusses innovative strategies to minimize antibiotic use in poultry farming which are vital for preventing and controlling zoonotic diseases, ensuring a healthier environment, and ultimately achieving optimal public health across all tiers of One Health.
Keywords: Poultry; Antibiotics; Antibiotic Resistance; ARG; Innovations

Ahmed Farouk Kineber, Atul Kumar Singh, Abdulwahed Fazeli, Saeed Reza Mohandes, Clara Cheung, Mehrdad Arashpour, Obuks Ejohwomu, Tarek Zayed,
Modelling the relationship between digital twins implementation barriers and sustainability pillars: Insights from building and construction sector,
Sustainable Cities and Society,
Volume 99,
2023,
104930,
ISSN 2210-6707,
https://doi.org/10.1016/j.scs.2023.104930.
(https://www.sciencedirect.com/science/article/pii/S2210670723005413)
Abstract: A Digital Twin (DT) is a digital copy of a real-world object or process. Although DT has gained traction in construction, its relationship with sustainable success remains insufficiently studied. This research addresses this gap by investigating barriers to implementing DT in sustainable construction. The study employs a hybrid approach involving literature review, expert interviews, and modeling techniques, with data collected from 108 construction experts based on a number of criteria, including the experience, degree, and familiarity of the experts about the Hong Kong building and construction sector Hong Kong. The findings reveal 45 barriers categorized into six clusters, including notable obstacles such as "legacy systems," "data uncertainties," and "connectivity." The key clusters identified are "performance" and "security," while the "social" aspect of sustainable success is least supported. Recognizing these challenges assists decision-makers in navigating obstacles and utilizing DT for environmentally conscious construction, streamlined processes, and positive societal impacts. Future research could delve into integrating sustainability throughout the project lifecycle using technology adoption theories.
Keywords: Digital twin; Sustainability; Sustainable construction; Overall sustainable success; Structural equation modelling

Zhen Ling Teo, Liyuan Jin, Nan Liu, Siqi Li, Di Miao, Xiaoman Zhang, Wei Yan Ng, Ting Fang Tan, Deborah Meixuan Lee, Kai Jie Chua, John Heng, Yong Liu, Rick Siow Mong Goh, Daniel Shu Wei Ting,
Federated machine learning in healthcare: A systematic review on clinical applications and technical architecture,
Cell Reports Medicine,
Volume 5, Issue 2,
2024,
101419,
ISSN 2666-3791,
https://doi.org/10.1016/j.xcrm.2024.101419.
(https://www.sciencedirect.com/science/article/pii/S2666379124000429)
Abstract: Summary
Federated learning (FL) is a distributed machine learning framework that is gaining traction in view of increasing health data privacy protection needs. By conducting a systematic review of FL applications in healthcare, we identify relevant articles in scientific, engineering, and medical journals in English up to August 31st, 2023. Out of a total of 22,693 articles under review, 612 articles are included in the final analysis. The majority of articles are proof-of-concepts studies, and only 5.2% are studies with real-life application of FL. Radiology and internal medicine are the most common specialties involved in FL. FL is robust to a variety of machine learning models and data types, with neural networks and medical imaging being the most common, respectively. We highlight the need to address the barriers to clinical translation and to assess its real-world impact in this new digital data-driven healthcare scene.
Keywords: federated learning; systematic review; artificial intelligence; healthcare

Pattharin Tangwaragorn, Nuttirudee Charoenruk, Wattana Viriyasitavat, Chatpong Tangmanee, Prasert Kanawattanachai, Danupol Hoonsopon, Vitara Pungpapong, Ra-Pee Pattanapanyasat, Sawitree Boonpatcharanon, Phoranee Rhuwadhana,
Analyzing key drivers of digital transformation: A review and framework,
Journal of Industrial Information Integration,
Volume 42,
2024,
100680,
ISSN 2452-414X,
https://doi.org/10.1016/j.jii.2024.100680.
(https://www.sciencedirect.com/science/article/pii/S2452414X24001237)
Abstract: In the digital era, comprehending the factors that drive digital transformation (DT) is crucial for organizations aiming to navigate the evolving technological landscape. This systematic review focuses on identifying and analyzing the key drivers of DT, drawing insights from 19 recognized DT readiness indexes. We examine the dimensions and indicators used across these indexes, highlighting their relevance and frequency of occurrence to uncover the primary factors influencing DT. The findings are synthesized into a comprehensive framework that offers strategic guidelines for organizations. This framework not only aids in understanding the core drivers of DT but also provides practical recommendations for implementing effective DT strategies. By emphasizing the critical drivers rather than the indexes themselves, our study shifts the focus towards actionable insights that can guide entities, policymakers, and academics in the digital transformation journey. The urgency of DT, further accelerated by the COVID-19 pandemic, enhances the relevance of our findings in shaping resilient and adaptable digital strategies.
Keywords: Digital transformation; Indicators; Systematic literature review (SLR); Survey

Jieshu Wang, José Lobo,
Extensive growth of inventions: Evidence from U.S. patenting,
Technological Forecasting and Social Change,
Volume 207,
2024,
123586,
ISSN 0040-1625,
https://doi.org/10.1016/j.techfore.2024.123586.
(https://www.sciencedirect.com/science/article/pii/S0040162524003822)
Abstract: Despite the seemingly fast development and wide diffusion of technologies in recent decades, concerns have been raised as to whether invention is slowing down. A question has also arisen as to whether the vast accumulation of technical knowledge, instead of speeding up the productivity of subsequent knowledge creation, has, on the contrary, become a “burden of knowledge” that makes it harder to find new ideas. We engage with these concerns by examining nearly 7 million utility patents granted by the U.S. Patent Office and characterizing the growth process of patenting from 1976 to 2018. Although the rate of patenting has steadily increased, patenting productivity as measured as patents per distinct inventor has continuously declined in utility patents in general and for technological frontier fields of biotechnology, climate change mitigation and adaptation, and artificial intelligence. The rapid growth rate of new patents can be credited to an increase in the number of individuals engaged in inventive activity rather than improved productivity. In the U.S., the proportion of the population engaging in patenting has grown significantly. Nevertheless, the growth of the inventive labor force and new patents relies more heavily on experienced inventors than new inventors. As the size of patenting teams keeps growing, the typical inventor participates in a growing number of patents while representing a declining proportion of the inventive labor responsible for patented inventions. We find evidence that as the stock of accumulated patented inventions grows, patenting productivity declines, suggesting that past invention makes it harder for inventors to find new knowledge. In the language of economics, invention (as tracked by patenting) has experienced extensive growth driven by the increase of the inventive labor force with declining productivity and a growing division of labor.
Keywords: Invention; Patenting; Growth; Productivity

Pyry Kotilainen, Niko Mäkitalo, Kari Systä, Ali Mehraj, Muhammad Waseem, Tommi Mikkonen, Juan Manuel Murillo,
Allocating distributed AI/ML applications to cloud–edge continuum based on privacy, regulatory, and ethical constraints,
Journal of Systems and Software,
Volume 222,
2025,
112333,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2025.112333.
(https://www.sciencedirect.com/science/article/pii/S0164121225000019)
Abstract: There is an increasing need for practitioners to address legislative and ethical issues in both the development and deployment of data-driven applications with AI/ML due to growing concerns and regulations, such as GDPR and the EU AI Act. Thus, the field needs a systematic framework for assessing risks and helping to stay compliant with regulations in designing and deploying software systems. Clear and concise descriptions of risks associated with each model and data source are needed to guide the design without acquiring deep knowledge of the regulations. In this paper, we propose a reference architecture for an ethical orchestration system that manages distributed AI/ML applications on the cloud–edge continuum and present a proof-of-concept implementation of the main ideas of the architecture. Our starting point is the methods already in use in the industry, such as model cards, and we extend the idea of model cards to data source cards and software component cards, which provide practitioners and the automated system with relevant information in actionable form. With the metadata card based orchestration system and information about the risk levels of the target infrastructure, the users can create deployments of distributed AI/ML systems that fulfill the regulatory and other requirements.
Keywords: Internet of Things; IoT; Cloud computing; Model cards; Ethical orchestration; Orchestration; Artificial Intelligence; AI; Ethics; Compliance; Privacy; AI regulation

Thomas Wilhelm,
Chapter 12 - Actions on Objectives,
Editor(s): Thomas Wilhelm,
Professional Penetration Testing (Third Edition),
Syngress,
2025,
Pages 359-386,
ISBN 9780443264788,
https://doi.org/10.1016/B978-0-443-26478-8.00013-3.
(https://www.sciencedirect.com/science/article/pii/B9780443264788000133)
Abstract: The actions on objectives stage within the Cyber Kill Chain is where professional penetration testers exfiltrate data with the intent of finding sensitive information that satisfies the objectives of the engagement or allows them to pivot onto additional, more impactful systems. Exfiltration of data includes configuration information on installed programs and services, user information, administrative credentials, infrastructure data, and more. Artificial Intelligence is a new tool being leveraged by professional pentesters to assist in identifying optimum attack vectors. Still in its infancy, Large Language Models (LLMs) are being designed specifically for the pentesting community, using new datasets designed to train the language models. Although their accuracy is comparable to current vulnerability scanners and other similar tools, there is an expectation that in time, LLMs will surpass their capabilities.
Keywords: Infrastructure analysis; data exfiltration; high-value targets sensitive data artificial intelligence large language models chatGPT

Ali Hassan, N. Nizam-Uddin, Asim Quddus, Syed Rizwan Hassan, Ateeq Ur Rehman, Salil Bharany,
Navigating IoT Security: Insights into Architecture, Key Security Features, Attacks, Current Challenges and AI-Driven Solutions Shaping the Future of Connectivity,
Computers, Materials and Continua,
Volume 81, Issue 3,
2024,
Pages 3499-3559,
ISSN 1546-2218,
https://doi.org/10.32604/cmc.2024.057877.
(https://www.sciencedirect.com/science/article/pii/S1546221824008609)
Abstract: Enhancing the interconnection of devices and systems, the Internet of Things (IoT) is a paradigm-shifting technology. IoT security concerns are still a substantial concern despite its extraordinary advantages. This paper offers an extensive review of IoT security, emphasizing the technology’s architecture, important security elements, and common attacks. It highlights how important artificial intelligence (AI) is to bolstering IoT security, especially when it comes to addressing risks at different IoT architecture layers. We systematically examined current mitigation strategies and their effectiveness, highlighting contemporary challenges with practical solutions and case studies from a range of industries, such as healthcare, smart homes, and industrial IoT. Our results highlight the importance of AI methods that are lightweight and improve security without compromising the limited resources of devices and computational capability. IoT networks can ensure operational efficiency and resilience by proactively identifying and countering security risks by utilizing machine learning capabilities. This study provides a comprehensive guide for practitioners and researchers aiming to understand the intricate connection between IoT, security challenges, and AI-driven solutions.
Keywords: Internet of Things (IoT); artificial intelligence (AI); IoT architecture; security; attacks in IoT

Xuyu Xiang, Yang Tan, Jiaohua Qin, Yun Tan,
Advancements and challenges in coverless image steganography: A survey,
Signal Processing,
Volume 228,
2025,
109761,
ISSN 0165-1684,
https://doi.org/10.1016/j.sigpro.2024.109761.
(https://www.sciencedirect.com/science/article/pii/S0165168424003815)
Abstract: Coverless image steganography has emerged as a significant research direction in the field of steganography in recent years. Unlike traditional image steganography, it does not require modifying the cover image to achieve information hiding. This review aims to systematically summarize the research progress and challenges in coverless image steganography. Firstly, the paper introduces the basic principles and classification methods of coverless image steganography, including embedding methods based on low-level image features and those combining advanced semantic features from deep learning. Secondly, it discusses key research achievements in this field, such as novel embedding algorithms, efficient extraction methods, and robustness enhancement techniques against various attacks. Additionally, the review highlights major challenges faced by current coverless image steganography, including difficulties in secret information extraction, capacity limitations, and practicality issues, and explores potential solutions and future research directions. Through comprehensive analysis of existing literature, the review aims to provide researchers with a holistic perspective, fostering further development and application of coverless image steganography. The paper includes 124 key contributions, offering a comprehensive overview of coverless image steganography, covering its fundamental principles, research progress, challenges, and solutions.
Keywords: Information security; Information hiding; Steganography; Coverless steganography

Lydia Neary-Zajiczek, Clara Essmann, Anita Rau, Sophia Bano, Neil Clancy, Marnix Jansen, Lauren Heptinstall, Elena Miranda, Amir Gander, Vijay Pawar, Delmiro Fernandez-Reyes, Michael Shaw, Brian Davidson, Danail Stoyanov,
Stain-free identification of tissue pathology using a generative adversarial network to infer nanomechanical signatures††Electronic supplementary information (ESI) available. See DOI: 10.1039/d1na00527h,
Nanoscale Advances,
Volume 3, Issue 22,
2021,
Pages 6403-6414,
ISSN 2516-0230,
https://doi.org/10.1039/d1na00527h.
(https://www.sciencedirect.com/science/article/pii/S2516023023007311)
Abstract: ABSTRACT
Intraoperative frozen section analysis can be used to improve the accuracy of tumour margin estimation during cancer resection surgery through rapid processing and pathological assessment of excised tissue. Its applicability is limited in some cases due to the additional risks associated with prolonged surgery, largely from the time-consuming staining procedure. Our work uses a measurable property of bulk tissue to bypass the staining process: as tumour cells proliferate, they influence the surrounding extra-cellular matrix, and the resulting change in elastic modulus provides a signature of the underlying pathology. In this work we accurately localise atomic force microscopy measurements of human liver tissue samples and train a generative adversarial network to infer elastic modulus from low-resolution images of unstained tissue sections. Pathology is predicted through unsupervised clustering of parameters characterizing the distributions of inferred values, achieving 89% accuracy for all samples based on the nominal assessment (n = 28), and 95% for samples that have been validated by two independent pathologists through post hoc staining (n = 20). Our results demonstrate that this technique could increase the feasibility of intraoperative frozen section analysis for use during resection surgery and improve patient outcomes.

Mohammad Wazid, Amit Kumar Mishra, Noor Mohd, Ashok Kumar Das,
A Secure Deepfake Mitigation Framework: Architecture, Issues, Challenges, and Societal Impact,
Cyber Security and Applications,
Volume 2,
2024,
100040,
ISSN 2772-9184,
https://doi.org/10.1016/j.csa.2024.100040.
(https://www.sciencedirect.com/science/article/pii/S2772918424000067)
Abstract: Deepfake refers to synthetic media generated through artificial intelligence (AI) techniques. It involves creating or altering video, audio, or images to make them appear as though they depict something or someone else. Deepfake technology advances just like the mechanisms that are used to detect them. There’s an ongoing cat-and-mouse game between creators of deepfakes and those developing detection methods. As the technology that underpins deepfakes continues to improve, we are obligated to confront the repercussions that it will have on society. The introduction of educational initiatives, regulatory frameworks, technical solutions, and ethical concerns are all potential avenues via which this matter can be addressed. Multiple approaches need to be combined to identify deepfakes effectively. Detecting deepfakes can be challenging due to their increasingly sophisticated nature, but several methods and techniques are being developed to identify them. Mitigating the negative impact of deepfakes involves a combination of technological advancements, awareness, and policy measures. In this paper, we propose a secure deepfake mitigation framework. We have also provided a security analysis of the proposed framework via the Scyhter tool-based formal security verification. It proves that the proposed framework is secure against various cyber attacks. We also discuss the societal impact of deepfake events along with its detection process. Then some AI models, which are used for creating and detecting the deepfake events, are highlighted. Ultimately, we provide the practical implementation of the proposed framework to observe its functioning in a real-world scenario.
Keywords: Deepfake; Artificial Intelligence (AI); Machine learning; Cyber security; Authentication

Nana Wang, Hui Xu, Feng Xu, Lei Cheng,
The algorithmic composition for music copyright protection under deep learning and blockchain,
Applied Soft Computing,
Volume 112,
2021,
107763,
ISSN 1568-4946,
https://doi.org/10.1016/j.asoc.2021.107763.
(https://www.sciencedirect.com/science/article/pii/S1568494621006840)
Abstract: To strengthen music copyright protection effectively, a new deep learning neural network music composition neural network (MCNN) is proposed. The probability distribution of LSTM generation is adjusted by constructing a reasonable reward function. Music theory rules are used to constrain the generated music style to realize the intelligent generation of specific music style. Then, the digital music copyright protection system based on blockchain is constructed from three perspectives of confirming right, using right, and protecting right. The validity of the model is further verified by relevant data. The results show that the composition algorithm based on deep learning can realize music creation, and the qualified rate reaches 95.11%. Compared with the composition algorithm in the latest study, the model achieves 62.4 percent satisfaction with subjective samples and a recognition rate of 75.6 percent for musical sentiment classification. It is proved that the music copyright protection model based on block chain can ensure that the copyright owners of works obtain corresponding economic benefits from various distribution channels, which is helpful to build a harmonious music market environment. In short, the innovation of this study is reflected in that it fills in the gap of detailed comparative study of the differences in the application of different models, realizes the framework of music copyright protection system, and provides convenient conditions for composers.
Keywords: Algorithmic composition; Blockchain; Copyright protection; Deep learning; Neural network

Lerina Aversano, Mario Luca Bernardi, Marta Cimitile, Riccardo Pecori,
A systematic review on Deep Learning approaches for IoT security,
Computer Science Review,
Volume 40,
2021,
100389,
ISSN 1574-0137,
https://doi.org/10.1016/j.cosrev.2021.100389.
(https://www.sciencedirect.com/science/article/pii/S1574013721000290)
Abstract: The constant spread of smart devices in many aspects of our daily life goes hand in hand with the ever-increasing demand for appropriate mechanisms to ensure they are resistant against various types of threats and attacks in the Internet of Things (IoT) environment. In this context, Deep Learning (DL) is emerging as one of the most successful and suitable techniques to be applied to different IoT security aspects. This work aims at systematically reviewing and analyzing the research landscape about DL approaches applied to different IoT security scenarios. The contributions we reviewed are classified according to different points of view into a coherent and structured taxonomy in order to identify the gap in this pivotal research area. The research focused on articles related to the keywords ’deep learning’, ’security’ and ’Internet of Things’ or ’IoT’ in four major databases, namely IEEEXplore, ScienceDirect, SpringerLink, and the ACM Digital Library. We selected and reviewed 69 articles in the end. We have characterized these studies according to three main research questions, namely, the involved security aspects, the used DL network architectures, and the engaged datasets. A final discussion highlights the research gaps still to be investigated as well as the drawbacks and vulnerabilities of the DL approaches in the IoT security scenario.
Keywords: Internet of Things; Security; Systematic review; Deep Learning

Adeline Nyamathi, Nikil Dutt, Jung-Ah Lee, Amir M Rahmani, Mahkameh Rasouli, Donna Krogh, Erik Krogh, David Sultzer, Humayun Rashid, Hamza Liaqat, Riyam Jawad, Farhan Azhar, Ali Ahmad, Bilal Qamar, Taha Yasin Bhatti, Chet Khay, Jocelyn Ludlow, Lisa Gibbs, Julie Rousseau, Mahyar Abbasian, Yutong Song, Cheonkam Jeong, Sabine Brunswicker,
Establishing the Foundations of Emotional Intelligence in Care Companion Robots to Mitigate Agitation Among High-Risk Patients With Dementia: Protocol for an Empathetic Patient-Robot Interaction Study,
JMIR Research Protocols,
Volume 13,
2024,
,
ISSN 1929-0748,
https://doi.org/10.2196/55761.
(https://www.sciencedirect.com/science/article/pii/S1929074824004803)
Abstract: Background
An estimated 6.7 million persons are living with dementia in the United States, a number expected to double by 2060. Persons experiencing moderate to severe dementia are 4 to 5 times more likely to fall than those without dementia, due to agitation and unsteady gait. Socially assistive robots fail to address the changing emotional states associated with agitation, and it is unclear how emotional states change, how they impact agitation and gait over time, and how social robots can best respond by showing empathy.
Objective
This study aims to design and validate a foundational model of emotional intelligence for empathetic patient-robot interaction that mitigates agitation among those at the highest risk: persons experiencing moderate to severe dementia.
Methods
A design science approach will be adopted to (1) collect and store granular, personal, and chronological data using Personicle (an open-source software platform developed to automatically collect data from phones and other devices), incorporating real-time visual, audio, and physiological sensing technologies in a simulation laboratory and at board and care facilities; (2) develop statistical models to understand and forecast the emotional state, agitation level, and gait pattern of persons experiencing moderate to severe dementia in real time using machine learning and artificial intelligence and Personicle; (3) design and test an empathy-focused conversation model, focused on storytelling; and (4) test and evaluate this model for a care companion robot (CCR) in the community.
Results
The study was funded in October 2023. For aim 1, architecture development for Personicle data collection began with a search for existing open-source data in January 2024. A community advisory board was formed and met in December 2023 to provide feedback on the use of CCRs and provide personal stories. Full institutional review board approval was received in March 2024 to place cameras and CCRs at the sites. In March 2024, atomic marker development was begun. For aim 2, after a review of open-source data on patients with dementia, the development of an emotional classifier was begun. Data labeling was started in April 2024 and completed in June 2024 with ongoing validation. Moreover, the team established a baseline multimodal model trained and validated on healthy-person data sets, using transformer architecture in a semisupervised manner, and later retrained on the labeled data set of patients experiencing moderate to severe dementia. In April 2024, empathy alignment of large language models was initiated using prompt engineering and reinforcement learning.
Conclusions
This innovative caregiving approach is designed to recognize the signs of agitation and, upon recognition, intervene with empathetic verbal communication. This proposal has the potential to have a significant impact on an emerging field of computational dementia science by reducing unnecessary agitation and falls of persons experiencing moderate to severe dementia, while reducing caregiver burden.
International Registered Report Identifier (IRRID)
PRR1-10.2196/55761
Keywords: persons with dementia; empathy-based care companion robot; agitation; fall risk; artificial intelligence; AI

Katarzyna J. McNaughton, Marcin Łukowski,
How frontline states tackle sanctions against Russia: Implementation and enforcement dynamics in Poland and the Baltics,
Journal of Economic Criminology,
Volume 8,
2025,
100130,
ISSN 2949-7914,
https://doi.org/10.1016/j.jeconc.2025.100130.
(https://www.sciencedirect.com/science/article/pii/S2949791425000065)
Abstract: Russia’s invasion of Ukraine in February 2022, reshaped the EU’s security landscape, prompting sanctions aimed at weakening Russia’s war capabilities. These sanctions also redefined the roles of public authorities and the private sector, introducing new challenges in a shifting geopolitical context. Public authorities, including financial intelligence units, customs, state security agencies, law-enforcement agencies, etc., must identify, prevent, and investigate sanctions evasion and circumvention. This requires robust legal frameworks, adequate resources, and expertise in sanctions evasion typologies. Similarly, businesses and financial institutions operate in legal ambiguity, often asking, “Who am I dealing with in this transaction?”, as they navigate complex compliance requirements. Both the public and private sectors need a strong framework for domestic and cross-border sharing of financial intelligence, trade data, and knowledge of sanctions evasion typologies, as well as insight into the corporate structures of sanctioned entities. However, the EU's decentralized approach of independently designed national enforcement models may hamper cooperation and cross-border financial intelligence sharing. This paper examines how Poland, Lithuania, Latvia, and Estonia that are post-Warsaw Pact EU countries bordering Russia, implement and enforce those sanctions. It explores who "does what" and whether national authorities are adapting their modi operandi to enforce sanctions effectively. The findings reveal distinct national approaches. Latvia’s FIU became Europe’s first sanctions authority, integrating intelligence and enforcement functions. Estonia’s FIU plays a significant role but shares responsibilities with other agencies. Lithuania’s FIU adopts a collaborative model, leveraging a public-private partnership with the Center of Excellence in Anti-Money Laundering. Poland has a fragmented enforcement structure and regulatory framework but is unique in implementing its own autonomous sanctions.
Keywords: EU Sanctions Enforcement on Russia; Comparative Study of Sanctions Implementation in Baltic States; Poland's Sanctions Enforcement Framework; Russian Sanctions Enforcement in Frontline Countries

Karen Renaud, Merrill Warkentin, Ganna Pogrebna, Karl van der Schyff,
VISTA: An inclusive insider threat taxonomy, with mitigation strategies,
Information & Management,
Volume 61, Issue 1,
2024,
103877,
ISSN 0378-7206,
https://doi.org/10.1016/j.im.2023.103877.
(https://www.sciencedirect.com/science/article/pii/S0378720623001258)
Abstract: Insiders have the potential to do a great deal of damage, given their legitimate access to organisational assets and the trust they enjoy. Organisations can only mitigate insider threats if they understand what the different kinds of insider threats are, and what tailored measures can be used to mitigate the threat posed by each of them. Here, we derive VISTA (inclusiVe InSider Threat tAxonomy) based on an extensive literature review and a survey with C-suite executives to ensure that the VISTA taxonomy is not only scientifically grounded, but also meets the needs of organisations and their executives. To this end, we map each VISTA category of insider threat to tailored mitigations that can be deployed to reduce the threat.
Keywords: Insider threats; Taxonomy; Mitigations; Cybersecurity

Aida Garcia-Lazaro, Jorge Mendez-Astudillo, Susan Lattanzio, Charles Larkin, Linda Newnes,
The digital skill premium: Evidence from job vacancy data,
Economics Letters,
2025,
112294,
ISSN 0165-1765,
https://doi.org/10.1016/j.econlet.2025.112294.
(https://www.sciencedirect.com/science/article/pii/S0165176525001314)
Abstract: This paper examines the relationship between digital skills demand and posted wages in the UK using novel vacancy data. Digital skills—classified into basic, intermediate, and advanced using an XGBoost model—are linked to significant wage premiums. Within occupations, they are associated with 5.8% higher wages, with advanced and intermediate skills increasing wages by up to 8.9% when listed in job postings. Each additional digital skill increases wages by 1%, rising to 1.6% for advanced and intermediate skills. Artificial intelligence (AI) and cybersecurity skills yield particularly high returns, increasing wages by 8.6%–9.7% when listed and by 4.8%–5.4% per additional skill.
Keywords: Digital skill premium; AI; Cybersecurity; Posted wages; Xgboost

Stacy Johnson, Erin Owens, Hannah Menendez, Dianna Kim,
Using ChatGPT-generated essays in library instruction,
The Journal of Academic Librarianship,
Volume 50, Issue 2,
2024,
102863,
ISSN 0099-1333,
https://doi.org/10.1016/j.acalib.2024.102863.
(https://www.sciencedirect.com/science/article/pii/S0099133324000247)
Abstract: This case study details a library instruction activity developed by a team of academic librarians, which intended to leverage experiential learning to make students and faculty aware of the function, capabilities, and limitations of text-generating artificial intelligence (AI) tools like OpenAI's ChatGPT. The activity is described, with its development connected to key instructional theories and frameworks. Feedback is shared from student, faculty, and librarian perspectives, and future possibilities for academic librarians to grow and adapt similar AI literacy activities are explored.
Keywords: Academic libraries; Library instruction; Information literacy; Artificial intelligence; AI literacy; Generative AI; ChatGPT

Mahdi Alkaeed, Adnan Qayyum, Junaid Qadir,
Privacy preservation in Artificial Intelligence and Extended Reality (AI-XR) metaverses: A survey,
Journal of Network and Computer Applications,
Volume 231,
2024,
103989,
ISSN 1084-8045,
https://doi.org/10.1016/j.jnca.2024.103989.
(https://www.sciencedirect.com/science/article/pii/S1084804524001668)
Abstract: The metaverse is a nascent concept that envisions a virtual universe, a collaborative space where individuals can interact, create, and participate in a wide range of activities. Privacy in the metaverse is a critical concern as the concept evolves and immersive virtual experiences become more prevalent. The metaverse privacy problem refers to the challenges and concerns surrounding the privacy of personal information and data within Virtual Reality (VR) environments as the concept of a shared VR space becomes more accessible. Metaverse will harness advancements from various technologies such as Artificial Intelligence (AI), Extended Reality (XR) and Mixed Reality (MR) to provide personalized and immersive services to its users. Moreover, to enable more personalized experiences, the metaverse relies on the collection of fine-grained user data that leads to various privacy issues. Therefore, before the potential of the metaverse can be fully realized, privacy concerns related to personal information and data within VR environments must be addressed. This includes safeguarding users’ control over their data, ensuring the security of their personal information, and protecting in-world actions and interactions from unauthorized sharing. In this paper, we explore various privacy challenges that future metaverses are expected to face, given their reliance on AI for tracking users, creating XR and MR experiences, and facilitating interactions. Moreover, we thoroughly analyze technical solutions such as differential privacy, Homomorphic Encryption, and Federated Learning and discuss related sociotechnical issues regarding privacy.
Keywords: Machine learning; Metaverse; Artificial Intelligence; Virtual Reality; Extended Reality; Mixed reality; Homomorphic encryption; Federated learning

Shijie Kuang, Zhe Quan, Guoqi Xie, Xiaomin Cai, Xiaoqian Chen, Keqin Li,
NtNDet: Hardware Trojan detection based on pre-trained language models,
Expert Systems with Applications,
Volume 271,
2025,
126666,
ISSN 0957-4174,
https://doi.org/10.1016/j.eswa.2025.126666.
(https://www.sciencedirect.com/science/article/pii/S095741742500288X)
Abstract: Hardware Trojans (HTs) are malicious modifications embedded in Integrated Circuits (ICs) that pose a significant threat to security. The concealment of HTs and the complexity of IC manufacturing make them difficult to detect. An effective solution is identifying HTs at the gate level through machine learning techniques. However, current methods primarily depend on end-to-end training, which fails to fully utilize the advantages of large-scale pre-trained models and transfer learning. Additionally, they do not take advantage of the extensive background knowledge available in massive datasets. This study proposes an HT detection approach based on large-scale pre-trained NLP models. We propose a novel approach named NtNDet, which includes a method called Netlist-to-Natural-Language (NtN) for converting gate-level netlists into a natural language format suitable for Natural Language Processing (NLP) models. We apply the self-attention mechanism of Transformer to model complex dependencies within the netlist. This is the first application of large-scale pre-trained models for gate-level netlists HT detection, promoting the use of pre-trained models in the security field. Experiments on the Trust-Hub, TRIT-TC, and TRIT-TS benchmarks demonstrate that our approach outperforms existing HT detection methods. The precision increased by at least 5.27%, The True Positive Rate (TPR) by 3.06%, the True Negative Rate (TNR) by 0.01%, and the F1 score increased by about 3.17%, setting a new state-of-the-art in HT detection.
Keywords: Gate-level netlists; Hardware Trojan detection; Large language model; Netlist-to-natural-language; Transfer learning

Hyunmin Ko, Seokbeom Kwon,
Prominence of corporate science in quantum computing research,
Technological Forecasting and Social Change,
Volume 212,
2025,
123949,
ISSN 0040-1625,
https://doi.org/10.1016/j.techfore.2024.123949.
(https://www.sciencedirect.com/science/article/pii/S0040162524007479)
Abstract: In this study, we empirically examined the growing prominence of corporate science and its influence on quantum computing research. An analysis of approximately 30,000 research papers on quantum computing revealed that firms are increasingly publishing scientifically impactful research compared to noncorporate entities in this field. Additional analyses of text data from research article abstracts using topic modeling indicated that corporate research is concentrated on prominent topics such as quantum computing for Machine Learning/Artificial Intelligence and quantum algorithms, attracting increasing scholarly attention. In contrast, non-corporate research has been relatively dispersed across various topics. Drawing on the Resource-Based View and insights from an interview with a field expert, we theorize that with secured access to unique and rare resources for quantum computing research, corporate researchers are better positioned to experiment and iterate on novel ideas than their noncorporate counterparts. The publication of these research outcomes provides strategic advantages without compromising their appropriability. Our findings have implications for science policymakers and corporate innovation strategists, contributing to the literature on the role of corporate research in scientific progress.
Keywords: Corporate research; Complementary asset; Quantum computing; Research impact; Resource-based view

Eugénia Pedro, João Leitão, Helena Alves,
Screening and enhancing intellectual capital consistency: A scoping review of systematised literature reviews,
Journal of Innovation & Knowledge,
Volume 10, Issue 2,
2025,
100664,
ISSN 2444-569X,
https://doi.org/10.1016/j.jik.2025.100664.
(https://www.sciencedirect.com/science/article/pii/S2444569X25000150)
Abstract: This scoping review aimed to screen and enhance intellectual capital consistency, providing a general overview of existing systematised literature reviews of intellectual capital. This scoping review addressed five research questions: 1. How did the typology of publications, both theoretical and empirical, evolve considering the different stages of intellectual capital? 2. What are the milestone studies marking the beginning of the five stages of evolution of the intellectual capital framework? 3. How has the intellectual capital construct evolved? 4. What are the main streams of research on intellectual capital and how are they characterised? 5. What are the most relevant topics, gaps, and future trends in the field of intellectual capital? To answer the research questions, a scoping review was conducted following a search of the Web of Science and SCOPUS databases. The final search identified 78 full-text articles, published between 2005 and 2023. The evidence revealed the emergence of new topics and identified 13 clusters. We found evidence of the beginning of the fifth stage around 2018 due to the change in the research paradigm observed in this study and the development of new themes, such as innovation, digitalisation, knowledge, sustainability, and entrepreneurship, contributing to the ecosystem development of cities, regions, and nations. This pioneering scoping review systematised literature reviews about intellectual capital, providing important implications for theory, as it presents paths to follow and relevant indications for the evolving fifth stage of intellectual capital.
Keywords: Digital transformation; Digitalisation; Ecosystems; Entrepreneurship; Innovation; Intellectual capital; Knowledge; Sustainability

Rahul C. Basole, Hyunwoo Park, C. David Seuss,
Complex business ecosystem intelligence using AI-powered visual analytics,
Decision Support Systems,
Volume 178,
2024,
114133,
ISSN 0167-9236,
https://doi.org/10.1016/j.dss.2023.114133.
(https://www.sciencedirect.com/science/article/pii/S0167923623002087)
Abstract: Business ecosystems are complex, dynamic systems characterized by a multitude of entities, including companies, ventures, and technologies, as well as activities and trends. Understanding the state of business ecosystems is an increasingly critical strategic imperative for many decision makers, but it is a resource-intensive activity as relevant information sources are dispersed, often highly unstructured, and not integrated or curated to deliver actionable insights. In this research, we present the design and implementation of an interactive visual analytic system that integrates artificial intelligence and graph visualization techniques to augment decision makers’ understanding of the complex public narrative associated with business ecosystems entities. Our system is driven by a real-time content engine of 100,000+ global data sources including press releases, news articles, industry reports, analyst blogs in multiple languages organized across several domain-specific repositories. Following a user-specified query, the engine extracts both domain-agnostic and domain-specific entities and concepts for each document in the result set. We then model and visualize the resulting data as a dynamic, multipartite network and implement graph pruning algorithms and interactive data controls to enable users to interactively explore and discover the underlying business ecosystem from multiple perspectives. We illustrate and discuss the value of our system using representative use cases. Our study makes multiple contributions to visual decision support theory and practice, including mining unstructured data, constructing and interacting with knowledge graphs, and designing visual analytic tools for ecosystem intelligence. We conclude the study with implications and future research opportunities.
Keywords: Business ecosystem; Artificial intelligence; Text mining; Complex networks; Interactive visualization

Xichen Zhang, Roozbeh Razavi-Far, Haruna Isah, Amir David, Griffin Higgins, Michael Zhang,
A survey on Deep Learning in Edge–Cloud Collaboration: Model partitioning, privacy preservation, and prospects,
Knowledge-Based Systems,
Volume 310,
2025,
112965,
ISSN 0950-7051,
https://doi.org/10.1016/j.knosys.2025.112965.
(https://www.sciencedirect.com/science/article/pii/S0950705125000139)
Abstract: Recently, the rapid advancements of AI technologies and mobile computing have led to the growing prevalence of smart devices and rising demands for on-device Deep Learning applications. Given this context, the Edge–Cloud Collaboration System has attracted considerable attention. This survey article focuses on a typical architecture in such a system, called Partitioned Deep Neural Network. Concretely, a complex Deep Learning model is partitioned into two segments. The shallow part, which serves as the feature extractor, is deployed on the edge device, while the remaining layers are processed on the cloud server for result inferences. We provide a comprehensive overview of Partitioning Deep Neural Networks for the Edge–Cloud Collaboration System, including model split, experimental settings, threat models, and assessment metrics. Then, we conduct a systematic summary of state-of-the-art privacy-preserving technologies, providing detailed comparisons of their advantages and limitations in practice. Finally, we highlight the main open challenges and propose intriguing research problems as future directions from various aspects, including attacking settings, novel application scenarios, evaluation measurements, and the applications and potential influences of Large Language Models in related domains.
Keywords: Deep Learning; Edge–Cloud Collaboration; Model partitioning; Privacy preservation

Zhen Zhang, Yang Zou, Brian H.W. Guo, Johannes Dimyadi, Roy Davies, Lixin Jiang,
Knowledge management for off-site construction,
Automation in Construction,
Volume 166,
2024,
105632,
ISSN 0926-5805,
https://doi.org/10.1016/j.autcon.2024.105632.
(https://www.sciencedirect.com/science/article/pii/S0926580524003686)
Abstract: Off-site construction (OSC) is expected to boost productivity, shorten construction time, and reduce labour and material wastage. Despite these benefits, most OSC projects have not fully achieved these advantages, where a primary obstacle lies in the limited management of OSC knowledge. However, there is still no holistic understanding of the integration of KM in the OSC context. Therefore, this paper explores the latest development in KM for OSC through a systematic literature review using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines and template analysis. The review is based on 66 screened and assessed journal articles from all years to 2024 with a particular focus on KM and OSC. Through the quantitative and qualitative analysis, this study groups four main research themes including KM for OSC design, KM for OSC project management, knowledge-based OSC decision-making, and the management of OSC knowledge. The results are discussed to gain a systematic understanding of key OSC knowledge domains, investigate the integration of KM for OSC, and explore future research needs including emerging artificial intelligence (AI) technologies.
Keywords: Off-site construction (OSC); Knowledge management (KM); Artificial intelligence (AI); Systematic literature review

María Florencia Sanchez, Laura Carolina Luciani-Giacobbe, Fiamma Barbieri, María Eugenia Olivera,
Defining critical quality attributes and composition parameters for burn wound dressings: Antibiotic-anesthetic films as a model,
Heliyon,
Volume 10, Issue 22,
2024,
e39766,
ISSN 2405-8440,
https://doi.org/10.1016/j.heliyon.2024.e39766.
(https://www.sciencedirect.com/science/article/pii/S2405844024157970)
Abstract: The management of wounds primarily revolves around pain relief, effective infection control and the promotion of tissue regeneration to prevent complications like chronic skin wounds. While polymeric bioactive films are innovative alternatives to conventional wound dressings, there exists a dearth of guidance regarding their quality control. This underscores the imperative need to establish precise critical quality attributes, a task undertaken within this study using an antibiotic-anesthetic film as a model. The aim was to establish the influence of critical composition and process parameters and optimize the formula. First, the quality target product profile was defined, and critical quality attributes were identified. Our material selection included ciprofloxacin hydrochloride (an antimicrobial), lidocaine hydrochloride (an anesthetic), as well as excipients, such as sodium alginate, sodium hyaluronate, carbomer and glycerol. The critical components were identified through a risk assessment matrix, and their influence on film composition was determined by experimental verification using Design-Expert® software. A full factorial design was employed to assess the effects of sodium hyaluronate, carbomer and glycerol (as independent variables) on transparency, homogeneity, folding capacity and handling. Following this, an optimized formulation was achieved and subjected to further characterization. These optimized antibiotic-anesthetic films exhibited uniform micro-distribution of components, ensuring dosage uniformity. Both ciprofloxacin hydrochloride and lidocaine hydrochloride displayed sustained release profiles, suggesting potential therapeutic benefits for skin wounds. Furthermore, the resistance and elongation properties were similar to those of human skin. Utilizing a QbD approach, we successfully developed an optimized antibiotic-anesthetic film that adhered to the essential critical quality attributes. This films exhibits potential utility as a wound dressing. The findings presented in this study establish a fundamental framework for delineating the critical quality attributes of dressing films and refining their formulation to optimize wound treatment.
Keywords: Film; Polyelectrolytes; Polymeric wound dressings; Quality by design; Risk analysis; Design space; Quality control

Paul Gilmour, Durgesh Pandey, Doron Goldbarsht,
Registers of beneficial owners based on blockchain technology: Implications for the accounting profession,
Technological Forecasting and Social Change,
Volume 214,
2025,
124051,
ISSN 0040-1625,
https://doi.org/10.1016/j.techfore.2025.124051.
(https://www.sciencedirect.com/science/article/pii/S0040162525000824)
Abstract: Central registers of beneficial owners are fraught with legal loopholes, and trust, privacy, and verification issues that devalue accountants' anti-money laundering compliance efforts. Yet, central registers have become important policy tools for governments in enhancing corporate transparency. We propose a blockchain-based solution that provides a more open, verifiable, and secure framework for registering beneficial ownership information, while ensuring greater transparency and trust. This paper examines the role of blockchain technology within registers of beneficial owners and highlights important implications for the accounting sector. We offer a fresh perspective into how blockchain technology supports company disclosure and contribute new insights into research on ‘digital trust’. This paper bridges the gap between the conceptual and real-world implementation of registers of beneficial owners and promotes a more nuanced understanding on how new digital infrastructures impact accountants' compliance responsibilities.
Keywords: Blockchain; Beneficial ownership; Accounting; Registers; Trust; AML/CTF

Indika Dissanayake, Sridhar P. Nerur, Roman Lukyanenko, Minoo Modaresnezhad,
The state-of-the-art of crowdsourcing systems: A computational literature review and future research agenda using a text analytics approach,
Information & Management,
Volume 62, Issue 2,
2025,
104098,
ISSN 0378-7206,
https://doi.org/10.1016/j.im.2025.104098.
(https://www.sciencedirect.com/science/article/pii/S0378720625000011)
Abstract: Crowdsourcing effectively harnesses diverse skills and perspectives of crowds beyond organizational, geographical, and cultural boundaries. Organizations are gaining invaluable insights through crowdsourcing across diverse domains. This study reviews the growing academic literature on crowdsourcing using advanced topic modeling, an approach to unraveling key themes latent in the literature. Following a systems approach, we adopted inter- and intra-systems perspectives to identify distinct crowdsourcing models and their interrelated components based on a text analysis of the crowdsourcing literature. The paper elucidates the intellectual foundations of crowdsourcing as represented in the literature and offers suggestions for pursuing research that will extend its conceptual boundaries.
Keywords: Crowdsourcing; Crowdwork; Literature review; Topic modeling; Text analytics; LDA; BERT

Pedro Company, Jorge D. Camba, Stanislao Patalano, Ferdinando Vitolo, Antonio Lanzotti,
A Functional Classification of Text Annotations for Engineering Design,
Computer-Aided Design,
Volume 158,
2023,
103486,
ISSN 0010-4485,
https://doi.org/10.1016/j.cad.2023.103486.
(https://www.sciencedirect.com/science/article/pii/S0010448523000180)
Abstract: Describing and supplementing geometric shapes (parts) and layouts (assemblies) with relevant information is key for successful product design communication. 3D annotation tools are widely available in commercial systems, but they are generally used in the same manner as 2D annotations in traditional engineering drawings. The gap between technology and practices is particularly evident in plain text annotations. In this paper, we introduce a functional classification of text annotations to provide an information framework for shifting traditional annotation practices towards the Model-Based Definition (MBD) paradigm. In our view, the current classification of dimensions, tolerances, symbols, notes, and text does not stress the inherent properties of two broader categories: symbols and text. Symbol-based annotations use a symbolic language (mostly standardized) such as Geometric Dimensioning and Tolerancing (GD&T) to provide precise information about the implications of geometric imperfections in manufacturing, whereas notes and text are based on non-standardized and unstructured plain text, and can be used to convey design information. We advocate that text annotations can be characterized in four different functional types (objectives, requirements, rationale, and intent), which should be classified as such when annotations are added to a model. The identification and definition of a formalized structure and syntax can enable the management of the annotations as separate entities, thus leveraging their individual features, or as a group to gain a global and collective view of the design problem. The proposed classification was tested with a group of users in a redesign task that involved a series of geometric changes to an annotated assembly model.
Keywords: Annotations; Model-based definition; Text annotations

Yifan Fei, Wenjie Liao, Xinzheng Lu, Ertugrul Taciroglu, Hong Guan,
Semi-supervised learning method incorporating structural optimization for shear-wall structure design using small and long-tailed datasets,
Journal of Building Engineering,
Volume 79,
2023,
107873,
ISSN 2352-7102,
https://doi.org/10.1016/j.jobe.2023.107873.
(https://www.sciencedirect.com/science/article/pii/S2352710223020533)
Abstract: Intelligent structural design based on machine learning represents a novel structural design paradigm and has received extensive attention in recent years. However, the performance of the machine learning models is heavily dependent on the quality and quantity of training data, as the underlying approaches are inherently data-driven. Well-recognized data issues ‒ particularly data insufficiencies and long-tailed data distributions ‒ have become critical impediments in this research area. To address these data issues, this study formulates a schematic structural design task as a semi-supervised learning problem. Specifically, a semi-supervised learning method using small, long-tailed datasets is proposed in which a structural optimization method is incorporated into a self-training framework. As a practical application of the proposed method, a shear-wall layout optimization procedure is devised, based on a two-stage evaluation strategy and the previously established empirical design rules. Results of the numerical experiments indicate that the proposed method can improve the design performance on the tail data by 11.6 % and reduce the performance difference between the head and tail data by 21.3 %, compared to the conventional supervised learning method. A typical case study shows that the shear-wall layout created by the proposed method can satisfactorily resemble that by design engineers whilst meeting key code-specified requirements.
Keywords: Intelligent structural design; Structural optimization; Semi-supervised learning; Long-tailed learning; Small dataset; Shear-wall structures

Oihab Allal-Chérif, José Fernando Gallego-Nicholls, Agustin Carrilero-Castillo, Francisco Javier Sendra Garcia,
Stepping out of the innovation race to embrace outnovation: Fostering well-being and responsible consumption through sustainability, simplicity, authenticity, and nostalgia,
Technological Forecasting and Social Change,
Volume 210,
2025,
123906,
ISSN 0040-1625,
https://doi.org/10.1016/j.techfore.2024.123906.
(https://www.sciencedirect.com/science/article/pii/S0040162524007042)
Abstract: This article theorizes and characterizes the concept of “outnovation” as an alternative or a complement to innovation within the framework of grounded theory. Outnovation consists of stepping out of the unrelenting innovation race and removing all unnecessary innovations from a product, focusing instead on sustainability, simplicity, authenticity, and nostalgia. After presenting the dangers and limits of innovative strategies and disasters resulting from poorly mastered innovations, the research studies four different cases, which examples demonstrate that not innovating or suppressing innovations is not synonymous with bankruptcy. At a time when customers are looking for more sustainable products and when many economists advocate degrowth and less unbridled consumption, companies are looking for new forms of differentiation and value creation. Outnovating is a way of getting out of the vicious circle of endless innovation and meeting United Nations' Sustainable Development Goals.
Keywords: Outnovation; Innovation; Sustainability; Simplicity; Authenticity; Nostalgia; Excellence

Ilekuttige Priyan Shanura Fernando, Jianping Wu,
Food-derived bioactive peptides: The gateway to reach the full potential of food proteins for human health,
Trends in Food Science & Technology,
Volume 157,
2025,
104896,
ISSN 0924-2244,
https://doi.org/10.1016/j.tifs.2025.104896.
(https://www.sciencedirect.com/science/article/pii/S0924224425000329)
Abstract: Background
The growing emphasis on preventative healthcare has driven interest in food-derived bioactive peptides (BAPs) for the treatment of a wide range of diseases. These molecules can potentially promote human health through dietary interventions; however, their full capabilities have not yet been fully realized. Recent innovations and ongoing research are continuously expanding the use of BAPs.
Scope and approach
This review explores the preventive potential of BAPs against a wide range of diseases, and their sources, extraction methods, and applications. It critically analyzes preclinical and clinical trial outcomes while acknowledging existing challenges associated with BAPs research and commercialization.
Key findings and conclusions
Food-derived BAPs show promise as functional food ingredients, nutraceuticals, and therapeutic agents with diverse bioactivities including antihypertensive, antioxidant, antimicrobial, and immunomodulatory effects. Challenges in BAP research include sourcing, yield, stability, bioaccessibility, bioavailability, and regulatory hurdles. Advancements in peptide discovery through peptidomics, metagenomics, and genome mining, with preparation methods and AI-powered prediction tools offer potential solutions. Emerging technologies such as quantitative systems, pharmacology models, virtual patients, and digital twins may improve the efficiency of predicting drug efficacy and safety potentially facilitating the translation of BAPs from laboratory research to clinical applications. These advances can pave the way for developing personalized nutrition and precision medicine, offering tailored therapeutic strategies to promote human health.
Keywords: Bioactive peptides; Functional foods; Enzymatic hydrolysis; Peptide stability; Food byproducts

Singamaneni Krishnapriya, Sukhvinder Singh,
A Comprehensive Survey on Advanced Persistent Threat (APT) Detection Techniques,
Computers, Materials and Continua,
Volume 80, Issue 2,
2024,
Pages 2675-2719,
ISSN 1546-2218,
https://doi.org/10.32604/cmc.2024.052447.
(https://www.sciencedirect.com/science/article/pii/S1546221824005952)
Abstract: The increase in number of people using the Internet leads to increased cyberattack opportunities. Advanced Persistent Threats, or APTs, are among the most dangerous targeted cyberattacks. APT attacks utilize various advanced tools and techniques for attacking targets with specific goals. Even countries with advanced technologies, like the US, Russia, the UK, and India, are susceptible to this targeted attack. APT is a sophisticated attack that involves multiple stages and specific strategies. Besides, TTP (Tools, Techniques, and Procedures) involved in the APT attack are commonly new and developed by an attacker to evade the security system. However, APTs are generally implemented in multiple stages. If one of the stages is detected, we may apply a defense mechanism for subsequent stages, leading to the entire APT attack failure. The detection at the early stage of APT and the prediction of the next step in the APT kill chain are ongoing challenges. This survey paper will provide knowledge about APT attacks and their essential steps. This follows the case study of known APT attacks, which will give clear information about the APT attack process—in later sections, highlighting the various detection methods defined by different researchers along with the limitations of the work. Data used in this article comes from the various annual reports published by security experts and blogs and information released by the enterprise networks targeted by the attack.
Keywords: Advanced persistent threats; APT; cyber security; intrusion detection; cyber attacks

Ahmad Burhan Mohammed, Lamia Chaari Fourati,
Investigation on datasets toward intelligent intrusion detection systems for Intra and inter-UAVs communication systems,
Computers & Security,
Volume 150,
2025,
104215,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.104215.
(https://www.sciencedirect.com/science/article/pii/S0167404824005212)
Abstract: UAVs, commonly known as drones, are increasingly utilized in various fields such as military operations, surveillance, agriculture, and delivery services. Given their expanding roles, several critical reasons underline the necessity for security and trustworthiness including sensitive operations, and Public Safety and Privacy. Effective and secure communication channels are fundamental to the reliability and efficiency of UAVs. This involves protecting data transmission from various threats and ensuring that the communication protocols are robust against attacks. The security of communication systems directly impacts the overall trustworthiness of UAV operations, making it a critical area of focus for researchers and developers in this field. Intrusion Detection Systems (IDS) are vital components of a resilient architecture, essential for ensuring the security of communication systems. These systems function as diligent sentinels, continuously monitoring network traffic for signs of malicious behavior or rule violations. Additionally, IDS plays a crucial role in protecting communication networks by promptly identifying and responding to potential threats. Integrating IDS with other security measures enables organizations to significantly enhance their overall security posture. Accordingly, several recent studies have proposed advanced approaches using artificial intelligence to enhance the security and trustworthiness of UAV, as well as to mitigate cyberattacks in real time. However, the efficiency of the proposed AI-based approaches relies on the learning phase, which is strongly correlated with the quality of the used datasets. In this context, the objective of this article is to offer a thorough investigation concerning this topic. Certainly, the development and testing of effective AI-based IDS for UAVs require access to a diverse range of datasets that precisely capture the various security challenges and potential attack scenarios. In light of this necessity, the current study undertakes a comprehensive examination of UAV communication systems and their associated networking architectures, both centralized and decentralized. This study specifically focused on Intra and Inter UAV communication systems and utilized relevant IDS datasets. Additionally, it delves into the realm of open datasets that are pertinent to intelligent intrusion detection systems. More specifically, this paper introduces a novel taxonomy designed to categorize datasets relevant to IDS within the UAV context. Furthermore, it furnishes a guide along with recommendations for the selection of appropriate datasets based on predetermined scenarios.
Keywords: Unmanned aerial vehicles; Intrusion detection systems; Artificial intelligence; Datasets; UAV security; Intra/inter UAV communication system

Chaowu Xie, Feifei Lai, Jiangchi Zhang, Songshan (Sam) Huang,
Transforming intangible cultural heritage in destinations: A fashion communication perspective,
Tourism Management,
Volume 110,
2025,
105161,
ISSN 0261-5177,
https://doi.org/10.1016/j.tourman.2025.105161.
(https://www.sciencedirect.com/science/article/pii/S0261517725000317)
Abstract: Intangible cultural heritage (ICH) is a key attraction for the development of tourist destinations, but few studies have examined the popularization of ICH in destinations through the lens of fashion communication. This research pioneers the conceptualization of ICH fashion communication in tourist destinations. Using qualitative and quantitative methods, we identify and construct a theoretical framework of ICH fashion communication. Study 1 reveals that the fashion communication of ICH in tourist destinations follows a process framework of “fashion communication elements - fashion communication channels - fashion communication results,” involving six distinct constructs. Study 2 and Study 3 demonstrate that the fashion communication elements (fashion representation, fashion ontology, and fashion construction) significantly influence tourists’ fashion perception. Additionally, fashion communication channels (diffusion of exhibition spaces and participation of diverse groups) mediate the relationship between these elements and tourists’ fashion perception. This research enhances the theoretical understanding of ICH communication and marketing in tourism.
Keywords: Destination; Intangible cultural heritage (ICH); Fashion communication; Framework construction; Diffusion of innovation theory

Tahereh Saheb, Tayebeh Saheb,
Topical review of artificial intelligence national policies: A mixed method analysis,
Technology in Society,
Volume 74,
2023,
102316,
ISSN 0160-791X,
https://doi.org/10.1016/j.techsoc.2023.102316.
(https://www.sciencedirect.com/science/article/pii/S0160791X23001215)
Abstract: A number of countries have adopted national policies and directives to balance the advantages and disadvantages of innovative technologies. The purpose of this paper is to identify the most prominent topics addressed by national AI policies, as well as their relative importance across nations. This paper integrates the results of a topic modeling analysis of 30 national AI policies with a qualitative content analysis of the policies. Based on this analysis, fourteen main common themes have been identified among national AI policies, which predominantly relate to educational, technological, government, ethical/legal, and social good concerns. Following this, we conducted a co-occurrence analysis of topics across countries to determine the extent of topic prioritization in each country. In this investigation, several marginalized AI policy topics were also identified. In general, the challenges and concerns of the majority of policies pertain to education, technology, and the government. Governments refer to real-world projects and investments in AI technologies without developing shared digital governance platforms that promote responsible and sustainable AI among technology titans and mitigate the negative effects of surveillance capitalism. Although governments acknowledge the ethical and legal aspects of AI development and frequently cite the GDPR, they limit their discussion to the data level, particularly data sharing, and marginalize ethical algorithms and other phases of data and AI management and design. In addition, government policies marginalize AI startups and the API economy, even though they play a crucial role in fostering the AI ecosystem. The paper contributes to the existing literature on AI policy and will serve as a guide for AI policymakers to help them better understand the topical similarities across countries and the neglected or marginalized challenges that require further attention.
Keywords: Artificial intelligence; National policy; Topic modeling; Qualitative content analysis; Ethic; Responsible; Open data

Thomas E. Exner, Joh Dokler, Steffi Friedrichs, Christian Seitz, Francesca L. Bleken, Jesper Friis, Thomas F. Hagelien, Francesco Mercuri, Anna L. Costa, Irini Furxhi, Haralambos Sarimveis, Antreas Afantitis, Antonino Marvuglia, Gustavo M. Larrea-Gallegos, Tommaso Serchi, Angela Serra, Dario Greco, Penny Nymark, Martin Himly, Karin Wiench, Nico Watzek, Eva-Kathrin Schillinger, Jérôme Gavillet, Iseult Lynch, Andreas Karwath, Alexe L. Haywood, Georgios V. Gkoutos, Roland Hischier,
Going Digital to Boost Safe and Sustainable Materials Innovation Markets. The Digital Safe-and-Sustainability-by-Design Innovation Approach of the PINK Project,
Computational and Structural Biotechnology Journal,
2025,
,
ISSN 2001-0370,
https://doi.org/10.1016/j.csbj.2025.03.019.
(https://www.sciencedirect.com/science/article/pii/S2001037025000881)
Abstract: In this innovation report, we present the vision of the PINK project to foster Safe-and-Sustainable-by-Design (SSbD) advanced materials and chemicals (AdMas&Chems) development by integrating state-of-the-art computational modelling, simulation tools and data resources. PINK proposes a novel approach for the use of the SSbD framework, whose innovative approach is based on the application of a multi-objective optimisation procedure for the criteria of functionality, safety, sustainability and cost efficiency. At the core is the PINK open innovation platform, a distributed system that integrates all relevant modelling resources enriched with advanced data visualisation and an AI-driven decision support system. Data and modelling tools from the, in large parts, independently developed areas of functional design, safety assessment, life cycle assessment & costing are brought together based on a newly created Interoperability Framework. The PINK In Silico Hub, as the user Interface to the platform, finally guides the user through the complete AdMas&Chems development process from idea creation to market introduction. Guided by two Developmental Case Studies, the process of building of the PINK Platform is iterative, ensuring industry readiness to implement and apply it. Additionally, the Industrial Demonstrator programme will be introduced as part of the final project phase, which allows industry partners and especially small and medium enterprises (SMEs) to become part of the PINK consortium. Feedback from the Demonstrators as well as other stakeholder-engagement activities and collaborations will shape the platform’s final look and feel and, even more important, activities to assure long-term technical sustainability.
Keywords: advanced materials; safe-and-sustainable-by-design; computational modelling and simulations; functionality modelling, safety assessment, life cycle assessment, life cycle costing

Jeffrey M. Ting, Teresa Tamayo-Mendoza, Shannon R. Petersen, Jared Van Reet, Usman Ali Ahmed, Nathaniel J. Snell, John D. Fisher, Mitchell Stern, Felipe Oviedo,
Frontiers in nonviral delivery of small molecule and genetic drugs, driven by polymer chemistry and machine learning for materials informatics,
Chemical Communications,
Volume 59, Issue 96,
2023,
Pages 14197-14209,
ISSN 1359-7345,
https://doi.org/10.1039/d3cc04705a.
(https://www.sciencedirect.com/science/article/pii/S1359734523033189)
Abstract: ABSTRACT
Materials informatics (MI) has immense potential to accelerate the pace of innovation and new product development in biotechnology. Close collaborations between skilled physical and life scientists with data scientists are being established in pursuit of leveraging MI tools in automation and artificial intelligence (AI) to predict material properties in vitro and in vivo. However, the scarcity of large, standardized, and labeled materials data for connecting structure–function relationships represents one of the largest hurdles to overcome. In this Highlight, focus is brought to emerging developments in polymer-based therapeutic delivery platforms, where teams generate large experimental datasets around specific therapeutics and successfully establish a design-to-deployment cycle of specialized nanocarriers. Three select collaborations demonstrate how custom-built polymers protect and deliver small molecules, nucleic acids, and proteins, representing ideal use-cases for machine learning to understand how molecular-level interactions impact drug stabilization and release. We conclude with our perspectives on how MI innovations in automation efficiencies and digitalization of data—coupled with fundamental insight and creativity from the polymer science community—can accelerate translation of more gene therapies into lifesaving medicines.

Chen Qu,
Female versus viral: Understanding the UK gender health inequalities during the Covid-19 pandemic using e-archives,
Social Science & Medicine,
Volume 366,
2025,
117589,
ISSN 0277-9536,
https://doi.org/10.1016/j.socscimed.2024.117589.
(https://www.sciencedirect.com/science/article/pii/S0277953624010438)
Abstract: Despite the development of digital health infrastructure, female health inequalities have worsened during the pandemic. This transdisciplinary study, through health, feminist, and infrastructural geographical lens, examines how gender health inequalities may have emerged or worsened during Covid-19 in the UK. This study leverages a novel web archive collection, Python coding-powered data-handling text analysis (of over 0.2 billion words), and thematic analysis to examine three themes: vaccines, social minority groups, and women’s self-care. The findings suggest that the pandemic has impacted health inequalities among British women and girls and more, in a ‘more-than-gender’ way in terms of health (care) outcomes and access. In addition to reflecting on the use of e-archives in this study including suggesting the potential of combining e-archiving, coding, natural language processing (NLP) and generative AI/Large Language Models (LLMs) in producing and analysing trans-temporal (big) datasets, I argue that a geographical crisis perspective that balances the needs of everyday life and possible crises can be considered when preparing for public health emergencies. I adopt the e-archiving of this study to rethink ‘digital health infrastructure’ as ‘actors’, ‘facilitators’, and ‘voicers’, revealing how human-computer interaction and people in the virtual realm can be infrastructure.
Keywords: The UK; Web archives; Gender health inequalities; Pandemic; Covid-19; Digital health infrastructure; Novel digital methods

Delfina Ramos-Vidal, Wesley K.G. Assunção, Alejandro Cortiñas, Miguel R. Luaces, Oscar Pedreira, Ángeles Saavedra Places,
SPL-DB-Sync: Seamless database transformation during feature-driven changes,
Journal of Systems and Software,
Volume 222,
2025,
112285,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2024.112285.
(https://www.sciencedirect.com/science/article/pii/S0164121224003297)
Abstract: Software Product Line (SPL) Engineering is a reuse-oriented approach to developing a suite of software products that share common components but vary in specific features. The advantages of SPLs (e.g., reducing development costs and time while improving quality) have already been proven in practice. However, despite the success in deriving new products from an SPL, challenges arise in evolving existing products. Altering the feature selection (e.g., adding or removing a feature) for an already existing product poses a challenge regarding the application data stored and managed by derived products, particularly when the features impact an already populated database. In many cases, these modifications imply loss of data or constraint violations. However, in both the state of the art and practice, there are no approaches to support feature and data evolution simultaneously for SPL products. This paper reports a novel evolution approach, SPL-DB-Sync, with actions required for database adjustments when adding or removing features for existing SPL products. Actions delineate modifications necessary within the database. These modifications are associated with the SPL features and linked to the components of the data model they influence. SPL-DB-Sync facilitates the automatic readjustment of the database while preserving clear traceability between features and elements of the data model. The applicability of our evolution model is detailed in four practical scenarios of in-production products of an SPL for Digital Libraries. The contributions of this work are: present a novel evolution approach for SPLs with databases; define an SPL Evolution Model considering data transformation/migration; advance the state of practice between software reuse and data management; and provide insights for practitioners that face the same challenges of evolving both business logic and its data in software products.
Keywords: Software evolution; Variability management; Database management; Data synchronization

Elçin Yenişen Yavuz, Dirk Riehle,
Why and how do organizations create user-led open source consortia? A systematic literature review,
Information and Software Technology,
Volume 181,
2025,
107681,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2025.107681.
(https://www.sciencedirect.com/science/article/pii/S0950584925000205)
Abstract: Context
User-led open source (OS) consortia (foundations) consist of organizations from industries beyond the software industry collaborating to create open-source software solutions for their internal processes. Initially pioneered by higher education organizations in the 2000s, this concept has gained traction in recent years across various industries.
Objective
This study has two research objectives. The first objective is to provide an overview of the current state of the art in this field by identifying previously studied topics and gathering examples from different industries. The second objective is to understand the structure of user-led OS consortia and the motivations of organizations for participating in such consortia.
Method
To gain a comprehensive understanding of this phenomenon, we conducted a systematic literature review, covering the years 2000 to 2023. Furthermore, we performed thematic analysis on 43 selected studies to identify and examine the key characteristics, ecosystems, and the benefits organizations gain from involvement in user-led OS consortia.
Results
We identified 43 unique papers on user-led OS consortia and provided details on 14 sample user-led OS consortia projects. We defined 19 characteristics of user-led OS consortia and 16 benefits for organizations’ involvement. Additionally, we outlined the key actors and their roles in user-led OS consortia.
Conclusion
We provided an overview of the current state of the art in this field. We identified the structure of user-led OS consortia and the organizations’ motivations for participating in such consortia.
Keywords: Open source foundations; User-led open source consortia; Collaborative software development; Open-source software projects; User-driven open-source software development; Community-source software development; Coopetition; SLR; Systematic literature review

Maarten Herbosch,
To err is human: Managing the risks of contracting AI systems,
Computer Law & Security Review,
Volume 56,
2025,
106110,
ISSN 2212-473X,
https://doi.org/10.1016/j.clsr.2025.106110.
(https://www.sciencedirect.com/science/article/pii/S0267364925000056)
Abstract: Artificial intelligence (AI) increasingly influences contract law. Applications like virtual home assistants can form contracts on behalf of users, while other AI tools can assist parties in deciding whether to contract. The advent of Generative AI has further accelerated and broadened the proliferation of such applications. However, AI systems are inherently imperfect, sometimes leading to unexpected or undesirable contracts, raising concerns about the legal protection of AI deployers. Some authors have suggested that autonomous AI deployment cannot lead to a legally binding contract in the absence of a human “intent”. Others have argued that the system deployer is completely unprotected in cases of undesirable AI output. They argue that that deployment implies that the deployer should bear the risk of any mistake. This article challenges these views by leveraging existing contract formation and mistake frameworks. Traditional analysis demonstrates that AI deployment can produce valid contracts. It also suggests that deployers may invoke the unilateral mistake doctrine, drawing parallels to clerical errors in human contracts. While AI outputs are probabilistic and unpredictable, similar characteristics apply to human decision-making. The potential benefits of AI development justify affording AI deployers protections analogous to those provided in traditional scenarios. To enhance protection, deployers should use high-performing systems with safeguards such as oversight mechanisms and registration tools. As industry standards evolve, these safeguards will become more defined. The analysis concludes that current contract law frameworks are flexible enough to accommodate AI systems, negating the need for a complete overhaul.
Keywords: Artificial Intelligence; Unilateral mistake; Automated contracts; Intent; Contract validity; law and technology; Law and artificial intelligence; Contract law and AI

Arup Varma, Vijay Pereira, Parth Patel,
Artificial intelligence and performance management,
Organizational Dynamics,
Volume 53, Issue 1,
2024,
101037,
ISSN 0090-2616,
https://doi.org/10.1016/j.orgdyn.2024.101037.
(https://www.sciencedirect.com/science/article/pii/S009026162400010X)
Abstract: Artificial Intelligence (AI) enabled tools have increasingly becoming popular in our societies and are increasingly being used by students and practitioners, among others. Within corporations, numerous different applications have been identified where AI-enabled tools have been applied with different levels of success. In this article, we explore the pros and cons of using AI in performance management (PM). We draw upon the practitioner literature to summarize the current status of AI and AI-enabled tools. We also interviewed 8 HR professionals from around the world to learn about their experience(s) with the tools and to gain an insight into the future. In doing so, we explore the various components of performance management systems (PMS) and discuss how each might be impacted by the use of AI. Finally, we discuss the pros and cons of such usage and make recommendations for organizations that are considering using AI or AI enabled tools in their PMSs.
Keywords: Artificial Intelligence; AI; Performance management systems; PMS

Inje Kang, Jiseong Yang, Wonjae Lee, Eun-Yeong Seo, Duk Hee Lee,
Delineating development trends of nanotechnology in the semiconductor industry: Focusing on the relationship between science and technology by employing structural topic model,
Technology in Society,
Volume 74,
2023,
102326,
ISSN 0160-791X,
https://doi.org/10.1016/j.techsoc.2023.102326.
(https://www.sciencedirect.com/science/article/pii/S0160791X23001318)
Abstract: The bibliometrics research on nanotechnology highlights close interrelationships between scientific and technological activities (S&T) in the field of nanotechnology. Notwithstanding abundant empirical evidence on the mutual relations between S&T, the dynamics of the relationship from a contextual perspective have gained relatively little attention. Accordingly, our understanding of how science- and technology-oriented nanotechnology identifies development opportunities from each other is still at a nascent stage. To address this gap, by focusing on nanotechnology in the semiconductor industry, we use structural topic model to empirically explore the dynamic interrelationships between science- and technology-oriented nanotechnology. We empirically delineate the dynamic development trends in the context of the interrelationships between S&T and demonstrate how development opportunities are identified from each other. These findings show a new window of opportunities for how state-of-the-art models for semantic analysis can be used in the literature on S&T interrelationships.
Keywords: Nanotechnology; Science-oriented nanotechnology; Technology-oriented nanotechnology; S&T interrelationships; Development opportunities; Structural topic model

Silvia Casola, Alberto Lavelli,
Summarization, simplification, and generation: The case of patents,
Expert Systems with Applications,
Volume 205,
2022,
117627,
ISSN 0957-4174,
https://doi.org/10.1016/j.eswa.2022.117627.
(https://www.sciencedirect.com/science/article/pii/S0957417422009356)
Abstract: We survey Natural Language Processing (NLP) approaches to summarizing, simplifying, and generating patents’ text. While solving these tasks has important practical applications – given patents’ centrality in the R&D process – patents’ idiosyncrasies open peculiar challenges to the current NLP state of the art. This survey aims at (a) describing patents’ characteristics and the questions they raise to the current NLP systems, (b) critically presenting previous work and its evolution, and (c) drawing attention to directions of research in which further work is needed. To the best of our knowledge, this is the first survey of generative approaches in the patent domain.
Keywords: Natural Language Processing; Patent mining; Summarization; Simplification; Natural Language Generation; Survey

Abhishek Bajpai, Divyansh Chaurasia, Naveen Tiwari,
A novel methodology for anomaly detection in smart home networks via Fractional Stochastic Gradient Descent,
Computers and Electrical Engineering,
Volume 119, Part B,
2024,
109604,
ISSN 0045-7906,
https://doi.org/10.1016/j.compeleceng.2024.109604.
(https://www.sciencedirect.com/science/article/pii/S0045790624005317)
Abstract: With the rising integration of IoT devices within smart home environments, securing these interconnected systems against unauthorized access and cyber threats has become increasingly critical. This study introduces a novel methodology utilizing an advanced Artificial Neural Network (ANN) frame-work to enhance attack and anomaly detection capabilities within smart home networks. The objective is to develop a robust model that outperforms traditional detection methods and provides high accuracy and low false positive rates in identifying potential security threats. The research employs a pioneering approach to train the ANN by incorporating a Fractional Stochastic Gradient Descent optimizer grounded in Grunwald–Letnikov fractional calculus. This method was chosen for its potential to refine learning processes and improve detection accuracy over standard optimizers. The evaluation of the model was performed using the DS2OS traffic traces dataset, applying precision, sensitivity (recall), and specificity metrics to assess performance. The proposed model demonstrated exceptional performance with an accuracy of 0.9951. It significantly surpassed traditional methods like Logistic Regression and Support Vector Machines. The precision achieved was high, indicating a low rate of false positives, while the sensitivity and specificity values underscore the model’s ability to identify both typical and unconventional behaviours within the network accurately. This study introduces a robust and efficient ANN-based methodology for enhancing security in smart home IoT networks. Using a fractional stochastic gradient descent optimizer has proven effective in improving the model’s accuracy and reliability in detecting anomalies and attacks. The findings suggest significant implications for the future of IoT security, highlighting the potential for broader applications of fractional calculus in machine learning to enhance cybersecurity measures in various domains.

Vivek Sharma, Ashish Kumar Tripathi, Himanshu Mittal,
Technological revolutions in smart farming: Current trends, challenges & future directions,
Computers and Electronics in Agriculture,
Volume 201,
2022,
107217,
ISSN 0168-1699,
https://doi.org/10.1016/j.compag.2022.107217.
(https://www.sciencedirect.com/science/article/pii/S0168169922005324)
Abstract: With increasing population, the demand for agricultural productivity is rising to meet the goal of “Zero Hunger”. Consequently, farmers have optimized the agricultural activities in a sustainable way with the modern technologies. This integration has boosted the agriculture production due to high potentiality in assisting the farmers. The impulse towards the technological advancement has revived the traditional agriculture methods and resulted in eco-friendly, sustainable, and efficient farming. This has revolutionized the era of smart farming which primarily alliance with modern technologies like, big data, machine learning, deep learning, swarm intelligence, internet-of-things, block chain, robotics and autonomous system, cloud-fog-edge computing, cyber physical systems, and generative adversarial networks (GAN). To cater the same, a detailed survey on ten hot-spots of smart farming is presented in this paper. The survey covers the technology-wise state-of-the-art methods along with their application domains. Moreover, the publicly available data sets with existing research challenges are investigated. Lastly, the paper concludes with suggestions to the identified problems and possible future research directions.
Keywords: Smart farming; Current Trends in smart farming; Precision agriculture; Agriculture 4.0; Machine Learning

Rosana Veroneze, Charles-Henry Bertrand Van Ouytsel, Khanh Huu The Dam, Axel Legay,
Feature selection for packer classification based on association rule mining,
Engineering Applications of Artificial Intelligence,
Volume 137, Part A,
2024,
109083,
ISSN 0952-1976,
https://doi.org/10.1016/j.engappai.2024.109083.
(https://www.sciencedirect.com/science/article/pii/S0952197624012417)
Abstract: Malware often uses packing, an obfuscation strategy, to bypass antivirus. Identifying and understanding packers is therefore essential for analyzing suspicious binary files. Proposed machine learning methods for packer classification use a wide range of features, but many of them are redundant or irrelevant. It leads to waste of computational resources, so minimizing such features without reducing the effectiveness of packer identification is essential to analyze the ever-growing number of malware. This paper presents a novel embedded feature selection method for packer classification named Feature Selection based on Associative Classification (FSbAC). FSbAC exploits established concepts of association rule mining, particularly associative classification. As a result, FSbAC can define important sets of features per each packer individually, not just for the entire dataset. This makes it possible to directly learn the characteristics of each packer, improving the knowledge of analysts against packing. It also allows the costs associated with feature extraction to be taken into account during the selection process, ensuring the efficiency of the selected feature set. Seven different classification algorithms were used to assess the performance of FSbAC against eight FS methods. The evaluation encompassed different scenarios of packer classification, employing both a synthetic dataset and real-world datasets. The performance of the FS methods was evaluated with and without the inclusion of byte features vulnerable to bypass by hackers. Our results indicate that FSbAC is efficient for packer classification and leads to a substantial decrease in the number of features and in the computational resources required, without compromising predictive performance.
Keywords: Feature selection; Malware; Packer detection; Pattern mining; Association rules; Associative classification

Zhenfeng Liu, Jian Feng, Lorna Uden,
Technology opportunity analysis using hierarchical semantic networks and dual link prediction,
Technovation,
Volume 128,
2023,
102872,
ISSN 0166-4972,
https://doi.org/10.1016/j.technovation.2023.102872.
(https://www.sciencedirect.com/science/article/pii/S0166497223001839)
Abstract: Technology opportunity analysis using network analysis and link prediction has attracted the interest of both academia and industry. However, there are several unresolved issues with existing research, such as a lack of semantic relationships between nodes in a single-layer network, analyzing current technology trends rather than predicting future technology developments based on existing edges in a semantic network, and ignoring evaluation criteria for technology opportunity identification based on a single link prediction. This study proposes a new systematic methodology to address these issues and identify technology opportunities using a hierarchical semantic network and dual link prediction. The proposed methodology consists of three modules: 1) constructing the hierarchical semantic network based on SAO structures extracted from patents; 2) identifying technology opportunities in this semantic network through probabilistic-based link prediction; and 3) evaluating these opportunities via similarity-based link prediction. The viability and usefulness of the proposed methodology is proved by empirical analysis of the exploitation technology in the coal seam gas (CSG) industry. The results show that the hierarchical semantic network, including semantic and co-word relationships, can improve prediction accuracy. The dual link prediction can not only automatically identify technology opportunities with semantics, but also evaluate them to narrow down the problem-solving according to the novelty criteria. This study represents a contribution to existing research on technology opportunity analysis by integrating the hierarchical semantic network and dual link prediction.
Keywords: Technology opportunity analysis; Patent analysis; Hierarchical semantic network; Link prediction

Leandro Goulart de Araujo, Léa Vilcocq, Pascal Fongarland, Yves Schuurman,
Recent developments in the use of machine learning in catalysis: A broad perspective with applications in kinetics,
Chemical Engineering Journal,
Volume 508,
2025,
160872,
ISSN 1385-8947,
https://doi.org/10.1016/j.cej.2025.160872.
(https://www.sciencedirect.com/science/article/pii/S1385894725016936)
Abstract: A thorough grasp of the underlying mechanisms of catalytic reactions is indispensable for furthering our understanding of chemical kinetics. However, traditional phenomenological models present certain difficulties, including the tendency to converge to local minima and a reliance on parameters that are difficult to measure, particularly in complex catalytic systems. These systems frequently comprise intricate feedstock compositions or catalyst structures that are challenging to anticipate through theory-driven approaches. This often results in the utilization of unrealistic models or the allocation of considerable computational resources. While traditional methods offer valuable insights, they are constrained by these challenges and the lack of robust uncertainty assessments. In view of these limitations, data-driven modeling, in particular through machine learning (ML), has emerged as a promising alternative in catalysis in the last five years. This review examines recent advancements in ML applications within the field of catalysis, encompassing a broad range of applications, including data generation, descriptor identification, and feature engineering. While the review takes a general perspective on ML in catalysis, particular attention is given to applications in chemical kinetics wherever relevant, recognizing the interconnection between reaction kinetics, catalyst design, reaction conditions, and reactor configurations. The discussion includes various ML models, including interpretable yet less flexible models and more complex black-box models, and considers their applications in catalysis. It also examines key factors in model selection, such as generalizability, computational efficiency, data quality, and interpretability. Finally, it outlines future directions for ML in catalysis, emphasizing how these technologies can further enhance the optimization, design, and improvement of catalytic systems.
Keywords: Catalytic reaction; Catalyst; Catalysis informatics; Machine learning

J. Vetters, G. Thomassen, S. Van Passel,
Getting stakeholders aboard for offshore wind decommissioning: A qualitative study on end-of-life challenges in Belgium,
Energy Research & Social Science,
Volume 120,
2025,
103873,
ISSN 2214-6296,
https://doi.org/10.1016/j.erss.2024.103873.
(https://www.sciencedirect.com/science/article/pii/S221462962400464X)
Abstract: Decommissioning offshore wind farms presents significant challenges as the sector approaches the final phase of its operational lifecycle. This research examines end-of-life challenges through the perspectives of a diverse range of stakeholders, including industry, government, research, and civil society. While the study focuses on Belgian stakeholders, the challenges and solutions are expected to be relevant to similar cases. Semi-structured interviews identified 67 challenges across five end-of-life phases: planning, dismantling, transport and logistics, waste management, and monitoring site recovery. These challenges span technical, economic, environmental, social, and policy dimensions. Among them, 27 newly recognized challenges were identified. Key issues, such as composite recycling, removal legislation, port suitability, artificial reef effects, and uncertainty surrounding dismantling approaches, emerged as central concerns. These concerns were highlighted by nearly all stakeholder groups. This study addresses gaps in existing knowledge by providing comprehensive stakeholder mapping for the end-of-life phase of offshore wind farms. It incorporates stakeholder perspectives into the identification and evaluation of challenges. To validate findings, the study includes a qualitative analysis that separately examines expert stakeholders. The findings offer a detailed understanding of major concerns in offshore wind decommissioning. Recommendations include ensuring transparent grid connections, developing improved removal strategies, and adopting a more coordinated approach to transport and logistics. Waste management recommendations focus on improving blade design and addressing policy and economic issues for existing blades. The study underscores the importance of stakeholder engagement. It highlights the need for systematic involvement in end-of-life research, offering valuable insights for sustainable decommissioning practices.
Keywords: Renewable energy; Dismantling; Interviews; Waste management; Recycling; Supply chain participation

Oluwaseun Kolade, Abiodun Adegbile, David Sarpong,
Can university-industry-government collaborations drive a 3D printing revolution in Africa? A triple helix model of technological leapfrogging in additive manufacturing,
Technology in Society,
Volume 69,
2022,
101960,
ISSN 0160-791X,
https://doi.org/10.1016/j.techsoc.2022.101960.
(https://www.sciencedirect.com/science/article/pii/S0160791X22001014)
Abstract: The protracted disruption of Covid-19 pandemic on global supply chains has renewed calls for a new model of manufacturing that removes the need for centralised high-volume production and large inventory stocking. Drawing ideas from the Triple Helix model of university-industry-government innovation, this paper analyses the prospects for a 3D manufacturing revolution in Africa, a continent which was was disproportionately affected in the rounds of international border restrictions imposed in response to the Omicron variant of the virus. Taking a conceptual approach supported with case illustrations, the paper reviews the evolution of 3D printing technologies, the disruptive impact they have had on the traditional supply chain and the global expansion of the 3D printing market. Highlighting the favourable conditions for technological leapfrogging within the African context, the paper proposes a new integrative framework that explains how the emergence of new hybrid organisations from the Triple Helix can drive a promising manufacturing future for the continent -with small and medium enterprises playing a key role.

Ralf Schmälzle, Shelby Wilcox,
Harnessing Artificial Intelligence for Health Message Generation: The Folic Acid Message Engine,
Journal of Medical Internet Research,
Volume 24, Issue 1,
2022,
,
ISSN 1438-8871,
https://doi.org/10.2196/28858.
(https://www.sciencedirect.com/science/article/pii/S1438887122000905)
Abstract: Background
Communication campaigns using social media can raise public awareness; however, they are difficult to sustain. A barrier is the need to generate and constantly post novel but on-topic messages, which creates a resource-intensive bottleneck.
Objective
In this study, we aim to harness the latest advances in artificial intelligence (AI) to build a pilot system that can generate many candidate messages, which could be used for a campaign to suggest novel, on-topic candidate messages. The issue of folic acid, a B-vitamin that helps prevent major birth defects, serves as an example; however, the system can work with other issues that could benefit from higher levels of public awareness.
Methods
We used the Generative Pretrained Transformer-2 architecture, a machine learning model trained on a large natural language corpus, and fine-tuned it using a data set of autodownloaded tweets about #folicacid. The fine-tuned model was then used as a message engine, that is, to create new messages about this topic. We conducted a web-based study to gauge how human raters evaluate AI-generated tweet messages compared with original, human-crafted messages.
Results
We found that the Folic Acid Message Engine can easily create several hundreds of new messages that appear natural to humans. Web-based raters evaluated the clarity and quality of a human-curated sample of AI-generated messages as on par with human-generated ones. Overall, these results showed that it is feasible to use such a message engine to suggest messages for web-based campaigns that focus on promoting awareness.
Conclusions
The message engine can serve as a starting point for more sophisticated AI-guided message creation systems for health communication. Beyond the practical potential of such systems for campaigns in the age of social media, they also hold great scientific potential for the quantitative analysis of message characteristics that promote successful communication. We discuss future developments and obvious ethical challenges that need to be addressed as AI technologies for health persuasion enter the stage.
Keywords: human-centered AI; campaigns; health communication; NLP; health promotion

Ang Liu, Stephen Lu, Fei Tao, Nabil Anwer,
Integration of data science with product design towards data-driven design,
CIRP Annals,
Volume 73, Issue 2,
2024,
Pages 509-532,
ISSN 0007-8506,
https://doi.org/10.1016/j.cirp.2024.06.003.
(https://www.sciencedirect.com/science/article/pii/S0007850624001252)
Abstract: This paper aims to investigate the scientific integration of data science with product design towards data-driven design (D3). Data science has potential to facilitate design decision-making through insight extraction, predictive analytics, and automatic decisions. A systematic scoping review is conduced to converge various D3 applications in four dimensions: the design dimension about design operations, the data dimension about popular data sources and common data-related challenges, the method dimension about the methodological foundations, and the social/ethical dimension about social/ethical considerations and implications. Based on the state-of-the-art, this paper also highlights potential future research avenues in this dynamic field.
Keywords: Product design; Data science; Data-driven design

Yuandong Lin, Ji Ma, Yong-Guang Jia, Chongchong Yu, Jun-Hu Cheng,
Deep learning-assisted methods for accelerating the intelligent screening of novel 2D materials: New perspectives focusing on data collection and description,
Coordination Chemistry Reviews,
Volume 529,
2025,
216436,
ISSN 0010-8545,
https://doi.org/10.1016/j.ccr.2025.216436.
(https://www.sciencedirect.com/science/article/pii/S0010854525000062)
Abstract: Since the isolation of graphene, the interest in two-dimensional (2D) materials has been steadily growing thanks to their unique chemical and physical properties, as well as their potential for various applications. Deep learning (DL), currently one of the most sophisticated machine learning (ML) models, is emerging as a highly effective tool for intelligently investigating and screening 2D materials. The utilization of abundant data sources, appropriate descriptors, and neural networks enables the prediction of the structural and physicochemical properties of undiscovered 2D materials based on DL. Specifically, high-quality and well-described data plays a crucial role in effective model training, accurate predictions, and the discovery of new 2D materials. It also promotes reproducibility, collaboration, and continuous improvement within this field. This tutorial review is dedicated to an examination of the characterization, prediction, and discovery of 2D materials facilitated by various DL techniques. It focuses on the perspective of data collection and description, aiming to provide a clearer understanding of underlying principles and predicting outcomes. In addition, it also offers insights into future research prospects. The growing acceptance of DL is set to accelerate and transform the study of 2D materials.
Keywords: 2D materials; Deep learning; Data collections; Data descriptions; Material screenings

Nicholas Kluge Corrêa, Camila Galvão, James William Santos, Carolina Del Pino, Edson Pontes Pinto, Camila Barbosa, Diogo Massmann, Rodrigo Mambrini, Luiza Galvão, Edmund Terem, Nythamar de Oliveira,
Worldwide AI ethics: A review of 200 guidelines and recommendations for AI governance,
Patterns,
Volume 4, Issue 10,
2023,
100857,
ISSN 2666-3899,
https://doi.org/10.1016/j.patter.2023.100857.
(https://www.sciencedirect.com/science/article/pii/S2666389923002416)
Abstract: Summary
The utilization of artificial intelligence (AI) applications has experienced tremendous growth in recent years, bringing forth numerous benefits and conveniences. However, this expansion has also provoked ethical concerns, such as privacy breaches, algorithmic discrimination, security and reliability issues, transparency, and other unintended consequences. To determine whether a global consensus exists regarding the ethical principles that should govern AI applications and to contribute to the formation of future regulations, this paper conducts a meta-analysis of 200 governance policies and ethical guidelines for AI usage published by public bodies, academic institutions, private companies, and civil society organizations worldwide. We identified at least 17 resonating principles prevalent in the policies and guidelines of our dataset, released as an open source database and tool. We present the limitations of performing a global-scale analysis study paired with a critical analysis of our findings, presenting areas of consensus that should be incorporated into future regulatory efforts.
Keywords: artificial intelligence; machine learning; ethics; ethics of artificial intelligence; guidelines

Anuja Shukla, Poornima Jirli, Anubhav Mishra, Alok Kumar Singh,
An overview of blockchain research and future agenda: Insights from structural topic modeling,
Journal of Innovation & Knowledge,
Volume 9, Issue 4,
2024,
100605,
ISSN 2444-569X,
https://doi.org/10.1016/j.jik.2024.100605.
(https://www.sciencedirect.com/science/article/pii/S2444569X24001446)
Abstract: As a disruptive technology, blockchain has become a strategic priority for many businesses. A vast amount of research exists on blockchain's innovative nature and immense potential for multiple industries. This study aims to synthesize the existing research to classify the findings into various themes and propose avenues for further research. A total of 2,360 academic articles were analyzed using the text-mining method of structural topic modeling. The identified fifteen topics were mapped to the four quadrants of the Datatopia model, leading to the development of the Datatopia-blockchain (DBlock) framework. The results present future scenarios that provide an understanding of what is known about blockchain, its characteristics, and potential research areas. The contributions to the theory and implications to the practitioners are discussed in detail.
Keywords: Structural topic modeling; Blockchain; Scenario building; Datatopia; Natural language processing; Emerging technologies

Huijuan Wang, Boyan Cui, Quanbo Yuan, Ruonan Shi, Mengying Huang,
A review of deep learning based malware detection techniques,
Neurocomputing,
Volume 598,
2024,
128010,
ISSN 0925-2312,
https://doi.org/10.1016/j.neucom.2024.128010.
(https://www.sciencedirect.com/science/article/pii/S0925231224007811)
Abstract: With the popularization of computer technology, the number of malware has increased dramatically in recent years. Some malware can threaten the network security of users by downloading and installing, and even spreading widely on the Internet, causing consequences such as private data leakage in the operating system, extortion, and network paralysis. In order to deal with these threats, researchers analyze malicious samples through various analysis techniques, which are usually divided into static and dynamic analysis based on the principle of whether the code needs to be executed or not. This paper analyzes in detail several classical methods of feature extraction in malware detection techniques. With the technological development of artificial intelligence, deep learning is gradually being introduced into malware detection, which does not require the identification of professional security personnel and greatly improves the generalization ability of detection. In the paper, text-based detection methods, image visualization-based detection, and graph structure-based detection techniques are reviewed according to different feature extraction methods. In addition, the paper compares 26 datasets that have been commonly used in recent years applied in the research field and explains the main contents and specifications of the datasets. Finally, a summary and outlook of the malware research field is given.
Keywords: Malware detection; Deep learning; Malware datasets

Liane Colonna,
The end of open source? Regulating open source under the cyber resilience act and the new product liability directive,
Computer Law & Security Review,
Volume 56,
2025,
106105,
ISSN 2212-473X,
https://doi.org/10.1016/j.clsr.2024.106105.
(https://www.sciencedirect.com/science/article/pii/S0267364924001705)
Abstract: Rooted in idealism, the open-source model leverages collaborative intelligence to drive innovation, leading to major benefits for both industry and society. As open-source software (OSS) plays an increasingly central role in driving the digitalization of society, policymakers are examining the interactions between upstream open-source communities and downstream manufacturers. They aim to leverage the benefits of OSS, such as performance enhancements and adaptability across diverse domains, while ensuring software security and accountability. The regulatory landscape is on the brink of a major transformation with the recent adoption of both the Cyber Resilience Act (CRA) as well as the Product Liability Directive (PLD), raising concerns that these laws could threaten the future of OSS. This paper investigates how the CRA and the PDL regulate OSS, specifically exploring the scope of exemptions found in the laws. It further explores how OSS practices might adapt to the evolving regulatory landscape, focusing on the importance of documentation practices to support compliance obligations, thereby ensuring OSS's continued relevance and viability. It concludes that due diligence requirements mandate a thorough assessment of OSS components to ensure their safety for integration into commercial products and services. Documentation practices like security attestations, Software Bill of Materials (SBOMs), data cards and model cards will play an increasingly important role in the software supply chain to ensure that downstream entities can meet their obligations under these new legal frameworks.
Keywords: Open source software; Information security; Model card; SBOM

Brendan James Keegan, Sophie Iredale, Peter Naudé,
Examining the dark force consequences of AI as a new actor in B2B relationships,
Industrial Marketing Management,
Volume 115,
2023,
Pages 228-239,
ISSN 0019-8501,
https://doi.org/10.1016/j.indmarman.2023.10.001.
(https://www.sciencedirect.com/science/article/pii/S0019850123001918)
Abstract: Artificial intelligence (AI) in industrial marketing has seen significant research attention through various theoretical lenses with an emerging thread examining the dark side effects of AI. Thirty-four semi-structured interviews were conducted with buyers and suppliers of AI marketing solutions to investigate the consequences of AI ‘dark forces’ on B2B relationships. We posit AI as a new actor that has blurred the lines of the actors-resources-activities model. Findings show AI is now considered a new actor within B2B networks wielding dark force consequences such as algorithmic gatekeeping, which initiates dehumanization effects. In addition, AI is reliant on access to datasets which drives up resource costs. A lack of accountability of AI marketing solutions leads to opportunistic behaviours compromising actor relationships. Our conceptual model maps our understanding of the dark force consequences underpinning theoretical and managerial implications and recommendations for increased awareness and mitigation of dark forces.
Keywords: Artificial intelligence; B2B relationships; Dark forces; Tensions; Dehumanization

Eva Maria Kuehn,
A new business model in the fine arts realm based on NFT certificates and pearl codes,
Digital Business,
Volume 4, Issue 2,
2024,
100079,
ISSN 2666-9544,
https://doi.org/10.1016/j.digbus.2024.100079.
(https://www.sciencedirect.com/science/article/pii/S2666954424000073)
Abstract: The potential of Non-Fungible Tokens (NFTs) is highly anticipated, particularly in the realm of visual arts. However, current applications within fine arts often involve trivial processes, such as creating digital versions of artworks or replicas of masterpieces as NFT images, and selling only these NFTs. To unlock the full potential of NFTs, more innovative models are needed. This paper introduces a novel model that establishes a permanent link between an NFT and a physical craft object. This linkage is utilized to orchestrate the trade workflow, ensuring a sustained connection between real and digital artifacts. A distinguishing feature is that they can be sold together or seperately and later reunited with a buyer. The NFT serves as a multifunctional certificate, tracing, and communication token. Through a comprehensive analysis, this paper explores diverse scenarios that may arise in the relationship between the physical object and its digital twin. It presents a systematic and formal description of the proposed model and its various cases, marking a pioneering effort in the field. Noteworthy advantages include the ability to detect plagiarism and fraud. By strategically incorporating stakeholder roles, the model preserves the anonymity of art collectors while extracting valuable information about the ownership of physical artworks. The primary objective is to enhance security in the art trade and foster new business opportunities for stakeholders. As a proof-of-concept, the model was implemented in a real-world scenario on a leading NFT marketplace platform.
Keywords: NFT; Fine arts; Business model; Coordination; Digital twin; Real and virtual worlds; Formal model

Swapnaneel Dhar, Aditya Kumar Sahu,
Digital to quantum watermarking: A journey from past to present and into the future,
Computer Science Review,
Volume 54,
2024,
100679,
ISSN 1574-0137,
https://doi.org/10.1016/j.cosrev.2024.100679.
(https://www.sciencedirect.com/science/article/pii/S1574013724000637)
Abstract: With the amplification of digitization, the surge in multimedia content, such as text, video, audio, and images, is incredible. Concomitantly, the incidence of multimedia tampering is also apparently increasing. Digital watermarking (DW) is the means of achieving privacy and authentication of the received content while preserving integrity and copyright. Literature has produced a plethora of state-of-the-art DW techniques to achieve the right balance between its performance measuring parameters, including high imperceptibility, increased watermarking ability, and tamper-free recovery. Meanwhile, during the vertex of DW, scientific advances in quantum computing led to the emergence of quantum-based watermarking. Though quantum watermarking (QW) is in its nascent stage, it has become captivating among researchers to dive deep inside it. This study not only investigates the performance of existing DW techniques but also extensively assesses the recently devised QW techniques. It further presents how the principles of quantum entanglement and superposition can be decisive in achieving superior immunity against several watermarking attacks. To the best of our knowledge, this study is the unique one to present a comprehensive review of both DW as well as QW techniques. Therefore, the facts presented in this study could be a baseline for the researchers to devise a novel DW or QW technique.
Keywords: Classical or digital watermarking; Quantum watermarking; Quantum entanglement; Quantum superposition

Apeesada Sompolgrunk, Saeed Banihashemi, Hamed Golzad, Khuong Le Nguyen,
Strategic alignment of BIM and big data through systematic analysis and model development,
Automation in Construction,
Volume 168, Part A,
2024,
105801,
ISSN 0926-5805,
https://doi.org/10.1016/j.autcon.2024.105801.
(https://www.sciencedirect.com/science/article/pii/S0926580524005375)
Abstract: Organisations increasingly rely on data-driven strategies, utilising analytics to achieve competitive advantages. This paper systematically investigates the integration of big data into Building Information Modeling (BIM) within the Architecture, Engineering, and Construction (AEC) sectors, named “big BIM data.” Employing mixed methods of systematic and bibliometric analysis, it synthesises findings from 125 records published 2013–23. While many studies are at preliminary stages with conceptual or small-scale experimental approaches, the paper categorises its results into four domains: AEC organisational infrastructure, big BIM data (IT) infrastructure, AEC organisational strategic domain, and big BIM data (IT) strategic domain, aligned with the Strategic Alignment Model (SAM), exploring organisational competencies, governance factors, and strategic frameworks. This paper introduces the AEC Organisational - Big BIM Data SAM as the research agenda to implement big BIM data utilisation across AEC industry. This framework thoroughly addresses organisational dynamics while emphasising interconnectedness among individual projects, organisational tiers, and industry-wide standards.
Keywords: BIM; Big data; Strategic alignment model (SAM); Industry 4.0; Construction industry

Fushu Luan, Yang Chen, Lin Lang, King Yoong Lim,
Banking prudentials, leverage, and innovation partnership choice in China,
Journal of Banking & Finance,
Volume 171,
2025,
107347,
ISSN 0378-4266,
https://doi.org/10.1016/j.jbankfin.2024.107347.
(https://www.sciencedirect.com/science/article/pii/S0378426624002619)
Abstract: In a theoretical context where innovators borrow loans or settle for state-owned enterprise (SOE) sponsorship for their projects, we examine the effects of banking prudential regulations and their interaction with corporate leverage on the patenting partnership choice in China using a unique matched patent-firm-bank loan dataset for 15,623 observations in the 2013–17 period. We use a unique instrumental variable (IV) strategy to identify idiosyncratic bank prudential reform shocks associated with the post-2012 Basel III regulation and find prudential metrics (corporate leverage) of the financiers (firms) to positively (negatively) influence SOE patenting partnership choice, though prudential regulation mitigates the latter. Prudential reforms therefore come at a cost of further SOE dominance. However, conditional on an innovation project being SOE sponsored, we find positive spillover effect from the SOE’s employment mandate to loan productivity. Our results are robust across different IV strategies, alternative measures, sub-sample and mechanism analyses.
Keywords: Bank regulation; China; Corporate leverage; Innovation and patenting; State-owned enterprises

Ilsoo Todd Seo, Hongbo Liu, Hengyun Li, Jin-Soo Lee,
AI-infused video marketing: Exploring the influence of AI-generated tourism videos on tourist decision-making,
Tourism Management,
Volume 110,
2025,
105182,
ISSN 0261-5177,
https://doi.org/10.1016/j.tourman.2025.105182.
(https://www.sciencedirect.com/science/article/pii/S0261517725000524)
Abstract: As Generative Artificial Intelligence (AI) becomes increasingly integrated into daily experiences, AI-generated content (AIGC) is gaining prominence in marketing. Despite the significant potential of AI-generated videos to transform the tourism industry, there has been limited exploration of their impact in both practical and academic contexts. This paper addresses this gap by applying topic modeling and thematic analysis to social media comments and survey responses. This study proposes a conceptual framework for AI-generated tourism destination videos, identifying 17 themes. The findings highlight key differences compared to human-generated tourism videos, particularly in terms of authenticity and trustworthiness. This paper also contributes to the literature on tourism videos by presenting a pioneering study of AIGC. Furthermore, this research offers practical insights for tourism marketers seeking to effectively integrate AIGC into their marketing strategies.
Keywords: AI-generated video; Generative AI; AI-generated content; Topic modeling; Thematic analysis

Sanli Faez, Vivien Barnier, Dimitrios Mentis,
The pivotal role of open source knowledge transfer to achieve universal energy access,
iScience,
Volume 28, Issue 3,
2025,
112093,
ISSN 2589-0042,
https://doi.org/10.1016/j.isci.2025.112093.
(https://www.sciencedirect.com/science/article/pii/S2589004225003530)
Abstract: Summary
Community-company collaboration based on open source technologies is emerging as an alternative to proprietary solutions for planning, implementation, and maintenance of localized access to clean renewable electricity. We highlight some recent breakthroughs in creation of local technology ecosystems that follow an open access approach to knowledge transfer. On the other hand, on top of engineering, manufacturing, and maintenance questions, community led projects need to address social acceptance, economic viability, and regulatory barriers. Despite these barriers, open source in energy access is expanding and new sustainable business models are practiced. By comparing the advances in open source hardware scholarship with that of free and open source software, we anticipate an increasing communal pressure for adopting open-source friendly innovation policies. Academia and in particular university knowledge transfer policies play an essential role in achieving universal energy access via open source technologies.
Keywords: Energy policy; Open source software; Energy sustainability; Energy systems

Benjamin L. Ranard, Soojin Park, Yugang Jia, Yiye Zhang, Fatima Alwan, Leo Anthony Celi, Elizabeth R. Lusczek,
Minimizing bias when using artificial intelligence in critical care medicine,
Journal of Critical Care,
Volume 82,
2024,
154796,
ISSN 0883-9441,
https://doi.org/10.1016/j.jcrc.2024.154796.
(https://www.sciencedirect.com/science/article/pii/S0883944124002831)
Keywords: Machine learning; Artificial intelligence; Bias; Disparities; Fairness; Health equity; Critical Care

Kexiong Fei, Jiang Zhou, Yucan Zhou, Xiaoyan Gu, Haihui Fan, Bo Li, Weiping Wang, Yong Chen,
LaAeb: A comprehensive log-text analysis based approach for insider threat detection,
Computers & Security,
Volume 148,
2025,
104126,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.104126.
(https://www.sciencedirect.com/science/article/pii/S0167404824004310)
Abstract: Insider threats have increasingly become a critical issue that modern enterprises and organizations faced. They are mainly initiated by insider attackers, which may cause disastrous impacts. Numerous research studies have been conducted for insider threat detection. However, most of them are limited due to a small number of malicious samples. Moreover, as existing methods often concentrate on feature information or statistical characteristics for anomaly detection, they still lack effective use of comprehensive textual content information contained in logs and thus will affect detection efficiency. We propose LaAeb, a novel unsupervised insider threat detection framework that leverages rich linguistic information in log contents to enable conventional methods, such as an Isolation Forest-based anomaly detection, to better detect insider threats besides using various features and statistical information. To find malicious acts under different scenarios, we consider three patterns of insider threats, including attention, emotion, and behavior anomaly. The attention anomaly detection analyzes textual contents of operation objects (e.g., emails and web pages) in logs to detect threats, where the textual information reflects the areas that employees focus on. When the attention seriously deviates from daily work, an employee may involve malicious acts. The emotion anomaly detection analyzes all dialogs between every two employees’ daily communicated texts and uses the degree of negative to find potential psychological problems. The behavior anomaly detection analyzes the operations of logs to detect threats. It utilizes information acquired from attention and emotion anomalies as ancillary features, integrating them with features and statistics extracted from log operations to create log embeddings. With these log embeddings, LaAeb employs anomaly detection algorithm like Isolation Forest to analyze an employee’s malicious operations, and further detects the employee’s behavior anomaly by considering all employees’ acts in the same department. Finally, LaAeb consolidates detection results of three patterns indicative of insider threats in a comprehensive manner. We implement the prototype of LaAeb and test it on CERT and LANL datasets. Our evaluations demonstrate that compared with state-of-the-art unsupervised methods, LaAeb reduces FPR by 50% to reach 0.05 on CERT dataset under the same AUC (0.93), and gets the best AUC (0.97) with 0.06 higher value on LANL dataset.
Keywords: Insider threat detection; Log analysis; Anomaly detection; Cyber security; User behavior analysis

Mostafa Ghane, Mei Choo Ang, Denis Cavallucci, Rabiah Abdul Kadir, Kok Weng Ng, Shahryar Sorooshian,
Semantic TRIZ feasibility in technology development, innovation, and production: A systematic review,
Heliyon,
Volume 10, Issue 1,
2024,
e23775,
ISSN 2405-8440,
https://doi.org/10.1016/j.heliyon.2023.e23775.
(https://www.sciencedirect.com/science/article/pii/S2405844023109832)
Abstract: The study unfolds with an acknowledgment of the extensive exploration of TRIZ components, spanning a solid philosophy, quantitative and inductive methods, and practical tools, over the years. While the adoption of Semantic TRIZ (S-TRIZ) in high-tech industries for system development, innovation, and production has increased, the application of AI technologies to specific TRIZ components remains unexplored. This systematic literature review is conducted to delve into the detailed integration of AI with TRIZ, particularly S-TRIZ. The results elucidate the current state of AI applications within TRIZ, identifying focal TRIZ components and areas requiring further study. Additionally, the study highlights the trending AI technologies in this context. This exploration serves as a foundational resource for researchers, developers, and inventors, providing valuable insights into the integration of AI technologies with TRIZ concepts. The study not only paves the way for the development and automation of S-TRIZ but also outlines limitations for future research, guiding the trajectory of advancements in this interdisciplinary field.
Keywords: Semantic TRIZ; Data analytics; Artificial intelligence; Automate innovation

Hao Ma, Mengyue Su,
The bounded intelligence of AI: Superficiality and deceivability,
Organizational Dynamics,
2024,
101100,
ISSN 0090-2616,
https://doi.org/10.1016/j.orgdyn.2024.101100.
(https://www.sciencedirect.com/science/article/pii/S0090261624000731)
Abstract: Artificial Intelligence (AI) is typically designed to replace or augment human beings in making and executing decisions. In the domain of organizational management, AI has already found wide applications in many areas such as HR functions, marketing campaigns, competitive analysis, and strategy formulations, exerting increasing impacts on a host of executives and management professionals. Accurate and timely replicating or capturing the know-how of human decisions and actions becomes imperative, as AI has to be, at least as intelligent as, or even more intelligent than, those human actors whose data are being fed to AI during its training and learning iterations. Just as human beings are subject to bounded rationality due to their limited capacities in information processing, AI, too, is subject to bounded intelligence, in the sense that it could appear not as smart as expected, due to its limited capacities in replicating and capturing human expertise, to say nothing of augmenting or extending it. Such bounded intelligence of AI hinges on two underlying factors: superficiality and deceivability. Superficiality refers to the inability of AI to fully replicate human expertise during its learning process due to natural or technical barriers such as imperfect capturability, relational embeddedness, and time sensitivity. Deceivability refers to the inability of AI to accurately capture human expertise during its learning process due to human-actor-created barriers such as passive evasion, deliberate manipulation, and malicious sabotage. Understanding such boundedness of AI and the specific mechanisms of superficiality and deceivability will help us better appreciate the usefulness and limitations of AI and take measures to both remedy and utilize the bounded intelligence of AI.
Keywords: Artificial intelligence; Bounded intelligence; Superficiality; Deceivability; Coping strategy

Edan Habler, Ron Bitton, Dan Avraham, Eitan Klevansky, Dudu Mimran, Oleg Brodt, Heiko Lehmann, Yuval Elovici, Asaf Shabtai,
Adversarial machine learning threat analysis and remediation in Open Radio Access Network (O-RAN),
Journal of Network and Computer Applications,
Volume 236,
2025,
104090,
ISSN 1084-8045,
https://doi.org/10.1016/j.jnca.2024.104090.
(https://www.sciencedirect.com/science/article/pii/S1084804524002674)
Abstract: O-RAN is a new, open, adaptive, and intelligent RAN architecture. Motivated by the success of artificial intelligence in other domains, O-RAN strives to leverage machine learning (ML) to automatically and efficiently manage network resources in diverse use cases such as traffic steering, quality of experience prediction, and anomaly detection. Unfortunately, it has been shown that ML-based systems are vulnerable to an attack technique referred to as adversarial machine learning (AML). This special kind of attack has already been demonstrated in recent studies and in multiple domains. In this paper, we present a systematic AML threat analysis for O-RAN. We start by reviewing relevant ML use cases and analyzing the different ML workflow deployment scenarios in O-RAN. Then, we define the threat model, identifying potential adversaries, enumerating their adversarial capabilities, and analyzing their main goals. Next, we explore the various AML threats associated with O-RAN and review a large number of attacks that can be performed to realize these threats and demonstrate an AML attack on a traffic steering model. In addition, we analyze and propose various AML countermeasures for mitigating the identified threats. Finally, based on the identified AML threats and countermeasures, we present a methodology and a tool for performing risk assessment for AML attacks for a specific ML use case in O-RAN.
Keywords: Open Radio Access Networks; Adversarial machine learning; Security and privacy; Threat analysis

Taofeeq D. Moshood, James OB. Rotimi, Wajiha Shahzad, J.A. Bamgbade,
Infrastructure digital twin technology: A new paradigm for future construction industry,
Technology in Society,
Volume 77,
2024,
102519,
ISSN 0160-791X,
https://doi.org/10.1016/j.techsoc.2024.102519.
(https://www.sciencedirect.com/science/article/pii/S0160791X24000678)
Abstract: The construction industry has traditionally been slow to adopt digital technology, resulting in inefficient workflows, frequent cost overruns, and delays. Moreover, its fragmented structure, inherent to market dynamics, exacerbates these challenges. Embracing digitalization and transitioning to Industry 4.0 can substantially enhance efficiency and productivity in construction through increased innovation and improved collaboration, ultimately reducing information gaps and data discrepancies. This study aims to assess the potential integration of digital twin technology across various construction stages, spanning from initial design to project delivery. Existing literature emphasizes the transformative power of digital twin technology in advancing building innovation and environmental sustainability. These virtual replicas are crucial in optimizing industrial manufacturing by harmonizing production processes and societal interactions. A focused examination of digital twin technology applications in construction highlights its ability to streamline coordination and facilitate data sharing among stakeholders. Property owners increasingly recognise the value of digital twin technology in local contexts, driving the digitization of design and collaboration methods in construction. Integrating digital twin technology right from a project's inception and extending it across design phases optimizes project delivery, enhances asset quality, and contributes to societal sustainability. As the nexus between digitalization and sustainability goals strengthens, the construction industry stands at the cusp of a significant transformative journey.
Keywords: Digital twin; Construction 4.0; Sustainability; Project delivery; Built environment; Construction industry

Iqbal H. Sarker, Helge Janicke, Mohamed Amine Ferrag, Alsharif Abuadbba,
Multi-aspect rule-based AI: Methods, taxonomy, challenges and directions towards automation, intelligence and transparent cybersecurity modeling for critical infrastructures,
Internet of Things,
Volume 25,
2024,
101110,
ISSN 2542-6605,
https://doi.org/10.1016/j.iot.2024.101110.
(https://www.sciencedirect.com/science/article/pii/S2542660524000520)
Abstract: Critical infrastructure (CI) typically refers to the essential physical and virtual systems, assets, and services that are vital for the functioning and well-being of a society, economy, or nation. However, the rapid proliferation and dynamism of today’s cyber threats in digital environments may disrupt CI functionalities, which would have a debilitating impact on public safety, economic stability, and national security. This has led to much interest in effective cybersecurity solutions regarding automation and intelligent decision-making, where AI-based modeling is potentially significant. In this paper, we take into account “Rule-based AI” rather than other black-box solutions since model transparency, i.e., human interpretation, explainability, and trustworthiness in decision-making, is an essential factor, particularly in cybersecurity application areas. This article provides an in-depth study on multi-aspect rule based AI modeling considering human interpretable decisions as well as security automation and intelligence for CI. We also provide a taxonomy of rule generation methods by taking into account not only knowledge-driven approaches based on human expertise but also data-driven approaches, i.e., extracting insights or useful knowledge from data, and their hybridization. This understanding can help security analysts and professionals comprehend how systems work, identify potential threats and anomalies, and make better decisions in various real-world application areas. We also cover how these techniques can address diverse cybersecurity concerns such as threat detection, mitigation, prediction, diagnosis for root cause findings, and so on in different CI sectors, such as energy, defence, transport, health, water, agriculture, etc. We conclude this paper with a list of identified issues and opportunities for future research, as well as their potential solution directions for how researchers and professionals might tackle future generation cybersecurity modeling in this emerging area of study.
Keywords: Cybersecurity; Rule-based Modeling; Explainable AI; Responsible AI; Machine learning; Security data analytics; Knowledge discovery; Data-driven decision-making; Automation; Intelligence; Transparency; Trustworthiness; Critical infrastructures

Daniel Rudmark, Rikard Lindgren, Ulrike Schultze,
Open data platforms: Design principles for embracing outlaw innovators,
The Journal of Strategic Information Systems,
Volume 33, Issue 3,
2024,
101850,
ISSN 0963-8687,
https://doi.org/10.1016/j.jsis.2024.101850.
(https://www.sciencedirect.com/science/article/pii/S0963868724000325)
Abstract: Open data platforms freely provide citizens with access to public data, thus enabling improved governance transparency, enhanced public services, and increased civic engagement. However, unlocking the potential of this digital transformation strategy requires that public institutions manage the tension between public and private interests. Furthermore, even when public institutions break down traditional barriers for citizens’ access to data, the potential users often lack the knowledge to leverage it in meaningful ways. Open data platforms therefore tend to fall short of expectations. Leveraging a 10-year action design research study (ADR) in the Swedish Transport Administration (STA), this paper develops design principles for creating value-generating open data platforms in the public domain. The ADR project was initiated to assist STA in its efforts to deal with outlaw innovators who scraped train data from different websites to develop travel apps. Through three iterative design cycles that eventually led to the formation of a new open data platform, the outlaw innovators increasingly became valued partners in the digital transformation process. Theorizing this development process, this paper offers three design principles that provide guidance to public institutions aspiring to digitally transform by making public data accessible. We also reflect upon how these institutions might mitigate the risks associated with partnering with outlaw innovators in the pursuit of an open data strategy.
Keywords: Open data platforms; Digital transformation; Public–private tension; Action design research

Ester Bernadó, Florian Bratzke,
Revisiting EntreComp through a systematic literature review of entrepreneurial competences. Implications for entrepreneurship education and future research,
The International Journal of Management Education,
Volume 22, Issue 3,
2024,
101010,
ISSN 1472-8117,
https://doi.org/10.1016/j.ijme.2024.101010.
(https://www.sciencedirect.com/science/article/pii/S1472811724000818)
Abstract: This study conducts a comprehensive review of entrepreneurial competences, utilising a systematic literature analysis encompassing 140 documents up to 2022. The primary objective is to critically examine the EntreComp framework, validating its structure and content through a meticulous comparison with competences identified in the literature. The findings confirm the robustness of EntreComp, emphasising the process-oriented nature of entrepreneurship, from opportunity identification to value creation. While EntreComp aligns with the majority of competences identified in the literature, certain nuances related to psychological and contextual factors, as well as practical considerations in current entrepreneurship practices, warrant attention. Furthermore, the study sheds light on the antecedents and developmental aspects of each competence, establishing a foundation for competence development informed by literature evidence. The paper also discusses the implications of the study's findings for entrepreneurship education, providing insights for the development of effective educational programs and suggesting avenues for future research in the field. Overall, this study contributes to advancing the understanding of entrepreneurship competences and their consideration in educational settings.
Keywords: EntreComp; Entrepreneurial competences; Entrepreneurship education; Systematic literature review; Content analysis

Jaewoong Choi, Byeongki Jeong, Janghyeok Yoon,
Technology opportunity discovery under the dynamic change of focus technology fields: Application of sequential pattern mining to patent classifications,
Technological Forecasting and Social Change,
Volume 148,
2019,
119737,
ISSN 0040-1625,
https://doi.org/10.1016/j.techfore.2019.119737.
(https://www.sciencedirect.com/science/article/pii/S0040162518312745)
Abstract: Technology opportunity discovery (TOD), have evolved over time from technology forecasting to an approach based on existing technology capabilities for increased practicality. Unfortunately, TOD studies are still lacking, in that they do not consider the unique direction of the target firm in technology development or the recent trends of technological fields. Consequently, this paper proposes an improved methodology for identifying technology opportunities with less uncertainty by focusing on the target firm's dynamic change of focus technology fields. The proposed approach is as follows: 1) generate a sequence database, containing firms' dynamic change of focus technology fields; 2) explore the frequent sequential patterns from a precedence enterprise (PE) sequence database using the PrefixSpan algorithm to identify the technology candidates from a PE sequence similar with that of the target firm; and 3) evaluate the candidates on technological similarity, business stability, and recency. The results of the proposed approach are expected to help firms discover appropriate technology opportunities by considering both their existing technological capacities and the dynamic change of their focus technology fields. Furthermore, the proposed approach can identify the most appropriate technology opportunities with less uncertainty in real-life business environments by evaluating technological similarity, business stability, and recency.
Keywords: Technology opportunity discovery; Sequential pattern mining; Uncertainty; Technology intelligence

Lamia Berriche, Souad Larabi-Marie-Sainte,
Unveiling ChatGPT text using writing style,
Heliyon,
Volume 10, Issue 12,
2024,
e32976,
ISSN 2405-8440,
https://doi.org/10.1016/j.heliyon.2024.e32976.
(https://www.sciencedirect.com/science/article/pii/S2405844024090078)
Abstract: Extensive use of AI-generated texts culminated recently after the advent of large language models. Although the use of AI text generators, such as ChatGPT, is beneficial, it also threatens the academic level as students may resort to it. In this work, we propose a technique leveraging the intrinsic stylometric features of documents to detect ChatGPT-based plagiarism. The stylometric features were normalized and fed to classical classifiers, such as k-Nearest Neighbors, Decision Tree, and Naïve Bayes, as well as ensemble classifiers, such as XGBoost and Stacking. A thorough examination of the classifier was conducted by using Cross-Fold validation, hyperparameters tuning, and multiple training iterations. The results show the efficacy of both classical and ensemble learning classifiers in distinguishing between human and ChatGPT writing styles with a noteworthy performance of XGBoost where 100 % was achieved for accuracy, recall, and precision metrics. Moreover, the proposed XGBoost classifier outperformed the state-of-the-art result on the same dataset and same classifier highlighting the superiority of the proposed feature style extraction method over TF-IDF techniques. The ensemble learning classifiers were also applied to the generated dataset with mixed texts, where paragraphs are written by ChatGPT and humans. The results show that 98 % of the documents were classified correctly as either mixed or human. The last contribution consists in the authorship attribution of the paragraphs of a single document where the accuracy reached 92.3 %.
Keywords: ChatGPT; Stylometry; Plagiarism; Ensemble learning; Writing style

Ahmed Bensaoud, Jugal Kalita, Mahmoud Bensaoud,
A survey of malware detection using deep learning,
Machine Learning with Applications,
Volume 16,
2024,
100546,
ISSN 2666-8270,
https://doi.org/10.1016/j.mlwa.2024.100546.
(https://www.sciencedirect.com/science/article/pii/S2666827024000227)
Abstract: The problem of malicious software (malware) detection and classification is a complex task, and there is no perfect approach. There is still a lot of work to be done. Unlike most other research areas, standard benchmarks are difficult to find for malware detection. This paper aims to investigate recent advances in malware detection on MacOS, Windows, iOS, Android, and Linux using deep learning (DL) by investigating DL in text and image classification, the use of pre-trained and multi-task learning models for malware detection approaches to obtain high accuracy and which the best approach if we have a standard benchmark dataset. We discuss the issues and the challenges in malware detection using DL classifiers by reviewing the effectiveness of these DL classifiers and their inability to explain their decisions and actions to DL developers presenting the need to use Explainable Machine Learning (XAI) or Interpretable Machine Learning (IML) programs. Additionally, we discuss the impact of adversarial attacks on deep learning models, negatively affecting their generalization capabilities and resulting in poor performance on unseen data. We believe there is a need to train and test the effectiveness and efficiency of the current state-of-the-art deep learning models on different malware datasets. We examine eight popular DL approaches on various datasets. This survey will help researchers develop a general understanding of malware recognition using deep learning.
Keywords: Malware detection; Multi-task learning; Malware image; Generative adversarial networks; Mobile malware; Convolutional neural network

Mikel Hernandez, Gorka Epelde, Ane Alberdi, Rodrigo Cilla, Debbie Rankin,
Synthetic data generation for tabular health records: A systematic review,
Neurocomputing,
Volume 493,
2022,
Pages 28-45,
ISSN 0925-2312,
https://doi.org/10.1016/j.neucom.2022.04.053.
(https://www.sciencedirect.com/science/article/pii/S0925231222004349)
Abstract: Synthetic data generation (SDG) research has been ongoing for some time with promising results in different application domains, including healthcare, biometrics and energy consumption. The need for a robust SDG solution to capitalise on advances in Big Data and AI technology has never been greater to enable access to useful data while ensuring reasonable privacy protections. This paper presents a systematic review from the last 5 years (2016–2021) to analyse and report on recent approaches in synthetic tabular data generation (STDG) with a focus on the healthcare application context to preserve patient privacy, paying special attention to the contribution of Generative Adversarial Networks (GAN). In total 34 publications have been retrieved and analysed. A classification of approaches has been proposed and the performance of GAN-based approaches has been extensively analysed. From the systematic review it has been concluded that there is no universal method or metric to evaluate and benchmark the performance of various approaches and that further research is needed to improve the generalisability of GANs to find a model that works optimally across tabular healthcare data.
Keywords: Synthetic data generation; Generative adversarial networks; Privacy preserving data; Data sharing; Healthcare; Artificial intelligence

Lei Shen, Qingyue Shi, Vinit Parida, Marin Jovanovic,
Ecosystem orchestration practices for industrial firms: A qualitative meta-analysis, framework development and research agenda,
Journal of Business Research,
Volume 173,
2024,
114463,
ISSN 0148-2963,
https://doi.org/10.1016/j.jbusres.2023.114463.
(https://www.sciencedirect.com/science/article/pii/S0148296323008226)
Abstract: This study ventures into the dynamic realm of ecosystem orchestration for industrial firms, emphasizing its significance in maintaining competitive advantage in the digital era. The fragmented research on this important subject poses challenges for firms aiming to navigate and capitalize on ecosystem orchestration. To bridge this knowledge gap, we conducted a comprehensive qualitative meta-analysis of 31 case studies and identified multifaceted orchestration practices employed by industrial firms. The core contribution of this research is the illumination of five interdependent but interrelated orchestration practices: strategic design, relational, resource integration, technological, and innovation. Together, these practices are synthesized into an integrative framework termed the “Stirring Model,” which serves as a practical guide to the orchestration practices. Furthermore, the conceptual framework clarifies the synergy between the identified practices and highlights their collective impact. This study proposes theoretical and practical implications for ecosystem orchestration literature and suggests avenues for further research.
Keywords: Ecosystem orchestration; Innovation ecosystem; Orchestration practices; Governance; Coordination; Qualitative meta-analysis

Miguel A. Pérez-Velasco, Julio Osuna-Sánchez, Mercedes Millán-Gómez, Michele Ricci, Almudena López-Sampalo, María-Rosa Bernal-López, Ricardo Gómez-Huelgas, Luis M. Pérez-Belmonte,
In-hospital linagliptin for management simplification and hypoglycemia reduction in very old patients with type 2 diabetes,
Medicina Clínica,
2024,
,
ISSN 0025-7753,
https://doi.org/10.1016/j.medcli.2024.10.021.
(https://www.sciencedirect.com/science/article/pii/S0025775324006997)
Abstract: Introduction and objectives
The role of in-hospital dipeptidyl peptidase-4 inhibitors in very old patients has not been widely described. This work analyzes the simplification of in-hospital antihyperglycemic management (less insulin use) and reductions in hypoglycemia events using linagliptin in patients aged≥80 years with type 2 diabetes.
Patients and methods
This real-world observational study included hospitalized patients≥80 years with type 2 diabetes treated with an antihyperglycemic protocol of either basal-bolus insulin or linagliptin between January 2016 and December 2023. A 1:1 propensity score matching analysis was performed.
Results
Post-matching, 944 patients were included in each group. The total and basal insulin doses and number of daily injections were significantly lower in the linagliptin group than the basal-bolus insulin group with no differences in glycemic efficacy. Regarding safety, patients on the basal-bolus insulin regimen had more hypoglycemic events. The use of basal-bolus insulin regimen (odds ratio: 4.22; 95% confidence interval: 2.14–6.28; p<0.001), a higher total insulin dose (odds ratio: 3.55; 95% confidence interval: 2.02–5.36; p<0.001) and the number of insulin injections (odds ratio: 2.86; 95% confidence interval: 1.50–4.12; p=0.002) were associated with a greater risk of hypoglycemia. Other hypoglycemia risk factors were older age, moderate–severe functional dependence, moderate–severe dementia, polypharmacy, and complex health status.
Conclusions
The linagliptin regimen simplified in-hospital antihyperglycemic management and reduced hypoglycemia events compared to basal-bolus insulin regimen in patients with type 2 diabetes aged≥80 years. Basal-bolus insulin use and clinical factors were associated with hypoglycemia. The linagliptin regimen could be considered as standard of care for older adult type 2 diabetes patients in the hospital setting.
Resumen
Antecedentes y objetivo
El papel de los inhibidores de la dipeptidil-peptidasa-4 intrahospitalario en pacientes de edad avanzada no ha sido ampliamente descrito. Este estudio analiza la simplificación del manejo antihiperglucémico intrahospitalario (uso de menos insulina) y la reducción de hipoglucemia usando linagliptina en pacientes de ≥80 años con diabetes mellitus tipo 2.
Materiales y métodos
Estudio observacional en pacientes hospitalizados con ≥80 años con diabetes tipo 2 tratados con el protocolo antihiperglucémico que incluye el regimen insulina en bolo-basal o linagliptina, entre enero 2016-diciembre 2023. Se realizó un análisis de puntuaciones de propensión 1:1.
Resultados
Tras la propensión, 944 pacientes fueron incluidos por grupo. Las dosis de insulina total y basal y el número de inyecciones fueron significativamente menores en el grupo linagliptina sin diferencias en la eficacia glucémica. Respecto a la seguridad, los pacientes con insulina bolo-basal tuvieron más hipoglucemias. El uso de insulina bolo-basal (Odds Ratio: 4.22; Intervalo de confianza 95%: 2.14-6.28; p<0.001), mayor dosis de insulina total (Odds Ratio: 3.55; Intervalo de confianza 95%: 2.02-5.36; p<0.001) y número de inyecciones (Odds Ratio: 2.86; Intervalo de confianza 95%: 1.50-4.12; p=0.002) fueron asociados con mayor riesgo de hipoglucemia. Otros factores fueron la edad avanzada, dependencia funcional moderada-severa, demencia moderada-severa, polifarmacia y estado de salud complejo.
Conclusiones
Linagliptina simplificó el manejo antihiperglucémico y redujo hipoglucemias respecto al regimen de insulina en bolo-basal en pacientes de ≥80 años con diabetes tipo 2. El uso del régimen bolo-basal y factores clínicos fueron asociados con la hipoglucemia. Linagliptina intrahospitalaria podría ser considerada como el tratamiento estándar para pacientes de edad avanzada con diabetes tipo 2.
Keywords: Age≥80; Type 2 diabetes; Linagliptin; Insulin; Hospitalization; Edad ≥80; Diabetes mellitus tipo 2; Linagliptina; Insulina; Hospitalización
