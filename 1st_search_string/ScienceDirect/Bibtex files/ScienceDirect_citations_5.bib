@article{CHIARELLO2024103002,
title = {Future applications of generative large language models: A data-driven case study on ChatGPT},
journal = {Technovation},
volume = {133},
pages = {103002},
year = {2024},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2024.103002},
url = {https://www.sciencedirect.com/science/article/pii/S016649722400052X},
author = {Filippo Chiarello and Vito Giordano and Irene Spada and Simone Barandoni and Gualtiero Fantoni},
keywords = {Generative artificial intelligence, Generative large language models, ChatGPT, Social media analysis, Technology adoption, Emerging technologies},
abstract = {This study delves into the evolving role of generative Large Language Models (LLMs). We develop a data-driven approach to collect and analyse tasks that users are asking to generative LLMs. Thanks to the focus on tasks this paper contributes to give a quantitative and granular understanding of the potential influence of LLMs in different business areas. Utilizing a dataset comprising over 3.8 million tweets, we identify and cluster 31,747 unique tasks, with a specific case study on ChatGPT. To reach this goal, the proposed method combines two Natural Language Processing (NLP) Techniques, Named Entity Recognition (NER) and BERTopic. The combination makes it possible to collect granular tasks of LLMs (NER) and clusters them in business areas (BERTopic). Our findings reveal a wide spectrum of applications, from programming assistance to creative content generation, highlighting LLM's versatility. The analysis highlighted six emerging areas of application for ChatGPT: human resources, programming, social media, office automation, search engines, education. The study also examines the implications of these findings for innovation management, proposing a research agenda to explore the intersection of the identified areas, with four stages of the innovation process: idea generation, screening/idea selection, development, and diffusion/sales/marketing.}
}
@article{BARNES2024102864,
title = {Assessing textbook affordability before and after the COVID-19 pandemic: Results of student and faculty surveys},
journal = {The Journal of Academic Librarianship},
volume = {50},
number = {2},
pages = {102864},
year = {2024},
issn = {0099-1333},
doi = {https://doi.org/10.1016/j.acalib.2024.102864},
url = {https://www.sciencedirect.com/science/article/pii/S0099133324000259},
author = {Christopher A. Barnes and Scott Vine and Ryan Nadeau},
keywords = {Course materials, Textbook affordability, Open educational resources, Textbook crisis, Student spending, COVID-19 pandemic, Liberal arts college, Faculty survey},
abstract = {This article compares the results of a pair of course material surveys for faculty and students conducted before and after the COVID-19 pandemic by academic librarians at a private liberal arts college in the northeastern U.S. Findings indicate that overall students are spending significantly less per semester on required course materials, but some are going without significantly more required materials due to cost. Furthermore, first-year students were not found to be spending any less than prior to the pandemic and, as a result, spent significantly more in 2023 than most of their more experienced peers. The decrease in average student spending corresponds with our findings that faculty became more cost conscious and expanded efforts to make required materials affordable by assigning more OER and fewer materials which they consider to be overpriced or unaffordable. As a result of these and other strategies, by 2023 significantly more faculty had been able to develop courses for which the required materials cost nothing for students. The authors discuss the importance of these and additional findings, placing them in the context of similar surveys and suggesting ways that the data can be used to inform current library practices and future research.}
}
@article{ZHANG2024109095,
title = {Public cloud networks oriented deep neural networks for effective intrusion detection in online music education},
journal = {Computers and Electrical Engineering},
volume = {115},
pages = {109095},
year = {2024},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2024.109095},
url = {https://www.sciencedirect.com/science/article/pii/S0045790624000235},
author = {Jianan Zhang and J Dinesh Peter and Achyut Shankar and Wattana Viriyasitavat},
keywords = {Public cloud networks, Deep neural networks, Intrusion detection, Online music education, Deep belief networks},
abstract = {The rapid growth of online music education has led to increased security risks from cyber intrusions. This paper proposes public cloud networks oriented deep neural networks for effective intrusion detection in online music education environments. Specifically, a novel intrusion detection framework is developed, comprising fuzzy logic based feature selection, chronological salp swarm algorithm optimized deep belief networks, and gated recurrent unit integrated convolutional neural networks. Detailed methodologies are presented for the fuzzy logic system, chronological salp optimization, deep belief network architecture, and convolutional neural networks. Comprehensive experiments are conducted on the NSL-KDD and CICIDS2017 datasets. Various deep neural networks are evaluated and compared, including multi-layer perceptrons, convolutional neural networks, deep belief networks, recurrent neural networks, and the proposed models. Experimental results demonstrate that the proposed fuzzy feature selection and chronological salp swarm algorithm optimized deep belief network achieves a test accuracy of 97.33 %, outperforming other peer models. The gated recurrent unit integrated convolutional neural network obtains a test accuracy of 98.46 %, superior to state-of-the-art methods. While the experiments on the newly created dataset for intrusion detection in cloud-based online music education demonstrate that the proposed models outperform the benchmarks. The experiments verify the effectiveness of the proposed deep learning frameworks for intrusion detection in online music education cloud networks.}
}
@article{202458,
title = {Guide for Authors},
journal = {Intelligent Medicine},
volume = {4},
number = {1},
pages = {58-64},
year = {2024},
issn = {2667-1026},
doi = {https://doi.org/10.1016/S2667-1026(24)00017-2},
url = {https://www.sciencedirect.com/science/article/pii/S2667102624000172}
}
@article{ONDEN2024108378,
title = {Exploring the adoption of the metaverse and chat generative pre-trained transformer: A single-valued neutrosophic Dombi Bonferroni-based method for the selection of software development strategies},
journal = {Engineering Applications of Artificial Intelligence},
volume = {133},
pages = {108378},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.108378},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624005360},
author = {Abdullah Önden and Karahan Kara and İsmail Önden and Galip Cihan Yalçın and Vladimir Simic and Dragan Pamucar},
keywords = {Virtual reality, Metaverse, Natural language processing, Single-valued neutrosophic sets, Alternative ranking order method accounting for two-step normalization},
abstract = {The contemporary era has witnessed remarkable developments that seek to transform and reshape traditional software development methodologies. Notably, artificial intelligence (AI) supported software development as well as software development in virtual reality environments have gained considerable prominence. This article introduces software development strategies to examine how software developers and companies respond to this transformation. Also, an advanced decision model is developed using the alternative ranking order method accounting for two-step normalization (AROMAN) method and further analyzed with the single-valued neutrosophic set-based AROMAN technique. The single-valued neutrosophic weighted Dombi Bonferroni operator is employed in the analysis process. This research offers two case studies investigating the preferences of developers and managers in software development strategies. The first case study examines the preferences of developers, while the second focuses on the preferences of managers. In both case studies, three fundamental software development methods are presented. These include the “traditional developers approach”, “AI-supported developers approach”, and “mixed reality and AI-supported developers approach”. These methods are ranked based on expert opinions concerning 10 criteria that influence the software development process. In both case studies, “output quality” is identified as the most influential criterion. From the perspective of software development methods, in both case studies, the “mixed reality and AI-supported developers approach” is identified as the most effective. Recommendations are provided for developers and managers. The findings also have significant implications for guiding developers and managers in making informed decisions and optimizing software development practices to align with the evolving AI and virtual reality landscape.}
}
@article{SJOVAAG2024102738,
title = {Delivering content: Modular broadcasting technology and the role of content delivery networks},
journal = {Telecommunications Policy},
volume = {48},
number = {4},
pages = {102738},
year = {2024},
issn = {0308-5961},
doi = {https://doi.org/10.1016/j.telpol.2024.102738},
url = {https://www.sciencedirect.com/science/article/pii/S0308596124000351},
author = {Helle Sjøvaag and Ragnhild Kr. Olsen and Raul Ferrer-Conill},
keywords = {Autonomy, Broadcasting, Content delivery networks, distribution, Infrastructure, value chains},
abstract = {Television distribution has changed profoundly over the past 10–15 years. Now increasingly geared towards streaming, broadcasting's value chain hinges on content delivery networks (CDNs) to reach audiences. CDNs are important for content quality, as they constitute the part of the chain that stores and transmits data from broadcasters to the end-user. In this article, we investigate what this value chain shift means for television distribution in Norway, a country where global actors like Akamai and Amazon's CloudFront dominate the CDN market. Based on seven whiteboard-based, co-creation sessions with 15 industry experts representing broadcasters, telecoms, regulators and interest organisations, a value chain analysis reveals that the distribution part of the chain is outsourced and modular. As the technology of television distribution becomes increasingly outsourced, we ask what this means for television's autonomy as a universal service provider.}
}
@article{JAHANIYEKTA2024100078,
title = {The general intelligence of GPT–4, its knowledge diffusive and societal influences, and its governance},
journal = {Meta-Radiology},
volume = {2},
number = {2},
pages = {100078},
year = {2024},
issn = {2950-1628},
doi = {https://doi.org/10.1016/j.metrad.2024.100078},
url = {https://www.sciencedirect.com/science/article/pii/S2950162824000316},
author = {Mohammad Mahdi {Jahani Yekta}},
keywords = {GPT–4, Artificial general intelligence, Knowledge diffusion, Interpretability and explainability, Societal influences, Governance},
abstract = {Recent breakthroughs in artificial intelligence (AI) research include advancements in natural language processing (NLP) achieved by large language models (LLMs), and; in particular, generative pre–trained transformer (GPT) architectures. The latest GPT developed by OpenAI, GPT–4, has shown remarkable intelligence across various domains and tasks. It exhibits capabilities in abstraction, comprehension, vision, computer coding, mathematics, and more, suggesting it to be a significant step towards artificial general intelligence (AGI), a level of AI that possesses capabilities similar to human intelligence. This paper explores this AGI, its knowledge diffusive and societal influences, and its governance. In addition to coverage of the major associated topics studied in the literature, and making up for their loopholes, we scrutinize how GPT-4 can facilitate the diffusion of knowledge across different areas of science by promoting their interpretability and explainability (IE) to inexperts. Where applicable, the topics are also accompanied by their specific potential implications on medical imaging.}
}
@article{WAMBA2024101912,
title = {How emerging technologies can solve critical issues in organizational operations: An analysis of blockchain-driven projects in the public sector},
journal = {Government Information Quarterly},
volume = {41},
number = {1},
pages = {101912},
year = {2024},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2024.101912},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X24000042},
author = {Samuel Fosso Wamba and Serge-Lopez Wamba-Taguimdje and Qihui Lu and Maciel M. Queiroz},
keywords = {Blockchain, Public sector, Process innovation, Operational performance, Administrative performance, Cases studies},
abstract = {Blockchain technology emerged as a concrete and disruptive application in all sectors. Even if the public sector witnessed this technology's first applications and implementations, it took a while to spread even in that environment. Previous studies have shown that blockchain technologies are a powerful, essential, and effective lever for transforming government processes and procedures and improving the management of public benefits and policies. Following an analysis of a sample of 167 blockchain-oriented projects in the public sector, we explore in this article the extent of the effects of blockchain on fundamental public governance functions, and we further explore the information technology and strategic management literature in this regard. As a result, our study shows concrete evidence of how blockchain improves several government core functions: (1) public service governance, administrative efficiency, and open government capabilities; (2) process innovation in public services; and operational and administrative performance improvement. Via a fsQCA analysis, we explored how indicators characterizing blockchain-based transformation projects in the public sector led to radical transformations in public services. Our findings move forward the blockchain perspective on the public sector by enriching the literature, bringing insights to policymakers, and opening new research directions to scholars and practitioners.}
}
@article{BACK202423,
title = {Accelerated chemical science with AI},
journal = {Digital Discovery},
volume = {3},
number = {1},
pages = {23-33},
year = {2024},
issn = {2635-098X},
doi = {https://doi.org/10.1039/d3dd00213f},
url = {https://www.sciencedirect.com/science/article/pii/S2635098X24000858},
author = {Seoin Back and Alán Aspuru-Guzik and Michele Ceriotti and Ganna Gryn'ova and Bartosz Grzybowski and Geun Ho Gu and Jason Hein and Kedar Hippalgaonkar and Rodrigo Hormázabal and Yousung Jung and Seonah Kim and Woo Youn Kim and Seyed Mohamad Moosavi and Juhwan Noh and Changyoung Park and Joshua Schrier and Philippe Schwaller and Koji Tsuda and Tejs Vegge and O. Anatole {von Lilienfeld} and Aron Walsh},
abstract = {In light of the pressing need for practical materials and molecular solutions to renewable energy and health problems, to name just two examples, one wonders how to accelerate research and development in the chemical sciences, so as to address the time it takes to bring materials from initial discovery to commercialization. Artificial intelligence (AI)-based techniques, in particular, are having a transformative and accelerating impact on many if not most, technological domains. To shed light on these questions, the authors and participants gathered in person for the ASLLA Symposium on the theme of ‘Accelerated Chemical Science with AI’ at Gangneung, Republic of Korea. We present the findings, ideas, comments, and often contentious opinions expressed during four panel discussions related to the respective general topics: ‘Data’, ‘New applications’, ‘Machine learning algorithms’, and ‘Education’. All discussions were recorded, transcribed into text using Open AI's Whisper, and summarized using LG AI Research's EXAONE LLM, followed by revision by all authors. For the broader benefit of current researchers, educators in higher education, and academic bodies such as associations, publishers, librarians, and companies, we provide chemistry-specific recommendations and summarize the resulting conclusions.}
}
@article{CROSBY2024e00336,
title = {Open-source extrusion 3D bioprinters: Trends and recommendations},
journal = {Bioprinting},
volume = {38},
pages = {e00336},
year = {2024},
issn = {2405-8866},
doi = {https://doi.org/10.1016/j.bprint.2024.e00336},
url = {https://www.sciencedirect.com/science/article/pii/S2405886624000083},
author = {Cody O. Crosby},
keywords = {Bioprinting, Open-source, Extrusion, Hydrogels, Bioink},
abstract = {Three-dimensional (3D) extrusion bioprinting, an additive manufacturing process that hybridizes traditional thermoplastic 3D printing technology with the latest developments in tissue engineering, is a promising tool for engineering lab-scale tissues and organs for drug screening, pathological modeling, and transplantation. The technology has been proven to be reliable, high-throughput, and capable of printing complex physiological structures at relevant scales. Commercially available 3D extrusion bioprinters can manipulate a broad range of soft materials with sub-millimeter resolution. However, these bioprinters are expensive and typically contain proprietary software, impeding the customization of bioprinters to lab-specific applications. In response, researchers have recently manufactured and published open-source 3D extrusion bioprinters converted from thermoplastic printers. This review compares and evaluates currently available open-source 3D extrusion bioprinters, including their total cost, features, and necessary technical experience to fabricate in most academic labs. Current open-source slicing software is detailed, and guidelines are offered to ensure this technology continues contributing to the democratization of additive manufacturing technology. These comparisons and recommendations will allow researchers to choose an open-source printer that best suits their laboratory's 3D bioprinting needs and will highlight the need to iterate and improve published designs.}
}
@article{OTOOLE2024100080,
title = {Extending human creativity with AI},
journal = {Journal of Creativity},
volume = {34},
number = {2},
pages = {100080},
year = {2024},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2024.100080},
url = {https://www.sciencedirect.com/science/article/pii/S2713374524000062},
author = {Katherine O'Toole and Emőke-Ágnes Horvát},
keywords = {Computational creativity, Generative AI, HCI},
abstract = {The development of generative AI has led to novel ways that technology can be integrated into creative activities. However, this has also raised concerns about how human creators will be affected, and what impact it may have on creative industries. As a result, there has been research into how we can design AI tools that work with human creators, rather than replacing them. In this paper we review approaches utilized to build AI tools that facilitate human creativity and allow users to engage fully and authentically in the creative process. These include leveraging AI models to help us shed light on elements of the creative process, building interfaces that encourage exploration of ideas, and designing technological affordances that can support the development of new creative practices.}
}
@article{2024105859,
title = {DLA Piper EU update},
journal = {Computer Law & Security Review},
volume = {52},
pages = {105859},
year = {2024},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2023.105859},
url = {https://www.sciencedirect.com/science/article/pii/S0267364923000699}
}
@article{JAVAID2024100083,
title = {Digital economy to improve the culture of industry 4.0: A study on features, implementation and challenges},
journal = {Green Technologies and Sustainability},
volume = {2},
number = {2},
pages = {100083},
year = {2024},
issn = {2949-7361},
doi = {https://doi.org/10.1016/j.grets.2024.100083},
url = {https://www.sciencedirect.com/science/article/pii/S2949736124000101},
author = {Mohd Javaid and Abid Haleem and Ravi Pratap Singh and Anil Kumar Sinha},
keywords = {Digital economy, Industry 4.0, Enablers, Feature, Technologies},
abstract = {The digital economy refers to the economic activities that emerge from connecting individuals, businesses, devices, data, and operations through digital technology. It includes online transactions across multiple sectors and technologies, such as the Internet, mobile technology, big data, and information and communications technology. The digital economy differs from a traditional economy because it relies on digital technology, online transactions, and its transformative effect on traditional industries Digital innovations such as the Internet of Things (IoT), Artificial Intelligence (AI), Virtual Reality, Blockchain, and autonomous vehicles all play a part in creating a digital economy. For this study, various papers on ”Digital Economy” and ”Industry 4.0” are identified from Scopus, Google Scholar and other research platforms and further studied briefly. This review paper has been developed after studying the digital economy and its needs in the Industry 4.0 Environment. The defining trends, key enablers, features and challenges associated with the digital economy towards Industry 4.0 are discussed briefly. Finally, the paper identifies and discusses the significant requirements of Industry 4.0 fulfilled through the digital economy. Today, customers are becoming aware of goods and services online and are turning to the industry for long-term solutions by deploying digital technologies. The digital economy is built on hyper connectivity, the growing interconnectedness of individuals, organisations, and machines due to the Internet, mobile technologies, and the IoT. Industry 4.0 technologies are automation, data exchange, cloud computing, robotics, big data, AI, the IoT, and other technological trends are all part of the industrial sector’s digital transformation, which aims to achieve industrial objectives and intelligent manufacturing practices that engage with customers, emerging technologies, and innovation. The economy is becoming more digital, changing how products and services are provided and consumed. A new road map is being provided by Industry 4.0 services to help many industries adapt their conventional methods and support the new revolution. In the digital economy, scaled-up, integrated ecosystems that leverage software platforms to generate value, build resilience, and stimulate innovation via networked goods, assets, people, and processes rapidly replace old, linear value chains with partner participation.}
}
@article{ALSHAIKH2024e25361,
title = {The implementation of the cognitive theory of multimedia learning in the design and evaluation of an AI educational video assistant utilizing large language models},
journal = {Heliyon},
volume = {10},
number = {3},
pages = {e25361},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e25361},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024013926},
author = {Rana AlShaikh and Norah Al-Malki and Maida Almasre},
keywords = {Large language models, Cognitive theory of multimedia learning, Educational video, ASR, Google's bard},
abstract = {The integration of Artificial Intelligence (AI) holds immense potential for revolutionizing education; especially, in contexts where multimodal learning experiences are designed. This paper investigated the potential benefits of Generative Artificial Intelligence (AI) in education, concentrating on the design and evaluation of an AI Educational Video Assistant tailored for multimodal learning experiences. The tool, utilizing the principles of the Cognitive Theory of Multimedia Learning (CTML), comprises three modules: Transcription, Engagement, and Reinforcement, each focusing on distinct aspects of the learning process. It Integraties Automatic Speech Recognition (ASR) using OpenAI's Whisper and Google's Large Language Model (LLM) Bard. Our twofold objective includes both the development of this AI assistant tool and the assessment of its effect on improving the learning experiences. For the evaluation, a mixed methods approach was adopted, combining human evaluation by nine educational experts with automatic metrics. Participants provided their perceptions on the tool's effectiveness in terms of engagement, content organization, clarity, and usability. Additionally, automatic metrics including Content Distinctiveness and Readability scores were computed. The results from the human evaluation suggest positive impacts across all assessed domains. The automatic metrics further proved the tool's ability in content generation and readability. Collectively, these preliminary results highlight the tool's potential to revolutionize educational design and provide personalized and engaging learning experiences.}
}
@article{ARCHAMBAULT2024102865,
title = {Ethical dimensions of algorithmic literacy for college students: Case studies and cross-disciplinary connections},
journal = {The Journal of Academic Librarianship},
volume = {50},
number = {3},
pages = {102865},
year = {2024},
issn = {0099-1333},
doi = {https://doi.org/10.1016/j.acalib.2024.102865},
url = {https://www.sciencedirect.com/science/article/pii/S0099133324000260},
author = {Susan Gardner Archambault and Shalini Ramachandran and Elisa Acosta and Sheree Fu},
keywords = {Algorithmic literacy, Information literacy, Algorithmic bias, AI ethics, Algorithmic fairness, Computer science education},
abstract = {This article addresses three key questions related to the ethical facets of algorithmic literacy. First, it synthesizes existing literature to identify six core ethical components, including bias, privacy, transparency, accountability, accuracy, and non-maleficence. Second, a crosswalk maps the intersections of these principles across the Association of College and Research Libraries' Framework for Information Literacy for Higher Education and the Association of Computing Machinery's Code of Ethics and Professional Conduct and Joint Statement on Principles for Responsible Algorithmic Systems. This analysis reveals significant overlap on issues like unfairness and transparency, helping prioritize topics for instruction. Finally, case studies showcase pedagogical strategies for teaching ethical considerations, informed by the crosswalk. Workshops for diverse undergraduates and computer science students employed reallife instances of algorithmic bias to prompt reflection on unintended harm, contestability, and responsible development. Pre-post surveys indicated expanded critical perspectives after the interventions. By systematically examining shared values and testing instructional approaches, this study provides practical tools to shape ethical thinking on algorithms. It also demonstrates promising practices for responsibly advancing algorithmic literacy across disciplines. Ultimately, fostering interdisciplinary awareness and multipronged educational initiatives can empower students to question algorithmic authority and biases.}
}
@article{GOMEZQUINTERO2024103338,
title = {A scoping study of crime facilitated by the metaverse},
journal = {Futures},
volume = {157},
pages = {103338},
year = {2024},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2024.103338},
url = {https://www.sciencedirect.com/science/article/pii/S0016328724000211},
author = {Juliana Gómez-Quintero and Shane D. Johnson and Hervé Borrion and Samantha Lundrigan},
keywords = {Metaverse, Crime, Future threats, Nominal group technique},
abstract = {The metaverse is an emerging convergence of technologies (e.g., virtual reality and blockchains) that enables users to experience mixed/extended realities for various legitimate purposes (e.g., gaming, tourism, manufacturing and education). Unfortunately, the crime and security implications of emerging technologies are often overlooked. To anticipate crimes that the metaverse might facilitate, we report the findings of a nominal group technique (NGT) study, which involved a state-of-the-art scoping review of the existing literature and elicitation exercises with two groups of experts (one a diverse group from the UK and Europe, the other representing international law enforcement) with a wide range of expertise. A total of 30 crime threats were identified in the literature or by participants. The elicitation exercises also explored how harmful, frequent, achievable and defeatable participants anticipated that the crimes identified would be. Ratings for these aspects were largely consistent across the two samples, with crimes of a sexual nature (e.g., child sexual abuse material), and crimes against the person (e.g., hate crime) being rated as presenting the highest future risks (i.e. being high harm and high frequency) and being the most difficult to address. The findings illuminate understanding of the most (and least) harmful and likely crime threats the metaverse could facilitate and consequently help stakeholders to prioritise which offences to focus on. In discussing how the crime threats might be addressed, we consider roles and responsibilities and how theory about the management of physical places might inform crime prevention in the metaverse(s).}
}
@article{LI2024215888,
title = {Combining machine learning and metal–organic frameworks research: Novel modeling, performance prediction, and materials discovery},
journal = {Coordination Chemistry Reviews},
volume = {514},
pages = {215888},
year = {2024},
issn = {0010-8545},
doi = {https://doi.org/10.1016/j.ccr.2024.215888},
url = {https://www.sciencedirect.com/science/article/pii/S0010854524002340},
author = {Chunhua Li and Luqian Bao and Yixin Ji and Zhehang Tian and Mengyao Cui and Yubo Shi and Zhilei Zhao and Xianyou Wang},
keywords = {Metal-organic frameworks, Machine learning, Novel modeling, Performance prediction, Materials discovery},
abstract = {Machine learning (ML) is the science of making computers learn and behave like humans, autonomously improving their learning by providing them with data and information through observations and real-world interactions. ML methods have significantly accelerated the progress of materials science research. Researchers can use ML frameworks to construct materials research models and design platforms to analyze and predict enormous data resources on materials. Metal-organic frameworks (MOFs), a rapidly developing coordination polymer in the last two decades, have become the most competitive candidate among thousands of porous materials with the application of numerous ML methods and models that have been successfully developed. This review offers an overview of how ML methods may be well-integrated with studying MOFs. It starts with a brief background on the concept and application of ML, points out the importance of various types of descriptors for ML modeling, and introduces several novel algorithms and models using ML in recent years. Then, we elaborate on the current research status of ML methods in MOFs performance prediction and materials discovery. At last, potential challenges are pointed out, and an outlook is given regarding the basic situation of ML-based MOF research. As various functionalized MOFs continue to be developed and applied in specific directions, ML will bring its advantages to the forefront in designing and discovering novel MOFs. Therefore, this review intends to provide readers with fundamental perspectives on the broad range of applications where ML is combined with MOFs research and expects to help enhance their study.}
}
@article{YADAV2024367,
title = {Revolutionizing drug discovery: The impact of artificial intelligence on advancements in pharmacology and the pharmaceutical industry},
journal = {Intelligent Pharmacy},
volume = {2},
number = {3},
pages = {367-380},
year = {2024},
issn = {2949-866X},
doi = {https://doi.org/10.1016/j.ipha.2024.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S2949866X24000327},
author = {Seema Yadav and Abhishek Singh and Rishika Singhal and Jagat Pal Yadav},
keywords = {Artificial intelligence, AI pharmacology, AI in drug discovery, Medical diagnosis, Clinical trials},
abstract = {To create novel treatments and treat complex diseases, the pharmaceutical sector is essential. Drug discovery, however, is a time-consuming, pricey, and dangerous endeavor. Artificial intelligence (AI) has become a potent instrument that has transformed several industries, including healthcare, in recent years. This summary gives a general overview of how AI is expediting the creation of novel medicines, revolutionizing the pharmaceutical sector, and enabling drug discovery. The pharmaceutical sector is experiencing a drug discovery revolution because of AI. The drug discovery process is changing at different phases because of AI approaches like machine learning and deep learning. This abstract demonstrates how AI facilitates drug development through target identification, lead compound optimization, drug design, drug repurposing, and clinical trial enhancement. AI integration has the potential to hasten the creation of novel treatments, save costs, and improve patient outcomes. To fully realize the potential of AI in pharmaceutical research and development, issues relating to data accessibility, algorithm interpretability, and laws must be resolved.}
}
@article{ZAFAR2024102769,
title = {Exploring the synergies between collaborative robotics, digital twins, augmentation, and industry 5.0 for smart manufacturing: A state-of-the-art review},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {89},
pages = {102769},
year = {2024},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2024.102769},
url = {https://www.sciencedirect.com/science/article/pii/S0736584524000553},
author = {Muhammad Hamza Zafar and Even Falkenberg Langås and Filippo Sanfilippo},
keywords = {Digital twins, Industry 5.0, Deep learning, Augmentation, HRC},
abstract = {Industry 5.0 aims at establishing an inclusive, smart and sustainable production process that encourages human creativity and expertise by leveraging enhanced automation and machine intelligence. Collaborative robotics, or “cobotics”,is a major enabling technology of Industry 5.0, which aspires at improving human dexterity by elevating robots to extensions of human capabilities and, ultimately, even as team members. A pivotal element that has the potential to operate as an interface for the teaming aspiration of Industry 5.0 is the adoption of novel technologies such as virtual reality (VR), augmented reality (AR), mixed reality (MR) and haptics, together known as “augmentation”. Industry 5.0 also benefit from Digital Twins (DTs), which are digital representations of a physical assets that serves as their counterpart — or twins. Another essential component of Industry 5.0 is artificial intelligence (AI), which has the potential to create a more intelligent and efficient manufacturing process. In this study, a systematic review of the state of the art is presented to explore the synergies between cobots, DTs, augmentation, and Industry 5.0 for smart manufacturing. To the best of the author’s knowledge, this is the first attempt in the literature to provide a comprehensive review of the synergies between the various components of Industry 5.0. This work aims at increasing the global efforts to realize the large variety of application possibilities offered by Industry 5.0 and to provide an up-to-date reference as a stepping-stone for new research and development within this field.}
}
@article{BALL2024368,
title = {Use of adeno-associated viruses for transgenic modulation of microglia structure and function: A review of technical considerations and challenges},
journal = {Brain, Behavior, and Immunity},
volume = {118},
pages = {368-379},
year = {2024},
issn = {0889-1591},
doi = {https://doi.org/10.1016/j.bbi.2024.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S088915912400285X},
author = {Jayson B. Ball and Matthew G. Frank and Suzanne M. Green-Fulgham and Linda R. Watkins},
keywords = {Neuroinflammation, Gene therapy, Macrophage, Transgene, AAV},
abstract = {Microglia play a central role in the etiology of many neuropathologies. Transgenic tools are a powerful experiment approach to gain reliable and specific control over microglia function. Adeno-associated virus (AAVs) vectors are already an indispensable tool in neuroscience research. Despite ubiquitous use of AAVs and substantial interest in the role of microglia in the study of central nervous system (CNS) function and disease, transduction of microglia using AAVs is seldom reported. This review explores the challenges and advancements made in using AAVs for expressing transgenes in microglia. First, we will examine the functional anatomy of the AAV capsid, which will serve as a basis for subsequent discussions of studies exploring the relationship between capsid mutations and microglia transduction efficacy. After outlining the functional anatomy of AAVs, we will consider the experimental evidence demonstrating AAV-mediated transduction of microglia and microglia-like cell lines followed by an examination of the most promising experimental approaches identified in the literature. Finally, technical limitations will be considered in future applications of AAV experimental approaches.}
}
@article{RESSI2024103858,
title = {AI-enhanced blockchain technology: A review of advancements and opportunities},
journal = {Journal of Network and Computer Applications},
volume = {225},
pages = {103858},
year = {2024},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2024.103858},
url = {https://www.sciencedirect.com/science/article/pii/S1084804524000353},
author = {Dalila Ressi and Riccardo Romanello and Carla Piazza and Sabina Rossi},
keywords = {Blockchain, Artificial intelligence, Machine learning},
abstract = {Blockchain technology has rapidly gained popularity, permeating various fields due to its inherent features of security, transparency, and decentralization. Blockchain-based applications, spanning from financial transactions to supply chain management, have revolutionized numerous industries. Concurrently, Artificial Intelligence (AI) techniques have emerged as a powerful tool for efficiently solving complex problems. The integration of AI into blockchain applications has shown promise in addressing key challenges such as security, consensus, scalability, and interoperability. While existing literature offers several surveys on the intersection of AI and blockchain, our work takes a distinct perspective by focusing on how AI solutions can enhance and optimize blockchain technology and its applications. Our goal is to provide a comprehensive literature overview of the methods that have been employed to improve blockchain technology through AI, encompassing machine learning, deep learning, natural language processing and reinforcement learning. Our contribution highlights AI’s potential to enhance blockchain, improving efficiency, security, and reliability of blockchain-based applications. By exploring AI’s role in consensus, smart contracts, and data privacy, it advances theory and practical applications, fostering innovation across sectors for a more secure and efficient digital future.}
}
@article{MAERTENS2024101755,
title = {Discovering and exploring cases of educational source code plagiarism with Dolos},
journal = {SoftwareX},
volume = {26},
pages = {101755},
year = {2024},
issn = {2352-7110},
doi = {https://doi.org/10.1016/j.softx.2024.101755},
url = {https://www.sciencedirect.com/science/article/pii/S2352711024001262},
author = {Rien Maertens and Maarten {Van Neyghem} and Maxiem Geldhof and Charlotte {Van Petegem} and Niko Strijbol and Peter Dawyndt and Bart Mesuere},
keywords = {Web app, Plagiarism, Source code, Academic dishonesty, Cheating, Learning analytics, Educational data mining, Online learning, Programming language},
abstract = {Source code plagiarism is a significant issue in educational practice, and educators need user-friendly tools to cope with such academic dishonesty. This article introduces the latest version of Dolos, a state-of-the-art ecosystem of tools for detecting and preventing plagiarism in educational source code. In this new version, the primary focus has been on enhancing the user experience. Educators can now run the entire plagiarism detection pipeline from a new web app in their browser, eliminating the need for any installation or configuration. Completely redesigned analytics dashboards provide an instant assessment of whether a collection of source files contains suspected cases of plagiarism and how widespread plagiarism is within the collection. The dashboards support hierarchically structured navigation to facilitate zooming in and out of suspect cases. Clusters are an essential new component of the dashboard design, reflecting the observation that plagiarism can occur among larger groups of students. To meet various user needs, the Dolos software stack for source code plagiarism detection now includes a self-hostable web app, a JSON application programming interface (API), a command line interface (CLI), a JavaScript library and a preconfigured Docker container. Clear documentation and a free-to-use instance of the web app can be found at https://dolos.ugent.be. The source code is also available on GitHub.}
}
@article{HAKIRI2024110350,
title = {A comprehensive survey on digital twin for future networks and emerging Internet of Things industry},
journal = {Computer Networks},
volume = {244},
pages = {110350},
year = {2024},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2024.110350},
url = {https://www.sciencedirect.com/science/article/pii/S1389128624001828},
author = {Akram Hakiri and Aniruddha Gokhale and Sadok Ben Yahia and Nedra Mellouli},
keywords = {Digital twin, Internet of Things, Interoperability, Standardization, Frameworks and prototypes, Security},
abstract = {The rapid growth of industrial digitalization in the Industry 4.0 era is fundamentally transforming the industrial sector by connecting products, machines, and people, offering real-time digital models to allow self-diagnosis, self-optimization and self-configuration. However, this uptake in such a digital transformation faces numerous obstacles. For example, the lack of real-time data feeds to perform custom closed-loop control and realize common, powerful industrial systems, the complexity of traditional tools and their inability in finding effective solutions to industry problems, lack of capabilities to experiment rapidly on innovative ideas, and the absence of continuous real-time interactions between physical objects and their simulation representations along with reliable two-way communications, are key barriers towards the adoption of such a digital transformation. Digital twins hold the promise of improving maintainability and deployability, enabling flexibility, auditability, and responsiveness to changing conditions, allowing continuous learning, monitoring and actuation, and allowing easy integration of new technologies in order to deploy open, scalable and reliable Industrial Internet of Things (IIoT). A critical understanding of this emerging paradigm is necessary to address the multiple dimensions of challenges in realizing digital twins at scale and create new means to generate knowledge in the industrial IoT. To address these requirements, this paper surveys existing digital twin along software technologies, standardization efforts and the wide range of recent and state-of-the-art digital twin-based projects; presents diverse use cases that can benefit from this emerging technology; followed by an in-depth discussion of the major challenges in this area drawing upon the research status and key trends in Digital Twins.}
}
@article{HE2024104752,
title = {Academic dishonesty in university nursing students: A scoping review},
journal = {International Journal of Nursing Studies},
volume = {154},
pages = {104752},
year = {2024},
issn = {0020-7489},
doi = {https://doi.org/10.1016/j.ijnurstu.2024.104752},
url = {https://www.sciencedirect.com/science/article/pii/S0020748924000646},
author = {Flora Xuhua He and Mahnaz Fanaian and Nancy Ming Zhang and Xanthe Lea and Sara Katherine Geale and Lisa Gielis and Kazem Razaghi and Alicia Evans},
keywords = {Academic integrity, Academic dishonesty, Academic misconduct, Clinical dishonesty, Nursing students, Nurses},
abstract = {Objective
This review seeks to deepen our understanding of the factors contributing to nursing students' academic dishonesty and the repercussions of such behaviours on their learning in both classroom and clinical settings, and on the integrity of the nursing profession.
Design and methods
It was a scoping review in which a five-stage methodological framework informed its process. Six databases were searched for relevant original studies. Other search methods were also conducted using Google Scholar, Trove, and ProQuest Dissertations for theses pertinent to the topic. An inductive descriptive approach was used to analyse and synthesise data.
Results
Twenty-seven studies and nine doctoral theses were selected and included in the scoping review. Of these, 25 studies used a quantitative approach, nine studies a qualitative one, and two studies used mixed methods. Three categorical factors, intrapersonal, interpersonal, and external, contributed to nursing students' academic dishonesty.
Conclusion
Academic dishonesty in nursing students is concerning. Noted factors contributing to academic dishonesty include stress and pressure experienced by students, the prevalence of peer cheating, and lack of knowledge. Most alarming is the significant correlation between academic dishonesty and clinical dishonesty. The evidence suggests that students who engage in dishonest behaviour in academic settings may be more likely to engage in dishonest behaviour in clinical settings. This raises serious concerns about integrity, ethics, patient safety and the reputation of nursing students, universities, healthcare providers and health professionals.}
}
@article{KRASNOV2024681,
title = {Comparing software tools for optical chemical structure recognition},
journal = {Digital Discovery},
volume = {3},
number = {4},
pages = {681-693},
year = {2024},
issn = {2635-098X},
doi = {https://doi.org/10.1039/d3dd00228d},
url = {https://www.sciencedirect.com/science/article/pii/S2635098X24000585},
author = {Aleksei Krasnov and Shadrack J. Barnabas and Timo Boehme and Stephen K. Boyer and Lutz Weber},
abstract = {The extraction of chemical information from images, also known as Optical Chemical Structure Recognition (OCSR) has recently gained new attention. This new interest is ignited by various machine learning methods introduced over the last years and the new possibilities to train image models for specific tasks such as OCSR. In the present paper, we have compared 8 open access OCSR methods (DECIMER, ReactionDataExtractor, MolScribe, RxnScribe, SwinOCSR, OCMR, MolVec, and OSRA) using an independent test set of images from patents and patent applications as this is an application area of general interest – precision and recall are highly desired by those who are analysing the intellectual property of chemistry patents. As a result, the used methods have shown different strengths when predicting structures from different images containing different modalities and chemistry categories. These existing methodologies for image extraction overall remain unsatisfactory, indicating a need for further advancements in the field. Further, we have created a machine learning image classifier, classifying images into one out of four image categories and applying the best performing OCSR method for each category. This classifier, the image comparator tools, and datasets have been made available to the public as open access tools.}
}
@article{MELMAN2024104073,
title = {Methods for countering attacks on image watermarking schemes: Overview},
journal = {Journal of Visual Communication and Image Representation},
volume = {99},
pages = {104073},
year = {2024},
issn = {1047-3203},
doi = {https://doi.org/10.1016/j.jvcir.2024.104073},
url = {https://www.sciencedirect.com/science/article/pii/S1047320324000282},
author = {Anna Melman and Oleg Evsutin},
keywords = {Digital images, Watermarking, Robustness, Removal attacks, Forgery attacks},
abstract = {Image watermarking is an effective and promising technology. Robust watermarks that are resistant to various attacks allow authors and owners of digital images to protect their rights to digital content, control its distribution and confirm its authenticity. Most of the modern algorithms for robust image watermarking aim to achieve resistance to a large number of different attacks. However, some authors develop algorithms designed to counter targeted attacks. The study of such schemes allows developers of watermarking algorithms to evaluate special means of counteracting various attacks, and then use them to create new robust schemes, both targeted and universal ones. In this paper, we present an overview of robust image watermarking schemes in terms of countering targeted attacks. We review the state-of-the-art in the field of attacking robust watermarks and propose a four-level classification of attacks that includes different levels of attack implementation, including an attacker’s intent, characteristics of actions, the main target and an attack type. The proposed classification considers a watermark as an object of attack and summarizes various characteristics of attacks in a hierarchical manner. We analyze the means of countering common attacks such as image processing attacks, geometric attacks, print-scan and screen capture attacks, collusion attacks, and ambiguity attacks. Based on the results of our review, we highlight the most common methods of countering attacks and formulate promising areas of research in the field of methods for improving security of embedding schemes.}
}
@article{SUNDBERG2024561,
title = {Innovating by prompting: How to facilitate innovation in the age of generative AI},
journal = {Business Horizons},
volume = {67},
number = {5},
pages = {561-570},
year = {2024},
note = {SPECIAL ISSUE: WRITTEN BY CHATGPT},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2024.04.014},
url = {https://www.sciencedirect.com/science/article/pii/S0007681324000594},
author = {Leif Sundberg and Jonny Holmström},
keywords = {Prompt engineering, Iterative prompting, ChatGPT, Generative AI, AI and innovation, Large language models},
abstract = {This article focuses on how recent advances in artificial intelligence (AI), particularly chatbots based on large language models (LLMs), such as ChatGPT, can be used for innovation purposes. The article begins with a brief overview of the development and characteristics of generative AI (GenAI). Elaborating on the implications of GenAI, we provide examples to demonstrate four mechanisms of LLMs: translation, summarization, classification, and amplification. These mechanisms inform a framework that highlights how LLMs enable the creation of innovative solutions for organizations through capacities in two dimensions: context awareness and content awareness. The strength of LLMs lies in the combination of capacities in both these dimensions, which enables them to comprehend and amplify content. Four managerial suggestions are presented, ranging from starting out with small-scale projects and data exploration, to scaling through integration efforts and educating prompt engineers. By presenting the framework, recommendations, and examples of use cases in various contexts, the article contributes to the emerging literature on GenAI and innovation.}
}
@article{TEO2024101419,
title = {Federated machine learning in healthcare: A systematic review on clinical applications and technical architecture},
journal = {Cell Reports Medicine},
volume = {5},
number = {2},
pages = {101419},
year = {2024},
issn = {2666-3791},
doi = {https://doi.org/10.1016/j.xcrm.2024.101419},
url = {https://www.sciencedirect.com/science/article/pii/S2666379124000429},
author = {Zhen Ling Teo and Liyuan Jin and Nan Liu and Siqi Li and Di Miao and Xiaoman Zhang and Wei Yan Ng and Ting Fang Tan and Deborah Meixuan Lee and Kai Jie Chua and John Heng and Yong Liu and Rick Siow Mong Goh and Daniel Shu Wei Ting},
keywords = {federated learning, systematic review, artificial intelligence, healthcare},
abstract = {Summary
Federated learning (FL) is a distributed machine learning framework that is gaining traction in view of increasing health data privacy protection needs. By conducting a systematic review of FL applications in healthcare, we identify relevant articles in scientific, engineering, and medical journals in English up to August 31st, 2023. Out of a total of 22,693 articles under review, 612 articles are included in the final analysis. The majority of articles are proof-of-concepts studies, and only 5.2% are studies with real-life application of FL. Radiology and internal medicine are the most common specialties involved in FL. FL is robust to a variety of machine learning models and data types, with neural networks and medical imaging being the most common, respectively. We highlight the need to address the barriers to clinical translation and to assess its real-world impact in this new digital data-driven healthcare scene.}
}
@article{MCKNIGHT202423,
title = {“Just a tool”? Troubling language and power in generative AI writing},
journal = {English Teaching: Practice & Critique},
volume = {23},
number = {1},
pages = {23-35},
year = {2024},
issn = {1175-8708},
doi = {https://doi.org/10.1108/ETPC-08-2023-0092},
url = {https://www.sciencedirect.com/science/article/pii/S117587082400013X},
author = {Lucinda McKnight and Cara Shipp},
keywords = {Pedagogy, Metaphor, Discourse analysis, Curriculum, Social justice, Feminism, Artificial intelligence, Professional learning, Writing, Generative AI writing tools},
abstract = {Purpose
The purpose of this paper is to share findings from empirically driven conceptual research into the implications for English teachers of understanding generative AI as a “tool” for writing.
Design/methodology/approach
The paper reports early findings from an Australian National Survey of English teachers and interrogates the notion of the AI writer as “tool” through intersectional feminist discursive-material analysis of the metaphorical entailments of the term.
Findings
Through this work, the authors have developed the concept of “coloniser tool-thinking” and juxtaposed it with First Nations and feminist understandings of “tools” and “objects” to demonstrate risks to the pursuit of social and planetary justice through understanding generative AI as a tool for English teachers and students.
Originality/value
Bringing together white and First Nations English researchers in dialogue, the paper contributes a unique perspective to challenge widespread and common-sense use of “tool” for generative AI services.}
}
@article{WANG2024100836,
title = {Fueling a net-zero future: The influence of government-funded research on climate change mitigation inventions},
journal = {Environmental Innovation and Societal Transitions},
volume = {51},
pages = {100836},
year = {2024},
issn = {2210-4224},
doi = {https://doi.org/10.1016/j.eist.2024.100836},
url = {https://www.sciencedirect.com/science/article/pii/S2210422424000273},
author = {Jieshu Wang and José Lobo and Shade T. Shutters and Deborah Strumsky},
keywords = {Environmental inventions, Patent data, Climate change mitigation technology, Net-zero emission, Novelty, Knowledge recombination, Government-funded research},
abstract = {This study examines the pace and content of Climate Change Mitigation Technology (CCMT) inventions, focusing on the influence of government-funded research on patent characteristics. Utilizing data from the USPTO, we analyze the trends in CCMT patenting from 1988 to 2017 and reveal a significant increase in CCMT inventions. However, patents in hydrogen technology and Carbon Capture and Storage (CCS) are comparatively low, suggesting these fields are still in the early development stages. CCMT inventions rely heavily on government-funded research, particularly in CCS and hydrogen technology. CCMT inventions relying on government research are more complex and generate larger and more pervasive knowledge spillovers than their counterparts. However, they are less likely to be novel and tend to consolidate rather than destabilize existing technologies. Interestingly, the effect of government research reducing the likelihood of novelty is only observed in CCMT inventions and does not extend to utility patents. These findings highlight the role of government-funded research in facilitating high-quality CCMT inventions through knowledge spillovers. Our study underscores the importance of sustained and targeted public investment in CCMT R&D.}
}
@article{NANDA2024100533,
title = {Enhancing cybersecurity: A review and comparative analysis of convolutional neural network approaches for detecting URL-based phishing attacks},
journal = {e-Prime - Advances in Electrical Engineering, Electronics and Energy},
volume = {8},
pages = {100533},
year = {2024},
issn = {2772-6711},
doi = {https://doi.org/10.1016/j.prime.2024.100533},
url = {https://www.sciencedirect.com/science/article/pii/S2772671124001153},
author = {Manika Nanda and Mala Saraswat and Pankaj Kumar Sharma},
keywords = {URL, Phishing, Features, Neural network, Machine learning, Deep learning, CNN, BiLSTM, APWG},
abstract = {Phishing attempts to mimic the official websites of businesses, including banks, e-commerce, government offices, and financial institutions. Phishing websites aim to collect and retrieve sensitive data from users, including passwords, credit card numbers, email addresses, personal information, and so on. The growing frequency of phishing attacks has prompted the development of numerous anti-phishing technologies. Because machine learning (ML) techniques perform better in categorization problems, they are used extensively. But the most crucial features are not extracted by the algorithms in use today, which could result in a false categorization. In addition, the complex algorithms contribute to the long reaction time. To solve these issues, this study suggests using a Bidirectional Long Short-Term Memory-based Gated Highway Attention Block Convolutional Neural Network (BiLSTM-GHA-CNN) to detect phishing URLs.}
}
@article{2024I,
title = {Full Issue PDF},
journal = {JACC: Basic to Translational Science},
volume = {9},
number = {3},
pages = {I-CLXV},
year = {2024},
issn = {2452-302X},
doi = {https://doi.org/10.1016/S2452-302X(24)00086-X},
url = {https://www.sciencedirect.com/science/article/pii/S2452302X2400086X}
}
@article{FERREIRA2024103100,
title = {GAN-based generation of realistic 3D volumetric data: A systematic review and taxonomy},
journal = {Medical Image Analysis},
volume = {93},
pages = {103100},
year = {2024},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2024.103100},
url = {https://www.sciencedirect.com/science/article/pii/S1361841524000252},
author = {André Ferreira and Jianning Li and Kelsey L. Pomykala and Jens Kleesiek and Victor Alves and Jan Egger},
keywords = {Synthetic volumetric data, Generative adversarial network, Systematic review, Volumetric GANs taxonomy},
abstract = {With the massive proliferation of data-driven algorithms, such as deep learning-based approaches, the availability of high-quality data is of great interest. Volumetric data is very important in medicine, as it ranges from disease diagnoses to therapy monitoring. When the dataset is sufficient, models can be trained to help doctors with these tasks. Unfortunately, there are scenarios where large amounts of data is unavailable. For example, rare diseases and privacy issues can lead to restricted data availability. In non-medical fields, the high cost of obtaining enough high-quality data can also be a concern. A solution to these problems can be the generation of realistic synthetic data using Generative Adversarial Networks (GANs). The existence of these mechanisms is a good asset, especially in healthcare, as the data must be of good quality, realistic, and without privacy issues. Therefore, most of the publications on volumetric GANs are within the medical domain. In this review, we provide a summary of works that generate realistic volumetric synthetic data using GANs. We therefore outline GAN-based methods in these areas with common architectures, loss functions and evaluation metrics, including their advantages and disadvantages. We present a novel taxonomy, evaluations, challenges, and research opportunities to provide a holistic overview of the current state of volumetric GANs.}
}
@article{XIE2024127225,
title = {A survey on vulnerability of federated learning: A learning algorithm perspective},
journal = {Neurocomputing},
volume = {573},
pages = {127225},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2023.127225},
url = {https://www.sciencedirect.com/science/article/pii/S0925231223013486},
author = {Xianghua Xie and Chen Hu and Hanchi Ren and Jingjing Deng},
keywords = {Federated Learning, Deep Learning, Model vulnerability, Privacy preserving},
abstract = {Federated Learning (FL) has emerged as a powerful paradigm for training Machine Learning (ML), particularly Deep Learning (DL) models on multiple devices or servers while maintaining data localized at owners’ sites. Without centralizing data, FL holds promise for scenarios where data integrity, privacy and security and are critical. However, this decentralized training process also opens up new avenues for opponents to launch unique attacks, where it has been becoming an urgent need to understand the vulnerabilities and corresponding defense mechanisms from a learning algorithm perspective. This review paper takes a comprehensive look at malicious attacks against FL, categorizing them from new perspectives on attack origins and targets, and providing insights into their methodology and impact. In this survey, we focus on threat models targeting the learning process of FL systems. Based on the source and target of the attack, we categorize existing threat models into four types, Data to Model (D2M), Model to Data (M2D), Model to Model (M2M) and composite attacks. For each attack type, we discuss the defense strategies proposed, highlighting their effectiveness, assumptions and potential areas for improvement. Defense strategies have evolved from using a singular metric to excluding malicious clients, to employing a multifaceted approach examining client models at various phases. In this survey paper, our research indicates that the to-learn data, the learning gradients, and the learned model at different stages all can be manipulated to initiate malicious attacks that range from undermining model performance, reconstructing private local data, and to inserting backdoors. We have also seen these threat are becoming more insidious. While earlier studies typically amplified malicious gradients, recent endeavors subtly alter the least significant weights in local models to bypass defense measures. This literature review provides a holistic understanding of the current FL threat landscape and highlights the importance of developing robust, efficient, and privacy-preserving defenses to ensure the safe and trusted adoption of FL in real-world applications. The categorized bibliography can be found at: https://github.com/Rand2AI/Awesome-Vulnerability-of-Federated-Learning.}
}
@article{LONGO2024102301,
title = {Explainable Artificial Intelligence (XAI) 2.0: A manifesto of open challenges and interdisciplinary research directions},
journal = {Information Fusion},
volume = {106},
pages = {102301},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2024.102301},
url = {https://www.sciencedirect.com/science/article/pii/S1566253524000794},
author = {Luca Longo and Mario Brcic and Federico Cabitza and Jaesik Choi and Roberto Confalonieri and Javier Del Ser and Riccardo Guidotti and Yoichi Hayashi and Francisco Herrera and Andreas Holzinger and Richard Jiang and Hassan Khosravi and Freddy Lecue and Gianclaudio Malgieri and Andrés Páez and Wojciech Samek and Johannes Schneider and Timo Speith and Simone Stumpf},
keywords = {Explainable artificial intelligence, XAI, Interpretability, Manifesto, Open challenges, Interdisciplinarity, Ethical AI, Large language models, Trustworthy AI, Responsible AI, Generative AI, Multi-faceted explanations, Concept-based explanations, Causality, Actionable XAI, Falsifiability},
abstract = {Understanding black box models has become paramount as systems based on opaque Artificial Intelligence (AI) continue to flourish in diverse real-world applications. In response, Explainable AI (XAI) has emerged as a field of research with practical and ethical benefits across various domains. This paper highlights the advancements in XAI and its application in real-world scenarios and addresses the ongoing challenges within XAI, emphasizing the need for broader perspectives and collaborative efforts. We bring together experts from diverse fields to identify open problems, striving to synchronize research agendas and accelerate XAI in practical applications. By fostering collaborative discussion and interdisciplinary cooperation, we aim to propel XAI forward, contributing to its continued success. We aim to develop a comprehensive proposal for advancing XAI. To achieve this goal, we present a manifesto of 28 open problems categorized into nine categories. These challenges encapsulate the complexities and nuances of XAI and offer a road map for future research. For each problem, we provide promising research directions in the hope of harnessing the collective intelligence of interested stakeholders.}
}
@article{CHEN2024103830,
title = {When deep learning meets watermarking: A survey of application, attacks and defenses},
journal = {Computer Standards & Interfaces},
volume = {89},
pages = {103830},
year = {2024},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2023.103830},
url = {https://www.sciencedirect.com/science/article/pii/S0920548923001113},
author = {Huajie Chen and Chi Liu and Tianqing Zhu and Wanlei Zhou},
keywords = {Model watermarking, Deep steganography, Deep learning, Security and privacy},
abstract = {Deep learning has been used to address various problems in a range of domains within both academia and industry. However, the issue of intellectual property with deep learning models has aroused broad attention. Watermarking, a proactive defense approach widely adopted to safeguard the copyright of digital content, is now sparking novel mechanisms for protecting the intellectual property of deep learning models. Further, significantly improved digital watermarking techniques have been developed to protect multimedia content, primarily images, with high efficiency and effectiveness. Yet, our current understandings of these two technical forefronts, i.e., deep learning model watermarking and image watermarking via deep learning, are unilaterally separated and application-oriented. To this end, we have undertaken a survey on emerging watermarking mechanisms in the two areas from a novel security perspective. That is, we have surveyed attacks and defenses in deep learning model watermarking and deep-learning-based image watermarking. Within the survey, we propose an objective taxonomy to unify the two domains, revealing their commonly shared properties with reference to design principles, functionalities, etc. Upon the taxonomy, a comprehensive analysis of attacks and defenses associated with the shared properties in both domains is presented. We have summarized the collected methods from a technical aspect and their advantages vs. disadvantages. A discussion of the joint characteristics and possible improvements of the methods are attached. Lastly, we have also proposed several potential research directions to inspire more ideas in these areas.}
}
@article{PIZZI2024103997,
title = {The 2023 video similarity dataset and challenge},
journal = {Computer Vision and Image Understanding},
volume = {243},
pages = {103997},
year = {2024},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2024.103997},
url = {https://www.sciencedirect.com/science/article/pii/S107731422400078X},
author = {Ed Pizzi and Giorgos Kordopatis-Zilos and Hiral Patel and Gheorghe Postelnicu and Sugosh {Nagavara Ravindra} and Akshay Gupta and Symeon Papadopoulos and Giorgos Tolias and Matthijs Douze},
keywords = {Video similarity challenge, Video copy detection, Video copy localization, Video dataset},
abstract = {This work introduces a dataset, benchmark, and challenge for the problem of video copy tracing. There are two related tasks: determining whether a query video shares content with a reference video (“detection”) and temporally localizing the shared content within each video (“localization”). The benchmark is designed to evaluate methods on these two tasks. It simulates a realistic needle-in-haystack setting, where the majority of both query and reference videos are “distractors” containing no copied content. We propose an accuracy metric for both tasks. The associated challenge imposes computing resource restrictions that reflect real-world settings. We also analyze the results and methods of the top submissions to the challenge. The dataset, baseline methods, and evaluation code are publicly available and were discussed at the Visual Copy Detection Workshop (VCDW) at CVPR’23. We provide reference code for evaluation and baselines at: https://github.com/facebookresearch/vsc2022.}
}
@article{CHRYSANTHOU2024103780,
title = {The anatomy of deception: Measuring technical and human factors of a large-scale phishing campaign},
journal = {Computers & Security},
volume = {140},
pages = {103780},
year = {2024},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2024.103780},
url = {https://www.sciencedirect.com/science/article/pii/S0167404824000816},
author = {Anargyros Chrysanthou and Yorgos Pantis and Constantinos Patsakis},
keywords = {Phishing, Digital forensics, Sentiment analysis, Human factors in cybersecurity},
abstract = {In an era dominated by digital interactions, phishing campaigns have evolved to exploit not just technological vulnerabilities but also human traits. This study takes an unprecedented deep dive into large-scale phishing campaigns aimed at Meta's users, offering a dual perspective on the technical mechanics and human elements involved. Analysing data from over 25,000 victims worldwide, we highlight the nuances of these campaigns, from the intricate techniques deployed by the attackers to the sentiments and behaviours of those targeted. Unlike prior research conducted in controlled environments, this investigation capitalises on the vast, diverse, and genuine data extracted directly from active phishing campaigns, allowing for a more holistic understanding of the drivers, facilitators, and human factors. Through applying advanced computational techniques, including natural language processing and machine learning, this work unveils critical insights into the psyche of victims and the evolving tactics of modern phishers. Our analysis illustrates very poor password selection choices from the victims, with 30.27% of them picking low-complexity passwords and 58.23% reusing leaked passwords. Additionally, more than 10% exhibit strong persistence in re-victimisation by posting again to the phishing platforms of the same phishers. Finally, we reveal many correlations regarding demographics and the time periods when victims are more vulnerable during the day, as well as analyse the sentiment, emotion, and tone of text responses that they submitted, illustrating how convinced they were of the scam.}
}
@article{HALEEM2024392,
title = {Exploring the competence of ChatGPT for customer and patient service management},
journal = {Intelligent Pharmacy},
volume = {2},
number = {3},
pages = {392-414},
year = {2024},
issn = {2949-866X},
doi = {https://doi.org/10.1016/j.ipha.2024.03.002},
url = {https://www.sciencedirect.com/science/article/pii/S2949866X24000480},
author = {Abid Haleem and Mohd Javaid and Ravi Pratap Singh},
keywords = {Artificial intelligence (AI), ChatGPT, Applications, Healthcare, Customer, Patient},
abstract = {The modern language generation model ChatGPT, created by Open Artificial Intelligence (AI), is recognised for its capacity to comprehend context and produce pertinent content. This model is built on the transformer architecture, which enables it to process massive volumes of data and produce text that is both cohesive and illuminating. Service is a crucial component everywhere as it provides the basis for establishing client rapport and offering aid and support. In healthcare, the application of ChatGPT for patient service support has been one of the most significant advances in recent years. ChatGPT can help overcome language obstacles and improve patient satisfaction by facilitating communication with healthcare personnel and understanding of care. It can assist in enhancing the entire patient experience by offering personalised information and support to patients and making it more straightforward for them to communicate with healthcare professionals. Its goal can be to expedite and streamline service by promptly and accurately responding to customers. Businesses of all sizes increasingly use ChatGPT since it allows them to provide 24/7 customer support without requiring human contact. This paper briefly discusses ChatGPT and the need for better services. Various perspectives on improving customer and patient services through ChatGPT are discussed. The article also discussed the major key enablers of ChatGPT for refining customer and patient assistance. Further, the paper identifies and discusses the critical application areas of ChatGPT for customer and patient service. With its ability to handle several requests simultaneously, respond quickly and accurately to client questions, and gain knowledge from every interaction, ChatGPT is revolutionising customer and patient service. Its accessibility and compatibility with various communication channels make it a desirable solution for businesses looking to improve support. As technology advances, ChatGPT is positioned to become an essential tool for businesses wishing to provide speedy and customised service. Although ChatGPT may give convincing solutions, the chance of providing accurate and updated information poses a problem for its usage in service jobs that need accurate and up-to-date information. In future, various services will become better and more efficient due to ChatGPT and AI.}
}
@article{YADAV2024123756,
title = {Datasets, clues and state-of-the-arts for multimedia forensics: An extensive review},
journal = {Expert Systems with Applications},
volume = {249},
pages = {123756},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.123756},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424006225},
author = {Ankit Yadav and Dinesh {Kumar Vishwakarma}},
keywords = {Tampering detection, Localization, Forgery, Manipulation, Deep learning, Convolutional neural networks},
abstract = {With the large chunks of social media data being created daily and the parallel rise of realistic multimedia tampering methods, detecting and localising tampering in images and videos has become essential. This survey focusses on approaches for tampering detection in multimedia data using deep learning models. Specifically, it presents a detailed analysis of publicly available benchmark datasets for malicious manipulation detection. It also offers a comprehensive list of tampering clues and commonly used deep learning architectures. Next, it discusses the current state-of-the-art tampering detection methods, categorizing them into meaningful types such as deepfake detection methods, splice tampering detection methods, copy-move tampering detection methods, etc. and discussing their strengths and weaknesses. Top results achieved on benchmark datasets, comparison of deep learning approaches against traditional methods and critical insights from the recent tampering detection methods are also discussed. Lastly, the research gaps, future direction and conclusion are discussed to provide an in-depth understanding of the tampering detection research arena.}
}
@article{ONG2024101356,
title = {Artificial intelligence, ChatGPT, and other large language models for social determinants of health: Current state and future directions},
journal = {Cell Reports Medicine},
volume = {5},
number = {1},
pages = {101356},
year = {2024},
issn = {2666-3791},
doi = {https://doi.org/10.1016/j.xcrm.2023.101356},
url = {https://www.sciencedirect.com/science/article/pii/S2666379123005736},
author = {Jasmine Chiat Ling Ong and Benjamin Jun Jie Seng and Jeren Zheng Feng Law and Lian Leng Low and Andrea Lay Hoon Kwa and Kathleen M. Giacomini and Daniel Shu Wei Ting},
abstract = {Summary
This perspective highlights the importance of addressing social determinants of health (SDOH) in patient health outcomes and health inequity, a global problem exacerbated by the COVID-19 pandemic. We provide a broad discussion on current developments in digital health and artificial intelligence (AI), including large language models (LLMs), as transformative tools in addressing SDOH factors, offering new capabilities for disease surveillance and patient care. Simultaneously, we bring attention to challenges, such as data standardization, infrastructure limitations, digital literacy, and algorithmic bias, that could hinder equitable access to AI benefits. For LLMs, we highlight potential unique challenges and risks including environmental impact, unfair labor practices, inadvertent disinformation or “hallucinations,” proliferation of bias, and infringement of copyrights. We propose the need for a multitiered approach to digital inclusion as an SDOH and the development of ethical and responsible AI practice frameworks globally and provide suggestions on bridging the gap from development to implementation of equitable AI technologies.}
}
@article{HU2024123715,
title = {Learning-based image steganography and watermarking: A survey},
journal = {Expert Systems with Applications},
volume = {249},
pages = {123715},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.123715},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424005815},
author = {Kun Hu and Mingpei Wang and Xiaohui Ma and Jia Chen and Xiaochao Wang and Xingjun Wang},
keywords = {Image steganography, Deep learning, Image watermarking},
abstract = {Extensive research has been conducted on image steganography and watermarking algorithms, owing to their crucial rules in secret data transmission, copyright protection, and traceability. Despite promising results and numerous surveys proposed in the literature, there is still a lack of comprehensive analysis dedicated to deep learning-based image steganography and watermarking algorithms. In this paper, we focus on investigating three important aspects: neural networks, structure models, and training strategies. Our review covers the vast literature in this field. Furthermore, we provide a comprehensive statistical analysis from diverse perspectives, including models, loss functions, platforms, datasets, and attacks. Moreover, we conduct in a thorough comparative analysis and evaluation of existing representative algorithms, assessing their effectiveness within the context of deep learning. Finally, the challenges and potential research directions in the domain of deep-learning image steganography and watermarking algorithms are discussed to facilitate future research.}
}
@article{JOHNSON2024102863,
title = {Using ChatGPT-generated essays in library instruction},
journal = {The Journal of Academic Librarianship},
volume = {50},
number = {2},
pages = {102863},
year = {2024},
issn = {0099-1333},
doi = {https://doi.org/10.1016/j.acalib.2024.102863},
url = {https://www.sciencedirect.com/science/article/pii/S0099133324000247},
author = {Stacy Johnson and Erin Owens and Hannah Menendez and Dianna Kim},
keywords = {Academic libraries, Library instruction, Information literacy, Artificial intelligence, AI literacy, Generative AI, ChatGPT},
abstract = {This case study details a library instruction activity developed by a team of academic librarians, which intended to leverage experiential learning to make students and faculty aware of the function, capabilities, and limitations of text-generating artificial intelligence (AI) tools like OpenAI's ChatGPT. The activity is described, with its development connected to key instructional theories and frameworks. Feedback is shared from student, faculty, and librarian perspectives, and future possibilities for academic librarians to grow and adapt similar AI literacy activities are explored.}
}
@article{2024134,
title = {Guide for Authors},
journal = {Intelligent Medicine},
volume = {4},
number = {2},
pages = {134-140},
year = {2024},
issn = {2667-1026},
doi = {https://doi.org/10.1016/S2667-1026(24)00028-7},
url = {https://www.sciencedirect.com/science/article/pii/S2667102624000287}
}
@incollection{2024552,
editor = {David Baker and Lucy Ellis},
booktitle = {Encyclopedia of Libraries, Librarianship, and Information Science (First Edition)},
publisher = {Academic Press},
edition = {First Edition},
address = {Oxford},
pages = {552-598},
year = {2024},
isbn = {978-0-323-95690-1},
doi = {https://doi.org/10.1016/B978-0-323-95689-5.09001-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780323956895090015}
}
@article{YAO2024100211,
title = {A survey on large language model (LLM) security and privacy: The Good, The Bad, and The Ugly},
journal = {High-Confidence Computing},
volume = {4},
number = {2},
pages = {100211},
year = {2024},
issn = {2667-2952},
doi = {https://doi.org/10.1016/j.hcc.2024.100211},
url = {https://www.sciencedirect.com/science/article/pii/S266729522400014X},
author = {Yifan Yao and Jinhao Duan and Kaidi Xu and Yuanfang Cai and Zhibo Sun and Yue Zhang},
keywords = {Large Language Model (LLM), LLM security, LLM privacy, ChatGPT, LLM attacks, LLM vulnerabilities},
abstract = {Large Language Models (LLMs), such as ChatGPT and Bard, have revolutionized natural language understanding and generation. They possess deep language comprehension, human-like text generation capabilities, contextual awareness, and robust problem-solving skills, making them invaluable in various domains (e.g., search engines, customer support, translation). In the meantime, LLMs have also gained traction in the security community, revealing security vulnerabilities and showcasing their potential in security-related tasks. This paper explores the intersection of LLMs with security and privacy. Specifically, we investigate how LLMs positively impact security and privacy, potential risks and threats associated with their use, and inherent vulnerabilities within LLMs. Through a comprehensive literature review, the paper categorizes the papers into “The Good” (beneficial LLM applications), “The Bad” (offensive applications), and “The Ugly” (vulnerabilities of LLMs and their defenses). We have some interesting findings. For example, LLMs have proven to enhance code security (code vulnerability detection) and data privacy (data confidentiality protection), outperforming traditional methods. However, they can also be harnessed for various attacks (particularly user-level attacks) due to their human-like reasoning abilities. We have identified areas that require further research efforts. For example, Research on model and parameter extraction attacks is limited and often theoretical, hindered by LLM parameter scale and confidentiality. Safe instruction tuning, a recent development, requires more exploration. We hope that our work can shed light on the LLMs’ potential to both bolster and jeopardize cybersecurity.}
}
@article{MOORHOUSE2024103290,
title = {The effects of generative AI on initial language teacher education: The perceptions of teacher educators},
journal = {System},
volume = {122},
pages = {103290},
year = {2024},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2024.103290},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X24000721},
author = {Benjamin Luke Moorhouse and Lucas Kohnke},
keywords = {Generative AI, Initial language teacher education, ChatGPT, Teacher educators},
abstract = {Since the public release of ChatGPT in November 2022, generative AI tools—capable of creating human-like content such as audio, code, images, text, simulations, 3D objects, and videos—have gained significant attention. While the impact of these tools on language teaching and learning has been widely speculated, the perspective of language teacher educators concerning their influence on initial language teacher education (ILTE) remains unexplored. This study investigates how teacher educators, who play a crucial role in adapting ILTE to technological advancements, perceive the effects of generative AI tools on ILTE. Data were collected through in-depth interviews with thirteen English language teacher educators from all four Hong Kong government-funded universities offering ILTE. Findings reveal that participants believe generative AI tools will substantially affect the ILTE curriculum, instruction, and assessment. However, most participants believed they lacked the confidence and competence to address the implications of generative AI tools effectively. This study highlights the need for further research and training to support teacher educators in adapting ILTE to the emerging influence of generative AI.}
}
@article{HANNIGAN2024471,
title = {Beware of botshit: How to manage the epistemic risks of generative chatbots},
journal = {Business Horizons},
volume = {67},
number = {5},
pages = {471-486},
year = {2024},
note = {SPECIAL ISSUE: WRITTEN BY CHATGPT},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2024.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S0007681324000272},
author = {Timothy R. Hannigan and Ian P. McCarthy and André Spicer},
keywords = {Chatbots, Bullshit, Botshit, Artificial intelligence, Natural language processing},
abstract = {Advances in large language model (LLM) technology enable chatbots to generate and analyze content for our work. Generative chatbots do this work by predicting responses rather than knowing the meaning of their responses. In other words, chatbots can produce coherent-sounding but inaccurate or fabricated content, referred to as hallucinations. When humans uncritically use this untruthful content, it becomes what we call botshit. This article focuses on how to use chatbots for content generation work while mitigating the epistemic (i.e., the process of producing knowledge) risks associated with botshit. Drawing on risk management research, we introduce a typology framework that orients how chatbots can be used based on two dimensions: response veracity verifiability and response veracity importance. The framework identifies four modes of chatbot work (authenticated, autonomous, automated, and augmented) with a botshit-related risk (ignorance, miscalibration, routinization, and black boxing). We describe and illustrate each mode and offer advice to help chatbot users guard against the botshit risks that come with each mode.}
}
@article{2024I,
title = {Full issue PDF},
journal = {JACC: Cardiovascular Imaging},
volume = {17},
number = {3},
pages = {I-CXVII},
year = {2024},
issn = {1936-878X},
doi = {https://doi.org/10.1016/S1936-878X(24)00057-3},
url = {https://www.sciencedirect.com/science/article/pii/S1936878X24000573}
}
@article{IVANOV2024102521,
title = {Drivers of generative AI adoption in higher education through the lens of the Theory of Planned Behaviour},
journal = {Technology in Society},
volume = {77},
pages = {102521},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2024.102521},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X24000691},
author = {Stanislav Ivanov and Mohammad Soliman and Aarni Tuomi and Nasser Alhamar Alkathiri and Alamir N. Al-Alawi},
keywords = {Generative AI, Theory of planned behaviour, Higher education},
abstract = {Drawing on the Theory of Planned Behaviour (TPB), this study investigates the relationship between the perceived benefits, strengths, weaknesses, and risks of generative AI (GenAI) tools and the fundamental factors of the TPB model (i.e., attitude, subjective norms, and perceived behavioural control). The study also investigates the structural association between the TPB variables and intention to use GenAI tools, and how the latter might affect the actual usage of GenAI tools in higher education. The paper adopts a quantitative approach, relying on an anonymous self-administered online questionnaire to gather primary data from 130 lecturers and 168 students in higher education institutions (HEIs) in several countries, and PLS-SEM for data analysis. The results indicate that although lecturers' and students' perceptions of the risks and weaknesses of GenAI tools differ, the perceived strengths and advantages of GenAI technologies have a significant and positive impact on their attitudes, subjective norms, and perceived behavioural control. The TPB core variables positively and significantly impact lecturers' and students’ intentions to use GenAI tools, which in turn significantly and positively impact their adoption of such tools. This paper advances theory by outlining the factors shaping the adoption of GenAI technologies in HEIs. It provides stakeholders with a variety of managerial and policy implications for how to formulate suitable rules and regulations to utilise the advantages of these tools while mitigating the impacts of their disadvantages. Limitations and future research opportunities are also outlined.}
}
@article{HE2024103332,
title = {Local media sentiment towards pollution and its effect on corporate green innovation},
journal = {International Review of Financial Analysis},
volume = {94},
pages = {103332},
year = {2024},
issn = {1057-5219},
doi = {https://doi.org/10.1016/j.irfa.2024.103332},
url = {https://www.sciencedirect.com/science/article/pii/S1057521924002643},
author = {Yu He and Shanglin Lu and Ran Wei and Shixuan Wang},
keywords = {Media sentiment, Green innovation, Environmental pollution, Corporate governance},
abstract = {This study examines the effect of local media sentiment on corporate green innovation based on a textual analysis of China's provincial official party newspapers from 2007 to 2018. The results show that the negative sentiment in official media positively influences firms' green innovation, measured by the number of green patents and green patent citations. This positive effect is more pronounced when firms have weaker internal or external governance structures, when the regional punitive measures are less stringent, or when the incentive measures are more complete, suggesting that official media plays a governance role in corporate green innovation. Further analysis shows that the negative sentiment from market-oriented media impedes green innovation and does not affect the relationship between official media sentiment and green innovation. Taken together, our findings reveal the real effects of local media negative sentiment on technological progress and pollution controls through its pressure on firms to engage in green innovation.}
}
@article{DUHAN2024e29802,
title = {Investigating attention mechanisms for plant disease identification in challenging environments},
journal = {Heliyon},
volume = {10},
number = {9},
pages = {e29802},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e29802},
url = {https://www.sciencedirect.com/science/article/pii/S240584402405833X},
author = {Sangeeta Duhan and Preeti Gulia and Nasib Singh Gill and Piyush Kumar Shukla and Surbhi Bhatia Khan and Ahlam Almusharraf and Norah Alkhaldi},
keywords = {Attention mechanism, Computer vision, Deep learning, Classification, Plant disease detection},
abstract = {There is an increasing demand for efficient and precise plant disease detection methods that can quickly identify disease outbreaks. For this, researchers have developed various machine learning and image processing techniques. However, real-field images present challenges due to complex backgrounds, similarities between different disease symptoms, and the need to detect multiple diseases simultaneously. These obstacles hinder the development of a reliable classification model. The attention mechanisms emerge as a critical factor in enhancing the robustness of classification models by selectively focusing on relevant regions or features within infected regions in an image. This paper provides details about various types of attention mechanisms and explores the utilization of these techniques for the machine learning solutions created by researchers for image segmentation, feature extraction, object detection, and classification for efficient plant disease identification. Experiments are conducted on three models: MobileNetV2, EfficientNetV2, and ShuffleNetV2, to assess the effectiveness of attention modules. For this, Squeeze and Excitation layers, the Convolutional Block Attention Module, and transformer modules have been integrated into these models, and their performance has been evaluated using different metrics. The outcomes show that adding attention modules enhances the original models' functionality.}
}
@article{DESAI2024100966,
title = {An archival perspective on pretraining data},
journal = {Patterns},
volume = {5},
number = {4},
pages = {100966},
year = {2024},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2024.100966},
url = {https://www.sciencedirect.com/science/article/pii/S2666389924000746},
author = {Meera A. Desai and Irene V. Pasquetto and Abigail Z. Jacobs and Dallas Card},
abstract = {Summary
Alongside an explosion in research and development related to large language models, there has been a concomitant rise in the creation of pretraining datasets—massive collections of text, typically scraped from the web. Drawing on the field of archival studies, we analyze pretraining datasets as informal archives—heterogeneous collections of diverse material that mediate access to knowledge. We use this framework to identify impacts of pretraining data creation and use beyond directly shaping model behavior and reveal how choices about what is included in pretraining data necessarily involve subjective decisions about values. In doing so, the archival perspective helps us identify opportunities for researchers who study the social impacts of technology to contribute to confronting the challenges and trade-offs that arise in creating pretraining datasets at this scale.}
}
@article{RAHHAL2024124101,
title = {Data science for job market analysis: A survey on applications and techniques},
journal = {Expert Systems with Applications},
volume = {251},
pages = {124101},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.124101},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424009679},
author = {Ibrahim Rahhal and Ismail Kassou and Mounir Ghogho},
keywords = {Labor market analytics, Job market needs, Data science, Job title classification, Skill identification, Natural language processing},
abstract = {The job market is evolving continuously due to changes in economic landscapes, technological improvements, and skill requirements. In the era of digitalization, a wealth of data is becoming available, opening up new opportunities for labor market analysis. Many stakeholders can make informed decisions if they benefit from accurate and timely insights about the job market. However, traditional data sources and methods used for labor market analysis often fall short of capturing the diversity and trends of the evolving job market. Recently, researchers started exploring various data sources by leveraging data science techniques, which makes information extraction achievable. This survey reviews recent research published between 2015 and 2022 on labor market analytics through data science techniques and discusses future research directions. 101 primary studies were classified and evaluated to identify the data sources utilized for job market analysis; the skill extraction methods and their type; the occupation and sector identification methods; and the application of the study conducted. Finally, we explore potential avenues for future research in this area.}
}
@article{ALFREDO2024100215,
title = {Human-centred learning analytics and AI in education: A systematic literature review},
journal = {Computers and Education: Artificial Intelligence},
volume = {6},
pages = {100215},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100215},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X2400016X},
author = {Riordan Alfredo and Vanessa Echeverria and Yueqiao Jin and Lixiang Yan and Zachari Swiecki and Dragan Gašević and Roberto Martinez-Maldonado},
keywords = {Human-centered AI, Human-centered learning analytics, AI in education, Stakeholders involvement, Education technology, Ethical considerations},
abstract = {The rapid expansion of Learning Analytics (LA) and Artificial Intelligence in Education (AIED) offers new scalable, data-intensive systems but raises concerns about data privacy and agency. Excluding stakeholders—like students and teachers—from the design process can potentially lead to mistrust and inadequately aligned tools. Despite a shift towards human-centred design in recent LA and AIED research, there remain gaps in our understanding of the importance of human control, safety, reliability, and trustworthiness in the design and implementation of these systems. We conducted a systematic literature review to explore these concerns and gaps. We analysed 108 papers to provide insights about i) the current state of human-centred LA/AIED research; ii) the extent to which educational stakeholders have contributed to the design process of human-centred LA/AIED systems; iii) the current balance between human control and computer automation of such systems; and iv) the extent to which safety, reliability and trustworthiness have been considered in the literature. Results indicate some consideration of human control in LA/AIED system design, but limited end-user involvement in actual design. Based on these findings, we recommend: 1) carefully balancing stakeholders' involvement in designing and deploying LA/AIED systems throughout all design phases 2) actively involving target end-users, especially students, to delineate the balance between human control and automation, and 3) exploring safety, reliability, and trustworthiness as principles in future human-centred LA/AIED systems.}
}
@article{GIORDANO2024123389,
title = {The impact of ChatGPT on human skills: A quantitative study on twitter data},
journal = {Technological Forecasting and Social Change},
volume = {203},
pages = {123389},
year = {2024},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2024.123389},
url = {https://www.sciencedirect.com/science/article/pii/S0040162524001859},
author = {Vito Giordano and Irene Spada and Filippo Chiarello and Gualtiero Fantoni},
keywords = {ChatGPT, Generative Artificial Intelligence, Natural Language Processing, Skills, ESCO},
abstract = {The novel generative Artificial Intelligence (AI) developed by OpenAI, i.e., ChatGPT, rised a great interest in both scientific and business contexts. This new wave of technological advancement typically produces deep transformation in the workplace, requiring new skills. However, none of the studies in literature provide quantitative analysis and measures on the impact of ChatGPT on human skills. To address this gap, we collected a database of 616,073 tweets about ChatGPT, and used Natural Language Processing techniques to identify the tasks users requested ChatGPT to perform, and the sentiment related to these tasks. Then, we compared these tasks with a standard taxonomy of skills (i.e., ESCO) using BERT. The results of the study underline that ChatGPT impacts 185 different skills. Moreover, we proposed a model to represent the interaction of the user and ChatGPT, useful to define four skills which are emerging for using this new technology.}
}
@article{KORKMAZ2024104954,
title = {From GitHub to GDP: A framework for measuring open source software innovation},
journal = {Research Policy},
volume = {53},
number = {3},
pages = {104954},
year = {2024},
issn = {0048-7333},
doi = {https://doi.org/10.1016/j.respol.2024.104954},
url = {https://www.sciencedirect.com/science/article/pii/S0048733324000039},
author = {Gizem Korkmaz and J. Bayoán {Santiago Calderón} and Brandon L. Kramer and Ledia Guci and Carol A. Robbins},
keywords = {Open source software, Cost measurement, GitHub, Innovation, Gross domestic product, Software investment, National accounts},
abstract = {Open source software (OSS) is software that anyone can review, modify, and distribute freely, usually with only minor restrictions such as giving credit to the creator of the work. The use of OSS is growing rapidly, due to its value in increasing firm and economy-wide productivity. Despite its widespread use, there is no standardized methodology for measuring the scope and impact of this fundamental intangible asset. This study presents a framework to measure the value of OSS using data collected from GitHub, the largest platform in the world with over 100 million developers. The data include over 7.6 million repositories where software is developed, stored, and managed. We collect information about contributors and development activity such as code changes and license detail. By adopting a cost estimation model from software engineering, we develop a methodology to generate estimates of investment in OSS that are consistent with the U.S. national accounting methods used for measuring software investment. We generate annual estimates of current and inflation-adjusted investment as well as the net stock of OSS for the 2009–2019 period. Our estimates show that the U.S. investment in 2019 was $37.8 billion with a current-cost net stock of $74.3 billion.}
}
@article{SILVA2024102984,
title = {Innovation processes in ecosystem settings: An integrative framework and future directions},
journal = {Technovation},
volume = {132},
pages = {102984},
year = {2024},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2024.102984},
url = {https://www.sciencedirect.com/science/article/pii/S0166497224000348},
author = {Lucas Emmanuel Nascimento Silva and Leonardo Augusto de Vasconcelos Gomes and Aline Mariane de Faria and Felipe Mendes Borini},
keywords = {Innovation processes, Ecosystem, Platform ecosystem, Innovation ecosystem, Entrepreneurial ecosystem, Knowledge ecosystem, Open innovation, Systematic literature review},
abstract = {Although the foundational works of ecosystem research recognized the central role of innovation, the current scholarship lacks a more systemic, systemized understanding of how innovation processes take place in ecosystem settings. This lack of a dominant framework that bridges innovation processes and ecosystem fields risks leading to a situation in which crucial problems at the intersection of these two fields remain poorly investigated. Through a systematic literature review, we made a case for rediscovering how these two branches of knowledge can be bridged. As an initial step, we consolidate the literature on these intersections, profile the studies that initially began to establish a bridge between ecosystem and innovation processes, propose a tentative framework for integrating both literatures, and set an agenda for further studies.}
}
@article{BANDARA2024101077,
title = {Lightweight, geo-scalable deterministic blockchain design for 5G networks sliced applications with hierarchical CFT/BFT consensus groups, IPFS and novel hardware design},
journal = {Internet of Things},
volume = {25},
pages = {101077},
year = {2024},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2024.101077},
url = {https://www.sciencedirect.com/science/article/pii/S2542660524000192},
author = {Eranga Bandara and Xueping Liang and Peter Foytik and Sachin Shetty and Ravi Mukkamala and Abdul Rahman and Nalin Ranasinghe and Kasun {De Zoysa} and Wee Keong Ng},
keywords = {5G, Blockchain, IPFS, IoT, Byzantine fault tolerance, Hierarchical consensus},
abstract = {5G network sliced applications enable IoT networks to connect billions of heterogeneous objects, providing high-quality service, network capacity, and enhanced throughput. The blockchain systems which attempt to facilitate 5G network-sliced application requirements present several challenges, such as lack of decentralized governance, reduced transaction throughput/scalability, inability to run on resource-constrained devices, lack of support for real-time/concurrent transaction handling, and non-deterministic Byzantine Fault Tolerance (BFT) consensus models. In this paper, we propose a highly scalable, lightweight blockchain system, “Librum,” for 5G-based network sliced applications. Librum’s lightweight design enables it to run in edge networks, and we have designed low-cost hardware nodes to run the Librum blockchain edge network. The embedded hardware devices contain wifi and cellular modules that allow the Librum blockchain nodes to be run on 5G edge networks. The Librum blockchain, stored on IPFS peer-to-peer decentralized storage, enables any Byzantine node to participate in the network. Librum’s Fungible (ERC20) and Non-Fungible Token (ERC721) smart contracts support concurrent transaction execution with a novel “Validate–Execute” blockchain architecture. We incorporated hierarchical consensus groups to run independent blockchain shards (local consensus groups) on different 5G network slices. The shards can run BFT or CFT (Crash Fault Tolerance) consensus models and reach global consensus via core-blockchain nodes in the network based on connectivity requirements. Core blockchain nodes can also run with BFT (e.g., Tendermint) or CFT (e.g., Proof-of-Authority/Kafka) consensus models, eliminating message-passing overhead and achieving BFT with a deterministic consensus model in Geo-distributed blockchain networks. Dynamic 5G network slice orchestration and data provenance of network slices are implemented with smart contracts. The proposed Librum blockchain is integrated with FreedomeFi and Magma 5G core-based 5G testbed environments.}
}
@incollection{LI2024683,
title = {27 - Additive manufacturing and its impact on pharmaceutical supply chains},
editor = {Shadpour Mallakpour and Chaudhery {Mustansar Hussain}},
booktitle = {Medical Additive Manufacturing},
publisher = {Elsevier},
pages = {683-712},
year = {2024},
series = {Additive Manufacturing Materials and Technologies},
isbn = {978-0-323-95383-2},
doi = {https://doi.org/10.1016/B978-0-323-95383-2.00018-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780323953832000184},
author = {Wenqi Li and Banu Y. Ekren and Emel Aktas},
keywords = {Additive manufacturing, medical supply chain, 3D printing technology, supply chain resilience, pharmaceutical supply chain},
abstract = {Additive manufacturing (AM), also known as 3D printing, has the potential to improve the performance of the pharmaceutical supply chain (PSC). By using 3D printing for manufacturing drugs, pharmaceutical companies can reduce waste by using only the required number of raw materials and eliminating excess inventory. This chapter will provide a systematic literature review of the state of the art of AM in PSC and develop a conceptual framework to explain their interconnections. It was found that 3D printing impacts the SC in three main ways: reducing complexity, moving manufacturing facilities closer to the end user, and shifting production from make-to-stock to make-to-order. These changes influence the inventory level, which in turn affects SC sustainability, efficiency, responsiveness, and resilience. This study provides a conceptual framework that illustrates the interrelationships between various variables in the medical SC impacted by 3D printing technology.}
}
@article{MARIANI2024114542,
title = {Generative artificial intelligence in innovation management: A preview of future research developments},
journal = {Journal of Business Research},
volume = {175},
pages = {114542},
year = {2024},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2024.114542},
url = {https://www.sciencedirect.com/science/article/pii/S0148296324000468},
author = {Marcello Mariani and Yogesh K. Dwivedi},
keywords = {Generative artificial intelligence, Delphi study, Management, Innovation},
abstract = {This study outlines the future research opportunities related to Generative Artificial Intelligence (GenAI) in innovation management. To this end, it combines a review of the academic literature with the results of a Delphi study involving leading innovation management scholars. Ten major research themes emerged that can guide future research developments at the intersection of GenAI and innovation management: 1) Gen AI and innovation types; 2) GenAI, dominant designs and technology evolution; 3) Scientific and artistic creativity and GenAI-enabled innovations; 4) GenAI-enabled innovations and intellectual property; 5) GenAI and new product development; 6) Multimodal/unimodal GenAI and innovation outcomes; 7) GenAI, agency and ecosystems; 8) Policymakers, lawmakers and anti-trust authorities in the regulation of GenAI-enabled innovation; 9) Misuse and unethical use of GenAI leading to biased innovation; and 10) Organizational design and boundaries for GenAI-enabled innovation. The paper concludes by discussing how these themes can inform theoretical development in innovation management studies.}
}
@incollection{FLORES20241,
title = {Chapter 1 - Introduction},
editor = {Romeo M. Flores and Tim A. Moore},
booktitle = {Coal and Coalbed Gas (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
pages = {1-39},
year = {2024},
isbn = {978-0-323-85937-0},
doi = {https://doi.org/10.1016/B978-0-323-85937-0.00007-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780323859370000078},
author = {Romeo M. Flores and Tim A. Moore},
keywords = {Coal, Coalbed gas, Nonfuel coal, GHG emissions, CCUS, Carbon emissions, Greenhouse, REEs, Gasification, Liquefaction},
abstract = {This, the first chapter, overviews the current state of coal and coalbed gas in a carbon-conscious world. The 2008 global economic recession resulting in protracted lowering of natural gas prices, the 2015 Paris Climate Change Agreement, as well as the effects of the 2022 Ukraine-Russia conflict have substantially influenced fossil fuel use. However, coal and, to a lesser degree, coalbed gas are still significant as energy fuel for current use and future development. These policies are driving research by countries into how coal can be utilized in nonfuel, alternative applications. This global awareness of climate change and impacts of fossil fuel use underscores the objectives, scope, vision, and principles of this book.}
}
@article{LE2024102470,
title = {Search engine optimization poisoning: A cybersecurity threat analysis and mitigation strategies for small and medium-sized enterprises},
journal = {Technology in Society},
volume = {76},
pages = {102470},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2024.102470},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X24000186},
author = {Tran Duc Le and Thang Le-Dinh and Sylvestre Uwizeyemungu},
keywords = {SME, SEO, Digital marketing, Cybersecurity},
abstract = {This study investigates the emerging cybersecurity threat of search engine optimization (SEO) poisoning and its impact on small and medium-sized enterprises’ (SMEs) digital marketing efforts. Through a comprehensive analysis of SEO poisoning techniques employed by attackers, the study reveals the significant risks and consequences for SMEs, including reputational damage, financial losses, and disrupted operations. To address these threats, the study proposes tailored mitigation strategies aligned with the principles of the NIST Cybersecurity Framework while considering the resource constraints facing SMEs. The mitigation recommendations encompass technical measures such as website security audits and employee training alongside non-technical initiatives to foster a culture of cybersecurity awareness. Additionally, the study offers several discussions that elucidate the multifaceted challenges posed by SEO poisoning in the SME context from both internal and external perspectives. These contributions will empower SMEs and digital marketers to implement proactive safeguards against SEO poisoning risks and preserve their online presence. The study underscores the need for continued vigilance and adaptive security to combat the evolving tactics of cyber adversaries in the digital marketing domain.}
}
@article{SHARMA2024103801,
title = {A review on client-server attacks and defenses in federated learning},
journal = {Computers & Security},
volume = {140},
pages = {103801},
year = {2024},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2024.103801},
url = {https://www.sciencedirect.com/science/article/pii/S0167404824001020},
author = {Anee Sharma and Ningrinla Marchang},
keywords = {Security, Federated learning, Machine learning, Attacks, Defenses},
abstract = {Federated Learning (FL) offers decentralized machine learning (ML) capabilities while potentially safeguarding data privacy. However, this architecture introduces unique security challenges. This paper presents a comprehensive survey of these challenges, categorizing attacks based on their targets: client-side training data, local models, FL channel, server-side aggregated parameters, and global models. We further discuss defense mechanisms tailored for local and global models. Through our investigation, we illuminate the vulnerabilities inherent to FL and provide insights into countermeasures that ensure robustness. Our findings underscore the significance of a dual-focused strategy, addressing security concerns at both client and server levels.}
}
@article{BOLL2024112087,
title = {Beyond code: Is there a difference between comments in visual and textual languages?},
journal = {Journal of Systems and Software},
volume = {215},
pages = {112087},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112087},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224001328},
author = {Alexander Boll and Pooja Rani and Alexander Schultheiß and Timo Kehrer},
keywords = {Documentation, Graphical, Diagram, Knowledge-transfer, Simulink, Model-driven engineering, Comment clones, Taxonomy},
abstract = {Code comments are crucial for program comprehension and maintenance. To better understand the nature and content of comments, previous work proposed taxonomies of comment information for textual languages, notably classical programming languages. However, paradigms such as model-driven or model-based engineering often promote the use of visual languages, to which existing taxonomies are not directly applicable. Taking MATLAB/Simulink as a representative of a sophisticated and widely used modeling environment, we extend a multi-language comment taxonomy onto new (visual) comment types and two new languages: Simulink and MATLAB. Furthermore, we outline Simulink commenting practices and compare them to textual languages. We analyze 259,267 comments from 9095 Simulink models and 17,792 MATLAB scripts. We identify the comment types, their usage frequency, classify comment information, and analyze their correlations with model metrics. We manually analyze 757 comments to extend the taxonomy. We also analyze commenting guidelines and developer adherence to them. Our extended taxonomy, SCoT (Simulink Comment Taxonomy), contains 25 categories. We find that Simulink comments, although often duplicated, are used at all model hierarchy levels. Of all comment types, Annotations are used most often; Notes scarcely. Our results indicate that Simulink developers, instead of extending comments, add new ones, and rarely follow commenting guidelines. Overall, we find Simulink comment information comparable to textual languages, which highlights commenting practice similarity across languages.}
}
@article{TOMASEVIC2024108495,
title = {Generating bimodal privacy-preserving data for face recognition},
journal = {Engineering Applications of Artificial Intelligence},
volume = {133},
pages = {108495},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.108495},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624006535},
author = {Darian Tomašević and Fadi Boutros and Naser Damer and Peter Peer and Vitomir Štruc},
keywords = {Image synthesis, Face-based biometrics, Privacy-preserving data, Multispectral recognition, Generative adversarial networks},
abstract = {The performance of state-of-the-art face recognition systems depends crucially on the availability of large-scale training datasets. However, increasing privacy concerns nowadays accompany the collection and distribution of biometric data, which has already resulted in the retraction of valuable face recognition datasets. The use of synthetic data represents a potential solution, however, the generation of privacy-preserving facial images useful for training recognition models is still an open problem. Generative methods also remain bound to the visible spectrum, despite the benefits that multispectral data can provide. To address these issues, we present a novel identity-conditioned generative framework capable of producing large-scale recognition datasets of visible and near-infrared privacy-preserving face images. The framework relies on a novel identity-conditioned dual-branch style-based generative adversarial network to enable the synthesis of aligned high-quality samples of identities determined by features of a pretrained recognition model. In addition, the framework incorporates a novel filter to prevent samples of privacy-breaching identities from reaching the generated datasets and improve both identity separability and intra-identity diversity. Extensive experiments on six publicly available datasets reveal that our framework achieves competitive synthesis capabilities while preserving the privacy of real-world subjects. The synthesized datasets also facilitate training more powerful recognition models than datasets generated by competing methods or even small-scale real-world datasets. Employing both visible and near-infrared data for training also results in higher recognition accuracy on real-world visible spectrum benchmarks. Therefore, training with multispectral data could potentially improve existing recognition systems that utilize only the visible spectrum, without the need for additional sensors.}
}
@article{ALI2024110370,
title = {Wavelet-based Auto-Encoder for simultaneous haze and rain removal from images},
journal = {Pattern Recognition},
volume = {150},
pages = {110370},
year = {2024},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2024.110370},
url = {https://www.sciencedirect.com/science/article/pii/S0031320324001213},
author = {Asfak Ali and Ram Sarkar and Sheli Sinha Chaudhuri},
keywords = {Dehaze, Derain, Auto encoder, U-Net, Wavelet, Noise removal},
abstract = {Noise introduced due to weather can reduce the efficiency of computer vision applications as the visibility of the objects in images is greatly affected. Haze and rain are the most common weather conditions seen in nature. However, most of the algorithms found in the literature apply rain and haze removal approaches separately. To this end, in this paper, we propose a novel Wavelet-based deep Auto-encoder, called WAE, for simultaneously removing the haze and rain effects from images. The proposed network uses wavelet transformation and inverse wavelet transformation as an alternative to down-sampling and up-sampling operations, respectively, in order to add sparsity to the network. By training the model on both spatial and frequency domains, it learns non-stationary features that are found to be useful to remove haze and rain effects from images. The proposed model is tested on several rain and haze-affected image datasets, and it performs well in terms of standard evaluation metrics like structural similarity index measure and peak signal-to-noise ratio. The code can be found at : https://github.com/asfakali/WAE.git.}
}
@article{ESMAEILZADEH2024102861,
title = {Challenges and strategies for wide-scale artificial intelligence (AI) deployment in healthcare practices: A perspective for healthcare organizations},
journal = {Artificial Intelligence in Medicine},
volume = {151},
pages = {102861},
year = {2024},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2024.102861},
url = {https://www.sciencedirect.com/science/article/pii/S0933365724001039},
author = {Pouyan Esmaeilzadeh},
keywords = {Artificial intelligence, AI, Deployment challenges, Healthcare, Data, Ethics, Law},
abstract = {Healthcare organizations have realized that Artificial intelligence (AI) can provide a competitive edge through personalized patient experiences, improved patient outcomes, early diagnosis, augmented clinician capabilities, enhanced operational efficiencies, or improved medical service accessibility. However, deploying AI-driven tools in the healthcare ecosystem could be challenging. This paper categorizes AI applications in healthcare and comprehensively examines the challenges associated with deploying AI in medical practices at scale. As AI continues to make strides in healthcare, its integration presents various challenges, including production timelines, trust generation, privacy concerns, algorithmic biases, and data scarcity. The paper highlights that flawed business models and wrong workflows in healthcare practices cannot be rectified merely by deploying AI-driven tools. Healthcare organizations should re-evaluate root problems such as misaligned financial incentives (e.g., fee-for-service models), dysfunctional medical workflows (e.g., high rates of patient readmissions), poor care coordination between different providers, fragmented electronic health records systems, and inadequate patient education and engagement models in tandem with AI adoption. This study also explores the need for a cultural shift in viewing AI not as a threat but as an enabler that can enhance healthcare delivery and create new employment opportunities while emphasizing the importance of addressing underlying operational issues. The necessity of investments beyond finance is discussed, emphasizing the importance of human capital, continuous learning, and a supportive environment for AI integration. The paper also highlights the crucial role of clear regulations in building trust, ensuring safety, and guiding the ethical use of AI, calling for coherent frameworks addressing transparency, model accuracy, data quality control, liability, and ethics. Furthermore, this paper underscores the importance of advancing AI literacy within academia to prepare future healthcare professionals for an AI-driven landscape. Through careful navigation and proactive measures addressing these challenges, the healthcare community can harness AI's transformative power responsibly and effectively, revolutionizing healthcare delivery and patient care. The paper concludes with a vision and strategic suggestions for the future of healthcare with AI, emphasizing thoughtful, responsible, and innovative engagement as the pathway to realizing its full potential to unlock immense benefits for healthcare organizations, physicians, nurses, and patients while proactively mitigating risks.}
}
@article{NIU2024404,
title = {A survey on membership inference attacks and defenses in machine learning},
journal = {Journal of Information and Intelligence},
volume = {2},
number = {5},
pages = {404-454},
year = {2024},
issn = {2949-7159},
doi = {https://doi.org/10.1016/j.jiixd.2024.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S2949715924000064},
author = {Jun Niu and Peng Liu and Xiaoyan Zhu and Kuo Shen and Yuecong Wang and Haotian Chi and Yulong Shen and Xiaohong Jiang and Jianfeng Ma and Yuqing Zhang},
keywords = {Machine learning, Privacy and security, Membership inference attacks, Defensive techniques},
abstract = {Membership inference (MI) attacks mainly aim to infer whether a data record was used to train a target model or not. Due to the serious privacy risks, MI attacks have been attracting a tremendous amount of attention in the research community. One existing work conducted — to our best knowledge — the first dedicated survey study in this specific area: The survey provides a comprehensive review of the literature during the period of 2017∼2021 (e.g., over 100 papers). However, due to the tremendous amount of progress (i.e., 176 papers) made in this area since 2021, the survey conducted by the one existing work has unfortunately already become very limited in the following two aspects: (1) Although the entire literature from 2017∼2021 covers 18 ways to categorize (all the proposed) MI attacks, the literature during the period of 2017∼2021, which was reviewed in the one existing work, only covered 5 ways to categorize MI attacks. With 13 ways missing, the survey conducted by the one existing work only covers 27% of the landscape (in terms of how to categorize MI attacks) if a retrospective view is taken. (2) Since the literature during the period of 2017∼2021 only covers 27% of the landscape (in terms of how to categorize), the number of new insights (i.e., why an MI attack could succeed) behind all the proposed MI attacks has been significantly increasing since year 2021. As a result, although none of the previous work has made the insights as a main focus of their studies, we found that the various insights leveraged in the literature can be broken down into 10 groups. Without making the insights as a main focus, a survey study could fail to help researchers gain adequate intellectual depth in this area of research. In this work, we conduct a systematic study to address these limitations. In particular, in order to address the first limitation, we make the 13 newly emerged ways to categorize MI attacks as a main focus on the study. In order to address the second limitation, we provide — to our best knowledge — the first review of the various insights leveraged in the entire literature. We found that the various insights leveraged in the literature can be broken down into 10 groups. Moreover, our survey also provides a comprehensive review of the existing defenses against MI attacks, the existing applications of MI attacks, the widely used datasets (e.g., 107 new datasets), and the evaluation metrics (e.g., 20 new evaluation metrics).}
}
@article{LAINE2024103969,
title = {Ethics-based AI auditing: A systematic literature review on conceptualizations of ethical principles and knowledge contributions to stakeholders},
journal = {Information & Management},
volume = {61},
number = {5},
pages = {103969},
year = {2024},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2024.103969},
url = {https://www.sciencedirect.com/science/article/pii/S037872062400051X},
author = {Joakim Laine and Matti Minkkinen and Matti Mäntymäki},
keywords = {Artificial intelligence, Auditing, AI ethics, AI governance, AI auditing, Ethics-based AI auditing, Systematic literature review},
abstract = {This systematic literature review synthesizes the conceptualizations of ethical principles in AI auditing literature and the knowledge contributions to the stakeholders of AI auditing. We explain how the literature discusses fairness, transparency, non-maleficence, responsibility, privacy, trust, beneficence, and freedom/autonomy. Conceptualizations vary along social/technical- and process/outcome-oriented dimensions. The main stakeholders of ethics-based AI auditing are system developers and deployers, the wider public, researchers, auditors, AI system users, and regulators. AI auditing provides three types of knowledge contributions to stakeholders: 1) guidance; 2) methods, tools, and frameworks; and 3) awareness and empowerment.}
}
@article{NGUYEN2024112059,
title = {GPTSniffer: A CodeBERT-based classifier to detect source code written by ChatGPT},
journal = {Journal of Systems and Software},
volume = {214},
pages = {112059},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112059},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224001043},
author = {Phuong T. Nguyen and Juri {Di Rocco} and Claudio {Di Sipio} and Riccardo Rubei and Davide {Di Ruscio} and Massimiliano {Di Penta}},
keywords = {ChatGPT, Code classification, CodeBERT, Pre-trained Models},
abstract = {Since its launch in November 2022, ChatGPT has gained popularity among users, especially programmers who use it to solve development issues. However, while offering a practical solution to programming problems, ChatGPT should be used primarily as a supporting tool (e.g., in software education) rather than as a replacement for humans. Thus, detecting automatically generated source code by ChatGPT is necessary, and tools for identifying AI-generated content need to be adapted to work effectively with code. This paper presents GPTSniffer– a novel approach to the detection of source code written by AI – built on top of CodeBERT. We conducted an empirical study to investigate the feasibility of automated identification of AI-generated code, and the factors that influence this ability. The results show that GPTSniffer can accurately classify whether code is human-written or AI-generated, outperforming two baselines, GPTZero and OpenAI Text Classifier. Also, the study shows how similar training data or a classification context with paired snippets helps boost the prediction. We conclude that GPTSniffer can be leveraged in different contexts, e.g., in software engineering education, where teachers use the tool to detect cheating and plagiarism, or in development, where AI-generated code may require peculiar quality assurance activities.}
}
@article{VAHIDNIA2024123279,
title = {A temporal ontology guided clustering methodology with a case study on detection and tracking of artificial intelligence topics},
journal = {Expert Systems with Applications},
volume = {247},
pages = {123279},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.123279},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424001441},
author = {Sahand Vahidnia and Alireza Abbasi and Hussein Abbass},
keywords = {Topic detection and tracking, Document clustering, Document topic models, Temporal clustering, Representation learning},
abstract = {Detection and tracking of topics from publicly available academic data can benefit the scientific community and other stakeholders throughout their investment and other decisions, by informing the decisions regarding the field of science, its evolution, and its dynamics. In this study, we introduce a novel temporal clustering method for topic detection, using document abstracts, keywords, and their corresponding textual representations. In this method, the temporal dimension is employed to parameterise the effect of older data on the clusters, while ontology guidance is utilised to guide their evolution. Ontology is used for both enhancing the representations, and decision-making for the evolutionary steps of split and merging of the clusters. We show the effectiveness of the representations of documents in a single time slice, before demonstrating the evolution of topics in a case study of AI-related publications. Finally, the resulting topic evolutionary map is evaluated after automatically labelling the clusters using ranked author keywords, facilitating the assessment of the topics and observing their evolution.}
}
@article{GEDIK2024101632,
title = {Print exposure leads to individual differences in the Turkish aorist},
journal = {Language Sciences},
volume = {104},
pages = {101632},
year = {2024},
issn = {0388-0001},
doi = {https://doi.org/10.1016/j.langsci.2024.101632},
url = {https://www.sciencedirect.com/science/article/pii/S0388000124000214},
author = {Tan Arda Gedik},
keywords = {Individual differences, Print exposure, Morphological productivity, The Turkish aorist, Nonce-verb conjugation},
abstract = {Several studies have established that not all native speakers extract the same generalization for a given construction due to speaker internal or external reasons, challenging a widely held assumption in linguistics. While there is a considerable number of studies investigating individual differences in grammatical knowledge in other languages, very little is known about how L1 Turkish speakers might manifest such differences in their linguistic knowledge. This is the first study to examine individual differences in the constructional representation of the Turkish aorist in adult L1 Turkish speakers. The aorist is known to be irregular and pose acquisition problems, especially when combined with monosyllabic sonorant ending verbs. The variants of the Turkish aorist have different corpus frequencies across spoken and written modalities. The study investigates to what extent differences in print exposure would lead to differences in how L1 Turkish speakers would apply the construction to monosyllabic-sonorant ending nonce-verbs. Based on the results, people with more written language experience extracted a more sensitive rule that applies to monosyllabic-sonorant ending nonce-verbs, such that they produced more -Ir than -Ar. Contrastingly, people who read less used more -Ar (r = –0.35), and print exposure accounted for roughly 12% of the variance. Our findings are compatible with usage-based approaches and suggest that print exposure-borne differences are pervasive in linguistic knowledge, adding to the growing body of evidence that challenges the convergence hypothesis.}
}
@article{WANG2025109871,
title = {Recent advances in polyoxometalates based strategies for green synthesis of drugs},
journal = {Chinese Chemical Letters},
volume = {36},
number = {5},
pages = {109871},
year = {2025},
issn = {1001-8417},
doi = {https://doi.org/10.1016/j.cclet.2024.109871},
url = {https://www.sciencedirect.com/science/article/pii/S1001841724003905},
author = {Tengteng Wang and Yiming Ju and Yao Cheng and Haiyang Wang and Dejin Zang},
keywords = {Polyoxometalates, Drug synthesis, Green catalysis, Healthcare, Medicine manufacture},
abstract = {ABSTRACT
Green synthesis of drugs is of paramount importance for current public health and a prerequisite to new drugs exploiting. Nowadays, novel strategies of disease diagnosis and therapies are in blooming development as remarkable advances have been achieved which are all highly depended on drug development. Under the current requirements to high production capacity and novel synthesis methods of drugs, green synthesis based on strategies with different ways of empowering, advanced catalysts and unique reaction equipment are attracting huge attention and of great challenging. Higher quality products and environmentally friendly synthesis conditions are becoming more and more important for manufacturing process which has new requirements for catalyst materials and synthesis processes. Polyoxometalates (POMs) are class of transition metals-oxygen clusters with precise molecular structures and superior physicochemical properties which have made longstanding and important applications upon research community of functional materials, catalysis and medicine. In this review, the recent advances of polyoxometalates based strategies for green synthesis of drugs are summarized including POMs based catalysts, alternative reaction equipment based novel synthesis protocols. The significance of POMs to pharmaceutical and industrial field is highlighted and the related perspective for future development are well discussed.}
}
@article{GRZYBOWSKI2024221,
title = {A History of Artificial Intelligence},
journal = {Clinics in Dermatology},
volume = {42},
number = {3},
pages = {221-229},
year = {2024},
note = {Dermatology and Artificial Intelligence},
issn = {0738-081X},
doi = {https://doi.org/10.1016/j.clindermatol.2023.12.016},
url = {https://www.sciencedirect.com/science/article/pii/S0738081X23002687},
author = {Andrzej Grzybowski and Katarzyna Pawlikowska–Łagód and W. Clark Lambert},
abstract = {The development of the computer and what is now known as artificial intelligence (AI) has evolved over more than two centuries in a long series of steps. The date of the invention of the first computer is estimated at 1822, when Charles Babbage (1791-1871) developed his first design of a working computer on paper, based mainly on a Jacquard loom. He worked on his project together with Augusta Ada King, Countess Lovelace (née Byron) (Ada Lovelace) (1815-1852), whom he called the “Sorceress of Numbers.” This work will present the profile and achievements of Charles Babbage, Augusta Ada King, Countess Lovelace, and Alan Mathison Turing (1912 - 1954), who is considered the father of computer science and artificial intelligence, and then provide an outline of the tumultuous events affecting AI up to the present.}
}
@article{ZHONG2024105316,
title = {Domain-specific language models pre-trained on construction management systems corpora},
journal = {Automation in Construction},
volume = {160},
pages = {105316},
year = {2024},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2024.105316},
url = {https://www.sciencedirect.com/science/article/pii/S0926580524000529},
author = {Yunshun Zhong and Sebastian D. Goodfellow},
keywords = {Construction management, Domain-specific large language models, Pre-training, Natural language processing (NLP), Transfer learning, Text classification (TC), Named entity recognition (NER), Corpus development},
abstract = {The rising demand for automated methods in the Construction Management Systems (CMS) sector highlights opportunities for the Transformer architecture, which enables pre-training Deep Learning models on large, unlabeled datasets for Natural Language Processing (NLP) tasks, outperforming traditional Recurrent Neural Network models. However, their potential in the CMS domain remains underexplored. Therefore, this research produced the first CMS domain corpora from academic papers and introduced an end-to-end pipeline for pre-training and fine-tuning domain-specific Pre-trained Language Models. Four corpora were constructed and transfer learning was employed to pre-train BERT and RoBERTa using the corpora. The best-performing models were then fine-tuned and outperformed models pre-trained on general corpora. In two key NLP tasks, text classification using an infrastructure condition prediction dataset and named entity recognition using an automatic construction control dataset, domain-specific pre-training improved F1 scores by 5.9% and 8.5%, respectively. These promising results demonstrate extended applicability beyond CMS to the Architecture, Engineering, and Construction sectors.}
}
@article{HOSSAIN2024107987,
title = {AraCovTexFinder: Leveraging the transformer-based language model for Arabic COVID-19 text identification},
journal = {Engineering Applications of Artificial Intelligence},
volume = {133},
pages = {107987},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.107987},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624001453},
author = {Md. Rajib Hossain and Mohammed Moshiul Hoque and Nazmul Siddique and M. Ali Akber Dewan},
keywords = {Natural language processing, Low-resource text identification, Text processing, Language model, Arabic covid text, Ablation study, Late-fusion},
abstract = {In light of the pandemic, the identification and processing of COVID-19-related text have emerged as critical research areas within the field of Natural Language Processing (NLP). With a growing reliance on online portals and social media for information exchange and interaction, a surge in online textual content, comprising disinformation, misinformation, fake news, and rumors has led to the phenomenon of an infodemic on the World Wide Web. Arabic, spoken by over 420 million people worldwide, stands as a significant low-resource language, lacking efficient tools or applications for the detection of COVID-19-related text. Additionally, the identification of COVID-19 text is an essential prerequisite task for detecting fake and toxic content associated with COVID-19. This gap hampers crucial COVID information retrieval and processing necessary for policymakers and health authorities. Addressing this issue, this paper introduces an intelligent Arabic COVID-19 text identification system named ‘AraCovTexFinder,’ leveraging a fine-tuned fusion-based transformer model. Recognizing the challenges posed by a scarcity of related text corpora, substantial morphological variations in the language, and a deficiency of well-tuned hyperparameters, the proposed system aims to mitigate these hurdles. To support the proposed method, two corpora are developed: an Arabic embedding corpus (AraEC) and an Arabic COVID-19 text identification corpus (AraCoV). The study evaluates the performance of six transformer-based language models (mBERT, XML-RoBERTa, mDeBERTa-V3, mDistilBERT, BERT-Arabic, and AraBERT), 12 deep learning models (combining Word2Vec, GloVe, and FastText embedding with CNN, LSTM, VDCNN, and BiLSTM), and the newly introduced model AraCovTexFinder. Through extensive evaluation, AraCovTexFinder achieves a high accuracy of 98.89 ± 0.001%, outperforming other baseline models, including transformer-based language and deep learning models. This research highlights the importance of specialized tools in low-resource languages to combat the infodemic relating to COVID-19, which can assist policymakers and health authorities in making informed decisions.}
}
@article{AUDRIN2024123279,
title = {Digital skills at work – Conceptual development and empirical validation of a measurement scale},
journal = {Technological Forecasting and Social Change},
volume = {202},
pages = {123279},
year = {2024},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2024.123279},
url = {https://www.sciencedirect.com/science/article/pii/S0040162524000751},
author = {Bertrand Audrin and Catherine Audrin and Xavier Salamin},
keywords = {Digital skills, Future of work, Digital competence, Employability},
abstract = {In today's increasingly digitalized work environments, the need for digital skills is on the rise. Surprisingly, current frameworks of digital skills fail to specifically address the identification and measurement of digital skills in the workplace. The objective of this research is thus to develop a framework and a validated scale for digital skills at work. To do so, we employ a multi-step process that includes a thorough literature review, cognitive interviews with five experts, two pilot surveys (respectively n = 22 and n = 106), and a full validation survey (n = 923) among professionals. The findings consist of a comprehensive framework and a validated scale for digital skills at work. The framework entails 8 dimensions: Technology use, Cybersecurity, Content management, Communication and collaboration, Critical inquiry, Responsibility, Well-being, and Identity and development. The final scale consists of 52 items. This work enables to better understand individuals' skillsets and organizational requirements in terms of digital skills for the future of work. Both practical and research implications are discussed.}
}
@article{KO2024115202,
title = {Revealing the clinical potential of high-resolution organoids},
journal = {Advanced Drug Delivery Reviews},
volume = {207},
pages = {115202},
year = {2024},
issn = {0169-409X},
doi = {https://doi.org/10.1016/j.addr.2024.115202},
url = {https://www.sciencedirect.com/science/article/pii/S0169409X24000243},
author = {Jihoon Ko and Sujin Hyung and Sunghun Cheong and Yoojin Chung and Noo {Li Jeon}},
abstract = {The symbiotic interplay of organoid technology and advanced imaging strategies yields innovative breakthroughs in research and clinical applications. Organoids, intricate three-dimensional cell cultures derived from pluripotent or adult stem/progenitor cells, have emerged as potent tools for in vitro modeling, reflecting in vivo organs and advancing our grasp of tissue physiology and disease. Concurrently, advanced imaging technologies such as confocal, light-sheet, and two-photon microscopy ignite fresh explorations, uncovering rich organoid information. Combined with advanced imaging technologies and the power of artificial intelligence, organoids provide new insights that bridge experimental models and real-world clinical scenarios. This review explores exemplary research that embodies this technological synergy and how organoids reshape personalized medicine and therapeutics.}
}
@article{BAKRI2024100084,
title = {Biomedical applications of wearable biosensors},
journal = {Next Materials},
volume = {3},
pages = {100084},
year = {2024},
issn = {2949-8228},
doi = {https://doi.org/10.1016/j.nxmate.2023.100084},
url = {https://www.sciencedirect.com/science/article/pii/S2949822823000849},
author = {Mais Haj Bakri and Ali Can Özarslan and Azime Erarslan and Yeliz {Basaran Elalmis} and Fatih Ciftci},
keywords = {Wearable biosensors, Functional nanomaterials, Stretchable electronics},
abstract = {Over the last decade, both scientific and commercial communities have focused on developing wearable sensors for biomedical use. These sensors monitor vital signs in various individuals, including patients, athletes, infants, and the elderly. They contribute to mobile health technologies, offering real-time health recommendations and management. Wearable and implantable devices are reshaping healthcare, driven by sensor advancements. Biosensors, known for their simplicity and adaptability, hold significant potential. This review focuses on categorizing wearable biosensors, including classifying biological elements, nanomaterials, and transducers. It also examines the various types of wearable sensors, specialized sensor designs, applications in textile materials, wearable medical devices, and the advantages of biosensors in medicine. Comprehensive analysis of the various applications of wearable biotechnology while addressing the challenges and possible remedies associated with wearable technology were reviewed.}
}
@article{2024101002,
title = {Full Issue PDF},
journal = {JACC: Advances},
volume = {3},
number = {5},
pages = {101002},
year = {2024},
issn = {2772-963X},
doi = {https://doi.org/10.1016/S2772-963X(24)00191-1},
url = {https://www.sciencedirect.com/science/article/pii/S2772963X24001911}
}
@article{SHARMA2024105761,
title = {Advances in Alzheimer's disease: A multifaceted review of potential therapies and diagnostic techniques for early detection},
journal = {Neurochemistry International},
volume = {177},
pages = {105761},
year = {2024},
issn = {0197-0186},
doi = {https://doi.org/10.1016/j.neuint.2024.105761},
url = {https://www.sciencedirect.com/science/article/pii/S0197018624000883},
author = {Monika Sharma and Pankaj Pal and Sukesh Kumar Gupta},
keywords = {COX-2, PPAR-γ, qRT-PCR, MicroRNA, Mitochondrial dysfunction},
abstract = {Alzheimer's disease (AD) remains one of the most formidable neurological disorders, affecting millions globally. This review provides a holistic overview of the therapeutic strategies, both conventional and novel, aimed at mitigating the impact of AD. Initially, we delve into the conventional approach, emphasizing the role of Acetylcholinesterase (AChE) inhibition, which has been a cornerstone in AD management. As our understanding of AD evolves, several novel potential approaches emerge. We discuss the promising roles of Butyrylcholinesterase (BChE) inhibition, Tau Protein inhibitors, COX-2 inhibition, PPAR-γ agonism, and FAHH inhibition, among others. The potential of the endocannabinoids (eCB) system, cholesterol-lowering drugs, metal chelators, and MMPs inhibitors are also explored, culminating in the exploration of the pivotal role of microRNA in AD progression. Parallel to these therapeutic insights, we shed light on the novel tools and methodologies revolutionizing AD research. From the quantitative analysis of gene expression by qRTPCR to the evaluation of mitochondrial function using induced pluripotent stem cells (iPSCs), the advances in diagnostic and research tools offer renewed hope. Moreover, we explore the current landscape of clinical trials, highlighting the leading drug interventions and their respective stages of development. This comprehensive review concludes with a look into the future perspectives, capturing the potential breakthroughs and innovations on the horizon. Through a synthesis of current knowledge and emerging research, this article aims to provide a consolidated resource for clinicians, researchers, and academicians in the realm of Alzheimer's disease.}
}
@article{SMMARWAR2024100130,
title = {Android malware detection and identification frameworks by leveraging the machine and deep learning techniques: A comprehensive review},
journal = {Telematics and Informatics Reports},
volume = {14},
pages = {100130},
year = {2024},
issn = {2772-5030},
doi = {https://doi.org/10.1016/j.teler.2024.100130},
url = {https://www.sciencedirect.com/science/article/pii/S2772503024000161},
author = {Santosh K. Smmarwar and Govind P. Gupta and Sanjay Kumar},
keywords = {Machine learning, Deep learning, Android malware detection, Malware detection},
abstract = {The ever-increasing growth of online services and smart connectivity of devices have posed the threat of malware to computer system, android-based smart phones, Internet of Things (IoT)-based systems. The anti-malware software plays an important role in order to safeguard the system resources, data and information against these malware attacks. Nowadays, malware writers used advanced techniques like obfuscation, packing, encoding and encryption to hide the malicious activities. Because of these advanced techniques of malware evasion, traditional malware detection system unable to detect new variants of malware. Cyber security has attracted many researchers in the past for designing of Machine Learning (ML) or Deep Learning (DL) based malware detection models. In this study, we present a comprehensive review of the literature on malware detection approaches. The overall literature of the malware detection is grouped into three categories such as review of feature selection (FS) techniques proposed for malware detection, review of ML-based techniques proposed for malware detection and review of DL-based techniques proposed for malware detection. Based on literature review, we have identified the shortcoming and research gaps along with some future directives to design of an efficient malware detection and identification framework.}
}
@article{FONSECABUSTOS2024106357,
title = {A robust self-supervised image hashing method for content identification with forensic detection of content-preserving manipulations},
journal = {Neural Networks},
volume = {177},
pages = {106357},
year = {2024},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2024.106357},
url = {https://www.sciencedirect.com/science/article/pii/S0893608024002818},
author = {Jesús Fonseca-Bustos and Kelsey Alejandra Ramírez-Gutiérrez and Claudia Feregrino-Uribe},
keywords = {Content identification, Robust image hashing, Self-supervised learning, Image processing},
abstract = {Image content identification systems have many applications in industry and academia. In particular, a hash-based content identification system uses a robust image hashing function that computes a short binary identifier summarizing the perceptual content in a picture and is invariant against a set of expected manipulations while being capable of differentiating between different pictures. A common approach to designing these algorithms is crafting a processing pipeline by hand. Unfortunately, once the context changes, the researcher may need to define a new function to adapt. A deep hashing approach exploits the feature learning capabilities in deep networks to generate a feature vector that summarizes the perceptual content in the image, achieving outstanding performance for the image retrieval task, which requires measuring semantic and perceptual similarity between items. However, its application to robust content identification systems is an open area of opportunity. Also, image hashing functions are valuable tools for image authentication. However, to our knowledge, its application to content-preserving manipulation detection for image forensics tasks is still an open research area. In this work, we propose a deep hashing method exploiting the metric learning capabilities in contrastive self-supervised learning with a new modular loss function for robust image hashing. Moreover, we propose a novel approach for content-preserving manipulation detection for image forensics through a sensitivity component in our loss function. We validate our method through extensive experimentation in different data sets and configurations, validating the generalization properties in our work.}
}
@incollection{HUSSAIN2024299,
title = {12 - Additive manufacturing in the next world},
editor = {Shadpour Mallakpour and Chaudhery {Mustansar Hussain}},
booktitle = {Medical Additive Manufacturing},
publisher = {Elsevier},
pages = {299-362},
year = {2024},
series = {Additive Manufacturing Materials and Technologies},
isbn = {978-0-323-95383-2},
doi = {https://doi.org/10.1016/B978-0-323-95383-2.00007-X},
url = {https://www.sciencedirect.com/science/article/pii/B978032395383200007X},
author = {Chaudhery Ghazanfar Hussain and Muhammad Qadeer and Rüstem Keçili and Chaudhery Mustansar Hussain},
keywords = {3D printing, fused deposition modeling (FDM), selective laser sintering (SLS), stereolithography (SLA), digital light processing (DLP), PolyJet technology, multijet fusion (MJF), direct metal laser sintering (DMLS), computer-aided design (CAD), postprocessing, rapid prototyping, materials, support structures, layer height, build volume, infill, powder bed fusion (PBF), binder jetting},
abstract = {Additive manufacturing (AM), also known as 3D printing, has revolutionized the manufacturing industry by enabling the creation of complex objects with intricate designs. This chapter explores the potential impact of AM in the next world, highlighting key advancements, challenges, and opportunities in various sectors. We discuss the transformative potential of additive manufacturing across industries such as healthcare, aerospace, automotive, consumer goods, and construction. Additionally, we examine the implications of AM for sustainability, supply chains, intellectual property, and societal implications. By analyzing current trends and prospects, this chapter aims to provide valuable insights into the next world's AM landscape.}
}
@article{DWIVEDI2024102750,
title = {“Real impact”: Challenges and opportunities in bridging the gap between research and practice – Making a difference in industry, policy, and society},
journal = {International Journal of Information Management},
volume = {78},
pages = {102750},
year = {2024},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2023.102750},
url = {https://www.sciencedirect.com/science/article/pii/S0268401223001317},
author = {Yogesh K. Dwivedi and Anand Jeyaraj and Laurie Hughes and Gareth H. Davies and Manju Ahuja and Mousa Ahmed Albashrawi and Adil S. Al-Busaidi and Salah Al-Sharhan and Khalid Ibrahim Al-Sulaiti and Levent Altinay and Shem Amalaya and Sunil Archak and María Teresa Ballestar and Shonil A. Bhagwat and Anandhi Bharadwaj and Amit Bhushan and Indranil Bose and Pawan Budhwar and Deborah Bunker and Alexandru Capatina and Lemuria Carter and Ioanna Constantiou and Crispin Coombs and Tom Crick and Csaba Csáki and Yves Darnige and Rahul Dé and Rick Delbridge and Rameshwar Dubey and Robin Gauld and Ravi Kumar Gutti and Marié Hattingh and Arve Haug and Leeya Hendricks and Airo Hino and Cathy H.C. Hsu and Netta Iivari and Marijn Janssen and Ikram Jebabli and Paul Jones and Iris Junglas and Abhishek Kaushik and Deepak Khazanchi and Mitsuru Kodama and Sascha Kraus and Vikram Kumar and Christian Maier and Tegwen Malik and Machdel Matthee and Ian P. McCarthy and Marco Meier and Bhimaraya Metri and Adrian Micu and Angela-Eliza Micu and Santosh K. Misra and Anubhav Mishra and Tonja Molin-Juustila and Leif Oppermann and Nicholas O’Regan and Abhipsa Pal and Neeraj Pandey and Ilias O. Pappas and Andrew Parker and Kavita Pathak and Daniel Pienta and Ariana Polyviou and Ramakrishnan Raman and Samuel Ribeiro-Navarrete and Paavo Ritala and Michael Rosemann and Suprateek Sarker and Pallavi Saxena and Daniel Schlagwein and Hergen Schultze and Chitra Sharma and Sujeet Kumar Sharma and Antonis Simintiras and Vinay Kumar Singh and Hanlie Smuts and John Soldatos and Manoj Kumar Tiwari and Jason Bennett Thatcher and Cristina Vanberghen and Ákos Varga and Polyxeni Vassilakopoulou and Viswanath Venkatesh and Giampaolo Viglia and Tim Vorley and Michael Wade and Paul Walton},
keywords = {Academic impact, Implications for practice, Relevance, Research benefits, Research contribution, Research impact},
abstract = {Achieving impact from academic research is a challenging, complex, multifaceted, and interconnected topic with a number of competing priorities and key performance indicators driving the extent and reach of meaningful and measurable benefits from research. Academic researchers are incentivised to publish their research in high-ranking journals and academic conferences but also to demonstrate the impact of their outputs through metrics such as citation counts, altmetrics, policy and practice impacts, and demonstrable institutional decision-making influence. However, academic research has been criticized for: its theoretical emphasis, high degree of complexity, jargon-heavy language, disconnect from industry and societal needs, overly complex and lengthy publishing timeframe, and misalignment between academic and industry objectives. Initiatives such as collaborative research projects and technology transfer offices have attempted to deliver meaningful impact, but significant barriers remain in the identification and evaluation of tangible impact from academic research. This editorial focusses on these aspects to deliver a multi-expert perspective on impact by developing an agenda to deliver more meaningful and demonstrable change to how “impact” can be conceptualized and measured to better align with the aims of academia, industry, and wider society. We present the 4D model - Design, Deliver, Disseminate, and Demonstrate - to provide a structured approach for academia to better align research endeavors with practice and deliver meaningful, tangible benefits to stakeholders.}
}
@article{ROWAN2024171672,
title = {Digital technologies to unlock safe and sustainable opportunities for medical device and healthcare sectors with a focus on the combined use of digital twin and extended reality applications: A review},
journal = {Science of The Total Environment},
volume = {926},
pages = {171672},
year = {2024},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2024.171672},
url = {https://www.sciencedirect.com/science/article/pii/S004896972401814X},
author = {Neil J. Rowan},
keywords = {Medical devices, Digital transformation, Design thinking, Sterilization, Sustainability, Circularity},
abstract = {Medical devices have increased in complexity where there is a pressing need to consider design thinking and specialist training for manufacturers, healthcare and sterilization providers, and regulators. Appropriately addressing this consideration will positively inform end-to-end supply chain and logistics, production, processing, sterilization, safety, regulation, education, sustainability and circularity. There are significant opportunities to innovate and to develop appropriate digital tools to help unlock efficiencies in these important areas. This constitutes the first paper to create an awareness of and to define different digital technologies for informing and enabling medical device production from a holistic end-to-end life cycle perspective. It describes the added-value of using digital innovations to meet emerging opportunities for many disposable and reusable medical devices. It addresses the value of accessing and using integrated multi-actor HUBs that combine academia, industry, healthcare, regulators and society to help meet these opportunities. Such as cost-effective access to specialist pilot facilities and expertise that converges digital innovation, material science, biocompatibility, sterility assurance, business model and sustainability. It highlights the marked gap in academic R&D activities (PRISMA review of best publications conducted between January 2010 and January 2024) and the actual list of U.S. FDA's approved and marketed artificial intelligence/machine learning (AI/ML), and augmented reality/virtual reality (AR/VR) enabled-medical devices for different healthcare applications. Bespoke examples of benefits underlying future use of digital tools includes potential implementation of machine learning for supporting and enabling parametric release of sterilized products through efficient monitoring of critical process data (complying with ISO 11135:2014) that would benefit stakeholders. This paper also focuses on the transformative potential of combining digital twin with extended reality innovations to inform efficiencies in medical device design thinking, supply chain and training to inform patient safety, circularity and sustainability.}
}
@article{RANARD2024154796,
title = {Minimizing bias when using artificial intelligence in critical care medicine},
journal = {Journal of Critical Care},
volume = {82},
pages = {154796},
year = {2024},
issn = {0883-9441},
doi = {https://doi.org/10.1016/j.jcrc.2024.154796},
url = {https://www.sciencedirect.com/science/article/pii/S0883944124002831},
author = {Benjamin L. Ranard and Soojin Park and Yugang Jia and Yiye Zhang and Fatima Alwan and Leo Anthony Celi and Elizabeth R. Lusczek},
keywords = {Machine learning, Artificial intelligence, Bias, Disparities, Fairness, Health equity, Critical Care}
}
@article{ALEBOUYEH202418,
title = {Benchmarking robustness and privacy-preserving methods in federated learning},
journal = {Future Generation Computer Systems},
volume = {155},
pages = {18-38},
year = {2024},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2024.01.009},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X24000086},
author = {Zeinab Alebouyeh and Amir Jalaly Bidgoly},
keywords = {Federated Learning, Deep Learning, Security, Robustness, Privacy-Preserving},
abstract = {Federated learning (FL) is a machine learning framework that enables the use of user data for training without the need to share the data with the central server. FL's decentralized structure can lead to security and privacy issues, as it allows malicious or curious users to potentially participate in the training process. One limitation of most defense methods presented in FL is that they typically focus on only one aspect, either security or privacy. Therefore, the unintended effects of defensive methods in one field on another field are not clear. The purpose of this article is to examine security and privacy threats and defensive strategies in FL. In addition, the article investigates the performance of seven robust aggregators against three security attacks in both IID and non-IID settings. Furthermore, the impact of security and privacy defensive methods on each other is explored in the remainder of the article. To investigate the effect of security methods on the success rate of privacy attacks, the performance of seven robust aggregation methods against the membership inference attack is studied. The experiments reveal that the degree of privacy leakage is inversely related to the aggregator's robustness to security attacks. In other words, the greater the aggregator algorithm's robustness to security attacks, the greater the risk of privacy leakage. The impact of privacy-preserving methods on the performance of robust aggregation algorithms was investigated by studying the effect of the adversarial regularization method on their performance. The results indicate that while the adversarial regularization method can help protect user data privacy in FL, it can also disrupt the performance of robust aggregation methods. This can make it difficult for aggregators to accurately identify malicious users and reduce the overall accuracy of the global model.}
}
@article{TRAN2024127345,
title = {A comprehensive survey and taxonomy on privacy-preserving deep learning},
journal = {Neurocomputing},
volume = {576},
pages = {127345},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.127345},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224001164},
author = {Anh-Tu Tran and The-Dung Luong and Van-Nam Huynh},
keywords = {Privacy-preserving deep learning (PPDL), Deep learning (DL), Deep neural network (DNN), Privacy, Secure Multi-Party Computation (SMC)},
abstract = {Deep learning (DL) has been shown to be very effective for many application domains of machine learning (ML), including image classification, voice recognition, natural language processing, and bioinformatics. The success of DL techniques is directly related to the availability of large amounts of training data. However, in many cases, the data are sensitive to the users and should be protected to preserve the privacy. Privacy-preserving deep learning (PPDL) has thus become a very active research field to ensure the training process and use of DL models are productive without exposing or leaking information about the data. This paper aims to provide a comprehensive survey of PPDL. We concentrate on the risks that affect data privacy in DL and conduct a detailed investigation into the models that ensure privacy. Finally, we propose a set of evaluation criteria, detailing the advantages and disadvantages of the solutions. Based on the analyzed strengths and weaknesses, the paper has highlighted some important research problems and application cases that have not been studied and these point to certain open research directions.}
}
@article{KHUAT2024108585,
title = {Applications of machine learning in antibody discovery, process development, manufacturing and formulation: Current trends, challenges, and opportunities},
journal = {Computers & Chemical Engineering},
volume = {182},
pages = {108585},
year = {2024},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2024.108585},
url = {https://www.sciencedirect.com/science/article/pii/S0098135424000036},
author = {Thanh Tung Khuat and Robert Bassett and Ellen Otte and Alistair Grevis-James and Bogdan Gabrys},
keywords = {Biopharmaceuticals, Machine learning, Upstream, Downstream, Bioprocesses, Digital twin, Soft sensors},
abstract = {While machine learning (ML) has made significant contributions to the biopharmaceutical field, its applications are still in the early stages in terms of providing direct support for quality-by-design based development and manufacturing of biologics, hindering the enormous potential for bioprocesses automation from their development to manufacturing. However, the adoption of ML-based models instead of conventional multivariate data analysis methods is significantly increasing due to the accumulation of large-scale production data. This trend is primarily driven by the real-time monitoring of process variables and quality attributes of biopharmaceutical products through the implementation of advanced process analytical technologies. Given the complexity and multidimensionality of a bioproduct design, bioprocess development, and product manufacturing data, ML-based approaches are increasingly being employed to achieve accurate, flexible, and high-performing predictive models to address the problems of analytics, monitoring, and control within the biopharma field. This paper aims to provide a comprehensive review of the current applications of ML solutions in the design, monitoring, control, and optimisation of upstream, downstream, and product formulation processes of monoclonal antibodies. Finally, this paper thoroughly discusses the main challenges related to the bioprocesses themselves, process data, and the use of machine learning models in monoclonal antibody process development and manufacturing. Moreover, it offers further insights into the adoption of innovative machine learning methods and novel trends in the development of new digital biopharma solutions.}
}
@article{MOSHOOD2024102519,
title = {Infrastructure digital twin technology: A new paradigm for future construction industry},
journal = {Technology in Society},
volume = {77},
pages = {102519},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2024.102519},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X24000678},
author = {Taofeeq D. Moshood and James OB. Rotimi and Wajiha Shahzad and J.A. Bamgbade},
keywords = {Digital twin, Construction 4.0, Sustainability, Project delivery, Built environment, Construction industry},
abstract = {The construction industry has traditionally been slow to adopt digital technology, resulting in inefficient workflows, frequent cost overruns, and delays. Moreover, its fragmented structure, inherent to market dynamics, exacerbates these challenges. Embracing digitalization and transitioning to Industry 4.0 can substantially enhance efficiency and productivity in construction through increased innovation and improved collaboration, ultimately reducing information gaps and data discrepancies. This study aims to assess the potential integration of digital twin technology across various construction stages, spanning from initial design to project delivery. Existing literature emphasizes the transformative power of digital twin technology in advancing building innovation and environmental sustainability. These virtual replicas are crucial in optimizing industrial manufacturing by harmonizing production processes and societal interactions. A focused examination of digital twin technology applications in construction highlights its ability to streamline coordination and facilitate data sharing among stakeholders. Property owners increasingly recognise the value of digital twin technology in local contexts, driving the digitization of design and collaboration methods in construction. Integrating digital twin technology right from a project's inception and extending it across design phases optimizes project delivery, enhances asset quality, and contributes to societal sustainability. As the nexus between digitalization and sustainability goals strengthens, the construction industry stands at the cusp of a significant transformative journey.}
}
@article{LEE2024100221,
title = {The impact of generative AI on higher education learning and teaching: A study of educators’ perspectives},
journal = {Computers and Education: Artificial Intelligence},
volume = {6},
pages = {100221},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100221},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000225},
author = {Daniel Lee and Matthew Arnold and Amit Srivastava and Katrina Plastow and Peter Strelan and Florian Ploeckl and Dimitra Lekkas and Edward Palmer},
keywords = {Artificial intelligence, Generative artificial intelligence, Higher education, ChatGPT, Learning and teaching},
abstract = {In recent months, Artificial Intelligence (AI) has had, and will continue to have, a dramatic impact on Higher Education (HE). A study conducted by researchers at a leading university in Australia surveyed 30 of their teaching staff, drawn predominantly from their teaching academy, and interviewed eight of them regarding the impact of AI on HE. Data were analyzed using the procedures of Inductive Thematic Analysis and revealed a lack of any homogenous sentiment around AI in HE and much ambiguity regarding best practice regarding recent technological developments. The results indicate concerns exist around concepts relating to academic integrity, however, these concerns may be exaggerated. Almost half of the participants indicated they were using AI within their teaching roles with the most common design change being modifications to assessments. Less than a quarter of staff agreed the university has adequately equipped them for AI, and more than three quarters indicated they would like support. They unanimously assumed the technology will improve. Keeping in mind universities’ obligation to serve students by preparing them for industry, it is vitally important that the HE sector stays informed of developments in AI and commit to ongoing research and discussions regarding best practice in response to AI. However, anything regarding AI and future developments will be extremely difficult to predict.}
}
@article{SARKER2024101110,
title = {Multi-aspect rule-based AI: Methods, taxonomy, challenges and directions towards automation, intelligence and transparent cybersecurity modeling for critical infrastructures},
journal = {Internet of Things},
volume = {25},
pages = {101110},
year = {2024},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2024.101110},
url = {https://www.sciencedirect.com/science/article/pii/S2542660524000520},
author = {Iqbal H. Sarker and Helge Janicke and Mohamed Amine Ferrag and Alsharif Abuadbba},
keywords = {Cybersecurity, Rule-based Modeling, Explainable AI, Responsible AI, Machine learning, Security data analytics, Knowledge discovery, Data-driven decision-making, Automation, Intelligence, Transparency, Trustworthiness, Critical infrastructures},
abstract = {Critical infrastructure (CI) typically refers to the essential physical and virtual systems, assets, and services that are vital for the functioning and well-being of a society, economy, or nation. However, the rapid proliferation and dynamism of today’s cyber threats in digital environments may disrupt CI functionalities, which would have a debilitating impact on public safety, economic stability, and national security. This has led to much interest in effective cybersecurity solutions regarding automation and intelligent decision-making, where AI-based modeling is potentially significant. In this paper, we take into account “Rule-based AI” rather than other black-box solutions since model transparency, i.e., human interpretation, explainability, and trustworthiness in decision-making, is an essential factor, particularly in cybersecurity application areas. This article provides an in-depth study on multi-aspect rule based AI modeling considering human interpretable decisions as well as security automation and intelligence for CI. We also provide a taxonomy of rule generation methods by taking into account not only knowledge-driven approaches based on human expertise but also data-driven approaches, i.e., extracting insights or useful knowledge from data, and their hybridization. This understanding can help security analysts and professionals comprehend how systems work, identify potential threats and anomalies, and make better decisions in various real-world application areas. We also cover how these techniques can address diverse cybersecurity concerns such as threat detection, mitigation, prediction, diagnosis for root cause findings, and so on in different CI sectors, such as energy, defence, transport, health, water, agriculture, etc. We conclude this paper with a list of identified issues and opportunities for future research, as well as their potential solution directions for how researchers and professionals might tackle future generation cybersecurity modeling in this emerging area of study.}
}
@article{HU2024801,
title = {T4SEpp: A pipeline integrating protein language models to predict bacterial type IV secreted effectors},
journal = {Computational and Structural Biotechnology Journal},
volume = {23},
pages = {801-812},
year = {2024},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2024.01.015},
url = {https://www.sciencedirect.com/science/article/pii/S2001037024000151},
author = {Yueming Hu and Yejun Wang and Xiaotian Hu and Haoyu Chao and Sida Li and Qinyang Ni and Yanyan Zhu and Yixue Hu and Ziyi Zhao and Ming Chen},
keywords = {T4SEpp, T4SE Prediction, T4SS, Deep learning, Protein language model,  T4SEs},
abstract = {Many pathogenic bacteria use type IV secretion systems (T4SSs) to deliver effectors (T4SEs) into the cytoplasm of eukaryotic cells, causing diseases. The identification of effectors is a crucial step in understanding the mechanisms of bacterial pathogenicity, but this remains a major challenge. In this study, we used the full-length embedding features generated by six pre-trained protein language models to train classifiers predicting T4SEs and compared their performance. We integrated three modules into a model called T4SEpp. The first module searched for full-length homologs of known T4SEs, signal sequences, and effector domains; the second module fine-tuned a machine learning model using data for a signal sequence feature; and the third module used the three best-performing pre-trained protein language models. T4SEpp outperformed other state-of-the-art (SOTA) software tools, achieving ∼0.98 accuracy at a high specificity of ∼0.99, based on the assessment of an independent validation dataset. T4SEpp predicted 13 T4SEs from Helicobacter pylori, including the well-known CagA and 12 other potential ones, among which eleven could potentially interact with human proteins. This suggests that these potential T4SEs may be associated with the pathogenicity of H. pylori. Overall, T4SEpp provides a better solution to assist in the identification of bacterial T4SEs and facilitates studies of bacterial pathogenicity. T4SEpp is freely accessible at https://bis.zju.edu.cn/T4SEpp.}
}
@article{BENSAOUD2024100546,
title = {A survey of malware detection using deep learning},
journal = {Machine Learning with Applications},
volume = {16},
pages = {100546},
year = {2024},
issn = {2666-8270},
doi = {https://doi.org/10.1016/j.mlwa.2024.100546},
url = {https://www.sciencedirect.com/science/article/pii/S2666827024000227},
author = {Ahmed Bensaoud and Jugal Kalita and Mahmoud Bensaoud},
keywords = {Malware detection, Multi-task learning, Malware image, Generative adversarial networks, Mobile malware, Convolutional neural network},
abstract = {The problem of malicious software (malware) detection and classification is a complex task, and there is no perfect approach. There is still a lot of work to be done. Unlike most other research areas, standard benchmarks are difficult to find for malware detection. This paper aims to investigate recent advances in malware detection on MacOS, Windows, iOS, Android, and Linux using deep learning (DL) by investigating DL in text and image classification, the use of pre-trained and multi-task learning models for malware detection approaches to obtain high accuracy and which the best approach if we have a standard benchmark dataset. We discuss the issues and the challenges in malware detection using DL classifiers by reviewing the effectiveness of these DL classifiers and their inability to explain their decisions and actions to DL developers presenting the need to use Explainable Machine Learning (XAI) or Interpretable Machine Learning (IML) programs. Additionally, we discuss the impact of adversarial attacks on deep learning models, negatively affecting their generalization capabilities and resulting in poor performance on unseen data. We believe there is a need to train and test the effectiveness and efficiency of the current state-of-the-art deep learning models on different malware datasets. We examine eight popular DL approaches on various datasets. This survey will help researchers develop a general understanding of malware recognition using deep learning.}
}
@article{ZHENG2024123394,
title = {FTA-DETR: An efficient and precise fire detection framework based on an end-to-end architecture applicable to embedded platforms},
journal = {Expert Systems with Applications},
volume = {248},
pages = {123394},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.123394},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424002598},
author = {Hongtao Zheng and Gaoyang Wang and Duo Xiao and Hong Liu and Xiaoyin Hu},
keywords = {Fire detection, Diffusion model, DDPM, Deformable-DETR, FTA-DETR, WiouV3},
abstract = {Timely fire alarms are crucial as they can save lives and avoid major economic losses. However, due to the complexity of the structure, the current mainstream DETR-based fire detection models are problematic in terms of practicality because they require large amounts of memory and long inference times. Meanwhile, high-quality fire detection datasets are very scarce, severely limiting the performance of the algorithms. To address these challenges and improve accuracy in complex fire environments, first, we introduce a dataset quality enhancement framework based on diffusion model (DDPM) to improve the quality of low-quality fire alarm datasets. Second, we propose a novel Deformable-DETR-based fire detection framework (FTA-DETR). Among the innovative optimizations of FTA-DETR, first, we introduce a trainable matrix in the encoder to compute features, which reduces the computational burden of the encoder, highlights compelling features, and significantly reduces the training time. Second, we improve the encoding block by alternately updating high-level and low-level features, greatly reducing the amount of feature computation required for effective detection. This encoder structure is compatible with any state-of-the-art transformer decoder. Next, to accommodate the multi-scale nature of fires and different environmental complexities, we modify the loss function to WiouV3, which not only speeds up the convergence of the model but also improves the performance. Finally, we smoothly combine FTA-DETR with an acceleration engine like TensorRT to improve inference speed with little loss of accuracy. The experiments show that the dataset quality enhancement framework based on the diffusion model generates high quality datasets, and the enhanced dataset can greatly improve the detection performance of FTA-DETR (mAP increased by 2.42%). Meanwhile, FTA-DETR outperforms almost all current fire detection frameworks in terms of detection accuracy and interference resistance, with accuracy reaching 98.32% and 99.21% on the two datasets, Mivia and FireNet, respectively, and precision reaching 94% on the BoWFire dataset. In addition, FTA-DETR after being paired with the TensorRT framework achieves an inference speed of 76 FPS on the Jetson Orin Nano, a small embedded device with very limited computational power. The code is available at https://github.com/wanggoat/FTA-detr.}
}
@article{GUNASEGARAM2024104013,
title = {Machine learning-assisted in-situ adaptive strategies for the control of defects and anomalies in metal additive manufacturing},
journal = {Additive Manufacturing},
volume = {81},
pages = {104013},
year = {2024},
issn = {2214-8604},
doi = {https://doi.org/10.1016/j.addma.2024.104013},
url = {https://www.sciencedirect.com/science/article/pii/S2214860424000599},
author = {D.R. Gunasegaram and A.S. Barnard and M.J. Matthews and B.H. Jared and A.M. Andreaco and K. Bartsch and A.B. Murphy},
keywords = {Artificial intelligence, Autonomous manufacturing, Closed-loop control, Diagnostics, Directed energy deposition, Industry 4.0, Powder bed fusion, Process monitoring, Prognostics, Zero defects manufacturing},
abstract = {In metal additive manufacturing (AM), the material microstructure and part geometry are formed incrementally. Consequently, the resulting part could be defect- and anomaly-free if sufficient care is taken to deposit each layer under optimal process conditions. Conventional closed-loop control (CLC) engineering solutions which sought to achieve this were deterministic and rule-based, thus resulting in limited success in the stochastic environment experienced in the highly dynamic AM process. On the other hand, emerging machine learning (ML) based strategies are better suited to providing the robustness, scope, flexibility, and scalability required for process control in an uncertain environment. Offline ML models that help optimise AM process parameters before a build begins and online ML models that efficiently processed in-situ sensory data to detect and diagnose flaws in real-time (or near-real-time) have been developed. However, ML models that enable a process to take evasive or corrective actions in relation to flaws via on the fly decision-making are only emerging. These models must possess prognostic capabilities to provide context-sensitive recommendations for in-situ process control based on real-time diagnostics. In this article, we pinpoint the shortcomings in traditional CLC strategies, and provide a framework for defect and anomaly control through ML-assisted CLC in AM. We discuss flaws in terms of their causes, in-situ detectability, and controllability, and examine their management under three scenarios: avoidance, mitigation, and repair. Then, we summarise the research into ML models developed for offline optimisation and in-situ diagnosis before initiating a detailed conversation on the implementation of ML-assisted in-situ process control. We found that researchers favoured reinforcement learning approaches or inverse ML models for making rapid, situation-aware control decisions. We also observed that, to-date, the defects addressed were those that may be quantified relatively easily autonomously, and that mitigation (rather than avoidance or repair) was the aim of ML-assisted in-situ control strategies. Additionally, we highlight the various technologies that must seamlessly combine to advance the field of autonomous in-situ control so that it becomes a reality in industrial settings. Finally, we raise awareness of seldom discussed, yet highly pertinent, topics relevant to adaptive control. Our work closes a significant gap in the current AM literature by broaching wide-ranging discussions on matters relevant to in-situ adaptive control in AM.}
}
@article{SHEN2024114463,
title = {Ecosystem orchestration practices for industrial firms: A qualitative meta-analysis, framework development and research agenda},
journal = {Journal of Business Research},
volume = {173},
pages = {114463},
year = {2024},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2023.114463},
url = {https://www.sciencedirect.com/science/article/pii/S0148296323008226},
author = {Lei Shen and Qingyue Shi and Vinit Parida and Marin Jovanovic},
keywords = {Ecosystem orchestration, Innovation ecosystem, Orchestration practices, Governance, Coordination, Qualitative -analysis},
abstract = {This study ventures into the dynamic realm of ecosystem orchestration for industrial firms, emphasizing its significance in maintaining competitive advantage in the digital era. The fragmented research on this important subject poses challenges for firms aiming to navigate and capitalize on ecosystem orchestration. To bridge this knowledge gap, we conducted a comprehensive qualitative meta-analysis of 31 case studies and identified multifaceted orchestration practices employed by industrial firms. The core contribution of this research is the illumination of five interdependent but interrelated orchestration practices: strategic design, relational, resource integration, technological, and innovation. Together, these practices are synthesized into an integrative framework termed the “Stirring Model,” which serves as a practical guide to the orchestration practices. Furthermore, the conceptual framework clarifies the synergy between the identified practices and highlights their collective impact. This study proposes theoretical and practical implications for ecosystem orchestration literature and suggests avenues for further research.}
}
@incollection{AHMED202421,
title = {2 - Medical additive manufacturing in the battle against the COVID-19 pandemic},
editor = {Shadpour Mallakpour and Chaudhery {Mustansar Hussain}},
booktitle = {Medical Additive Manufacturing},
publisher = {Elsevier},
pages = {21-60},
year = {2024},
series = {Additive Manufacturing Materials and Technologies},
isbn = {978-0-323-95383-2},
doi = {https://doi.org/10.1016/B978-0-323-95383-2.00023-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780323953832000238},
author = {Ammar Ahmed and Ali Azam},
keywords = {Medical additive manufacturing, 3D printing, COVID-19},
abstract = {This chapter comprehensively discusses the applications of medical additive manufacturing in the fight against the pandemic. Recent applications of MAM in the fight against the COVID-19 pandemic include 3D-printed holographic microscopes, medical face shields, nasopharyngeal swabs for preventive/diagnostic testing, personal protective equipment, respiratory masks, air filtration masks made of polylactic acid, new IT-based additive manufacturing and 3D-bioprinted ideal tissue models for antiviral research. Also, a scientometric study of the MAM-related literature (published between January 2000 and April 2022) against the COVID-19 infection was conducted in VOS viewer. The most cooccurring keywords and up-to-date research frontiers of the MAM research were evaluated, and the MAM knowledge was categorized into ten distinct themes. Significantly, this chapter presents the significant role of MAM during the COVID-19 pandemic, in addition to evaluating the frontiers and potential challenges hindering the enhancement of MAM. To conduct the bibliometric study of the MAM research, the published literature was downloaded from the Science Citation Index Expanded (SCIE) and Emerging Science Citation Index (ESCI) databases. The scientometric simulations were conducted in VOS viewer to obtain the following objectives. (1) To find the most collaborative forces and highly influential keywords in the MAM research against COVID-19. (2) Research clusters of the MAM knowledge. (3) Knowledge structure of the MAM literature including various subfields, documents and keywords. (4) Distribution of MAM-related published literature into the research frontiers and hotspots for future studies.}
}