Alfredo Madrid-García, Beatriz Merino-Barbancho, Dalifer Freites-Núñez, Luis Rodríguez-Rodríguez, Ernestina Menasalvas-Ruíz, Alejandro Rodríguez-González, Anselmo Peñas,
From Web to RheumaLpack: Creating a Linguistic Corpus for Exploitation and Knowledge Discovery in Rheumatology,
Computers in Biology and Medicine,
Volume 179,
2024,
108920,
ISSN 0010-4825,
https://doi.org/10.1016/j.compbiomed.2024.108920.
(https://www.sciencedirect.com/science/article/pii/S0010482524010059)
Abstract: This study introduces RheumaLinguisticpack (RheumaLpack), the first specialised linguistic web corpus designed for the field of musculoskeletal disorders. By combining web mining (i.e., web scraping) and natural language processing (NLP) techniques, as well as clinical expertise, RheumaLpack systematically captures and curates structured and unstructured data across a spectrum of web sources including clinical trials registers (i.e., ClinicalTrials.gov), bibliographic databases (i.e., PubMed), medical agencies (i.e. European Medicines Agency), social media (i.e., Reddit), and accredited health websites (i.e., MedlinePlus, Harvard Health Publishing, and Cleveland Clinic). Given the complexity of rheumatic and musculoskeletal diseases (RMDs) and their significant impact on quality of life, this resource can be proposed as a useful tool to train algorithms that could mitigate the diseases' effects. Therefore, the corpus aims to improve the training of artificial intelligence (AI) algorithms and facilitate knowledge discovery in RMDs. The development of RheumaLpack involved a systematic six-step methodology covering data identification, characterisation, selection, collection, processing, and corpus description. The result is a non-annotated, monolingual, and dynamic corpus, featuring almost 3 million records spanning from 2000 to 2023. RheumaLpack represents a pioneering contribution to rheumatology research, providing a useful resource for the development of advanced AI and NLP applications. This corpus highlights the value of web data to address the challenges posed by musculoskeletal diseases, illustrating the corpus's potential to improve research and treatment paradigms in rheumatology. Finally, the methodology shown can be replicated to obtain data from other medical specialities. The code and details on how to build RheumaLpack are also provided to facilitate the dissemination of such resource.
Keywords: Web corpus; Artificial intelligence; Rheumatology; Natural language processing

Jianan Zhang, J Dinesh Peter, Achyut Shankar, Wattana Viriyasitavat,
Public cloud networks oriented deep neural networks for effective intrusion detection in online music education,
Computers and Electrical Engineering,
Volume 115,
2024,
109095,
ISSN 0045-7906,
https://doi.org/10.1016/j.compeleceng.2024.109095.
(https://www.sciencedirect.com/science/article/pii/S0045790624000235)
Abstract: The rapid growth of online music education has led to increased security risks from cyber intrusions. This paper proposes public cloud networks oriented deep neural networks for effective intrusion detection in online music education environments. Specifically, a novel intrusion detection framework is developed, comprising fuzzy logic based feature selection, chronological salp swarm algorithm optimized deep belief networks, and gated recurrent unit integrated convolutional neural networks. Detailed methodologies are presented for the fuzzy logic system, chronological salp optimization, deep belief network architecture, and convolutional neural networks. Comprehensive experiments are conducted on the NSL-KDD and CICIDS2017 datasets. Various deep neural networks are evaluated and compared, including multi-layer perceptrons, convolutional neural networks, deep belief networks, recurrent neural networks, and the proposed models. Experimental results demonstrate that the proposed fuzzy feature selection and chronological salp swarm algorithm optimized deep belief network achieves a test accuracy of 97.33 %, outperforming other peer models. The gated recurrent unit integrated convolutional neural network obtains a test accuracy of 98.46 %, superior to state-of-the-art methods. While the experiments on the newly created dataset for intrusion detection in cloud-based online music education demonstrate that the proposed models outperform the benchmarks. The experiments verify the effectiveness of the proposed deep learning frameworks for intrusion detection in online music education cloud networks.
Keywords: Public cloud networks; Deep neural networks; Intrusion detection; Online music education; Deep belief networks

Graham Smith,
The intelligent solution: automation, the skills shortage and cyber-security,
Computer Fraud & Security,
Volume 2018, Issue 8,
2018,
Pages 6-9,
ISSN 1361-3723,
https://doi.org/10.1016/S1361-3723(18)30073-3.
(https://www.sciencedirect.com/science/article/pii/S1361372318300733)
Abstract: A Las Vegas hacking event in 2016, the Cyber Grand Challenge, was the ultimate – and only – all-machine hacking competition.1 Each machine identified software vulnerabilities, exploited them and patched their own systems to protect against threats – all without the intervention of a human programmer. Could this be the future of information security? And in particular, could it address the infamous skills shortage? The lack of security skills in the IT industry is in part because professionals in this field work long hours and require patience, resources, knowledge and experience Unfortunately, the cyber-security talent pool simply isn't wide enough to meet these needs. Graham Smith of Curo Talent discusses how AI and automation might relieve some of the pressure, automating the longwinded and repetitive tasks that are currently filling the workflows of IT teams, such as testing, basis threat analysis and data deception tactics.

Chun Jiang, Shihan Li, Qi Shen,
Science and technology evaluation reform and universities’ innovation performance,
Technology in Society,
Volume 78,
2024,
102614,
ISSN 0160-791X,
https://doi.org/10.1016/j.techsoc.2024.102614.
(https://www.sciencedirect.com/science/article/pii/S0160791X24001623)
Abstract: Does science and technology evaluation (STE) policy reform improve universities' innovation performance? Research typically argues that more upstream R&D investment leads to more downstream innovation performance, but it is less clear what the trade-offs over time might be for targeted investments in universities influenced by STE reform. In 2013, China proposed STE reform measures focused on ‘innovation quality, efficiency, and contribution’. Using a difference-in-differences research design on a comprehensive longitudinal database of 62 universities spanning from 2009 to 2016, we show that this STE policy positively affects university basic research outputs and quality but weakens applied research outputs. This effect is pronounced in pilot universities with better resources. Empirical evidence suggests that the STE policy works mainly through mobilising the enthusiasm of human capital, improving R&D intensity in science and technology funds, and promoting industrialisation-oriented R&D projects. We consider the following possible perspectives on the mechanisms of change: knowledge asset development, economic competition, and a socio-political process. This analysis leads to theoretical developments about how basic versus applied science produces outputs in the Chinese context. The paper also shows that the STE policy promotes technology transfer in universities.
Keywords: Science and technology evaluation reform; University innovation; Basic research; Applied research; Difference in differences

Shengchao Zhao, Deming Zeng, Jian Li, Ke Feng, Yao Wang,
Quantity or quality: The roles of technology and science convergence on firm innovation performance,
Technovation,
Volume 126,
2023,
102790,
ISSN 0166-4972,
https://doi.org/10.1016/j.technovation.2023.102790.
(https://www.sciencedirect.com/science/article/pii/S0166497223001013)
Abstract: While firms in science-based sectors have multiple convergence opportunities, few empirical studies have explored how technology and science convergence can improve innovation performance. This study offered a novel approach by distinguishing between novel technology convergence (NTC) and reinforced technology convergence (RTC), investigated their different effects on firm innovation quantity and quality, and examined the moderating role of science convergence. We analyzed data on published papers, patents, and other panel data of firms in China's organic chemical industry between 1998 and 2015. The results show that (a) NTC and RTC positively affect firm innovation quantity, but NTC's effect is weaker than that of RTC; (b) NTC positively affects firm innovation quality, whereas RTC negatively affects it; (c) NTC's positive effect on firm innovation quantity is strengthened by science convergence, whereas RTC's positive effect on firm innovation quantity is weakened by it; and (d) NTC's positive effect on firm innovation quality is strengthened by science convergence, while RTC's negative effect on firm innovation quality is weakened by it. By shedding light on these relationships, this study contributes to the literature on technology convergence and recombinant innovation theory, and offers valuable management implications, particularly in terms of selecting appropriate convergence strategies for different innovation orientations.
Keywords: Novel technology convergence; Reinforced technology convergence; Science convergence; Innovation quantity; Innovation quality

Rohit Madan, Mona Ashok,
AI adoption and diffusion in public administration: A systematic literature review and future research agenda,
Government Information Quarterly,
Volume 40, Issue 1,
2023,
101774,
ISSN 0740-624X,
https://doi.org/10.1016/j.giq.2022.101774.
(https://www.sciencedirect.com/science/article/pii/S0740624X22001101)
Abstract: Artificial Intelligence (AI) implementation in public administration is gaining momentum heralded by the hope of smart public services that are personalised, lean, and efficient. However, the use of AI in public administration is riddled with ethical tensions of fairness, transparency, privacy, and human rights. We call these AI tensions. The current literature lacks a contextual and processual understanding of AI adoption and diffusion in public administration to be able to explore such tensions. Previous studies have outlined risks, benefits, and challenges with the use of AI in public administration. However, a large gap remains in understanding AI tensions as they relate to public value creation. Through a systematic literature review grounded in public value management and the resource-based view of the firms, we identify technology-organisational-environmental (TOE) contextual variables and absorptive capacity as factors influencing AI adoption as discussed in the literature. To our knowledge, this is the first paper that outlines distinct AI tensions from an AI implementation and diffusion perspective within public administration. We develop a future research agenda for the full AI innovation lifecycle of adoption, implementation, and diffusion.
Keywords: Public administration; Public values; AI tensions; Absorptive capacity; Data governance; AI adoption; AI diffusion

Helle Sjøvaag, Ragnhild Kr. Olsen, Raul Ferrer-Conill,
Delivering content: Modular broadcasting technology and the role of content delivery networks,
Telecommunications Policy,
Volume 48, Issue 4,
2024,
102738,
ISSN 0308-5961,
https://doi.org/10.1016/j.telpol.2024.102738.
(https://www.sciencedirect.com/science/article/pii/S0308596124000351)
Abstract: Television distribution has changed profoundly over the past 10–15 years. Now increasingly geared towards streaming, broadcasting's value chain hinges on content delivery networks (CDNs) to reach audiences. CDNs are important for content quality, as they constitute the part of the chain that stores and transmits data from broadcasters to the end-user. In this article, we investigate what this value chain shift means for television distribution in Norway, a country where global actors like Akamai and Amazon's CloudFront dominate the CDN market. Based on seven whiteboard-based, co-creation sessions with 15 industry experts representing broadcasters, telecoms, regulators and interest organisations, a value chain analysis reveals that the distribution part of the chain is outsourced and modular. As the technology of television distribution becomes increasingly outsourced, we ask what this means for television's autonomy as a universal service provider.
Keywords: Autonomy; Broadcasting; Content delivery networks; distribution; Infrastructure; value chains

Samuel Fosso Wamba, Serge-Lopez Wamba-Taguimdje, Qihui Lu, Maciel M. Queiroz,
How emerging technologies can solve critical issues in organizational operations: An analysis of blockchain-driven projects in the public sector,
Government Information Quarterly,
Volume 41, Issue 1,
2024,
101912,
ISSN 0740-624X,
https://doi.org/10.1016/j.giq.2024.101912.
(https://www.sciencedirect.com/science/article/pii/S0740624X24000042)
Abstract: Blockchain technology emerged as a concrete and disruptive application in all sectors. Even if the public sector witnessed this technology's first applications and implementations, it took a while to spread even in that environment. Previous studies have shown that blockchain technologies are a powerful, essential, and effective lever for transforming government processes and procedures and improving the management of public benefits and policies. Following an analysis of a sample of 167 blockchain-oriented projects in the public sector, we explore in this article the extent of the effects of blockchain on fundamental public governance functions, and we further explore the information technology and strategic management literature in this regard. As a result, our study shows concrete evidence of how blockchain improves several government core functions: (1) public service governance, administrative efficiency, and open government capabilities; (2) process innovation in public services; and operational and administrative performance improvement. Via a fsQCA analysis, we explored how indicators characterizing blockchain-based transformation projects in the public sector led to radical transformations in public services. Our findings move forward the blockchain perspective on the public sector by enriching the literature, bringing insights to policymakers, and opening new research directions to scholars and practitioners.
Keywords: Blockchain; Public sector; Process innovation; Operational performance; Administrative performance; Cases studies

Jaechang Ko, Donghyuk Lee,
Graph neural networks for classification and error detection in 2D architectural detail drawings,
Automation in Construction,
Volume 170,
2025,
105936,
ISSN 0926-5805,
https://doi.org/10.1016/j.autcon.2024.105936.
(https://www.sciencedirect.com/science/article/pii/S0926580524006721)
Abstract: The assessment and classification of architectural sectional drawings is critical in the architecture, engineering, and construction (AEC) field, where the accurate representation of complex structures and the extraction of meaningful patterns are key challenges. This paper established a framework for standardizing different forms of architectural drawings into a consistent graph format, and evaluated different Graph Neural Networks (GNNs) architectures, pooling methods, node features, and masking techniques. This paper demonstrates that GNNs can be practically applied in the design and review process, particularly for categorizing details and detecting errors in architectural drawings. The potential for visual explanations of model decisions using Explainable AI (XAI) is also explored to enhance the reliability and user understanding of AI models in architecture. This paper highlights the potential of GNNs in architectural data analysis and outlines the challenges and future directions for broader application in the AEC field.
Keywords: Architectural detail drawings; Graph neural networks (GNN); Drawing classification; Error detection; Explainable AI (XAI)

Nadine Kathrin Ostern, Friedrich Holotiuk, Jürgen Moormann,
Organizations’ approaches to blockchain: A critical realist perspective,
Information & Management,
Volume 59, Issue 7,
2022,
103552,
ISSN 0378-7206,
https://doi.org/10.1016/j.im.2021.103552.
(https://www.sciencedirect.com/science/article/pii/S0378720621001269)
Abstract: Organizations face manifold implementation barriers in blockchain adoption. Of particular interest is the pre-adoption phase, where knowledge and attitudes guide organizations’ approaches toward a new technology. This paper examines organizations’ approaches to blockchain through a sensemaking lens to identify how blockchain prototype development is guided by perceived business value of and sentiments toward the technology. Taking a critical realist perspective, we examine divergences between organizations’ approaches toward blockchain adoption, i.e., what they do, and why and how they approach blockchain. We differentiate between four types of approaches and provide recommendations how the pre-adoption phase can be considered in academic analyses.
Keywords: Blockchain; Distributed ledger; Critical realism; IT adoption; Sensemaking; Financial organizations

Ravi S. Ramani, Herman Aguinis,
Using field and quasi experiments and text-based analysis to advance international business theory,
Journal of World Business,
Volume 58, Issue 5,
2023,
101463,
ISSN 1090-9516,
https://doi.org/10.1016/j.jwb.2023.101463.
(https://www.sciencedirect.com/science/article/pii/S109095162300038X)
Abstract: Methodological developments are critical for driving theoretical advancements in international business (IB) due to the field's diversity regarding disciplinary, theoretical, and conceptual bases. We provide an accessible introduction to two methodological approaches—one related to design and one to analysis—that are currently underutilized in IB despite their great potential: (a) field and quasi experiments, and (b) text-based analysis. We describe each method and provide examples of how they can be used to make advancements in several IB domains and theories including internationalization process theory; ownership, location, internalization (OLI) paradigm; knowledge-based view of multinational enterprises; dynamic capability theory; and international entrepreneurship.
Keywords: Research methodology; Research design; Analytical methods; Topic models; Sentiment analysis; Experiments

Katherine O'Toole, Emőke-Ágnes Horvát,
Extending human creativity with AI,
Journal of Creativity,
Volume 34, Issue 2,
2024,
100080,
ISSN 2713-3745,
https://doi.org/10.1016/j.yjoc.2024.100080.
(https://www.sciencedirect.com/science/article/pii/S2713374524000062)
Abstract: The development of generative AI has led to novel ways that technology can be integrated into creative activities. However, this has also raised concerns about how human creators will be affected, and what impact it may have on creative industries. As a result, there has been research into how we can design AI tools that work with human creators, rather than replacing them. In this paper we review approaches utilized to build AI tools that facilitate human creativity and allow users to engage fully and authentically in the creative process. These include leveraging AI models to help us shed light on elements of the creative process, building interfaces that encourage exploration of ideas, and designing technological affordances that can support the development of new creative practices.
Keywords: Computational creativity; Generative AI; HCI

Cody O. Crosby,
Open-source extrusion 3D bioprinters: Trends and recommendations,
Bioprinting,
Volume 38,
2024,
e00336,
ISSN 2405-8866,
https://doi.org/10.1016/j.bprint.2024.e00336.
(https://www.sciencedirect.com/science/article/pii/S2405886624000083)
Abstract: Three-dimensional (3D) extrusion bioprinting, an additive manufacturing process that hybridizes traditional thermoplastic 3D printing technology with the latest developments in tissue engineering, is a promising tool for engineering lab-scale tissues and organs for drug screening, pathological modeling, and transplantation. The technology has been proven to be reliable, high-throughput, and capable of printing complex physiological structures at relevant scales. Commercially available 3D extrusion bioprinters can manipulate a broad range of soft materials with sub-millimeter resolution. However, these bioprinters are expensive and typically contain proprietary software, impeding the customization of bioprinters to lab-specific applications. In response, researchers have recently manufactured and published open-source 3D extrusion bioprinters converted from thermoplastic printers. This review compares and evaluates currently available open-source 3D extrusion bioprinters, including their total cost, features, and necessary technical experience to fabricate in most academic labs. Current open-source slicing software is detailed, and guidelines are offered to ensure this technology continues contributing to the democratization of additive manufacturing technology. These comparisons and recommendations will allow researchers to choose an open-source printer that best suits their laboratory's 3D bioprinting needs and will highlight the need to iterate and improve published designs.
Keywords: Bioprinting; Open-source; Extrusion; Hydrogels; Bioink

Zhenlin Chen, Roujia Zhong, Wennan Long, Haoyu Tang, Anjing Wang, Zemin Liu, Xuelin Yang, Bo Ren, James Littlefield, Sanmi Koyejo, Mohammad S. Masnadi, Adam R. Brandt,
Advancing oil and gas emissions assessment through large language model data extraction,
Energy and AI,
Volume 20,
2025,
100481,
ISSN 2666-5468,
https://doi.org/10.1016/j.egyai.2025.100481.
(https://www.sciencedirect.com/science/article/pii/S2666546825000138)
Abstract: The oil and gas industry strives to improve environmental stewardship and reduce its carbon footprint, but lacks comprehensive global operational data for accurate environmental assessment and decision-making. This challenge is compounded by dispersed information sources and the high costs of accessing proprietary databases. This paper presents an innovative framework using Large Language Models (LLMs) – specifically GPT-4 and GPT-4o – to extract critical oil and gas asset information from diverse literature sources. Our framework employs iterative comparisons between GPT-4’s output and a dataset of 129 ground truth documents labeled by domain experts. Through 11 training and testing iterations, we fine-tuned prompts to optimize information extraction. The evaluation process assessed performance using true positive rate, precision, and F1 score metrics. The framework achieved strong results, with a true positive rate of 83.74% and an F1 score of 78.16% on the testing dataset. The system demonstrated remarkable efficiency, processing 32 documents in 61.41 min with GPT-4o, averaging 7.09 s per extraction - a substantial improvement over the manual method. Cost-effectiveness was also achieved, with GPT-4o reducing extraction costs by a factor of 10 compared to GPT-4. This research has significant implications for the oil and gas industry. By creating an organized, transparent, and accessible database, we aim to democratize access to critical information. The framework supports more accurate climate modeling efforts, enhances decision-making processes for operations and investments, and contributes to the sector’s ability to meet environmental commitments. These improvements particularly impact emissions reduction and energy transition strategies, potentially transforming how data is extracted and utilized in this field and beyond.
Keywords: Artificial intelligence; Large language models; Carbon intensity; Supervised learning; Oil and gas field; Greenhouse gas emissions

Larissa da Silva Marioni, Ana Rincon-Aznar, Francesco Venturini,
Productivity performance, distance to frontier and AI innovation: Firm-level evidence from Europe,
Journal of Economic Behavior & Organization,
Volume 228,
2024,
106762,
ISSN 0167-2681,
https://doi.org/10.1016/j.jebo.2024.106762.
(https://www.sciencedirect.com/science/article/pii/S0167268124003767)
Abstract: Using firm-level data from 15 European countries between 2011 and 2019, this paper examines the productivity effect associated with the development of Artificial Intelligence (AI), measured by patenting success in AI fields. By making advances in AI and expanding on their knowledge base, companies can optimise production tasks, and improve resource utilisation, ultimately leading to higher levels of efficiency. To investigate this, we develop a two-fold panel regression analysis estimated within a Difference-in-Differences (DiD) framework. First, we investigate whether firms that engage in AI innovation experience a productivity boost after developing the new technology, compared to similar firms which do not undertake AI innovation. To analyse this, we employ a novel event-analysis methodology that quantifies the effect of the treatment (AI innovation) on firm performance (productivity) using a Local Projections approach within the DiD setting. Second, we utilise a Distance-to-Frontier (DTF) regression framework in order to examine whether the productivity premium of AI is associated with a firm’s ability to absorb knowledge and learn from the technologies developed by market leaders. Our findings reveal that the productivity gains directly associated with AI are statistically significant and quantitatively important, ranging between 6.2 and 17% in the event analysis, and between 2.1 and 6% in the DTF framework. We also provide some evidence that the productivity benefits of AI might be greater for those firms further away from the frontier (between 0.3 and 0.7%). Our research demonstrates that Artificial Intelligence can play a crucial role in enhancing firm productivity in Europe, a result that is evident even in these early stages of the technology’s life cycle.
Keywords: Artificial Intelligence; Multi-Factor Productivity; European firms; Local Projections Difference-in-Differences; Distance-to-Frontier

Mohd Javaid, Abid Haleem, Ravi Pratap Singh, Anil Kumar Sinha,
Digital economy to improve the culture of industry 4.0: A study on features, implementation and challenges,
Green Technologies and Sustainability,
Volume 2, Issue 2,
2024,
100083,
ISSN 2949-7361,
https://doi.org/10.1016/j.grets.2024.100083.
(https://www.sciencedirect.com/science/article/pii/S2949736124000101)
Abstract: The digital economy refers to the economic activities that emerge from connecting individuals, businesses, devices, data, and operations through digital technology. It includes online transactions across multiple sectors and technologies, such as the Internet, mobile technology, big data, and information and communications technology. The digital economy differs from a traditional economy because it relies on digital technology, online transactions, and its transformative effect on traditional industries Digital innovations such as the Internet of Things (IoT), Artificial Intelligence (AI), Virtual Reality, Blockchain, and autonomous vehicles all play a part in creating a digital economy. For this study, various papers on ”Digital Economy” and ”Industry 4.0” are identified from Scopus, Google Scholar and other research platforms and further studied briefly. This review paper has been developed after studying the digital economy and its needs in the Industry 4.0 Environment. The defining trends, key enablers, features and challenges associated with the digital economy towards Industry 4.0 are discussed briefly. Finally, the paper identifies and discusses the significant requirements of Industry 4.0 fulfilled through the digital economy. Today, customers are becoming aware of goods and services online and are turning to the industry for long-term solutions by deploying digital technologies. The digital economy is built on hyper connectivity, the growing interconnectedness of individuals, organisations, and machines due to the Internet, mobile technologies, and the IoT. Industry 4.0 technologies are automation, data exchange, cloud computing, robotics, big data, AI, the IoT, and other technological trends are all part of the industrial sector’s digital transformation, which aims to achieve industrial objectives and intelligent manufacturing practices that engage with customers, emerging technologies, and innovation. The economy is becoming more digital, changing how products and services are provided and consumed. A new road map is being provided by Industry 4.0 services to help many industries adapt their conventional methods and support the new revolution. In the digital economy, scaled-up, integrated ecosystems that leverage software platforms to generate value, build resilience, and stimulate innovation via networked goods, assets, people, and processes rapidly replace old, linear value chains with partner participation.
Keywords: Digital economy; Industry 4.0; Enablers; Feature; Technologies

Pia Hurmelinna-Laukkanen, Jialei Yang,
Distinguishing between appropriability and appropriation: A systematic review and a renewed conceptual framing,
Research Policy,
Volume 51, Issue 1,
2022,
104417,
ISSN 0048-7333,
https://doi.org/10.1016/j.respol.2021.104417.
(https://www.sciencedirect.com/science/article/pii/S0048733321002122)
Abstract: This study systematically reviews 200 articles published over the past three decades to reveal how appropriability and appropriation have been explained and how those perspectives resonate with developments in the innovation environment. Our results show that despite the extensive stream of literature, little effort has been made to systematically advance theory on appropriability and appropriation. Based on and extending prior literature, we propose a conceptual framing that distinguishes appropriability and appropriation, and that explains how innovating organizations build their readiness to benefit from innovation and how they realize that potential. We outline appropriability as the potential to benefit from an innovation, which accrues through instruments of appropriability: isolating appropriability mechanisms and complementary assets; and appropriation as the realization of that potential, which manifests in private and social benefits when the instruments are employed in processes for exclusion, leverage, or disclosure. We highlight the strategic importance of aligning these elements and appropriability conditions in realizing appropriation outcomes. The paper closes with a discussion on the framework's applications and relevant future research avenues.
Keywords: Appropriability; Appropriation; Innovation; Systematic literature review

P. Aberna, L. Agilandeeswari,
PoWBWM: Proof of work consensus cryptographic blockchain-based adaptive watermarking system for tamper detection applications,
Alexandria Engineering Journal,
Volume 112,
2025,
Pages 510-537,
ISSN 1110-0168,
https://doi.org/10.1016/j.aej.2024.10.016.
(https://www.sciencedirect.com/science/article/pii/S1110016824011694)
Abstract: Image tamper detection is a challenging area in multimedia research. The advances in photography technology have made it possible to capture real-time high-dynamic-range (HDR) images through an iPhone or an Android device, which highlights the need for rigorous research on HDR images for tamper detection, and localization. The algorithms built for standard images may affect the watermark visibility when it is applied to HDR images as this produces high perceptual variations in the image compared to the original. To tackle this problem, we presented a Proof of Work consensus blockchain watermarking scheme combined with a convolution attention model (PoWBWM) system for tamper detection and localization. The system utilizes a Convolution Attention model (CoAtNet) to generate robust watermarks. A quaternion graph-based transform (QGBT) for embedding, ensuring imperceptibility and robustness. A fuzzy inference system optimizes embedding regions and factors based on human visual system characteristics. The system's security is enhanced through blockchain's proof-of-work (consensus) mechanism, providing a semi-blind watermarking scheme that authenticates ownership and detects tampering efficiently. The security is ensured only when the embedded hash key is authentic with its previous block to proceed further extraction process. The proposed algorithm's performance is evaluated in terms of its visibility by Peak-Signal-to-Noise-Ratio (PSNR), Structural Similarity Index (SSIM), and the perceptual quality of an HDR image is additionally measured by the Visual Dynamic Predictor (VDP) metric. On the other hand, the robustness performance is measured by Normalized Correlation Coefficient (NCC) and Bit Error Rate (BER). The experimental results for CASIA images achieved the highest PSNR value of 63.84 dB, and the SSIM value of 1.000, whereas the maximum VDP value obtained for HDR images is 98.02. In comparison with the existing system, the experimental findings of the suggested model show an effective tamper detection watermarking system as well as a robust against both intentional and unintentional attacks with an average NCC value of 0.98.
Keywords: Convolution attention model; Fuzzy inference system; High dynamic range image (HDR); Proof of work consensus blockchain; Quaternion graph-based transform (QGBT)

Xiaoyu Zhang, Chao Chen, Yi Xie, Xiaofeng Chen, Jun Zhang, Yang Xiang,
A survey on privacy inference attacks and defenses in cloud-based Deep Neural Network,
Computer Standards & Interfaces,
Volume 83,
2023,
103672,
ISSN 0920-5489,
https://doi.org/10.1016/j.csi.2022.103672.
(https://www.sciencedirect.com/science/article/pii/S0920548922000435)
Abstract: Deep Neural Network (DNN), one of the most powerful machine learning algorithms, is increasingly leveraged to overcome the bottleneck of effectively exploring and analyzing massive data to boost advanced scientific development. It is not a surprise that cloud computing providers offer the cloud-based DNN as an out-of-the-box service. Though there are some benefits from the cloud-based DNN, the interaction mechanism among two or multiple entities in the cloud inevitably induces new privacy risks. This survey presents the most recent findings of privacy attacks and defenses appeared in cloud-based neural network services. We systematically and thoroughly review privacy attacks and defenses in the pipeline of cloud-based DNN service, i.e., data manipulation, training, and prediction. In particular, a new theory, called cloud-based ML privacy game, is extracted from the recently published literature to provide a deep understanding of state-of-the-art research. Finally, the challenges and future work are presented to help researchers to continue to push forward the competitions between privacy attackers and defenders.
Keywords: Privacy inference attack; Privacy defense; Deep Neural Network; Cloud computing

Seema Yadav, Abhishek Singh, Rishika Singhal, Jagat Pal Yadav,
Revolutionizing drug discovery: The impact of artificial intelligence on advancements in pharmacology and the pharmaceutical industry,
Intelligent Pharmacy,
Volume 2, Issue 3,
2024,
Pages 367-380,
ISSN 2949-866X,
https://doi.org/10.1016/j.ipha.2024.02.009.
(https://www.sciencedirect.com/science/article/pii/S2949866X24000327)
Abstract: To create novel treatments and treat complex diseases, the pharmaceutical sector is essential. Drug discovery, however, is a time-consuming, pricey, and dangerous endeavor. Artificial intelligence (AI) has become a potent instrument that has transformed several industries, including healthcare, in recent years. This summary gives a general overview of how AI is expediting the creation of novel medicines, revolutionizing the pharmaceutical sector, and enabling drug discovery. The pharmaceutical sector is experiencing a drug discovery revolution because of AI. The drug discovery process is changing at different phases because of AI approaches like machine learning and deep learning. This abstract demonstrates how AI facilitates drug development through target identification, lead compound optimization, drug design, drug repurposing, and clinical trial enhancement. AI integration has the potential to hasten the creation of novel treatments, save costs, and improve patient outcomes. To fully realize the potential of AI in pharmaceutical research and development, issues relating to data accessibility, algorithm interpretability, and laws must be resolved.
Keywords: Artificial intelligence; AI pharmacology; AI in drug discovery; Medical diagnosis; Clinical trials

Saikat Banerjee,
CEO-board directional age difference and R&D of firms: Examining the moderation effects of strategic orientation,
Acta Psychologica,
Volume 254,
2025,
104815,
ISSN 0001-6918,
https://doi.org/10.1016/j.actpsy.2025.104815.
(https://www.sciencedirect.com/science/article/pii/S0001691825001283)
Abstract: This study explores the influence of CEO-board age differences on a firm's R&D intensity through the lens of the Knowledge-Based View, considering how strategic orientations such as digital, entrepreneurial, and long-term focus moderate this relationship. Drawing on the KBV, the research posits that age diversity between CEOs and board members enhances the firm's knowledge base by combining diverse experiences, insights, and cognitive styles, thereby fostering innovation. Using data from 309 Indian firms listed on the NSE 500 index between 2007 and 2016, the findings demonstrate that a digital orientation strengthens the positive impact of CEO-board age differences on R&D intensity by facilitating knowledge creation and sharing. Conversely, an entrepreneurial orientation may weaken this relationship by focusing more on immediate market opportunities than on sustained knowledge development. A long-term orientation further amplifies the positive linkage by aligning diverse leadership knowledge with sustained innovation objectives. This study contributes to the strategic management literature by clarifying how leadership demographic diversity, viewed through a knowledge-based perspective, influences a firm's ability to generate and leverage knowledge for innovation, thereby optimizing R&D outcomes.
Keywords: R&d; CEO; Knowledge based view; Upper echelon theory; Strategic orientation; Innovation

Mengshu Hao, Jieying Hong, Yining Zhang,
Disrupting political ties, enhancing transparency: China's anti-corruption campaign and corporate R&D disclosure,
International Review of Financial Analysis,
2025,
104160,
ISSN 1057-5219,
https://doi.org/10.1016/j.irfa.2025.104160.
(https://www.sciencedirect.com/science/article/pii/S1057521925002479)
Abstract: This paper examines the impact of China's anti-corruption campaign on firms' R&D disclosure practices. Utilizing a novel measure of R&D disclosure transparency, constructed via the Latent Dirichlet Allocation (LDA) approach applied to question-and-answer texts from Earnings Communication Conferences (ECCs), we find that firms with high levels of corruption prior to the campaign significantly increase the transparency of their R&D disclosures following its implementation. These findings remain robust across a range of robustness and endogeneity tests. Further analysis reveals that firms receiving greater R&D subsidies or benefiting from lower debt costs demonstrate more pronounced improvements in R&D disclosure transparency. Moreover, firms exhibiting larger increases in disclosure transparency secure higher levels of R&D subsidies and long-term loans post-campaign. These results suggest that the enhanced R&D disclosure likely represents a strategic response by firms to sustain government support and obtain favorable financing conditions amid weakened political connections. Thus, our study illuminates a novel role for R&D disclosure in enabling firms to adapt to the loss of political ties and highlights an unintended benefit of government anti-corruption efforts in enhancing corporate information transparency.
Keywords: Anti-corruption campaign; R&D disclosure transparency; Political connections; Topic modeling

Anna Melman, Oleg Evsutin,
Methods for countering attacks on image watermarking schemes: Overview,
Journal of Visual Communication and Image Representation,
Volume 99,
2024,
104073,
ISSN 1047-3203,
https://doi.org/10.1016/j.jvcir.2024.104073.
(https://www.sciencedirect.com/science/article/pii/S1047320324000282)
Abstract: Image watermarking is an effective and promising technology. Robust watermarks that are resistant to various attacks allow authors and owners of digital images to protect their rights to digital content, control its distribution and confirm its authenticity. Most of the modern algorithms for robust image watermarking aim to achieve resistance to a large number of different attacks. However, some authors develop algorithms designed to counter targeted attacks. The study of such schemes allows developers of watermarking algorithms to evaluate special means of counteracting various attacks, and then use them to create new robust schemes, both targeted and universal ones. In this paper, we present an overview of robust image watermarking schemes in terms of countering targeted attacks. We review the state-of-the-art in the field of attacking robust watermarks and propose a four-level classification of attacks that includes different levels of attack implementation, including an attacker’s intent, characteristics of actions, the main target and an attack type. The proposed classification considers a watermark as an object of attack and summarizes various characteristics of attacks in a hierarchical manner. We analyze the means of countering common attacks such as image processing attacks, geometric attacks, print-scan and screen capture attacks, collusion attacks, and ambiguity attacks. Based on the results of our review, we highlight the most common methods of countering attacks and formulate promising areas of research in the field of methods for improving security of embedding schemes.
Keywords: Digital images; Watermarking; Robustness; Removal attacks; Forgery attacks

Harine Rajashree R, Sundarakantham K, Sivasankar E, Mercy Shalinie S,
A hybrid deep learning framework for privacy preservation in edge computing,
Computers & Security,
Volume 129,
2023,
103209,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103209.
(https://www.sciencedirect.com/science/article/pii/S0167404823001190)
Abstract: The number of connected devices in our world is continuously increasing at a rapid rate. The Internet of Things(IoT) civilization has resulted in the generation of enormous amounts of data. Analytics on this data pays off in various sectors like health care, manufacturing, and transportation. However, the data generated in the IoT environment is often sensitive, and hence, the need to address the privacy concerns of the data owners. Existing approaches incur a huge computation cost and there is also a gap between privacy preservation and data utility. In this work, a genetic algorithm is coupled with a deep learning network based on adversarial training to build a utility-privacy balanced, low computation solution. The proposal aims to prevent inference of implicit privacy labels present in the data while maintaining data utility. The first part of the proposed work leverages an optimized encoder architecture to learn latent space representation of the input and the second part is the incorporation of adversary for training the framework to prevent unintended sensitive inference. Both parts are governed by a genetic algorithm to output a fitting encoder. Numerical results carried on a benchmark dataset exhibit the capability to protect sensitive data by keeping the accuracy level of the adversary within 23%, and producing a maximum inference accuracy of 95% for the intended task.
Keywords: Internet of things; Privacy preservation; Evolutionary algorithm; Adversarial training; Deep learning

Natali Helberger,
FutureNewsCorp, or how the AI Act changed the future of news,
Computer Law & Security Review,
Volume 52,
2024,
105915,
ISSN 2212-473X,
https://doi.org/10.1016/j.clsr.2023.105915.
(https://www.sciencedirect.com/science/article/pii/S0267364923001255)
Abstract: Inspired by scenario writing methods to foster discussion on the societal implications of technology and regulation, the paper develops a ‘legal fiction scenario’ to anticipate the impact of the proposed European AI Act and examine some of the regulatory choices made. The paper tells the story of FutureNewsCorp – the largest news media company in Europe in the year 2043. The story of FutureNewsCorp is used for a critical analysis of the most recent draft of the AI Act and here, in particular, of the role of standardisation bodies and the division of responsibility between providers of AI systems and their professional users. Using the scenario method, the paper demonstrates that regulations like the planned AI Act can result in a shift of the power to decide what responsible use of AI is - from regulators and editors to technology developers and standardisation bodies - and that in doing so it may contribute to changing the structure and workings of an entire sector.
Keywords: AI Regulation; journalistic AI; standardisation; future scenario writing method; values; legal responsibility

Soumia Zohra El Mestari, Gabriele Lenzini, Huseyin Demirci,
Preserving data privacy in machine learning systems,
Computers & Security,
Volume 137,
2024,
103605,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103605.
(https://www.sciencedirect.com/science/article/pii/S0167404823005151)
Abstract: The wide adoption of Machine Learning to solve a large set of real-life problems came with the need to collect and process large volumes of data, some of which are considered personal and sensitive, raising serious concerns about data protection. Privacy-enhancing technologies (PETs) are often indicated as a solution to protect personal data and to achieve a general trustworthiness as required by current EU regulations on data protection and AI. However, an off-the-shelf application of PETs is insufficient to ensure a high-quality of data protection, which one needs to understand. This work systematically discusses the risks against data protection in modern Machine Learning systems taking the original perspective of the data owners, who are those who hold the various data sets, data models, or both, throughout the machine learning life cycle and considering the different Machine Learning architectures. It argues that the origin of the threats, the risks against the data, and the level of protection offered by PETs depend on the data processing phase, the role of the parties involved, and the architecture where the machine learning systems are deployed. By offering a framework in which to discuss privacy and confidentiality risks for data owners and by identifying and assessing privacy-preserving countermeasures for machine learning, this work could facilitate the discussion about compliance with EU regulations and directives. We discuss current challenges and research questions that are still unsolved in the field. In this respect, this paper provides researchers and developers working on machine learning with a comprehensive body of knowledge to let them advance in the science of data protection in machine learning field as well as in closely related fields such as Artificial Intelligence.
Keywords: Privacy enhancing technologies; Trustworthy machine learning; Machine learning; Differential privacy; Homomorphic encryption; Functional encryption; Secure multiparty computation; Privacy threats

Lu Wei, Guowen Li, Xiaoqian Zhu, Xiaolei Sun, Jianping Li,
Developing a hierarchical system for energy corporate risk factors based on textual risk disclosures,
Energy Economics,
Volume 80,
2019,
Pages 452-460,
ISSN 0140-9883,
https://doi.org/10.1016/j.eneco.2019.01.020.
(https://www.sciencedirect.com/science/article/pii/S0140988319300350)
Abstract: Selecting risk factors is essential for measuring energy corporate risk. However, the comprehensive identification of energy corporate risk factors is still a difficult issue. This paper innovatively uses the text mining approach to comprehensively identify energy corporate risk factors from textual risk disclosures reported in financial statements. Based on 131,755 risk factor headings from 3707 Form 10-K filings from 840 U.S. energy corporations over the period 2010–2016, 66 types of risk factors that affect energy corporate risks are identified. Furthermore, we develop a hierarchical system for 66 energy corporate risk factors by dividing energy corporations into nine subsectors. Thus, the hierarchical energy corporate risk factor system provides fundamental support for further energy corporate risk measurement. Researchers can comprehensively and effectively select risk factors in measuring risks of the entire energy industry or each of nine energy subsectors.
Keywords: Risk management; Energy industry; Risk factor; Text mining; Form 10-K

M. Smits, N. Back, W. Ebbers,
Responsible design and implementation of technologies for the prevention of infectious diseases: towards a values-based assessment framework for the Dutch government,
Public Health,
Volume 222,
2023,
Pages 29-36,
ISSN 0033-3506,
https://doi.org/10.1016/j.puhe.2023.06.027.
(https://www.sciencedirect.com/science/article/pii/S0033350623002172)
Abstract: Objectives
The Dutch government implemented the apps ‘CoronaMelder’ and ‘CoronaCheck’ to prevent the transmission of SARS-CoV-2. They faced many questions on how to responsibly implement such technologies. Here, we aim to develop an assessment framework to support the Dutch national government with the responsible design and implementation of technologies for the prevention of future infectious diseases.
Study design
Three-stage web-based Delphi process.
Methods
The assessment framework was developed through two research phases. During the Initial Design phase, a conceptual version of the assessment framework was developed through a scoping review and semistructured interviews with a scientific board. The Consensus phase involved a three-stage web-based Delphi process with an expert community.
Results
The final assessment framework consists of five development phases, 10 values, and a total of 152 questions.
Conclusions
Technology assessment frameworks help policymakers to make informed decisions and contribute to the responsible implementation of technologies in society. The framework is now available for the Dutch government and other stakeholders to use in future pandemics. We discuss the possibilities of using the framework transnationally.
Keywords: Assessment framework; Contact tracing; COVID-19; Technologies; Values

Manika Nanda, Mala Saraswat, Pankaj Kumar Sharma,
Enhancing cybersecurity: A review and comparative analysis of convolutional neural network approaches for detecting URL-based phishing attacks,
e-Prime - Advances in Electrical Engineering, Electronics and Energy,
Volume 8,
2024,
100533,
ISSN 2772-6711,
https://doi.org/10.1016/j.prime.2024.100533.
(https://www.sciencedirect.com/science/article/pii/S2772671124001153)
Abstract: Phishing attempts to mimic the official websites of businesses, including banks, e-commerce, government offices, and financial institutions. Phishing websites aim to collect and retrieve sensitive data from users, including passwords, credit card numbers, email addresses, personal information, and so on. The growing frequency of phishing attacks has prompted the development of numerous anti-phishing technologies. Because machine learning (ML) techniques perform better in categorization problems, they are used extensively. But the most crucial features are not extracted by the algorithms in use today, which could result in a false categorization. In addition, the complex algorithms contribute to the long reaction time. To solve these issues, this study suggests using a Bidirectional Long Short-Term Memory-based Gated Highway Attention Block Convolutional Neural Network (BiLSTM-GHA-CNN) to detect phishing URLs.
Keywords: URL; Phishing; Features; Neural network; Machine learning; Deep learning; CNN; BiLSTM; APWG

Jieshu Wang, José Lobo, Shade T. Shutters, Deborah Strumsky,
Fueling a net-zero future: The influence of government-funded research on climate change mitigation inventions,
Environmental Innovation and Societal Transitions,
Volume 51,
2024,
100836,
ISSN 2210-4224,
https://doi.org/10.1016/j.eist.2024.100836.
(https://www.sciencedirect.com/science/article/pii/S2210422424000273)
Abstract: This study examines the pace and content of Climate Change Mitigation Technology (CCMT) inventions, focusing on the influence of government-funded research on patent characteristics. Utilizing data from the USPTO, we analyze the trends in CCMT patenting from 1988 to 2017 and reveal a significant increase in CCMT inventions. However, patents in hydrogen technology and Carbon Capture and Storage (CCS) are comparatively low, suggesting these fields are still in the early development stages. CCMT inventions rely heavily on government-funded research, particularly in CCS and hydrogen technology. CCMT inventions relying on government research are more complex and generate larger and more pervasive knowledge spillovers than their counterparts. However, they are less likely to be novel and tend to consolidate rather than destabilize existing technologies. Interestingly, the effect of government research reducing the likelihood of novelty is only observed in CCMT inventions and does not extend to utility patents. These findings highlight the role of government-funded research in facilitating high-quality CCMT inventions through knowledge spillovers. Our study underscores the importance of sustained and targeted public investment in CCMT R&D.
Keywords: Environmental inventions; Patent data; Climate change mitigation technology; Net-zero emission; Novelty; Knowledge recombination; Government-funded research

Melkamu Mersha, Khang Lam, Joseph Wood, Ali K. AlShami, Jugal Kalita,
Explainable artificial intelligence: A survey of needs, techniques, applications, and future direction,
Neurocomputing,
Volume 599,
2024,
128111,
ISSN 0925-2312,
https://doi.org/10.1016/j.neucom.2024.128111.
(https://www.sciencedirect.com/science/article/pii/S0925231224008828)
Abstract: Artificial intelligence models encounter significant challenges due to their black-box nature, particularly in safety-critical domains such as healthcare, finance, and autonomous vehicles. Explainable Artificial Intelligence (XAI) addresses these challenges by providing explanations for how these models make decisions and predictions, ensuring transparency, accountability, and fairness. Existing studies have examined the fundamental concepts of XAI, its general principles, and the scope of XAI techniques. However, there remains a gap in the literature as there are no comprehensive reviews that delve into the detailed mathematical representations, design methodologies of XAI models, and other associated aspects. This paper provides a comprehensive literature review encompassing common terminologies and definitions, the need for XAI, beneficiaries of XAI, a taxonomy of XAI methods, and the application of XAI methods in different application areas. The survey is aimed at XAI researchers, XAI practitioners, AI model developers, and XAI beneficiaries who are interested in enhancing the trustworthiness, transparency, accountability, and fairness of their AI models.
Keywords: XAI; Explainable artificial intelligence; Interpretable deep learning; Machine learning; Neural networks; Evaluation methods; Computer vision; Natural language processing; NLP; Transformers; Time series; Healthcare; Autonomous cars

Jawad Ahmad Dar, Kamal Kr Srivastava, Alok Mishra,
Lung anomaly detection from respiratory sound database (sound signals),
Computers in Biology and Medicine,
Volume 164,
2023,
107311,
ISSN 0010-4825,
https://doi.org/10.1016/j.compbiomed.2023.107311.
(https://www.sciencedirect.com/science/article/pii/S001048252300776X)
Abstract: Chest or upper body auscultation has long been considered a useful part of the physical examination going back to the time of Hippocrates. However, it did not become a prevalent practice until the invention of the stethoscope by Rene Laennec in 1816, which made the practice suitable and hygienic. Pulmonary disease is a kind of sickness that affects the lungs and various parts of the respiratory system. Lung diseases are the third largest cause of death in the world. According to the World Health Organization (WHO), the five major respiratory diseases, namely chronic obstructive pulmonary disease (COPD), tuberculosis, acute lower respiratory tract infection (LRTI), asthma, and lung cancer, cause the death of more than 3 million people each year worldwide. Respiratory sounds disclose significant information regarding the lungs of patients. Numerous methods are developed for analyzing the lung sounds. However, clinical approaches require qualified pulmonologists to diagnose such kind of signals appropriately and are also time consuming. Hence, an efficient Fractional Water Cycle Swarm Optimizer-based Deep Residual Network (Fr-WCSO-based DRN) is developed in this research for detecting the pulmonary abnormalities using respiratory sounds signals. The proposed Fr-WCSO is newly designed by the incorporation of Fractional Calculus (FC) and Water Cycle Swarm Optimizer WCSO. Meanwhile, WCSO is the combination of Water Cycle Algorithm (WCA) with Competitive Swarm Optimizer (CSO). The respiratory input sound signals are pre-processed and the important features needed for the further processing are effectively extracted. With the extracted features, data augmentation is carried out for minimizing the over fitting issues for improving the overall detection performance. Once data augmentation is done, feature selection is performed using proposed Fr-WCSO algorithm. Finally, pulmonary abnormality detection is performed using DRN where the training procedure of DRN is performed using the developed Fr-WCSO algorithm. The developed method achieved superior performance by considering the evaluation measures, namely True Positive Rate (TPR), True Negative Rate (TNR) and testing accuracy with the values of 0.963(96.3%), 0.932,(93.2%) and 0.948(94.8%), respectively.

Taha Loghmani-Khouzani, Victoria Dany, Nadine Seifert, Kaveh Madani, Edeltraud Guenther,
Can citizen science in water-related nature-based solutions deliver transformative participation in agri-food systems? A review,
Agricultural Systems,
Volume 220,
2024,
104052,
ISSN 0308-521X,
https://doi.org/10.1016/j.agsy.2024.104052.
(https://www.sciencedirect.com/science/article/pii/S0308521X24002026)
Abstract: CONTEXT
Highly water-dependent agri-food systems are impacted by external shocks, revealing their vulnerabilities and stressing the need to transform them towards increased sustainability and resilience. Various disciplines and scholars highlight the role of Nature-based Solutions (NbS) in addressing societal challenges while creating sustainable and resilient contexts.
OBJECTIVE
In steering transformative processes, participation is vital as a governance variable. However, motivating stakeholders' engagement with NbS uptake in decision-making requires evidence proving its potential to effectively address their direct and indirect environmental, societal, and economic concerns. This review systematically analyzed the potential of Citizen Science (CS) to overcome the barriers to NbS adoption and to drive stakeholders' attitudes towards sustainability.
METHODS
Focused on water as an essential for the agri-food system, 46 articles were systematically analyzed to examine water-related NbS, locate relevant drivers and barriers of NbS and ecosystem services, including associated advantages and disadvantages.
RESULTS AND CONCLUSIONS
Current research focuses heavily on NbS that benefit people, often overlooking the broader environmental benefits. While a trend towards using NbS for extreme weather events is evident, other critical areas like irrigation, groundwater management, food security, and water sanitation (WASH) need more attention. These elements are vital for sustainable and resilient agri-food systems. The literature identifies three central challenges to implementing NbS: knowledge gaps, participation, and funding. Novel participatory research methods like CS could prove pivotal in addressing NbS adoption barriers. CS in NbS can enhance engagement through improved and informed stakeholder participation while ensuring cost-effective and transparent processes of monitoring and evaluating potential success. Although NbS are gaining traction, scopes and scales of implementation must be more inclusive of various stakeholders and ecological services for the broader environment.
SIGNIFICANCE
CS in NbS can promote sustainable attitudes within the individuals of the society, and by design, NbS provides a sustainable context. Upon proper alignment, CS-NbS can increase the harmony between human and natural systems, shedding light on the Resource Nexus cycle and ultimately causing a visible change in behavior within the engaged stakeholder network. This approach values and amplifies notions of inclusiveness and the incorporation of local knowledge. Living labs and mixed-method research in CS-NbS can initiate inter and transdisciplinarity, collaborative learning, knowledge sharing, and enhanced participation in decision-making while unlocking the transformative capacities of NbS and strengthening the science-policy-society interface.
Keywords: Agri-food; Participation; Sustainability; Resilience; Transformation; Behavior

Veronica Scuotto, Theofilos Tzanidis, Alan Murray, Del Giudice Manlio,
Growth hacking: Leveraging hyper-scalability, hyper-specialization, and human-centric strategies for competitive advantage,
Journal of Business Research,
Volume 190,
2025,
115217,
ISSN 0148-2963,
https://doi.org/10.1016/j.jbusres.2025.115217.
(https://www.sciencedirect.com/science/article/pii/S0148296325000402)
Abstract: The Growth Hacking process brings new opportunities for business which are achieved through new strategies such as hyper-scalability, hyperspecialization and human- based competitive advantage. However this is a field which has not been deeply studied. In order to bridge this gap, by applying the lens of resource-based theory of the digital firm, this study is based on the findings from 20 semi-structured interviews with growth orientated entrepreneurs from a diverse range of sectors based in the UK. The study applies a content analysis and inductive approach and the results show that in the competitive marketplace new digital skills are needed to grow a successful business and these skills should be balanced with the introduction of any new technologies. The requirement for human skills and engagement is necessity for the development and leverage of unique capabilities and competencies to drive growth hacking strategies. As a result, these new strategies allow entrepreneurs to exploit new opportunities and overcome business challenges.
Keywords: Growth hacking; Digital strategy; Digital adoption; Digital capability; Hyper-scalability; Hyprspecialization; Human-based competitive advantage

Madita Amoneit, Dagmara Weckowska, Stephanie Spahr, Olaf Wagner, Mohsen Adeli, Inka Mai, Rainer Haag,
Green chemistry and responsible research and innovation: Moving beyond the 12 principles,
Journal of Cleaner Production,
Volume 484,
2024,
144011,
ISSN 0959-6526,
https://doi.org/10.1016/j.jclepro.2024.144011.
(https://www.sciencedirect.com/science/article/pii/S0959652624034607)
Abstract: Green chemistry focuses on designing products and processes that minimize hazardous substances and address pollution, resource depletion, and climate change. Green chemistry products and processes could contribute to the transition to circular economy and reaching Sustainable Development Goals. However, green chemistry philosophy offers none or little guidance on social, ethical, economic, or political aspects that are inherent to complex transition processes. Such broad and future-oriented considerations are at the heart of ‘Responsible Research and Innovation’ (RRI) approach but to date the ideas of RRI and green chemistry remain largely unconnected. This study aims to shed light on how RRI and green chemistry approaches can be combined. A refined responsible roadmapping method is proposed to help researchers to go beyond the 12 principles of green chemistry and develop inter- and transdisciplinary research agendas that address technical, environmental as well as social, ethical, economic and political considerations. The method was piloted in three research projects aspiring to develop sustainable and safe chemical processes and their applications. The study demonstrates that at the early stage of research planning, the responsible roadmapping method can facilitate the integration of RRI and green chemistry practices and the development of interdisciplinary research plans, which address technical, environmental, socio-ethical, economic and political dimensions. The implications of our study for future research on roadmapping methods as well as for policy and innovation practice are discussed.
Keywords: Circular economy; Green chemistry; Responsible research and innovation; Responsible roadmapping; SDGs

Niclas Ståhl, Lisa Weimann,
Identifying wetland areas in historical maps using deep convolutional neural networks,
Ecological Informatics,
Volume 68,
2022,
101557,
ISSN 1574-9541,
https://doi.org/10.1016/j.ecoinf.2022.101557.
(https://www.sciencedirect.com/science/article/pii/S1574954122000061)
Abstract: The local environment and land usages have changed a lot during the past one hundred years. Historical documents and materials are crucial in understanding and following these changes. Historical documents are, therefore, an important piece in the understanding of the impact and consequences of land usage change. This, in turn, is important in the search of restoration projects that can be conducted to turn and reduce harmful and unsustainable effects originating from changes in the land-usage. This work extracts information on the historical location and geographical distribution of wetlands, from hand-drawn maps. This is achieved by using deep learning (DL), and more specifically a convolutional neural network (CNN). The CNN model is trained on a manually pre-labelled dataset on historical wetlands in the area of Jönköping county in Sweden. These are all extracted from the historical map called “Generalstabskartan”. The presented CNN performs well and achieves a F1-score of 0.886 when evaluated using a 10-fold cross validation over the data. The trained models are additionally used to generate a GIS layer of the presumable historical geographical distribution of wetlands for the area that is depicted in the southern collection in Generalstabskartan, which covers the southern half of Sweden. This GIS layer is released as an open resource and can be freely used. To summarise, the presented results show that CNNs can be a useful tool in the extraction and digitalisation of non-textual information in historical documents, such as historical maps. A modern GIS material that can be used to further understand the past land-usage change is produced within this research. Previously, no material of this detail and extent have been available, due to the large effort needed to manually create such. However, with the presented resource better quantifications and estimations of historical wetlands that have been lost can be made.
Keywords: Analysis of historical maps; Convolutional neural networks; Wetland management; Wetland restoration

Mariangela Vecchiarini, Tatiana Somià,
Redefining entrepreneurship education in the age of artificial intelligence: An explorative analysis,
The International Journal of Management Education,
Volume 21, Issue 3,
2023,
100879,
ISSN 1472-8117,
https://doi.org/10.1016/j.ijme.2023.100879.
(https://www.sciencedirect.com/science/article/pii/S1472811723001179)
Abstract: AI-powered chatbots, such as ChatGPT, have gained significant attention in the education field due to recent advancements and growing popularity. This article investigates the potential uses of ChatGPT in higher education, specifically within entrepreneurship courses, and explores the benefits and challenges associated with its implementation. To address the need for further research on the use of AI in business education, a survey was conducted among undergraduate students enrolled in entrepreneurship courses. The survey focused on students' awareness and usage of ChatGPT, perceived benefits and limitations, and integration strategies for this tool into entrepreneurship courses. As entrepreneurship education evolves alongside AI advancements, AI technologies like ChatGPT can play a transformative role in various activities, from idea generation, to crafting a business model, writing a business plan, or conducting customer interviews. The study's results indicate that ChatGPT has the potential to streamline processes, increase students' efficiency, and support certain types of creativity. The article also addresses concerns regarding ChatGPT accuracy and reliability, emphasizing the importance of using it critically. This research contributes to the understanding of how AI can enable entrepreneurship education and provides valuable insights for educators, students, and institutions seeking to leverage AI in the classroom.
Keywords: Artificial intelligence; ChatGPT; Entrepreneurship education

Ankit Yadav, Dinesh Kumar Vishwakarma,
Datasets, clues and state-of-the-arts for multimedia forensics: An extensive review,
Expert Systems with Applications,
Volume 249, Part C,
2024,
123756,
ISSN 0957-4174,
https://doi.org/10.1016/j.eswa.2024.123756.
(https://www.sciencedirect.com/science/article/pii/S0957417424006225)
Abstract: With the large chunks of social media data being created daily and the parallel rise of realistic multimedia tampering methods, detecting and localising tampering in images and videos has become essential. This survey focusses on approaches for tampering detection in multimedia data using deep learning models. Specifically, it presents a detailed analysis of publicly available benchmark datasets for malicious manipulation detection. It also offers a comprehensive list of tampering clues and commonly used deep learning architectures. Next, it discusses the current state-of-the-art tampering detection methods, categorizing them into meaningful types such as deepfake detection methods, splice tampering detection methods, copy-move tampering detection methods, etc. and discussing their strengths and weaknesses. Top results achieved on benchmark datasets, comparison of deep learning approaches against traditional methods and critical insights from the recent tampering detection methods are also discussed. Lastly, the research gaps, future direction and conclusion are discussed to provide an in-depth understanding of the tampering detection research arena.
Keywords: Tampering detection; Localization; Forgery; Manipulation; Deep learning; Convolutional neural networks

Sarina Aminizadeh, Arash Heidari, Shiva Toumaj, Mehdi Darbandi, Nima Jafari Navimipour, Mahsa Rezaei, Samira Talebi, Poupak Azad, Mehmet Unal,
The applications of machine learning techniques in medical data processing based on distributed computing and the Internet of Things,
Computer Methods and Programs in Biomedicine,
Volume 241,
2023,
107745,
ISSN 0169-2607,
https://doi.org/10.1016/j.cmpb.2023.107745.
(https://www.sciencedirect.com/science/article/pii/S016926072300411X)
Abstract: Medical data processing has grown into a prominent topic in the latest decades with the primary goal of maintaining patient data via new information technologies, including the Internet of Things (IoT) and sensor technologies, which generate patient indexes in hospital data networks. Innovations like distributed computing, Machine Learning (ML), blockchain, chatbots, wearables, and pattern recognition can adequately enable the collection and processing of medical data for decision-making in the healthcare era. Particularly, to assist experts in the disease diagnostic process, distributed computing is beneficial by digesting huge volumes of data swiftly and producing personalized smart suggestions. On the other side, the current globe is confronting an outbreak of COVID-19, so an early diagnosis technique is crucial to lowering the fatality rate. ML systems are beneficial in aiding radiologists in examining the incredible amount of medical images. Nevertheless, they demand a huge quantity of training data that must be unified for processing. Hence, developing Deep Learning (DL) confronts multiple issues, such as conventional data collection, quality assurance, knowledge exchange, privacy preservation, administrative laws, and ethical considerations. In this research, we intend to convey an inclusive analysis of the most recent studies in distributed computing platform applications based on five categorized platforms, including cloud computing, edge, fog, IoT, and hybrid platforms. So, we evaluated 27 articles regarding the usage of the proposed framework, deployed methods, and applications, noting the advantages, drawbacks, and the applied dataset and screening the security mechanism and the presence of the Transfer Learning (TL) method. As a result, it was proved that most recent research (about 43%) used the IoT platform as the environment for the proposed architecture, and most of the studies (about 46%) were done in 2021. In addition, the most popular utilized DL algorithm was the Convolutional Neural Network (CNN), with a percentage of 19.4%. Hence, despite how technology changes, delivering appropriate therapy for patients is the primary aim of healthcare-associated departments. Therefore, further studies are recommended to develop more functional architectures based on DL and distributed environments and better evaluate the present healthcare data analysis models.
Keywords: Medical data processing; Healthcare data analysis; Deep learning; Distributed computing

Hassan Khosravi, Paul Denny, Steven Moore, John Stamper,
Learnersourcing in the age of AI: Student, educator and machine partnerships for content creation,
Computers and Education: Artificial Intelligence,
Volume 5,
2023,
100151,
ISSN 2666-920X,
https://doi.org/10.1016/j.caeai.2023.100151.
(https://www.sciencedirect.com/science/article/pii/S2666920X23000309)
Abstract: Engaging students in creating novel content, also referred to as learnersourcing, is increasingly recognised as an effective approach to promoting higher-order learning, deeply engaging students with course material and developing large repositories of content suitable for personalised learning. Despite these benefits, some common concerns and criticisms are associated with learnersourcing (e.g., the quality of resources created by students, challenges in incentivising engagement and lack of availability of reliable learnersourcing systems), which have limited its adoption. This paper presents a framework that considers the existing learnersourcing literature, the latest insights from the learning sciences and advances in AI to offer promising future directions for developing learnersourcing systems. The framework is designed around important questions and human-AI partnerships relating to four key aspects: (1) creating novel content, (2) evaluating the quality of the created content, (3) utilising learnersourced contributions of students and (4) enabling instructors to support students in the learnersourcing process. We then present two comprehensive case studies that illustrate the application of the proposed framework in relation to two existing popular learnersourcing systems.
Keywords: Learnersourcing; Crowdsourcing in education; Student generating content; Human-AI partnership

Elissa Dickson, Nathan Clay,
"Eat up. Save Earth." Alternative proteins and the myth of inevitable sustainability,
Journal of Rural Studies,
Volume 112,
2024,
103447,
ISSN 0743-0167,
https://doi.org/10.1016/j.jrurstud.2024.103447.
(https://www.sciencedirect.com/science/article/pii/S0743016724002511)
Abstract: The emerging agri-food tech sector promises to solve myriad environmental problems. This article considers the sociotechnical imaginaries that animate these claims. We focus on plant-based meat and dairy substitutes, or 'alternative proteins' (APs). To examine how APs are constructed as environmental solutions, we analyzed marketing materials, sustainability reports, and interviews. Our study illustrates how environmental metrics (Life Cycle Assessments) and corporate marketing make environmental issues legible to agri-industrial logics by reducing them to a narrow, technical issue: inefficient livestock. To critique this problem closure, we develop the concept of inevitable sustainability–where the increased adoption of a technology is equated with the assured reduction of environmental harm. We caution that APs support a neoliberal model of environmental governance that propagates apolitical and deterritorialized solutions. To reflect on the limits of agri food tech environmental fixes, we discuss three myths surrounding inevitable sustainability. We outline this concept's applicability to similar instances of environmental solutionism in agri-food tech and beyond.
Keywords: Agri-food tech; Alternative protein; Climate change; Livestock; Sustainability; Technology

Namuk Ko, Byeongki Jeong, Janghyeok Yoon, Changho Son,
Patent-trademark linking framework for business competition analysis,
Computers in Industry,
Volume 122,
2020,
103242,
ISSN 0166-3615,
https://doi.org/10.1016/j.compind.2020.103242.
(https://www.sciencedirect.com/science/article/pii/S0166361519311169)
Abstract: A major concern of technology-based firms (TBFs) is gaining a competitive edge, for which TBFs develop technologies to embed in their products and services to differentiate themselves from their competitors. TBFs that share similar products or services must compete against each other, which means that business competition among TBFs should be conducted at the product and service levels. However, faced with challenges in obtaining information of the products and services for which TBFs apply their own technologies, previous studies have not thoroughly analyzed the business competition from the perspectives of products and services. Therefore, this study proposes a framework to better understand the business competition among TBFs by linking their business areas and technologies, which refer to products and services in their trademarks, and the technologies described in their patents, respectively. This framework provides the identification of technology-based business portfolios and an understanding of the business competition from both an overall business perspective and within specific areas, considering the technological capabilities and business willingness of the TBFs. This study academically contributes as the first study to conduct a business competition analysis at the product and service levels and industrially contributes by suggesting a systematic process that will help in understanding the rapidly evolving business competition environment.
Keywords: Technology-based firms; Business intelligence; Competitive information; Goods and services; Patent; Trademark

Abhishek Agnihotri, Narendra Kohli,
Challenges, opportunities, and advances related to COVID-19 classification based on deep learning,
Data Science and Management,
Volume 6, Issue 2,
2023,
Pages 98-109,
ISSN 2666-7649,
https://doi.org/10.1016/j.dsm.2023.03.005.
(https://www.sciencedirect.com/science/article/pii/S2666764923000188)
Abstract: The novel coronavirus disease, or COVID-19, is a hazardous disease. It is endangering the lives of many people living in more than two hundred countries. It directly affects the lungs. In general, two main imaging modalities, i.e., computed tomography (CT) and chest x-ray (CXR) are used to achieve a speedy and reliable medical diagnosis. Identifying the coronavirus in medical images is exceedingly difficult for diagnosis, assessment, and treatment. It is demanding, time-consuming, and subject to human mistakes. In biological disciplines, excellent performance can be achieved by employing artificial intelligence (AI) models. As a subfield of AI, deep learning (DL) networks have drawn considerable attention than standard machine learning (ML) methods. DL models automatically carry out all the steps of feature extraction, feature selection, and classification. This study has performed comprehensive analysis of coronavirus classification using CXR and CT imaging modalities using DL architectures. Additionally, we have discussed how transfer learning is helpful in this regard. Finally, the problem of designing and implementing a system using computer-aided diagnostic (CAD) to find COVID-19 using DL approaches highlighted a future research possibility.
Keywords: Classification; COVID-19; Coronavirus; Deep learning; CAD system

Josip Marić, Marco Opazo-Basáez, Božidar Vlačić, Marina Dabić,
Innovation management of three-dimensional printing (3DP) technology: Disclosing insights from existing literature and determining future research streams,
Technological Forecasting and Social Change,
Volume 193,
2023,
122605,
ISSN 0040-1625,
https://doi.org/10.1016/j.techfore.2023.122605.
(https://www.sciencedirect.com/science/article/pii/S0040162523002901)
Abstract: Three-dimensional printing (3DP) is a technological innovation that has been receiving an increased amount of attention – both in the media and among scholars – as a result of its profound implications for business, industry, and society. Although it has existed since the 1980s, literature reviews covering major aspects of 3DP technology through the lenses of business and management studies remain limiting with regards to their scope and insights. Through a systematic literature review of 192 manuscripts published in top-tier journals indexed in Scopus and Web of Science scholarly databases, this study combines the results of a Multiple Correspondence Analysis and a content analysis to holistically elaborate principal research themes, theoretical frameworks, and future research trends. Major research themes, summarized respectively as: industrial revolution; strategy; technology adoption and governance; performance; risk and uncertainty; human resources; innovation; and sustainability and circular economy, are closely analyzed, and research predictions are provided with regards to the topics of Industry 5.0, future of governance and 3DP adoption, operations performance and supply chain management, and sustainable development and circular economy. Theoretical contributions explore and consolidate the most relevant theoretical foundations of 3DP as a research field and offer guidelines for scholars to consider in future projects.
Keywords: 3D print; Additive manufacturing; Innovation management; Systematic literature review; Multi correspondence analysis

Guowei Jiang, Zhouyan He, Jiangtao Huang, Ting Luo, Haiyong Xu, Chongchong Jin,
RDD-net: Robust duplicated-diffusion watermarking based on deep network,
Journal of Visual Communication and Image Representation,
Volume 96,
2023,
103934,
ISSN 1047-3203,
https://doi.org/10.1016/j.jvcir.2023.103934.
(https://www.sciencedirect.com/science/article/pii/S1047320323001840)
Abstract: This paper proposes a novel robust duplicated-diffusion watermarking model based on deep network (RDD-net). RDD-net employs the encoder-noise-decoder structure for end-to-end training to obtain high image watermarking invisibility and robustness. Firstly, a duplicated-diffusion strategy is employed in the encoder to replicate the original watermark iteratively until all copies are diffused to the whole image so that the generalized ability in resisting various noises is obtained. Then, a channel connection technique is designed to extract inherent image features for fusing watermark for robustness by mining correlations of RGB three channels of the color image. Meanwhile, each channel is fused with watermark to increase robustness. Another attempt to improve the watermarking performance is the optimizer, which optimizes the watermark distribution by evaluating the similarities between the encoded image and the original image, as well as between the encoded image and the noised image. Our extensive experimental results demonstrate that the proposed RDD-net not only resists different noises, but also obtains better image quality and higher robustness than the existing watermarking models.
Keywords: Watermarking; Deep network; Robustness; RGB channels; Channel connection

Yifan Duan, Xiaojie Liu, Ran Liu, Xin Li, Hongwei Li, Hongyang Li, Yanqin Sun, Yujie Zhang, Qing Lv,
A novel anomaly detection and classification algorithm for application in tuyere images of blast furnace,
Engineering Applications of Artificial Intelligence,
Volume 139, Part A,
2025,
109558,
ISSN 0952-1976,
https://doi.org/10.1016/j.engappai.2024.109558.
(https://www.sciencedirect.com/science/article/pii/S0952197624017160)
Abstract: Traditional relying on manual experience to assess the tuyere status consumes significant human resources. In the era of intelligent blast furnaces and intensified smelting, this approach struggles to meet the demands for accuracy and real-time assessment, posing challenges to safety and efficiency of blast furnace production. Tuyere images exhibit high feature similarity, and the number of samples is often limited. Therefore, if a simple convolution operation is only used, it will be difficult to discern differences across various images. To address this challenge and cater to the requirements of intelligent tuyere status recognition across different steel enterprises, we designed a novel deep neural network algorithm called ES-SFRNet (Enhanced Sequential: Feature Fusion and Recognition Network), building upon our prior research. The algorithm concurrently modeled tuyere images alongside relevant time series data, comprising three components: Feature pre-extraction, Tuyere status recognition, and Generalization & Robustness. The first two modules focus on feature extraction and fusion of tuyere images, while leveraging edge detection information from the image, we developed a mathematical index Ar (Area Ratio) to serve as an auxiliary criterion for tuyere status recognition. Given the model's future scalability and multi-scenario application, the final module focuses on knowledge integration and parameter control. Test results reveal an overall accuracy rate of 99.3% for the ES-SFRNet algorithm, effectively capturing key parameters to facilitate on-site operations. In comparison to other mainstream object detection algorithms, our algorithm framework excels in tuyere image feature extraction and recognition, which can offer broad applications to Chinese blast furnace ironmaking industry.
Keywords: Tuyere image recognition; Feature extraction and fusion; Edge detection; Knowledge integration and control; Key parameters

Shuling Lu, Qijing Yang,
Price of going green: The employment effects of the environmental protection tax in China,
China Economic Review,
Volume 87,
2024,
102244,
ISSN 1043-951X,
https://doi.org/10.1016/j.chieco.2024.102244.
(https://www.sciencedirect.com/science/article/pii/S1043951X24001330)
Abstract: Compared with command-and-control regulations, it is less known about the labor market consequences of environmental taxes. This study examines the employment impact of the 2018 Environmental Protection Tax (EPT). Applying a triple-difference framework, we empirically establish the employment-suppressing consequence of EPT, which is primarily attributable to output reductions and green technological advances. Moreover, our analysis highlights a size-dependent strategy adopted by companies to navigate the escalating environmental costs: while small companies opt for production downsizing, larger counterparts tend to invest more in technical abatement initiatives. Heterogeneity analysis reveals that the unemployment effect is more pronounced in companies facing higher financial constraints and greater public environmental attention, with low-skilled workers bearing the brunt, albeit without significant wage inequality. Further, we find that government green subsidies can mute this job-reduction effect. Our study illuminates an unintended incidence of environmental policy costs on labor in China and underscores comprehensive policy evaluation.
Keywords: Environmental protection tax; Employment effects; Manufacturing company; China

Yu An, Haiwen Du, Siteng Ma, Yingjie Niu, Dairui Liu, Jing Wang, Yuhan Du, Conrad Childs, John Walsh, Ruihai Dong,
Current state and future directions for deep learning based automatic seismic fault interpretation: A systematic review,
Earth-Science Reviews,
Volume 243,
2023,
104509,
ISSN 0012-8252,
https://doi.org/10.1016/j.earscirev.2023.104509.
(https://www.sciencedirect.com/science/article/pii/S0012825223001988)
Abstract: Automated seismic fault interpretation has been an active area of research. Since 2018, Deep learning (DL) based seismic fault interpretation methods have emerged and shown promising results. However, to date, these methods have not been reasonably summarised, making it difficult for those involved to make sense of the current development process. To close this gap, we systematically reviewed the DL-based fault interpretation literature published between 2012 and 2022, and searched seven digital libraries. Fault interpretation has been considered an image-processing task using only convolutional neural networks (CNN)-based DL methods, and most of them have been trained in a supervised manner. U-Net and its variants designed for the image segmentation task are the most commonly used network structures. A total of 73 seismic datasets were summarised from the 56 articles included, of which only three field datasets and four synthetic datasets were publicly available benchmarks. The study reported benefits of using DL, such as its outstanding learning and generalisation capabilities or predicting faults in a fast, cheap and repeatable manner, which ultimately led to an increase in the acceptability of these methods and the potential to incorporate them into oil and industry workflows. However, we identified 12 challenges that hinder its integration into industrial workflows, including the most discussed lack of sufficient annotated data. We conclude with an in-depth discussion of current research trends and potential future research directions to promote research on less studied areas and collaboration between computer scientists and geoscientists.
Keywords: Systematic literature review; Deep learning; DL; Seismic fault interpretation; Artificial intelligence; Convolutional neural network

Anil Kumar Saini, Anshul Kumar Yadav,  Dhiraj,
A Comprehensive review on technological breakthroughs in precision agriculture: IoT and emerging data analytics,
European Journal of Agronomy,
Volume 163,
2025,
127440,
ISSN 1161-0301,
https://doi.org/10.1016/j.eja.2024.127440.
(https://www.sciencedirect.com/science/article/pii/S1161030124003617)
Abstract: Rapid population expansion has led to a corresponding rise in the demand for sustenance. Researchers have found that traditional agricultural practices are insufficient to meet the demands of commodities, and their inefficiency poses the most pressing obstacle to addressing the growing global food demand. Precision agriculture (PA) is an advanced hierarchy farming system supported by multidisciplinary technologies such as specialized sensors, communication protocols, algorithms, and management tools, helping mitigate the problems of conventional farming by ensuring maximum production and minimum wastage. Given the rapid evolution of the aforementioned multidisciplinary technologies, this review paper analyzed 24337 research documents from 1938 to April 2024 using bibliographical software from the Scopus dataset. Internet of Things (IoT), Agriculture Robots (AR), and Artificial Intelligence (AI) are currently driving ongoing research, with frequency occurrences of 12.245, 8.259, and 7.791, highlighting the trend towards interconnected farming systems and data-driven automated systems. Bibliographical evidence indicates the current utilization of AI, AR, and IoT for accurate assessments like crop yield prediction, disease and weed detection, and soil analysis. Additionally, China is the most productive country in terms of publication, while the United States leads in terms of patents. This review paper also explores emerging trends that could guide future research, including blockchain technology, big data analysis, computing paradigms, and drone technology. Subsequently, a PA framework has been suggested to facilitate innovation in this field, followed by the open issues, highlighting the ongoing concerns related to insufficient infrastructure, integration, cost, and security measures, with the aim to engage all stakeholders.
Keywords: Precision Agriculture; Internet of Things; Artificial Intelligence; Communication technology

Daniel P. Gross, Bhaven N. Sampat,
The Government Patent Register: A new resource for measuring U.S. government-funded patenting,
Research Policy,
Volume 54, Issue 1,
2025,
105142,
ISSN 0048-7333,
https://doi.org/10.1016/j.respol.2024.105142.
(https://www.sciencedirect.com/science/article/pii/S0048733324001914)
Abstract: We introduce new historical administrative data identifying U.S. government-funded patents since the early twentieth century. In addition to the funding agency, the data report whether the government has title to the patent (“title” patents) or funded a patent assigned to a private organization (“license” patents). The data include a large number of “license” patents that cannot be linked to government funding from patent text or other sources. Combining the historical data with modern administrative sources, we present a public, consolidated data series measuring U.S. government-funded patents — including funding agencies — through 2020, and we provide code to extend this series in the future. We use the data to document long-run patterns in U.S. government-funded patents and federal patent policy, propose ways in which these data can be used in future research, and discuss limitations of the data.
Keywords: Public R&D; Patents; Patent policy; Patent data

Yu He, Shanglin Lu, Ran Wei, Shixuan Wang,
Local media sentiment towards pollution and its effect on corporate green innovation,
International Review of Financial Analysis,
Volume 94,
2024,
103332,
ISSN 1057-5219,
https://doi.org/10.1016/j.irfa.2024.103332.
(https://www.sciencedirect.com/science/article/pii/S1057521924002643)
Abstract: This study examines the effect of local media sentiment on corporate green innovation based on a textual analysis of China's provincial official party newspapers from 2007 to 2018. The results show that the negative sentiment in official media positively influences firms' green innovation, measured by the number of green patents and green patent citations. This positive effect is more pronounced when firms have weaker internal or external governance structures, when the regional punitive measures are less stringent, or when the incentive measures are more complete, suggesting that official media plays a governance role in corporate green innovation. Further analysis shows that the negative sentiment from market-oriented media impedes green innovation and does not affect the relationship between official media sentiment and green innovation. Taken together, our findings reveal the real effects of local media negative sentiment on technological progress and pollution controls through its pressure on firms to engage in green innovation.
Keywords: Media sentiment; Green innovation; Environmental pollution; Corporate governance

Jeffery Cruz,
Equity, Diversity, and Inclusion and Critical Libraries: A Historical Evolution of Awareness and Informed Practice,
Editor(s): David Baker, Lucy Ellis,
Encyclopedia of Libraries, Librarianship, and Information Science (First Edition),
Academic Press,
2025,
Pages 25-35,
ISBN 9780323956901,
https://doi.org/10.1016/B978-0-323-95689-5.00150-4.
(https://www.sciencedirect.com/science/article/pii/B9780323956895001504)
Abstract: In principle, libraries have espoused the values of equity, diversity, and inclusion (EDI) as evidenced by the broad range of diversity initiatives, commitments, conferences and literature within the library and information studies sector. More recently, concepts of equity and inclusion have played a role in library diversity initiatives in addition to newer concepts such as critical librarianship and the decolonization, Indigenization and queering of libraries. Starting from affirmative action and anti-discrimination policies and legislation in the 1960s, this entry reviews the historical evolution of EDI awareness and informed practice in the US and Australia over the past 65 years.
Keywords: Affirmative action in libraries; Anti-discrimination in libraries; Critical librarianship; Decolonization in libraries; Diversity initiatives in libraries; Equal opportunity in libraries; Equity, diversity, and inclusion; Indigenization in libraries; Library and information services; Queering the library

Sangeeta Duhan, Preeti Gulia, Nasib Singh Gill, Piyush Kumar Shukla, Surbhi Bhatia Khan, Ahlam Almusharraf, Norah Alkhaldi,
Investigating attention mechanisms for plant disease identification in challenging environments,
Heliyon,
Volume 10, Issue 9,
2024,
e29802,
ISSN 2405-8440,
https://doi.org/10.1016/j.heliyon.2024.e29802.
(https://www.sciencedirect.com/science/article/pii/S240584402405833X)
Abstract: There is an increasing demand for efficient and precise plant disease detection methods that can quickly identify disease outbreaks. For this, researchers have developed various machine learning and image processing techniques. However, real-field images present challenges due to complex backgrounds, similarities between different disease symptoms, and the need to detect multiple diseases simultaneously. These obstacles hinder the development of a reliable classification model. The attention mechanisms emerge as a critical factor in enhancing the robustness of classification models by selectively focusing on relevant regions or features within infected regions in an image. This paper provides details about various types of attention mechanisms and explores the utilization of these techniques for the machine learning solutions created by researchers for image segmentation, feature extraction, object detection, and classification for efficient plant disease identification. Experiments are conducted on three models: MobileNetV2, EfficientNetV2, and ShuffleNetV2, to assess the effectiveness of attention modules. For this, Squeeze and Excitation layers, the Convolutional Block Attention Module, and transformer modules have been integrated into these models, and their performance has been evaluated using different metrics. The outcomes show that adding attention modules enhances the original models' functionality.
Keywords: Attention mechanism; Computer vision; Deep learning; Classification; Plant disease detection

John R. Craig, Rod W. Tataryn, Alberto M. Saibene,
The Future of Odontogenic Sinusitis,
Otolaryngologic Clinics of North America,
Volume 57, Issue 6,
2024,
Pages 1173-1181,
ISSN 0030-6665,
ISBN 9780443297885,
https://doi.org/10.1016/j.otc.2024.06.008.
(https://www.sciencedirect.com/science/article/pii/S0030666524000938)
Keywords: Odontogenic sinusitis; Multidisciplinary; Diagnostic criteria; Antibiotic stewardship; Coding; Research; Pediatrics; Patient selection

Jeewanthi Ukwaththa, Sumudu Herath, D.P.P. Meddage,
A review of machine learning (ML) and explainable artificial intelligence (XAI) methods in additive manufacturing (3D Printing),
Materials Today Communications,
Volume 41,
2024,
110294,
ISSN 2352-4928,
https://doi.org/10.1016/j.mtcomm.2024.110294.
(https://www.sciencedirect.com/science/article/pii/S235249282402275X)
Abstract: Additive Manufacturing (AM) (known as 3D printing) has modernised traditional manufacturing processes by enabling the layer-by-layer fabrication of complex geometries, along with advanced design capabilities, cost efficiency, and reduced production time. AM offers flexibility and customisation in product development, allowing for the deposition, solidification, or joining of materials based on computer-aided models. In recent years, the large-scale collection of AM-related data has facilitated the use of machine learning (ML) techniques to embed into AM processes and optimise quality. However, many advanced ML algorithms do not provide their underlying decision-making criteria, remaining as a black box. Alternatively, explainable artificial intelligence (XAI) methods have been employed to explain these black box models. Even though ML has been widely used in AM, the use of XAI in AM is still very limited. This paper provides a comprehensive review of the integration of ML and XAI (XAI for the first time) in AM processes, exploring current research progress and future prospects. The study outlines the various ML techniques and XAI applied in different domains of AM. Additionally, it examines ML and XAI applications across different AM technologies and life cycle stages, highlighting their functions in design optimisation, process monitoring, and sustainability analysis. Furthermore, the review discusses new developments, challenges, and future research directions in ML and XAI for AM, allowing for enhanced efficiency, innovation, and sustainability in AM processes.
Keywords: Additive manufacturing; 3D printing; Machine learning; Artificial intelligence; Metals; Materials

Yu Yan, Lei Ni, Lijun Sun, Ying Wang, Jianing Zhou,
Digital Twin Enabling Technologies for Advancing Road Engineering and Lifecycle Applications,
Engineering,
Volume 44,
2025,
Pages 184-206,
ISSN 2095-8099,
https://doi.org/10.1016/j.eng.2024.12.017.
(https://www.sciencedirect.com/science/article/pii/S2095809924007343)
Abstract: Road infrastructure is facing significant digitalization challenges within the context of new infrastructure construction in China and worldwide. Among the advanced digital technologies, digital twin (DT) has gained prominence across various engineering sectors, including the manufacturing and construction industries. Specifically, road engineering has demonstrated a growing interest in DT and has achieved promising results in DT-related applications over the past several years. This paper systematically introduces the development of DT and examines its current state in road engineering by reviewing research articles on DT-enabling technologies, such as model creation, condition sensing, data processing, and interaction, as well as its applications throughout the lifecycle of road infrastructure. The findings indicate that research has primarily focused on data perception and virtual model creation, while real-time data processing and interaction between physical and virtual models remain underexplored. DT in road engineering has been predominantly applied during the operation and maintenance phases, with limited attention given to the construction and demolition phases. Future efforts should focus on establishing uniform standards, developing innovative perception and data interaction techniques, optimizing development costs, and expanding the scope of lifecycle applications to facilitate the digital transformation of road engineering. This review provides a comprehensive overview of state-of-the-art advancements in this field and paves the way for leveraging DT in road infrastructure lifecycle management.
Keywords: Digital twin; Road infrastructure; Enabling technology; Life cycle

Lillian Boxman-Shabtai,
Reframing the popular: A new approach to parody,
Poetics,
Volume 67,
2018,
Pages 1-12,
ISSN 0304-422X,
https://doi.org/10.1016/j.poetic.2018.03.001.
(https://www.sciencedirect.com/science/article/pii/S0304422X17301560)
Abstract: The ubiquity of intertextuality in internet culture has ignited long-standing debates about the cultural significance of parody as a device of commentary and as civic speech. It also raises concerns about the legal implications of unprecedented uses of copyrighted material. This paper examines how YouTube videos, self-labeled by their creators as “parody”, reframe the meaning structures of copyrighted material. Focusing on representations of gender in the music industry, it probes 100 music video parodies through a qualitative textual analysis. The paper offers a typology of five interpretive configurations underscoring the relationships between originals and their renditions. While the majority of parodies did not convey the critical commentary that their label promised, most of them did aspire to transform the meaning of the music videos. The typology, which presents a discrepancy between textual and societal forms of critique, is discussed in relation to its contribution to broader evaluations of media audiences and user-generated-content.
Keywords: Copyright; Framing; Gender; Music; Parody; YouTube

Francis McKay, Darren Treanor, Nina Hallowell,
Inalienable data: Ethical imaginaries of de-identified health data ownership,
SSM - Qualitative Research in Health,
Volume 4,
2023,
100321,
ISSN 2667-3215,
https://doi.org/10.1016/j.ssmqr.2023.100321.
(https://www.sciencedirect.com/science/article/pii/S2667321523001051)
Abstract: Many legal, ethical, and regulatory frameworks allow de-identified health data to be shared for research without patients’ opt-in consent. However, there may be public concerns about this practice, as people may feel they should have some say in how such data is used. This paper introduces the concept of the “inalienability of de-identified data,” to describe a key assumption underlying that public concern and preference. The assumption, derived from ethnographic research with public and professional stakeholders in AI driven medical image analysis over the past two years, refers to a sense of felt ownership over de-identified health data, even where the subject has been obscured as referent and no clear legal rights of data ownership otherwise exist. The concept is important to medical ethics because it underpins public expectations regarding the rights people should have over the sharing of medical data (including expectations for consent). We note that where those expectations go counter to current legal and bioethical frameworks for de-identified data sharing, they provide a challenge for public support of big data and artificial intelligence driven health research.
Keywords: Artificial intelligence; Health data; Ownership; De-identification; Anonymity; Consent; Public involvement

Sergio España, Chris van der Maaten, Jens Gulden, Óscar Pastor,
Ethical reasoning methods for ICT: What they are and when to use them,
Data & Knowledge Engineering,
Volume 155,
2025,
102373,
ISSN 0169-023X,
https://doi.org/10.1016/j.datak.2024.102373.
(https://www.sciencedirect.com/science/article/pii/S0169023X24000971)
Abstract: Information and communication technology (ICT) brings about numerous advantages across various domains of our lives. However, alongside these benefits, there is a growing awareness of its potential negative ethical, social, and environmental impacts. Consequently, stakeholders ranging from conceptual modellers to policy makers often find themselves grappling with ethical considerations stemming from ICT engineering and usage. This paper presents a review of 10 ethical reasoning methods suitable for the ICT domain. We have employed a method engineering technique to author metamodels for the methods, which were subsequently subjected to validation by experts proficient in the respective methods. Following a situational method engineering approach, we have also characterised each ethical reasoning method and validated the characterisation with the experts. This has allowed us to develop a tool that helps select the method that is most suitable for a given ethical reasoning situation. Furthermore, we deliberate on the practical application of ethical reasoning methods within conceptual modelling contexts. We are confident that we have laid the groundwork for further research into ethical reasoning of ICT, with a specific emphasis on its role during conceptual modelling.
Keywords: Conceptual modelling; Ethics; Ethical reasoning; Sustainability assessment; Method engineering; Situational factors

Andreas Müller,
A tour d'horizon of de Casteljau's work,
Computer Aided Geometric Design,
Volume 113,
2024,
102366,
ISSN 0167-8396,
https://doi.org/10.1016/j.cagd.2024.102366.
(https://www.sciencedirect.com/science/article/pii/S0167839624001006)
Abstract: Whilst Paul de Casteljau is now famous for his fundamental algorithm of curve and surface approximation, little is known about his other findings. This article offers an insight into his results in geometry, algebra and number theory. Related to geometry, his classical algorithm is reviewed as an index reduction of a polar form. This idea is used to show de Casteljau's algebraic way of smoothing, which long went unnoticed. We will also see an analytic polar form and its use in finding the intersection of two curves. The article summarises unpublished material on metric geometry. It includes theoretical advances, e.g., the 14-point strophoid or a way to link Apollonian circles with confocal conics, and also practical applications such as a recurrence for conjugate mirrors in geometric optics. A view on regular polygons leads to an approximation of their diagonals by golden matrices, a generalisation of the golden ratio. Relevant algebraic findings include matrix quaternions (and anti-quaternions) and their link with Lorentz' equations. De Casteljau generalised the Euclidean algorithm and developed an automated method for approximating the roots of a class of polynomial equations. His contributions to number theory not only include aspects on the sum of four squares as in quaternions, but also a view on a particular sum of three cubes. After a review of a complete quadrilateral in a heptagon and its angles, the paper concludes with a summary of de Casteljau's key achievements. The article contains a comprehensive bibliography of de Casteljau's works, including previously unpublished material.
Keywords: de Casteljau algorithm; Blossoming and polar forms; Quasi-interpolation; Metric geometry; Geometric optics; Quaternions; Regular polygons; Generalised Euclidean algorithm; 14-point strophoid

Zixuan He, Guoheng Huang, Xiaochen Yuan, Guo Zhong, Chi-Man Pun, Yiwen Zeng,
Progressive normalizing flow with learnable spectrum transform for style transfer,
Knowledge-Based Systems,
Volume 284,
2024,
111277,
ISSN 0950-7051,
https://doi.org/10.1016/j.knosys.2023.111277.
(https://www.sciencedirect.com/science/article/pii/S0950705123010250)
Abstract: Most current style transfer models are designed as encoder–decoder structures. Some encoding operations, such as downsampling and pooling, cause a loss of image details. If the encoder and decoder are not compatible, it can also introduce distortion. Reversible neural networks have demonstrated their superior power in lossless projection. However, since the inputs and outputs of neural flows are holistic features, merely the high-level features can be utilized for image generation through reverse inference. These high-level features emphasize the image style more, leading to the generated results easily losing content details and producing abstract colors. To address the above issues, we propose LSTFlow, the first progressive reversible neural network capable of feature decomposition. First, LSTFlow incorporates our proposed reversible Learnable Spectrum Transform (LST), which can dynamically decompose the feature into feature spectrum and recover them losslessly. LSTFlow can retain more details by enabling multi-level features to be fused in backward inference. Second, we propose a Progressive Flow Stylization Strategy (PFSS) to balance the model’s emphasis between content and style and enhance the color perception. Forward inference based PFSS is carried out progressively, while the backward inference focuses on progressive generation. To demonstrate the effectiveness of our proposed method, we conducted comparative experiments with seven other state-of-the-art algorithms. The stylized effects are evaluated in terms of visual effects and quantitative indicators. The experiments show that the lightest LSTFlow performs the best in SSIM, Color Entropy, Color Uniformity and FID indicators and outperforms state-of-the-art methods.
Keywords: Style transfer; Reversible neural network; Neural flow; Feature spectrum; Progressive stylization; Feature decomposition

Anee Sharma, Ningrinla Marchang,
A review on client-server attacks and defenses in federated learning,
Computers & Security,
Volume 140,
2024,
103801,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103801.
(https://www.sciencedirect.com/science/article/pii/S0167404824001020)
Abstract: Federated Learning (FL) offers decentralized machine learning (ML) capabilities while potentially safeguarding data privacy. However, this architecture introduces unique security challenges. This paper presents a comprehensive survey of these challenges, categorizing attacks based on their targets: client-side training data, local models, FL channel, server-side aggregated parameters, and global models. We further discuss defense mechanisms tailored for local and global models. Through our investigation, we illuminate the vulnerabilities inherent to FL and provide insights into countermeasures that ensure robustness. Our findings underscore the significance of a dual-focused strategy, addressing security concerns at both client and server levels.
Keywords: Security; Federated learning; Machine learning; Attacks; Defenses

Amy Trappey, Charles V. Trappey, Alex Hsieh,
An intelligent patent recommender adopting machine learning approach for natural language processing: A case study for smart machinery technology mining,
Technological Forecasting and Social Change,
Volume 164,
2021,
120511,
ISSN 0040-1625,
https://doi.org/10.1016/j.techfore.2020.120511.
(https://www.sciencedirect.com/science/article/pii/S0040162520313378)
Abstract: Recommendation systems are widely applied in many fields, such as online customized product searches and customer-centric advertisements. This research develops the methodology for a patent recommender to discover semantically relevant patents for further technology mining and trend analysis. The proposed recommender adopts machine learning (ML) algorithms for natural language processing (NLP) to represent patent documents in vector space and to enable semantic analyses of the patent documents. The ML approach of neural network (NN) language models, trained by domain patent documents (text) as a training set, convert patent documents into vectors and, thus, can identify semantically similar patents using document similarity measures. In particular, the proposed recommender is deployed to in-depth case studies for advanced patent recommendations. The case domain of smart machinery is used to better enable smart manufacturing by incorporating innovative technologies, such as intelligent sensors, intelligent controllers, and intelligent decision making. The research uses six sub-domains in smart machinery technologies as the case studies to verify the superior accuracy and efficacy of the recommender system and methodologies.
Keywords: Natural language processing; Patent recommendation; Word embedding; Technology mining and trend analysis

Jun Niu, Peng Liu, Xiaoyan Zhu, Kuo Shen, Yuecong Wang, Haotian Chi, Yulong Shen, Xiaohong Jiang, Jianfeng Ma, Yuqing Zhang,
A survey on membership inference attacks and defenses in machine learning,
Journal of Information and Intelligence,
Volume 2, Issue 5,
2024,
Pages 404-454,
ISSN 2949-7159,
https://doi.org/10.1016/j.jiixd.2024.02.001.
(https://www.sciencedirect.com/science/article/pii/S2949715924000064)
Abstract: Membership inference (MI) attacks mainly aim to infer whether a data record was used to train a target model or not. Due to the serious privacy risks, MI attacks have been attracting a tremendous amount of attention in the research community. One existing work conducted — to our best knowledge — the first dedicated survey study in this specific area: The survey provides a comprehensive review of the literature during the period of 2017∼2021 (e.g., over 100 papers). However, due to the tremendous amount of progress (i.e., 176 papers) made in this area since 2021, the survey conducted by the one existing work has unfortunately already become very limited in the following two aspects: (1) Although the entire literature from 2017∼2021 covers 18 ways to categorize (all the proposed) MI attacks, the literature during the period of 2017∼2021, which was reviewed in the one existing work, only covered 5 ways to categorize MI attacks. With 13 ways missing, the survey conducted by the one existing work only covers 27% of the landscape (in terms of how to categorize MI attacks) if a retrospective view is taken. (2) Since the literature during the period of 2017∼2021 only covers 27% of the landscape (in terms of how to categorize), the number of new insights (i.e., why an MI attack could succeed) behind all the proposed MI attacks has been significantly increasing since year 2021. As a result, although none of the previous work has made the insights as a main focus of their studies, we found that the various insights leveraged in the literature can be broken down into 10 groups. Without making the insights as a main focus, a survey study could fail to help researchers gain adequate intellectual depth in this area of research. In this work, we conduct a systematic study to address these limitations. In particular, in order to address the first limitation, we make the 13 newly emerged ways to categorize MI attacks as a main focus on the study. In order to address the second limitation, we provide — to our best knowledge — the first review of the various insights leveraged in the entire literature. We found that the various insights leveraged in the literature can be broken down into 10 groups. Moreover, our survey also provides a comprehensive review of the existing defenses against MI attacks, the existing applications of MI attacks, the widely used datasets (e.g., 107 new datasets), and the evaluation metrics (e.g., 20 new evaluation metrics).
Keywords: Machine learning; Privacy and security; Membership inference attacks; Defensive techniques

Harpreet Singh, Rupinder P. Kaur,
Preclinical: Drug Target Identification and Validation in Humans,
Editor(s): Shoba Ranganathan, Mario Cannataro, Asif M. Khan,
Encyclopedia of Bioinformatics and Computational Biology (Second Edition),
Elsevier,
2025,
Pages 259-280,
ISBN 9780323955034,
https://doi.org/10.1016/B978-0-323-95502-7.00145-7.
(https://www.sciencedirect.com/science/article/pii/B9780323955027001457)
Abstract: The process of discovering a new drug begins by understanding the biological origin of a disease and recognizing key target molecules involved in its onset and/or progression. In order to understand the cellular processes taking place in response to a drug, it is critical to elucidate its molecular targets. This has tremendous implications for disease prevention and treatment. Correct identification and validation of drug targets is important for the success of clinical trials and drug development initiatives. A number of approaches have been evolving for target identification as well validation ranging from experimental to computational including the recent addition of Artificial Intelligence tools. In addition, drug, drug target and drug interaction databases have also been playing an important role in this early drug discovery phase. This chapter provides an overview of these techniques along with their applications as well as limitations. The recent implementation of Guidelines On Target Assessment for Innovative Therapeutics (GOT-IT) have been also highlighted.
Keywords: Drug discovery; Guidelines on target assessment for innovative therapeutics (GOT-IT); Target identification; Target validation

Arpita Srivastava, Ditipriya Sinha,
FP-growth-based signature extraction and unknown variants of DoS/DDoS attack detection on real-time data stream,
Journal of Information Security and Applications,
Volume 89,
2025,
103996,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2025.103996.
(https://www.sciencedirect.com/science/article/pii/S2214212625000341)
Abstract: Protecting sensitive information on Internet from unknown attacks is challenging due to no known signatures, limited historical data, a high number of false positives, and a lack of vendor patches. This paper has proposed a statistical method to detect unknown variants of denial-of-service (DoS)/ distributed denial-of-service (DDoS) (high-volume) attacks. The proposed method is primarily divided into two modules: DoS/DDoS attack signature extraction and unknown variants of DoS/DDoS attack detection. A setup in laboratory of NITP is created to capture real-time traffic of six different variants of DoS or DDoS attacks with benign network traffic behavior, referred to as RTNITP24. Unique DoS/DDoS attack signatures are extracted by applying a Frequent-Pattern Growth (FP-Growth) algorithm using 71 % of RTNITP24 data having DoS/DDoS attack and benign traffic, assuming these signatures are primarily present in DoS/DDoS attack traffic but rarely in benign traffic. These signatures are stored in a high-volume attack (HVA) knowledge base (KB). Unknown variants of the DoS/DDoS (high-volume) attack detection module use an HVA knowledge base and pcap files of 29 % RTNITP24 and CICIDS2017 new data packets, which is not considered in the attack signature extraction module. Jaccard similarity score is computed between new data packets and attack signatures and scrutinizes the two main conditions: if similarity score of any of the signatures is greater than or equal to rule threshold or if the average similarity score of all the signatures is greater than or equal to the overall threshold. Packet is detected as malicious if any of aforementioned conditions are true. Otherwise, the packet is benign. Proposed model achieves high accuracy (91.66 % and 94.87 %) and low false alarm rates (5.32 % and 4.98 %) on RTNITP24 and CICIDS2017 datasets, respectively. Additionally, proposed model is compared to apriori-based rule extraction technique and current state-of-the-art methods, revealing that it outperforms both apriori-based and existing methods.
Keywords: DoS/DDoS Attack; Real-time data capturing; Signature extraction; FP-growth algorithm; High-volume attack detection; Jaccard similarity

Xingyan Ye, Kezhen Qin, Alisdair R. Fernie, Youjun Zhang,
Prospects for synthetic biology in 21st Century agriculture,
Journal of Genetics and Genomics,
2024,
,
ISSN 1673-8527,
https://doi.org/10.1016/j.jgg.2024.12.016.
(https://www.sciencedirect.com/science/article/pii/S1673852724003692)
Abstract: Plant synthetic biology has emerged as a transformative field in agriculture, offering innovative solutions to enhance food security, provide resilience to climate change, and transition to sustainable farming practices. By integrating advanced genetic tools, computational modeling, and systems biology, researchers can precisely modify plant genomes to enhance traits such as yield, stress tolerance, and nutrient use efficiency. The ability to design plants with specific characteristics tailored to diverse environmental conditions and agricultural needs holds great potential to address global food security challenges. Here, we highlight recent advancements and applications of plant synthetic biology in agriculture, focusing on key areas such as photosynthetic efficiency, nitrogen fixation, drought tolerance, pathogen resistance, nutrient use efficiency, biofortification, climate resilience, microbiology engineering, synthetic plant genomes, and the integration of artificial intelligence (AI) with synthetic biology. These innovations aim to maximize resource use efficiency, reduce reliance on external inputs, and mitigate environmental impacts associated with conventional agricultural practices. Despite challenges related to regulatory approval and public acceptance, the integration of synthetic biology in agriculture holds immense promise for creating more resilient and sustainable agricultural systems, contributing to global food security and environmental sustainability. Rigorous multi-field testing of these approaches will undoubtedly be required to ensure reproducibility.
Keywords: Plant synthetic biology; Photosynthesis; Nitrogen fixation; AI integration; Genetic circuits; Precision agriculture

Vassilios S. Vassiliadis, Vasileios Mappas, Thomas A. Espaas, Bogdan Dorneanu, Adeniyi Isafiade, Klaus Möller, Harvey Arellano-Garcia,
Reloading Process Systems Engineering within Chemical Engineering,
Chemical Engineering Research and Design,
Volume 209,
2024,
Pages 380-398,
ISSN 0263-8762,
https://doi.org/10.1016/j.cherd.2024.07.066.
(https://www.sciencedirect.com/science/article/pii/S0263876224004568)
Abstract: Established as a sub-discipline of Chemical Engineering in the 1960s by the late Professor R.W.H. Sargent at Imperial College London, Process Systems Engineering (PSE) has played a significant role in advancing the field, positioning it as a leading engineering discipline in the contemporary technological landscape. Rooted in Applied Mathematics and Computing, PSE aligns with the key components driving advancements in our modern, information-centric era. Sargent’s visionary foresight anticipated the evolution of early computational tools into fundamental elements for future technological and scientific breakthroughs, all while maintaining a central focus on Chemical Engineering. This paper aims to present concise and concrete ideas for propelling PSE into a new era of progress. The objective is twofold: to preserve PSE’s extensive and diverse knowledge base and to reposition it more prominently within modern Chemical Engineering, while also establishing robust connections with other data-driven engineering and applied science domains that play important roles in industrial and technological advancements. Rather than merely reacting to contemporary challenges, this article seeks to proactively create opportunities to lead the future of Chemical Engineering across its vital contributions in education, research, technology transfer, and business creation, fully leveraging its inherent multidisciplinarity and versatile character.
Keywords: Chemical Engineering; Process Systems Engineering; Process model construction and deployment; Digital Twinning; Machine Learning

Shahzad Sarwar Bhatti, Xiaofeng Gao, Guihai Chen,
General framework, opportunities and challenges for crowdsourcing techniques: A Comprehensive survey,
Journal of Systems and Software,
Volume 167,
2020,
110611,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2020.110611.
(https://www.sciencedirect.com/science/article/pii/S0164121220300893)
Abstract: Crowdsourcing, a distributed human problem-solving paradigm is an active research area which has attracted significant attention in the fields of computer science, business, and information systems. Crowdsourcing holds novelty with advantages like open innovation, scalability, and cost-efficiency. Although considerable research work is performed, however, a survey on the crowdsourcing process-technology has not been divulged yet. In this paper, we present a systematic survey of crowdsourcing in focussing emerging techniques and approaches for improving conventional and developing future crowdsourcing systems. We first present a simplified definition of crowdsourcing. Then, we propose a framework based on three major components, synthesize a wide spectrum of existing studies for various dimensions of the framework. According to the framework, we first introduce the initialization step, including task design, task settings, and incentive mechanisms. Next, in the implementation step, we look into task decomposition, crowd and platform selection, and task assignment. In the last step, we discuss different answer aggregation techniques, validation methods and reward tactics, and reputation management. Finally, we identify open issues and suggest possible research directions for the future.
Keywords: Crowdsourcing; Framework; Incentives; Decomposition; Aggregation; Reputation

Yilan Hu, Weihang Zhang, Shah Rukh Ali, Koji Takeda, Torsten Peter Vahl, Donghui Zhu, Yi Hong, Ke Cheng,
Extracellular vesicle therapeutics for cardiac repair,
Journal of Molecular and Cellular Cardiology,
Volume 199,
2025,
Pages 12-32,
ISSN 0022-2828,
https://doi.org/10.1016/j.yjmcc.2024.11.005.
(https://www.sciencedirect.com/science/article/pii/S0022282824001950)
Abstract: Extracellular vesicles (EVs) are cell-secreted heterogeneous vesicles that play crucial roles in intercellular communication and disease pathogenesis. Due to their non-tumorigenicity, low immunogenicity, and therapeutic potential, EVs are increasingly used in cardiac repair as cell-free therapy. There exist multiple steps for the design of EV therapies, and each step offers many choices to tune EV properties. Factors such as EV source, cargo, loading methods, routes of administration, surface modification, and biomaterials are comprehensively considered to achieve specific goals. PubMed and Google Scholar were searched in this review, 89 articles related to EV-based cardiac therapy over the past five years (2019 Jan - 2023 Dec) were included, and their key steps in designing EV therapies were counted and analyzed. We aim to provide a comprehensive overview that can serve as a reference guide for researchers to design EV-based cardiac therapies.
Keywords: Extracellular vesicles; Therapeutics; Cardiac repair; Bioengineering

Jan Egger, Christina Gsaxner, Antonio Pepe, Kelsey L. Pomykala, Frederic Jonske, Manuel Kurz, Jianning Li, Jens Kleesiek,
Medical deep learning—A systematic meta-review,
Computer Methods and Programs in Biomedicine,
Volume 221,
2022,
106874,
ISSN 0169-2607,
https://doi.org/10.1016/j.cmpb.2022.106874.
(https://www.sciencedirect.com/science/article/pii/S0169260722002565)
Abstract: Deep learning has remarkably impacted several different scientific disciplines over the last few years. For example, in image processing and analysis, deep learning algorithms were able to outperform other cutting-edge methods. Additionally, deep learning has delivered state-of-the-art results in tasks like autonomous driving, outclassing previous attempts. There are even instances where deep learning outperformed humans, for example with object recognition and gaming. Deep learning is also showing vast potential in the medical domain. With the collection of large quantities of patient records and data, and a trend towards personalized treatments, there is a great need for automated and reliable processing and analysis of health information. Patient data is not only collected in clinical centers, like hospitals and private practices, but also by mobile healthcare apps or online websites. The abundance of collected patient data and the recent growth in the deep learning field has resulted in a large increase in research efforts. In Q2/2020, the search engine PubMed returned already over 11,000 results for the search term ‘deep learning’, and around 90% of these publications are from the last three years. However, even though PubMed represents the largest search engine in the medical field, it does not cover all medical-related publications. Hence, a complete overview of the field of ‘medical deep learning’ is almost impossible to obtain and acquiring a full overview of medical sub-fields is becoming increasingly more difficult. Nevertheless, several review and survey articles about medical deep learning have been published within the last few years. They focus, in general, on specific medical scenarios, like the analysis of medical images containing specific pathologies. With these surveys as a foundation, the aim of this article is to provide the first high-level, systematic meta-review of medical deep learning surveys.
Keywords: Deep learning; Artificial neural networks; Machine learning; Data analysis; Image analysis; Medical image analysis; Medical image processing; Medical imaging; Patient data; Pathology; Detection; Segmentation; Registration; Generative adversarial networks; PubMed; Systematic; Review; Survey; Meta-review; Meta-survey

Li Yao, Jun Li, Kaihua Chen, Rongjian Yu,
Winning the second race of technology standardization: Strategic maneuvers in SEP follow-on innovations,
Research Policy,
Volume 53, Issue 6,
2024,
105023,
ISSN 0048-7333,
https://doi.org/10.1016/j.respol.2024.105023.
(https://www.sciencedirect.com/science/article/pii/S0048733324000726)
Abstract: Innovation is cumulative in nature, and follow-on innovation is a way to extract value from existing technology. Thus, to appropriate the value of standard essential patents (SEPs), firms need to win the first race in pushing proprietary technologies to become SEPs and the second race in exploiting SEP-related opportunities in follow-on innovations. This study investigates how, when, and to what effect firms strategically maneuver in follow-on innovations to maximize the value appropriation from SEPs. Drawing from a resource-based logic, we argue that SEP firms’ winning strategic maneuver involves such moves: (a) engaging in early follow-on innovation targeting SEPs, (b) prioritizing the exploitation of SEPs over non-SEPs, and (c) exploiting cross-follow-on innovations to take advantage of the information and network resources they obtain from their participation in the standardization process. We further argue that SEP firms’ strategic maneuvering results in high-quality follow-on innovations, which together with SEPs form stronger patent portfolios. Analyzing a unique dataset of patents from leading Chinese ICT firms matched with forward citations, we find empirical evidence that supports our arguments. Our research has important theoretical and managerial implications for firms’ strategic innovation management with a focus on technology standardization.
Keywords: Follow-on innovation; Patent citation; Standardization strategy; Standard essential patent; China

Andreas Reiter, Joachim Stonig, Karolin Frankenberger,
Managing multi-tiered innovation ecosystems,
Research Policy,
Volume 53, Issue 1,
2024,
104905,
ISSN 0048-7333,
https://doi.org/10.1016/j.respol.2023.104905.
(https://www.sciencedirect.com/science/article/pii/S0048733323001890)
Abstract: We study how orchestrators of innovation ecosystems govern their relationships with multiple heterogeneous complementors that differ in their positions and activities that contribute to an integrated value proposition. Prior research has focused on ecosystem-wide and complementor-specific governance, each not suited to adequately address the challenges of this context. Building on a multiple-case study in the financial services sector, our findings demonstrate that orchestrators create distinctly governed tiers of complementors based on the domains of uncertainty underlying their ecosystem blueprint. The organizational form and coordination mechanisms of these tiers reflect the convergent or explorative role of complementors in the core or the periphery of the blueprint. We contribute to ecosystem governance by introducing complementor tiers as a governance approach that blends elements of ecosystem-wide and complementor-specific governance and by linking governance choices to uncertainty and complementor roles. Furthermore, we discuss the potential for future research at the intersection of ecosystem and open innovation governance.
Keywords: Ecosystems; Governance; Open innovation; Complementors; Multiple-case study

Limao Zhang, Yongsheng Li, Yue Pan, Lieyun Ding,
Advanced informatic technologies for intelligent construction: A review,
Engineering Applications of Artificial Intelligence,
Volume 137, Part A,
2024,
109104,
ISSN 0952-1976,
https://doi.org/10.1016/j.engappai.2024.109104.
(https://www.sciencedirect.com/science/article/pii/S0952197624012624)
Abstract: Since there is a growing interest in driving the digital transformation of the construction industry, the goal of this paper is to provide a full picture and understanding of the emerging research front on intelligent construction. Through the quantitative and qualitative analysis, relevant pieces of literature are thoroughly reviewed to extract useful knowledge to raise awareness of intelligent construction, resulting in the summary of research status and the determination of future needs. In light of the research findings, the rapid development of intelligent construction follows the strategies of standardization, digitization, intellectualization, collaboration, greenization, and customization, which mainly support “4S” technologies. The popular research topics covering intelligent engineering services for the project's full lifecycle (i.e., design, construction, operation, and maintenance) and even the city level have been deeply explored, which are proven to dramatically improve project efficiency, safety, and automation. Moreover, challenges exist in three potential paths for future research, including the digital twin-enabled engineering cloud platform, man-machine-environment interaction, great sustainability under carbon peaking and carbon neutrality goals. As for the practical value, a synthesized point of up-to-date reference is created to guide managers to promote intelligent construction in real-world engineering.
Keywords: Intelligent construction; Digital transformation; Construction automation and informatics; Critical review

Ethan Sacoransky, Benjamin Y.M. Kwan, Donald Soboleski,
ChatGPT and assistive AI in structured radiology reporting: A systematic review,
Current Problems in Diagnostic Radiology,
Volume 53, Issue 6,
2024,
Pages 728-737,
ISSN 0363-0188,
https://doi.org/10.1067/j.cpradiol.2024.07.007.
(https://www.sciencedirect.com/science/article/pii/S0363018824001130)
Abstract: Introduction
The rise of transformer-based large language models (LLMs), such as ChatGPT, has captured global attention with recent advancements in artificial intelligence (AI). ChatGPT demonstrates growing potential in structured radiology reporting—a field where AI has traditionally focused on image analysis.
Methods
A comprehensive search of MEDLINE and Embase was conducted from inception through May 2024, and primary studies discussing ChatGPT's role in structured radiology reporting were selected based on their content.
Results
Of the 268 articles screened, eight were ultimately included in this review. These articles explored various applications of ChatGPT, such as generating structured reports from unstructured reports, extracting data from free text, generating impressions from radiology findings and creating structured reports from imaging data. All studies demonstrated optimism regarding ChatGPT's potential to aid radiologists, though common critiques included data privacy concerns, reliability, medical errors, and lack of medical-specific training.
Conclusion
ChatGPT and assistive AI have significant potential to transform radiology reporting, enhancing accuracy and standardization while optimizing healthcare resources. Future developments may involve integrating dynamic few-shot prompting, ChatGPT, and Retrieval Augmented Generation (RAG) into diagnostic workflows. Continued research, development, and ethical oversight are crucial to fully realize AI's potential in radiology.
Keywords: ChatGPT; Artificial intelligence; Radiology; Radiologist; Large language models

S.P. Sharmila, Shubham Gupta, Aruna Tiwari, Narendra S. Chaudhari,
Leveraging Memory Forensic Features for Explainable Obfuscated Malware Detection with Isolated Family Distinction Paradigm,
Computers and Electrical Engineering,
Volume 123, Part C,
2025,
110107,
ISSN 0045-7906,
https://doi.org/10.1016/j.compeleceng.2025.110107.
(https://www.sciencedirect.com/science/article/pii/S0045790625000503)
Abstract: In the IoT edge computing era, inevitable and ubiquitous presence of the internet is opening the door for numerous cyberattacks. Obfuscated malware adds layers of difficulty to detect complex modern cyber attacks by evading AI-enabled Next-Generation Anti-Virus (NGAV) scanners and breaching digital privacy. To tackle this problem, in this paper, we propose “Augmented Sparse Projection Oblique Random Forest (AugSPORF)”, an Explainable sparse projections based Oblique Random Forest (ORF) with Isolated Family Distinction (IFD) Paradigm to detect multiple obfuscated malware belonging to Spyware, Ransomware, and Trojan families effectively. Irrespective of obfuscation, malware variants possess common behavior and family traits aligned with their families and leave traces in the memory on execution. To begin with this motivation, we handle the huge dimension of memory forensic features with sparse random projections. Next, we perform feature importance aware training with ORF to learn inherent behavioral features of malware families by isolating the target family, and distinguishing with other families. Further, the model’s scalability is assessed by increasing the number of malware families. To offer an insightful conclusion on the predictions, an Interpretable Machine Learning (IML) layer is interleaved to generate a report of explanations, thereby enhancing the interpretability of the model. The proposed approach yields an average accuracy of 96.76%, 96.45%, and 97.33% in detecting sub-families of Spyware, Ransomware, and Trojan respectively. Improved accuracy is also demonstrated by benchmarking the performance of AugSPORF on UCI repository datasets.
Keywords: Ransomware; Spyware; Trojan; Multi-class classification; Explainable AI; Sparse Projections

Zhiwei Yang, Zhengjie Feng, Rongxin Huo, Huiru Lin, Hanghan Zheng, Ruichi Nie, Hongrui Chen,
The Imitation Game revisited: A comprehensive survey on recent advances in AI-generated text detection,
Expert Systems with Applications,
Volume 272,
2025,
126694,
ISSN 0957-4174,
https://doi.org/10.1016/j.eswa.2025.126694.
(https://www.sciencedirect.com/science/article/pii/S0957417425003161)
Abstract: In recent years, AI-generated text detection (AIGTD) has attracted more and more attention, with numerous novel methodologies being proposed. However, most existing reviews on this topic tend to be fragmented and incoherent in content, lacking a coherent and comprehensive framework for understanding. This paper comprehensively analyzes and summarizes the latest advancements and prominent technologies in this fast-moving field. In order to do that, we introduce a novel comprehensive multi-level taxonomy for AIGTD approaches, where the existing research can be broadly categorized into three directions, tackling the key challenges of classifier training, intrinsic attributes, and information embedding, respectively. To help researchers and practitioners understand and address detection and attack scenarios, we also introduce a classification of black-box and white-box models based on interpretability and transparency, as well as the computational requirements required to use the baseline methods. Moreover, we carefully provide a comprehensive performance comparison and analysis across several datasets for these methods, collect commonly used benchmark datasets, and outline potential future research directions in this field. To facilitate sharing, we consistently maintain the relevant materials at: https://github.com/Nicozwy/AIGTD-Survey.
Keywords: AI-generated text detection; Methodological review; Hierarchical analysis; Potential future research

Kisik Song, Siyeong Yun, Leehee Kim, Sungjoo Lee,
Investigating new design concepts based on customer value and patent data: The case of a future mobility door,
Technological Forecasting and Social Change,
Volume 184,
2022,
121963,
ISSN 0040-1625,
https://doi.org/10.1016/j.techfore.2022.121963.
(https://www.sciencedirect.com/science/article/pii/S004016252200484X)
Abstract: Design-based strategies are becoming as important in corporate competitive approaches as technology-based strategies, and accordingly, design patents have emerged as a mechanism for capturing technology opportunities. The text data of the design patent are not only simpler than the complex text structure of the utility patent but also clearly explain the application and design characteristics of the invention. Therefore, design patents have high value as an innovation database that can be complemented with utility data. Despite the potential of design patents as a source of technology intelligence, however, most studies on capturing technology opportunities have focused on utility patents. Therefore, this study proposed an approach to investigate new design concepts using design patents, and it employed the approach in the case of a future mobility door. More specifically, we first identified valuable design concepts within the target field (i.e., vehicle doors) and reference field (i.e., oven doors) to be applied to the target object (i.e., future mobility door), and we prioritized the ideas by technology- and user value-related criteria. Then, the highly-prioritized ideas were provided with the experts in the automobile industry to verify the effectiveness of the proposed approach. The research outputs are expected to contribute to the development of product design concepts in a company by helping to discover technology opportunities with reference to the designs in other industries as well as within the target industry.
Keywords: Design concept; Technology opportunity; Patent analysis; Text mining; User value; Future mobility

Santosh K. Smmarwar, Govind P. Gupta, Sanjay Kumar,
Android malware detection and identification frameworks by leveraging the machine and deep learning techniques: A comprehensive review,
Telematics and Informatics Reports,
Volume 14,
2024,
100130,
ISSN 2772-5030,
https://doi.org/10.1016/j.teler.2024.100130.
(https://www.sciencedirect.com/science/article/pii/S2772503024000161)
Abstract: The ever-increasing growth of online services and smart connectivity of devices have posed the threat of malware to computer system, android-based smart phones, Internet of Things (IoT)-based systems. The anti-malware software plays an important role in order to safeguard the system resources, data and information against these malware attacks. Nowadays, malware writers used advanced techniques like obfuscation, packing, encoding and encryption to hide the malicious activities. Because of these advanced techniques of malware evasion, traditional malware detection system unable to detect new variants of malware. Cyber security has attracted many researchers in the past for designing of Machine Learning (ML) or Deep Learning (DL) based malware detection models. In this study, we present a comprehensive review of the literature on malware detection approaches. The overall literature of the malware detection is grouped into three categories such as review of feature selection (FS) techniques proposed for malware detection, review of ML-based techniques proposed for malware detection and review of DL-based techniques proposed for malware detection. Based on literature review, we have identified the shortcoming and research gaps along with some future directives to design of an efficient malware detection and identification framework.
Keywords: Machine learning; Deep learning; Android malware detection; Malware detection

Jiewu Leng, Jiwei Guo, Junxing Xie, Xueliang Zhou, Ang Liu, Xi Gu, Dimitris Mourtzis, Qinglin Qi, Qiang Liu, Weiming Shen, Lihui Wang,
Review of manufacturing system design in the interplay of Industry 4.0 and Industry 5.0 (Part II): Design processes and enablers,
Journal of Manufacturing Systems,
Volume 79,
2025,
Pages 528-562,
ISSN 0278-6125,
https://doi.org/10.1016/j.jmsy.2025.02.005.
(https://www.sciencedirect.com/science/article/pii/S0278612525000366)
Abstract: Following up on our previous review paper ‘Review of manufacturing system design in the interplay of Industry 4.0 and Industry 5.0 (Part I): Design thinking and modeling methods’ [1], based on the proposed Thinking-Modelling-Process-Enabler (TMPE) framework of Manufacturing System Design (MSD), this paper (Part II of the two-part review) further reviews the Process and Enabler dimensions of MSD in the interplay of Industry 4.0 and Industry 5.0. MSD methods are reviewed from the single-dimensional design process and cross-dimensional design process perspectives, respectively. MSD methods are reorganized and categorized from the key enabler's perspective. Finally, challenges are discussed along with directions for future research in the domain of MSD. This review is anticipated to offer novel insights for advancing MSD research and engineering in the interplay of Industry 4.0 and Industry 5.0.
Keywords: Manufacturing system design; Production system design; Smart manufacturing; Industry 5.0; Design methods

Spyridon Bakas, Philipp Vollmuth, Norbert Galldiks, Thomas C Booth, Hugo J W L Aerts, Wenya Linda Bi, Benedikt Wiestler, Pallavi Tiwari, Sarthak Pati, Ujjwal Baid, Evan Calabrese, Philipp Lohmann, Martha Nowosielski, Rajan Jain, Rivka Colen, Marwa Ismail, Ghulam Rasool, Janine M Lupo, Hamed Akbari, Joerg C Tonn, David Macdonald, Michael Vogelbaum, Susan M Chang, Christos Davatzikos, Javier E Villanueva-Meyer, Raymond Y Huang,
Artificial Intelligence for Response Assessment in Neuro Oncology (AI-RANO), part 2: recommendations for standardisation, validation, and good clinical practice,
The Lancet Oncology,
Volume 25, Issue 11,
2024,
Pages e589-e601,
ISSN 1470-2045,
https://doi.org/10.1016/S1470-2045(24)00315-2.
(https://www.sciencedirect.com/science/article/pii/S1470204524003152)
Abstract: Summary
Technological advancements have enabled the extended investigation, development, and application of computational approaches in various domains, including health care. A burgeoning number of diagnostic, predictive, prognostic, and monitoring biomarkers are continuously being explored to improve clinical decision making in neuro-oncology. These advancements describe the increasing incorporation of artificial intelligence (AI) algorithms, including the use of radiomics. However, the broad applicability and clinical translation of AI are restricted by concerns about generalisability, reproducibility, scalability, and validation. This Policy Review intends to serve as the leading resource of recommendations for the standardisation and good clinical practice of AI approaches in health care, particularly in neuro-oncology. To this end, we investigate the repeatability, reproducibility, and stability of AI in response assessment in neuro-oncology in studies on factors affecting such computational approaches, and in publicly available open-source data and computational software tools facilitating these goals. The pathway for standardisation and validation of these approaches is discussed with the view of trustworthy AI enabling the next generation of clinical trials. We conclude with an outlook on the future of AI-enabled neuro-oncology.

Raahul Sharma, Caitlin R.M. Oyagawa, Hamid Abbasi, Michael Dragunow, Daniel Conole,
Phenotypic approaches for CNS drugs,
Trends in Pharmacological Sciences,
Volume 45, Issue 11,
2024,
Pages 997-1017,
ISSN 0165-6147,
https://doi.org/10.1016/j.tips.2024.09.003.
(https://www.sciencedirect.com/science/article/pii/S0165614724001883)
Abstract: Central nervous system (CNS) drug development is plagued by high clinical failure rate. Phenotypic assays promote clinical translation of drugs by reducing complex brain diseases to measurable, clinically valid phenotypes. We critique recent platforms integrating patient-derived brain cells, which most accurately recapitulate CNS disease phenotypes, with higher throughput models, including immortalized cells, to balance validity and scalability. These platforms were screened with conventional commercial chemogenomic compound libraries. We explore emerging library curation strategies to improve hit rate and quality, and screening novel fragment libraries as alternatives, for more tractable drug target deconvolution. The clinically relevant models used in these platforms could harbor important, unidentified drug targets, so we review evolving agnostic target deconvolution approaches, including chemical proteomics and artificial intelligence (AI), which aid in phenotypic screening hit mechanism elucidation, thereby facilitating rational hit-to-drug optimization.
Keywords: CNS disorders; phenotypic drug discovery; screening platforms; compound library; chemical proteomics; artificial intelligence

Sajad Ashouri, Arash Hajikhani, Arho Suominen, Lukas Pukelis, Scott W. Cunningham,
Measuring digitalization at scale using web scraped data,
Technological Forecasting and Social Change,
Volume 207,
2024,
123618,
ISSN 0040-1625,
https://doi.org/10.1016/j.techfore.2024.123618.
(https://www.sciencedirect.com/science/article/pii/S0040162524004165)
Abstract: Measuring digitalization has been a central topic in academic discourse. While evaluating firms' efforts in increasing digitalization is crucial, quantifying it at scale, presents considerable challenges. This paper uses website information as a source of data to operationalize a measure of digitalization. Drawing on a sample of 60,942 firms, our approach proposes two distinct measures of digitalization: one at the product level and the other at the general organizational level. We substantiate these measures using a blend of qualitative and quantitative methods. The study validates the content of websites as a relevant source of innovation indicator data and verifies the indicators using multiple experiments. The developed digitalization indicators offer future research an empirical measure of digitalization that can be run at scale, across industries and regions through time.
Keywords: Digitalization; Innovation; Web scraping; Big data; Text mining

Yogesh K. Dwivedi, Anand Jeyaraj, Laurie Hughes, Gareth H. Davies, Manju Ahuja, Mousa Ahmed Albashrawi, Adil S. Al-Busaidi, Salah Al-Sharhan, Khalid Ibrahim Al-Sulaiti, Levent Altinay, Shem Amalaya, Sunil Archak, María Teresa Ballestar, Shonil A. Bhagwat, Anandhi Bharadwaj, Amit Bhushan, Indranil Bose, Pawan Budhwar, Deborah Bunker, Alexandru Capatina, Lemuria Carter, Ioanna Constantiou, Crispin Coombs, Tom Crick, Csaba Csáki, Yves Darnige, Rahul Dé, Rick Delbridge, Rameshwar Dubey, Robin Gauld, Ravi Kumar Gutti, Marié Hattingh, Arve Haug, Leeya Hendricks, Airo Hino, Cathy H.C. Hsu, Netta Iivari, Marijn Janssen, Ikram Jebabli, Paul Jones, Iris Junglas, Abhishek Kaushik, Deepak Khazanchi, Mitsuru Kodama, Sascha Kraus, Vikram Kumar, Christian Maier, Tegwen Malik, Machdel Matthee, Ian P. McCarthy, Marco Meier, Bhimaraya Metri, Adrian Micu, Angela-Eliza Micu, Santosh K. Misra, Anubhav Mishra, Tonja Molin-Juustila, Leif Oppermann, Nicholas O’Regan, Abhipsa Pal, Neeraj Pandey, Ilias O. Pappas, Andrew Parker, Kavita Pathak, Daniel Pienta, Ariana Polyviou, Ramakrishnan Raman, Samuel Ribeiro-Navarrete, Paavo Ritala, Michael Rosemann, Suprateek Sarker, Pallavi Saxena, Daniel Schlagwein, Hergen Schultze, Chitra Sharma, Sujeet Kumar Sharma, Antonis Simintiras, Vinay Kumar Singh, Hanlie Smuts, John Soldatos, Manoj Kumar Tiwari, Jason Bennett Thatcher, Cristina Vanberghen, Ákos Varga, Polyxeni Vassilakopoulou, Viswanath Venkatesh, Giampaolo Viglia, Tim Vorley, Michael Wade, Paul Walton,
“Real impact”: Challenges and opportunities in bridging the gap between research and practice – Making a difference in industry, policy, and society,
International Journal of Information Management,
Volume 78,
2024,
102750,
ISSN 0268-4012,
https://doi.org/10.1016/j.ijinfomgt.2023.102750.
(https://www.sciencedirect.com/science/article/pii/S0268401223001317)
Abstract: Achieving impact from academic research is a challenging, complex, multifaceted, and interconnected topic with a number of competing priorities and key performance indicators driving the extent and reach of meaningful and measurable benefits from research. Academic researchers are incentivised to publish their research in high-ranking journals and academic conferences but also to demonstrate the impact of their outputs through metrics such as citation counts, altmetrics, policy and practice impacts, and demonstrable institutional decision-making influence. However, academic research has been criticized for: its theoretical emphasis, high degree of complexity, jargon-heavy language, disconnect from industry and societal needs, overly complex and lengthy publishing timeframe, and misalignment between academic and industry objectives. Initiatives such as collaborative research projects and technology transfer offices have attempted to deliver meaningful impact, but significant barriers remain in the identification and evaluation of tangible impact from academic research. This editorial focusses on these aspects to deliver a multi-expert perspective on impact by developing an agenda to deliver more meaningful and demonstrable change to how “impact” can be conceptualized and measured to better align with the aims of academia, industry, and wider society. We present the 4D model - Design, Deliver, Disseminate, and Demonstrate - to provide a structured approach for academia to better align research endeavors with practice and deliver meaningful, tangible benefits to stakeholders.
Keywords: Academic impact; Implications for practice; Relevance; Research benefits; Research contribution; Research impact

Greg Hlavaty, Heather Lindenman, Travis Maynard,
All the attention, all the time: How first-year students experience writing in a horizontal digital ecosystem,
Computers and Composition,
Volume 75,
2025,
102922,
ISSN 8755-4615,
https://doi.org/10.1016/j.compcom.2025.102922.
(https://www.sciencedirect.com/science/article/pii/S875546152500009X)
Abstract: This article examines how first-year composition students navigate digital attention ecosystems while writing. It presents findings from a qualitative focus group study in which undergraduate students participated in writing and reflection activities. The findings indicate that students are immersed in a “horizontal attention ecosystem,” in which all online tasks, communications, and media feel equally worthy of their attention. Although students attempt to manage their physical-digital writing environments strategically, the intrusive nature of current technology hinders their ability to focus, especially on academic writing assignments. When completing academic assignments, students report relying on self-restrictive measures and approaching writing as a solitary act, contrasting with writing studies’ understanding of writing as a social act. This article suggests pedagogical approaches that privilege embodied writing strategies and encourage writing-oriented social interactions between students.
Keywords: Digital writing ecosystem; attention economy; distraction; horizontal attention ecosystem; embodiment; interpersonal support; environment selecting- and structuring-practices; writing processes; pedagogy; technology

Zeinab Alebouyeh, Amir Jalaly Bidgoly,
Benchmarking robustness and privacy-preserving methods in federated learning,
Future Generation Computer Systems,
Volume 155,
2024,
Pages 18-38,
ISSN 0167-739X,
https://doi.org/10.1016/j.future.2024.01.009.
(https://www.sciencedirect.com/science/article/pii/S0167739X24000086)
Abstract: Federated learning (FL) is a machine learning framework that enables the use of user data for training without the need to share the data with the central server. FL's decentralized structure can lead to security and privacy issues, as it allows malicious or curious users to potentially participate in the training process. One limitation of most defense methods presented in FL is that they typically focus on only one aspect, either security or privacy. Therefore, the unintended effects of defensive methods in one field on another field are not clear. The purpose of this article is to examine security and privacy threats and defensive strategies in FL. In addition, the article investigates the performance of seven robust aggregators against three security attacks in both IID and non-IID settings. Furthermore, the impact of security and privacy defensive methods on each other is explored in the remainder of the article. To investigate the effect of security methods on the success rate of privacy attacks, the performance of seven robust aggregation methods against the membership inference attack is studied. The experiments reveal that the degree of privacy leakage is inversely related to the aggregator's robustness to security attacks. In other words, the greater the aggregator algorithm's robustness to security attacks, the greater the risk of privacy leakage. The impact of privacy-preserving methods on the performance of robust aggregation algorithms was investigated by studying the effect of the adversarial regularization method on their performance. The results indicate that while the adversarial regularization method can help protect user data privacy in FL, it can also disrupt the performance of robust aggregation methods. This can make it difficult for aggregators to accurately identify malicious users and reduce the overall accuracy of the global model.
Keywords: Federated Learning; Deep Learning; Security; Robustness; Privacy-Preserving

Seongwoo Cho, Jongsu Park, Jumyung Um,
Development of Fine-Tuned Retrieval Augmented Language Model specialized to manual books on machine tools⁎⁎This work is supported by Korea Evaluation Institute of Industrial Technology (KEIT) grant funded by the Ministry of Trade, Industry and Energy(No. 20026431) and Institute of information communications Technology Planning Evaluation (IITP) grant funded by the Korea government(MSIT) (No.RS-2022-00155911, Artificial Intelligence Convergence Innovation Human) Resources Development(Kyung Hee University),
IFAC-PapersOnLine,
Volume 58, Issue 19,
2024,
Pages 187-192,
ISSN 2405-8963,
https://doi.org/10.1016/j.ifacol.2024.09.157.
(https://www.sciencedirect.com/science/article/pii/S2405896324015696)
Abstract: This paper aims to reduce potential human errors and loads that arise from the lack of novice human operators and different interfaces in advanced machine tool industries. A digital assistant using generative artificial intelligence is designed to answer questions about machine terminologies, and operation sequences happening in an alarm state. Combining Fine-Tuning, Retrieval Augmented Generation, and Prompt Engineering, it solves problems of common-purpose large language models. The proposed system is implemented on a local server and connected to a mobile device. It shows increasing quantitative accuracy from 51% to 79% and 84% in the fine-tuned and retriever model, and the qualitative score increases from 21 to 25 in the retriever model.
Keywords: Fine-tuning; Retrieval Augmented Generation; Prompt Engineering; Large Language Models; Artificial Intelligence; Machine tools

Anh-Tu Tran, The-Dung Luong, Van-Nam Huynh,
A comprehensive survey and taxonomy on privacy-preserving deep learning,
Neurocomputing,
Volume 576,
2024,
127345,
ISSN 0925-2312,
https://doi.org/10.1016/j.neucom.2024.127345.
(https://www.sciencedirect.com/science/article/pii/S0925231224001164)
Abstract: Deep learning (DL) has been shown to be very effective for many application domains of machine learning (ML), including image classification, voice recognition, natural language processing, and bioinformatics. The success of DL techniques is directly related to the availability of large amounts of training data. However, in many cases, the data are sensitive to the users and should be protected to preserve the privacy. Privacy-preserving deep learning (PPDL) has thus become a very active research field to ensure the training process and use of DL models are productive without exposing or leaking information about the data. This paper aims to provide a comprehensive survey of PPDL. We concentrate on the risks that affect data privacy in DL and conduct a detailed investigation into the models that ensure privacy. Finally, we propose a set of evaluation criteria, detailing the advantages and disadvantages of the solutions. Based on the analyzed strengths and weaknesses, the paper has highlighted some important research problems and application cases that have not been studied and these point to certain open research directions.
Keywords: Privacy-preserving deep learning (PPDL); Deep learning (DL); Deep neural network (DNN); Privacy; Secure Multi-Party Computation (SMC)

Haziq Jamil, Amira Barizah Noorosmawie, Hafeezul Waezz Rabu, Lutfi Abdul Razak,
From Archives to AI: Residential Property Data Across Three Decades in Brunei Darussalam,
Data in Brief,
2025,
111505,
ISSN 2352-3409,
https://doi.org/10.1016/j.dib.2025.111505.
(https://www.sciencedirect.com/science/article/pii/S2352340925002379)
Abstract: This article introduces the first publicly available data set for analysing the Brunei housing market, covering more than 30,000 property listings from 1993 to early 2025. The data set, curated from property advertisements in newspapers and online platforms, includes key attributes such as price, location, property type, and physical characteristics, enriched with area-level spatial information. Comprehensive and historical, it complements the Brunei Darussalam Central Bank's Residential Property Price Index (RPPI), addressing the limitations of restricted access to raw RPPI data and its relatively short timeline since its inception in 2015. Data collection involved manual transcription from archival sources and automated web scraping using programmatic methods, supported by innovative processing with Large Language Models (LLMs) to codify unstructured text. The data set enables spatial and temporal analysis, with potential applications in economics, urban planning, and real estate research. Although listing prices are only a proxy for market values and may deviate from actual sale prices due to negotiation dynamics and other factors, this data set still provides a valuable resource for quantitative analyses of housing market trends and for informing policy decisions.
Keywords: Housing Market; Property Listings; Spatial Data; Web Scraping; Large Language Models; Brunei

Lachlan Deer, Susanne J. Adler, Hannes Datta, Natalie Mizik, Marko Sarstedt,
Toward open science in marketing research,
International Journal of Research in Marketing,
Volume 42, Issue 1,
2025,
Pages 212-233,
ISSN 0167-8116,
https://doi.org/10.1016/j.ijresmar.2024.12.005.
(https://www.sciencedirect.com/science/article/pii/S0167811624001150)
Abstract: The open science paradigm has gained prominence in marketing as researchers seek to enhance the validity, reliability, and transparency of research methods and findings. Journals and institutions increasingly encourage or require open science practices, and many authors have started to adapt to and meet these new research and publishing expectations. We provide guidance for effectively implementing open science practices in empirical marketing research. Our recommendations, are tailored to the unique methodological approaches and challenges of each subdiscipline and their specific research contexts. Successful integration of these practices into academic marketing research will require concerted and collaborative efforts among authors, journals, institutions, and funding agencies. We argue that the gradual, thoughtful adoption of these principles and practices will improve the quality and efficiency of scientific discovery.
Keywords: Open access; Open data; Open science; Preregistration; Transparency

Mousa Al-kfairy, Soha Ahmed, Ashraf Khalil,
Factors impacting users’ willingness to adopt and utilize the metaverse in education: A systematic review,
Computers in Human Behavior Reports,
Volume 15,
2024,
100459,
ISSN 2451-9588,
https://doi.org/10.1016/j.chbr.2024.100459.
(https://www.sciencedirect.com/science/article/pii/S2451958824000927)
Abstract: Purpose
This study explores the factors influencing the adoption and acceptance of Metaverse technologies in educational settings. Despite the growing interest in immersive educational environments provided by the Metaverse, there is a lack of comprehensive understanding regarding the elements that affect user engagement and acceptance. This paper aims to bridge this gap through a systematic review of empirical studies that apply Information Systems theories such as TAM, UTAUT, TPB, and their extensions.
Methods
A total of 35 empirical studies were analyzed using a methodical review approach. The research methodologies employed in these studies include surveys, structural equation modeling, and interviews, providing a broad spectrum of data on how different factors influence educational outcomes in the Metaverse.
Results
The findings reveal that user adoption of the Metaverse in educational contexts is influenced by multiple factors at individual, technological, and environmental levels. Key factors identified include effort expectancy, behavioral intention, self-efficacy, enjoyment, and immersion. These factors are subject to moderating effects, suggesting that the dynamics of Metaverse adoption are highly context-dependent.
Conclusion
The insights gained from this review provide valuable guidelines for educators, policymakers, and technology developers aiming to effectively integrate Metaverse technologies into educational frameworks. The study also outlines limitations and suggests directions for future research, highlighting the need for further investigations into the longitudinal impacts and cultural adaptability of Metaverse applications in education.
Keywords: Metaverse education; Intention to use; Acceptance; Systematic review; Information systems theories

Khatereh Ghasemzadeh, Guido Bortoluzzi, Zornitsa Yordanova,
Collaborating with users to innovate: A systematic literature review,
Technovation,
Volume 116,
2022,
102487,
ISSN 0166-4972,
https://doi.org/10.1016/j.technovation.2022.102487.
(https://www.sciencedirect.com/science/article/pii/S0166497222000347)
Abstract: The purpose of this study is to systematize and consolidate a scattered literature on the theme of firm-user collaboration by focusing on the strategic, organizational, and managerial dynamics of firms. To achieve this aim, a systematic review of 152 articles was carried out. Papers were first organized into six clusters of firm-user collaboration: (1) Identifying and Selecting Users and Ideas, (2) Organizing Collaboration with Users, (3) Networking with Users, (4) Engaging Users in the Innovation Process, (5) Developing Resources and Capabilities to support Collaboration with Users, and (6) Strategizing for Users’ Involvement. The main topics within each area were then organized sequentially, following a typical innovation-management process to facilitate the identification of further research opportunities and under-addressed topics that could be relevant to tackle. The paper contributes to the innovation literature by providing a firm-centered perspective on the strategic, organizational, and managerial preconditions and dynamics needed to enable and enhance collaboration with users.
Keywords: Firm-user collaboration; User innovation; Innovation strategy; Innovation management; Review

Tatevik Harutyunyan, Bram Timmermans, Lars Frederiksen,
Outside board director experience and the growth of new ventures,
Journal of Business Venturing,
Volume 40, Issue 3,
2025,
106484,
ISSN 0883-9026,
https://doi.org/10.1016/j.jbusvent.2025.106484.
(https://www.sciencedirect.com/science/article/pii/S0883902625000126)
Abstract: Most research on entrepreneurship focuses on entrepreneurs' human and social capital as the drivers of new venture performance. However, less is known about how much the endowments of other strategic human resources, namely board directors, influence new venture performance. To generate new insights on this topic, we theorize and empirically investigate to what extent, and under which conditions, the experience of outside board directors affects new venture growth. Our analysis of Norwegian registry data on 15,594 new ventures does not provide immediate evidence that the presence of outside board directors or their experiences drive new venture growth. However, post hoc analysis suggests that the timing of board entry, combined with industry and directorial experience, plays a significant role in shaping growth outcomes. Additionally, the impact of industrial and directorial experience varies depending on the industry environment.
Keywords: Board of directors; Industry experience; Directorial experience; New ventures; New venture growth; Environmental characteristics

Shuning Zheng, Yueqiu Hu, Alain Yee Loong Chong, Chee-Wee Tan,
Leveraging blockchain technology to control contextualized business risks: Evidence from China,
Information & Management,
Volume 59, Issue 7,
2022,
103628,
ISSN 0378-7206,
https://doi.org/10.1016/j.im.2022.103628.
(https://www.sciencedirect.com/science/article/pii/S0378720622000404)
Abstract: The complexity and diversity of socio-economic environments call for a more nuanced consideration of contextualized risks confronting enterprises operating in these environments. By dissecting six cases that successfully adopted blockchain technology in China, we present findings of a grounded theory study into the deployment of blockchain for managing contextualized risks and opportunistic risks. Findings reveal that applying blockchain can augment risk management by controlling opportunistic risk, the latter of which denotes the variability arising from opportunistic practices of internal agents or external parties afforded by their immediate socio-economic environment. Particularly, we not only identify credibility, predatory, and compliance risk as three distinct types of opportunistic risk stemming from the unique socio-economic environment of China, but we also illustrate how blockchain could be leveraged to deal with such opportunistic risks through trust-evoking mechanisms. We discovered that blockchain could evoke trust between individuals-to-organization, organization-to-organization, and organization-to-individuals by bolstering competency, fostering benevolence, and gauging integrity in individual, inter-organizational and intra-organizational contexts, respectively.
Keywords: Blockchain; Risk management; Opportunistic risk; Trust-evoking technology

Chengliang Zheng, Xingyu Tao, Liang Dong, Umer Zukaib, Jingyuan Tang, Haohua Zhou, Jack C.P. Cheng, Xiaohui Cui, Zhidong Shen,
Decentralized artificial intelligence in construction using blockchain,
Automation in Construction,
Volume 166,
2024,
105669,
ISSN 0926-5805,
https://doi.org/10.1016/j.autcon.2024.105669.
(https://www.sciencedirect.com/science/article/pii/S0926580524004059)
Abstract: Alleviating cybersecurity risks associated with centralized AI training and implementation is a burgeoning challenge in the construction industry. This paper addresses two primary questions: (1) What is the knowledge of AI security vulnerability in construction, and (2) How can AI be decentralized using blockchain? To this end, this paper proposes a blockchain-AI integrated framework (BAII), enabling AI to be trained, verified, and applied on a decentralized blockchain. The framework has been successfully validated in an excavator pose recognition scenario, demonstrating acceptable latency and high performance with 95 % accuracy, 94 % precision, and 96 % recall. This research is pivotal for construction managers and IT security professionals, enhancing the reliability and safety of AI applications in construction. The decentralized AI (DAI) approach can also inspire further research into motivating constructors to contribute to AI modeling and training through incentive mechanisms in the blockchain.
Keywords: Artificial intelligence (AI); Blockchain; Smart contract; Decentralized machine learning; Excavator pose recognition

Yueming Hu, Yejun Wang, Xiaotian Hu, Haoyu Chao, Sida Li, Qinyang Ni, Yanyan Zhu, Yixue Hu, Ziyi Zhao, Ming Chen,
T4SEpp: A pipeline integrating protein language models to predict bacterial type IV secreted effectors,
Computational and Structural Biotechnology Journal,
Volume 23,
2024,
Pages 801-812,
ISSN 2001-0370,
https://doi.org/10.1016/j.csbj.2024.01.015.
(https://www.sciencedirect.com/science/article/pii/S2001037024000151)
Abstract: Many pathogenic bacteria use type IV secretion systems (T4SSs) to deliver effectors (T4SEs) into the cytoplasm of eukaryotic cells, causing diseases. The identification of effectors is a crucial step in understanding the mechanisms of bacterial pathogenicity, but this remains a major challenge. In this study, we used the full-length embedding features generated by six pre-trained protein language models to train classifiers predicting T4SEs and compared their performance. We integrated three modules into a model called T4SEpp. The first module searched for full-length homologs of known T4SEs, signal sequences, and effector domains; the second module fine-tuned a machine learning model using data for a signal sequence feature; and the third module used the three best-performing pre-trained protein language models. T4SEpp outperformed other state-of-the-art (SOTA) software tools, achieving ∼0.98 accuracy at a high specificity of ∼0.99, based on the assessment of an independent validation dataset. T4SEpp predicted 13 T4SEs from Helicobacter pylori, including the well-known CagA and 12 other potential ones, among which eleven could potentially interact with human proteins. This suggests that these potential T4SEs may be associated with the pathogenicity of H. pylori. Overall, T4SEpp provides a better solution to assist in the identification of bacterial T4SEs and facilitates studies of bacterial pathogenicity. T4SEpp is freely accessible at https://bis.zju.edu.cn/T4SEpp.
Keywords: T4SEpp; T4SE Prediction; T4SS; Deep learning; Protein language model; Helicobacter pylori T4SEs

Jim Harmening,
Chapter 24 - Information Security Essentials for IT Managers: Protecting Mission-Critical Systems,
Editor(s): John R. Vacca,
Computer and Information Security Handbook (Fourth Edition),
Morgan Kaufmann,
2025,
Pages 423-432,
ISBN 9780443132230,
https://doi.org/10.1016/B978-0-443-13223-0.00024-2.
(https://www.sciencedirect.com/science/article/pii/B9780443132230000242)
Abstract: Good policies and procedures are essential to the success of every information technology (IT) manager. Being agile in a constantly changing world will help you succeed in the long run. Knowing your assets, protecting them, and utilizing a risk-based approach to your security plans, policies, and procedures will make you prosper. Make sure you consider how you are handling data. The three key principles of data confidentiality, integrity, and availability will come in handy.
Keywords: Access control; Application security; Cybersecurity; Cybersecurity framework; Cybersecurity risk management; Cybersecurity supply chain risk management; Encryption; Information security management; Risk management; Security architecture

Leonardo Augusto de Vasconcelos Gomes, Ximena Alejandra Flechas, Ana Lucia Figueiredo Facin, Felipe Mendes Borini,
Ecosystem management: Past achievements and future promises,
Technological Forecasting and Social Change,
Volume 171,
2021,
120950,
ISSN 0040-1625,
https://doi.org/10.1016/j.techfore.2021.120950.
(https://www.sciencedirect.com/science/article/pii/S0040162521003826)
Abstract: The introduction of supply chain management (SCM) between the 1980s and 1990s represented a breakthrough in the field of management. SCM provides the analytical and theoretical background to design, plan, and manage production activities involving complex chains of firms. Nowadays, both production activities and incremental and radical innovation are organized through complex networks. Innovations, especially radical ones, have unique characteristics related to production flows, which generate new challenges for researchers and managers. In this study, we argue that similar to SCM, ecosystem management (EM) represents a potential breakthrough in the field. However, no general framework exists to address EM. To address this challenge, we perform a systematic literature review by adopting a hybrid approach that combines bibliometric analysis and content analysis. Our findings offer a historical perspective of how EM and the ecosystem concept have evolved over three generations. Building on and reaching beyond current scholarship, we propose a definition of ecosystem as a type of meta-organization. We also identify the goals, scope, and boundaries of EM. Our contributions invite scholars to explore old and new questions related to innovation and management in a novel way.
Keywords: Ecosystem management; Innovation ecosystem; Distributed value creation; Supply chain management; New scientific field

Jiale Xiong, Jing Yang, Lei Yan, Muhammad Awais, Abdullah Ayub Khan, Roohallah Alizadehsani, U. Rajendra Acharya,
Efficient reinforcement learning-based method for plagiarism detection boosted by a population-based algorithm for pretraining weights,
Expert Systems with Applications,
Volume 238, Part E,
2024,
122088,
ISSN 0957-4174,
https://doi.org/10.1016/j.eswa.2023.122088.
(https://www.sciencedirect.com/science/article/pii/S0957417423025903)
Abstract: Plagiarism detection (PD) in natural language processing involves locating similar words in two distinct sources. The paper introduces a new approach to plagiarism detection utilizing bidirectional encoder representations from transformers (BERT)-generated embedding, an enhanced artificial bee colony (ABC) optimization algorithm for pre-training, and a training process based on reinforcement learning (RL). The BERT model can be incorporated into a subsequent task and meticulously refined to function as a model, enabling it to apprehend a variety of linguistic characteristics. Imbalanced classification is one of the fundamental obstacles to PD. To handle this predicament, we present a novel methodology utilizing RL, in which the problem is framed as a series of sequential decisions in which an agent receives a reward at each level for classifying a received instance. To address the disparity between classes, it is determined that the majority class will receive a lower reward than the minority class. We also focus on the training stage, which often utilizes gradient-based learning techniques like backpropagation (BP), leading to certain drawbacks such as sensitivity to initialization. In our proposed model, we utilize a mutual learning-based ABC (ML-ABC) approach that adjusts the food source with the most beneficial results for the candidate by considering a mutual learning factor that incorporates the initial weight. We evaluated the efficacy of our novel approach by contrasting its results with those of population-based techniques using three standard datasets, namely Stanford Natural Language Inference (SNLI), Microsoft Research Paraphrase Corpus (MSRP), and Semantic Evaluation Database (SemEval2014). Our model attained excellent results that outperformed state-of-the-art models. Optimal values for important parameters, including reward function are identified for the model based on experiments on the study dataset. Ablation studies that exclude the proposed ML-ABC and reinforcement learning from the model confirm the independent positive incremental impact of these components on model performance.
Keywords: Plagiarism detection; Unbalanced classification; Bidirectional encoder representations from transformers; Artificial bee colony; Reinforcement learning

Lidia Auret,
Machine Learning for Industrial Process Monitoring,
Reference Module in Materials Science and Materials Engineering,
Elsevier,
2024,
,
ISBN 9780128035818,
https://doi.org/10.1016/B978-0-443-14081-5.00014-3.
(https://www.sciencedirect.com/science/article/pii/B9780443140815000143)
Abstract: The safe and efficient operation of industrial processes is a growing concern. As industrial processes have become increasingly automated, more process data is being collected, presenting an opportunity for data-driven process monitoring, albeit in the presence of challenging process characteristics. Statistical and machine learning methods have been applied to process monitoring with general success in the task of fault detection. However, challenges remain in locating faults and providing timely and specific suggestions for interventions to return the process to optimal operations. Practical considerations in machine learning for process monitoring also includes the motivation, design, and maintenance of deployed solutions.
Keywords: Autoencoders; Chemical process control; Fault detection; Fault detection, supervision and safety of technical processes; Fault diagnosis; Fault identification; Kernel methods; Latent variable methods; Machine learning; Mining, mineral and metal processing; Power and energy systems; Process automation; Process monitoring; Process recovery; Tree methods
