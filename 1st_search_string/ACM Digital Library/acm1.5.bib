@inproceedings{10.1145/3627673.3679219,
author = {Xie, Nan and Bai, Yuelin and Gao, Hengyuan and Xue, Ziqiang and Fang, Feiteng and Zhao, Qixuan and Li, Zhijian and Zhu, Liang and Ni, Shiwen and Yang, Min},
title = {DeliLaw: A Chinese Legal Counselling System Based on a Large Language Model},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679219},
doi = {10.1145/3627673.3679219},
abstract = {Traditional legal retrieval systems designed to retrieve legal documents, statutes, precedents, and other legal information are unable to give satisfactory answers due to lack of semantic understanding of specific questions. Large Language Models (LLMs) have achieved excellent results in a variety of natural language processing tasks, which inspired us that we train a LLM in the legal domain to help legal retrieval. However, in the Chinese legal domain, due to the complexity of legal questions and the rigour of legal articles, there is no legal large model with satisfactory practical application yet. In this paper, we present DeliLaw, a Chinese legal counselling system based on a large language model. DeliLaw integrates a legal retrieval module and a case retrieval module to overcome the model hallucination. Users can consult professional legal questions, search for legal articles and relevant judgement cases, etc. on the DeliLaw system in a dialogue mode. In addition, DeliLaw supports the use of English for counseling. we provide the address of the system: https://data.delilegal.com/lawQuestion.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5299–5303},
numpages = {5},
keywords = {guided conversations, large language model, law, legal counselling},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3627673.3679581,
author = {Tang, Zuoli and Huan, Zhaoxin and Li, Zihao and Hu, Shirui and Zhang, Xiaolu and Zhou, Jun and Zou, Lixin and Li, Chenliang},
title = {TEXT CAN BE FAIR: Mitigating Popularity Bias with PLMs by Learning Relative Preference},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679581},
doi = {10.1145/3627673.3679581},
abstract = {Recently, the item textual information has been exploited with pre-trained language models (PLMs) to enrich the representations of tail items. The underlying idea is to align the hot items and tail items in terms of the external semantic knowledge covered by the PLM. However, it is non-trivial to eliminate the popularity bias by exploiting the textual semantics. One major obstacle is that the model supervision still counts on the sparse yet binary user behaviors. In the preliminary investigation, we discover that text-based recommendations also suffer from the popularity bias.To this end, we propose a novel self-distillation framework based on a pre-trained language model, named Staple. The proposed Staple consists of two main components: ranker model and recommender model, which are both instantiated as a PLM towards exploiting the item textual semantics. Motivated by the recent success of reinforcement learning with human feedback (RLHF), the proposed Staple aims to recover the relative preference by learning a fair ranker model that can successfully distinguish the preference levels for uninteracted items. Specifically, analogous to the training of large language models (LLMs), we introduce a pre-training and a fair supervised fine-tuning with a decoupled layer to build the ranker model. Then, similar to RLHF for LLM training, we utilize the relative preference information estimated by the ranker over candidate items to complement the learning of the recommender model. We show that this RLHF process can be reformed as an efficient distillation learning process. We conduct extensive experiments on three real-world datasets. In addition to the performance metrics, we employ two additional metrics to measure fairness and debiased performance. The experiments show that our method can significantly improve the item exposure fairness of recommendation and mitigate popularity bias, while also improving the recommendation performance. The source code is available at https://github.com/WHUIR/STAPLE.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {2240–2249},
numpages = {10},
keywords = {popularity bias, sequential recommendation, text-based recommendation},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3627673.3679582,
author = {Zhu, Yinghao and Ren, Changyu and Wang, Zixiang and Zheng, Xiaochen and Xie, Shiyun and Feng, Junlan and Zhu, Xi and Li, Zhoujun and Ma, Liantao and Pan, Chengwei},
title = {EMERGE: Enhancing Multimodal Electronic Health Records Predictive Modeling with Retrieval-Augmented Generation},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679582},
doi = {10.1145/3627673.3679582},
abstract = {The integration of multimodal Electronic Health Records (EHR) data has significantly advanced clinical predictive capabilities. Existing models, which utilize clinical notes and multivariate time-series EHR data, often fall short of incorporating the necessary medical context for accurate clinical tasks, while previous approaches with knowledge graphs (KGs) primarily focus on structured knowledge extraction. In response, we propose EMERGE, a Retrieval-Augmented Generation (RAG) driven framework to enhance multimodal EHR predictive modeling. We extract entities from both time-series data and clinical notes by prompting Large Language Models (LLMs) and align them with professional PrimeKG, ensuring consistency. In addition to triplet relationships, we incorporate entities' definitions and descriptions for richer semantics. The extracted knowledge is then used to generate task-relevant summaries of patients' health statuses. Finally, we fuse the summary with other modalities using an adaptive multimodal fusion network with cross-attention. Extensive experiments on the MIMIC-III and MIMIC-IV datasets' in-hospital mortality and 30-day readmission tasks demonstrate the superior performance of the EMERGE framework over baseline models. Comprehensive ablation studies and analysis highlight the efficacy of each designed module and robustness to data sparsity. EMERGE contributes to refining the utilization of multimodal EHR data in healthcare, bridging the gap with nuanced medical contexts essential for informed clinical predictions. We have publicly released the code at https://github.com/yhzhu99/EMERGE.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {3549–3559},
numpages = {11},
keywords = {electronic health record, large language model, multimodal learning, retrieval-augmented generation},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3627673.3679608,
author = {Zeng, Qingkai and Bai, Yuyang and Tan, Zhaoxuan and Feng, Shangbin and Liang, Zhenwen and Zhang, Zhihan and Jiang, Meng},
title = {Chain-of-Layer: Iteratively Prompting Large Language Models for Taxonomy Induction from Limited Examples},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679608},
doi = {10.1145/3627673.3679608},
abstract = {Automatic taxonomy induction is crucial for web search, recommendation systems, and question answering. Manual curation of taxonomies is expensive in terms of human effort, making automatic taxonomy construction highly desirable. In this work, we introduce Chain-of-Layer which is an in-context learning framework designed to induct taxonomies from a given set of entities. Chain-of-Layer breaks down the task into selecting relevant candidate entities in each layer and gradually building the taxonomy from top to bottom. To minimize errors, we introduce the Ensemble-based Ranking Filter to reduce the hallucinated content generated at each iteration. Through extensive experiments, we demonstrate that Chain-of-Layer achieves state-of-the-art performance on four real-world benchmarks. Source code available at: https://github.com/qingkaizeng/chain-of-layer.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {3093–3102},
numpages = {10},
keywords = {in-context learning, large language models, taxonomy induction},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3627673.3679722,
author = {Shi, Yucheng and Tan, Qiaoyu and Wu, Xuansheng and Zhong, Shaochen and Zhou, Kaixiong and Liu, Ninghao},
title = {Retrieval-enhanced Knowledge Editing in Language Models for Multi-Hop Question Answering},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679722},
doi = {10.1145/3627673.3679722},
abstract = {Large Language Models (LLMs) have shown proficiency in question-answering tasks but often struggle to integrate real-time knowledge, leading to potentially outdated or inaccurate responses. This problem becomes even more challenging when dealing with multi-hop questions, since they require LLMs to update and integrate multiple knowledge pieces relevant to the questions. To tackle the problem, we propose the Retrieval-Augmented model Editing (RAE) framework for multi-hop question answering. RAE first retrieves edited facts and then refines the language model through in-context learning. Specifically, our retrieval approach, based on mutual information maximization, leverages the reasoning abilities of LLMs to identify chain facts that traditional similarity-based searches might miss. In addition, our framework includes a pruning strategy to eliminate redundant information from the retrieved facts, which enhances the editing accuracy and mitigates the hallucination problem. Our framework is supported by theoretical justification for its fact retrieval efficacy. Finally, comprehensive evaluation across various LLMs validates RAE's ability in providing accurate answers with updated knowledge. Our code is available at: https://github.com/sycny/RAE.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {2056–2066},
numpages = {11},
keywords = {model editing, question answering, retrieval-augmented generation},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3627673.3679730,
author = {Liu, Zihan and Hou, Yupeng and McAuley, Julian},
title = {Multi-Behavior Generative Recommendation},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679730},
doi = {10.1145/3627673.3679730},
abstract = {The task of multi-behavioral sequential recommendation (MBSR) has grown in importance in personalized recommender systems, aiming to incorporate behavior types of interactions for better recommendations. Existing approaches focus on the next-item prediction objective, neglecting the value of integrating the target behavior type into the learning objective. In this paper, we propose MBGen, a novel Multi-Behavioral sequential Generative recommendation framework. We model the MBSR task into a consecutive two-step process: (1) given item sequences, MBGen first predicts the next behavior type to frame the user intention, (2) given item sequences and a target behavior type, MBGen then predicts the next items. To model such a two-step process, we tokenize both behaviors and items into tokens and construct one single token sequence with both behaviors and items placed interleaved. Furthermore, we design a unified generative recommendation paradigm that learns to autoregressive generate next behavior and item tokens, naturally enabling a multi-task capability. Additionally, we exploit the heterogeneous nature of token sequences in the generative recommendation and propose a position-routed sparse architecture to efficiently scale up models under the generative recommendation paradigm. Extensive experiments on real-world public datasets demonstrate that MBGen significantly outperforms existing MBSR models across multiple tasks.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {1575–1585},
numpages = {11},
keywords = {generative recommendation, multi-behavior modeling, sequential recommendation},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3627673.3679789,
author = {Chen, Jizheng and Du, Kounianhua and Lin, Jianghao and Chen, Bo and Tang, Ruiming and Zhang, Weinan and Yu, Yong},
title = {ELCoRec: Enhance Language Understanding with Co-Propagation of Numerical and Categorical Features for Recommendation},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679789},
doi = {10.1145/3627673.3679789},
abstract = {Large language models have been flourishing in the natural language processing (NLP) domain, and their potential for recommendation has been paid much attention to. Despite the intelligence shown by the recommendation-oriented finetuned models, LLMs struggle to fully understand the user behavior patterns due to their innate weakness in interpreting numerical features and the overhead for long context, where the temporal relations among user behaviors, subtle quantitative signals among different ratings, and various side features of items are not well explored. Existing works only fine-tune a sole LLM on given text data without introducing that important information to it, leaving these problems unsolved. In this paper, we propose ELCoRec to Enhance Language understanding with Co-Propagation of numerical and categorical features for Recommendation. Concretely, we propose to inject the preference understanding capability into LLM via a GAT expert model where the user preference is better encoded by parallelly propagating the temporal relations, and rating signals as well as various side information of historical items. The parallel propagation mechanism could stabilize heterogeneous features and offer an informative user preference encoding, which is then injected into the language models via soft prompting at the cost of a single token embedding. To further obtain the user's recent interests, we proposed a novel Recent interaction Augmented Prompt (RAP) template. Experiment results over three datasets against strong baselines validate the effectiveness of ELCoRec.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {259–269},
numpages = {11},
keywords = {graph attention network, large language model, prompt engineering, sequential recommendation},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3636534.3690668,
author = {Laskaridis, Stefanos and Katevas, Kleomenis and Minto, Lorenzo and Haddadi, Hamed},
title = {MELTing Point: Mobile Evaluation of Language Transformers},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690668},
doi = {10.1145/3636534.3690668},
abstract = {Transformers have recently revolutionized the machine learning (ML) landscape, gradually making their way into everyday tasks and equipping our computers with "sparks of intelligence". However, their runtime requirements have prevented them from being broadly deployed on mobile. As personal devices become increasingly powerful at the consumer edge and prompt privacy becomes an ever more pressing issue, we explore the current state of mobile execution of Large Language Models (LLMs). To achieve this, we have created our own automation infrastructure, MELT, which supports the headless execution and benchmarking of LLMs on device, supporting different models, devices and frameworks, including Android, iOS and Nvidia Jetson devices. We evaluate popular instruction fine-tuned LLMs and leverage different frameworks to measure their end-to-end and granular performance, tracing their memory and energy requirements along the way.Our analysis is the first systematic study of on-device LLM execution, quantifying performance, energy efficiency and accuracy across various state-of-the-art models and showcases the state of on-device intelligence in the era of hyperscale models. Results highlight the performance heterogeneity across targets and corroborates that LLM inference is largely memory-bound. Quantization drastically reduces memory requirements and renders execution viable, but at a non-negligible accuracy cost. Drawing from its energy footprint and thermal behavior, the continuous execution of LLMs remains elusive, as both factors negatively affect user experience. Last, our experience shows that the ecosystem is still in its infancy, and algorithmic as well as hardware break-throughs can significantly shift the execution cost. We expect NPU acceleration, and framework-hardware co-design to be the biggest bet towards efficient standalone execution, with the alternative of offloading tailored towards edge deployments.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {890–907},
numpages = {18},
keywords = {machine learning, mobile systems, large language models},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}

@inproceedings{10.1145/3636534.3690684,
author = {Khalili, Hossein and Park, Seongbin and Li, Vincent and Bright, Brandan and Payani, Ali and Kompella, Ramana Rao and Sehatbakhsh, Nader},
title = {LightPure: Realtime Adversarial Image Purification for Mobile Devices Using Diffusion Models},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690684},
doi = {10.1145/3636534.3690684},
abstract = {Autonomous mobile systems increasingly rely on deep neural networks for perception and decision-making. While effective, these systems are vulnerable to adversarial machine learning attacks where small perturbations in the input could significantly impact the outcome of the system. Common countermeasures include leveraging adversarial training and/or data or network transformation. Although widely used, the main drawback of these countermeasures is that they require full and invasive access to the classifiers, which are typically proprietary. Additionally, the cost of training or retraining is often prohibitively expensive for large models. To tackle this, purification models have recently been proposed. The aim is to incorporate a "purification" layer before classification, thereby eliminating the necessity to modify the classifier. Despite their effectiveness, state-of-the-art purification methods are compute-intensive, rendering them unsuitable for mobile systems where resources are constrained and large latency is not desired.This paper presents a new approach, LightPure, that enhances the purification of adversarial images. It improves the accuracy of the current leading purification methods while also providing notable enhancements in speed and computational efficiency, making it suitable for mobile devices with limited resources. Our approach uses a two-step diffusion and one-shot Generative Adversarial Network (GAN) framework for purification, prioritizing latency without compromising robustness. We propose several new techniques in designing our model to achieve a reasonable balance between classification accuracy and adversarial robustness while maintaining a desired latency. We design and implement a proof-of-concept on a Jetson Nano board and evaluate our method using several attack scenarios and datasets. Our results show that LightPure can outperform existing purification methods by up to 10x in terms of latency while achieving higher accuracy and robustness for various black-, gray-, and white-box attack scenarios. The fusion of speed and robust defense mechanisms positions our method as a significant advancement in the field of adversarial image purification, offering a scalable and effective solution for real-world mobile systems.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1147–1161},
numpages = {15},
keywords = {autonomous mobile system, adversarial machine learning, diffusion models},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}

@proceedings{10.1145/3641237,
title = {SIGDOC '24: Proceedings of the 42nd ACM International Conference on Design of Communication},
year = {2024},
isbn = {9798400705199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Fairfax, VA, USA}
}

@inproceedings{10.1145/3641237.3691693,
author = {Kasierski, Benjamin and Fagnano, Emma},
title = {Optimizing the Grant Writing Process: A Framework for Creating a Grant Writing Assistant Using ChatGPT 4},
year = {2024},
isbn = {9798400705199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641237.3691693},
doi = {10.1145/3641237.3691693},
abstract = {This extended abstract explores prompt engineering strategies and usability testing that can be applied to create a grant writing assistant using ChatGPT 4. Utilizing scholarly literature from the past 3 years concerning LLM development, AI integration, and prompt engineering, along with White et al's experimental prompt pattern catalog [13] for software engineering, and previously accepted grants from a given institution, ChatGPT 4 can be applied to create a transferable template that streamlines the grant writing process. By following the frameworks outlined in the literature and guidelines for potential applications, we propose that grant writers can integrate a more efficient grant writing process that reduces confusion in understanding NSF's guidelines and criteria, helps to articulate clear and achievable objectives, and improves proposal alignment with NSF's strategic priorities.},
booktitle = {Proceedings of the 42nd ACM International Conference on Design of Communication},
pages = {286–291},
numpages = {6},
keywords = {Artificial Intelligence, ChatGPT, NSF, National Science Foundation, grant writing, large language models},
location = {Fairfax, VA, USA},
series = {SIGDOC '24}
}

@proceedings{10.1145/3641554,
title = {SIGCSETS 2025: Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 56th annual SIGCSE Technical Symposium on Computer Science Education (SIGCSE TS 2025)! For the first time since 1978, our symposium is being held in the "Steel City" of Pittsburgh, Pennsylvania, at the intersection of the Allegheny, Ohio, and Monongahela rivers. We are looking forward to four days of productive and informative presentations, vibrant and engaging discussions, and an overall wonderful experience with our SIGCSE community members. We are confident that our program of events provides meaningful and productive experiences for all.Our theme for this year is "Leading the Transformation". Our theme reflects the role of the computer science education community in adapting educational practice to new technologies and challenges. With advances in Artificial Intelligence (AI) transforming both academia and the workplace, the computer science education community has a unique opportunity to help shape the future use and application of computing. Our program this year is quite diverse and offers something for everyone, so please take time to peruse the schedule and choose the sessions which appeal to you. Pittsburgh is also an exciting city with lots to see and do, so you are encouraged to enjoy all the city has to offer.The format of the 2025 Technical Symposium is similar to 2024 in many ways. We will once again have a program that extends into Saturday afternoon, including papers and the Nifty Assignment session after lunch. We will also again have three Birds-of-a-Feather sessions, two on Thursday evening and one during lunch on Friday. For online attendees, we will continue to offer streaming of keynotes, the Nifty Assignment session, the First-Timers Lunch presentation, and a small set of paper, panel, and special sessions.This year we received almost 1200 submissions. Submission statistics for all of the Technical Symposium's tracks can be found in the table that follows. Papers were submitted to one of three tracks (Computing Education Research, Experience Reports and Tools, Position and Curricula Initiatives) with reviewing tailored to each track. Each paper submission was reviewed by at least three reviewers, with a substantial proportion of papers receiving four (or more) reviews, plus a meta review. We sincerely appreciate the work of the more than 800 reviewers and 112 Associate Program Chairs who contributed to the creation of this years' program. Their reviews helped us decide which submissions were accepted while also providing detailed feedback that allowed authors to further improve the final versions of their submissions.},
location = {Pittsburgh, PA, USA}
}

@inproceedings{10.1145/3641554.3701827,
author = {Renzella, Jake and Vassar, Alexandra and Lee Solano, Lorenzo and Taylor, Andrew},
title = {Compiler-Integrated, Conversational AI for Debugging CS1 Programs},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701827},
doi = {10.1145/3641554.3701827},
abstract = {Large Language Models (LLMs) present a transformative opportunity to address longstanding challenges in computing education. This paper presents a conversational AI extension to an LLM-enhanced C/C++ compiler which generates pedagogically sound programming error explanations. Our new tool, DCC Sidekick, retains compiler integration, allowing students to see their code, error messages, and stack frames alongside a conversational AI interface. Compiler context improves error explanations, and provides a seamless development experience. We present quantitative analyses of Sidekick's usage and engagement patterns in a large CS1 course. In the first seven weeks of use, 959 students initiated 11,222 DCC Sidekick sessions, generating 17,982 error explanations. Over half of all conversations occur outside of business hours, highlighting the value of these always-available tools. Early results indicate strong adoption of conversational AI debugging tools, demonstrating scalability in supporting large CS1 courses. We share implementation details and lessons learned, offering guidance to educators considering integrating AI tools with pedagogical guardrails.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {994–1000},
numpages = {7},
keywords = {ai in education, cs1, generative ai, programming error messages},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701841,
author = {Aljedaani, Wajdi and Eler, Marcelo Medeiros and Parthasarathy, P D},
title = {Enhancing Accessibility in Software Engineering Projects with Large Language Models (LLMs)},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701841},
doi = {10.1145/3641554.3701841},
abstract = {Digital accessibility ensures that digital products and services are usable by a diverse range of users, regardless of their physical or cognitive abilities. While numerous standards and guidelines have been established to aid developers in creating accessible content, studies reveal a persistent lack of accessibility in many web and mobile applications. This gap is often attributed to barriers such as lack of awareness, insufficient knowledge, absence of specific requirements, time constraints, and lack of executive support. In this context, we aim to address the lack of awareness and knowledge challenges by proposing a hands-on approach that leverages the capabilities of Large Language Models (LLMs) like ChatGPT to enhance students' accessibility awareness, knowledge, and practical skills. We engaged software engineering students in tasks involving website development and accessibility evaluation using checker tools, and we utilized ChatGPT 3.5 to fix identified accessibility issues. Our findings suggest that practical assignments significantly enhance learning outcomes, as interactions with LLMs allow students to develop a deeper understanding of accessibility concepts. This approach not only reinforces theoretical knowledge but also highlights the real-world impact of their work. The results indicate that combining practical assignments with AI-driven support effectively improves students' proficiency in web accessibility.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {25–31},
numpages = {7},
keywords = {chatgpt 3.5, digital accessibility, large language models, llms, project based learning, software engineering, wcag},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701844,
author = {Yu, Zezhu and Liu, Suqing and Denny, Paul and Bergen, Andreas and Liut, Michael},
title = {Integrating Small Language Models with Retrieval-Augmented Generation in Computing Education: Key Takeaways, Setup, and Practical Insights},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701844},
doi = {10.1145/3641554.3701844},
abstract = {Leveraging a Large Language Model (LLM) for personalized learning in computing education is promising, yet cloud-based LLMs pose risks around data security and privacy. To address these concerns, we developed and deployed a locally stored Small Language Model (SLM) utilizing Retrieval-Augmented Generation (RAG) methods to support computing students' learning. Previous work has demonstrated that SLMs can match or surpass popular LLMs (gpt-3.5-turbo and gpt-4-32k) in handling conversational data from a CS1 course. We deployed SLMs with RAG (SLM + RAG) in a large course with more than 250 active students, fielding nearly 2,000 student questions, while evaluating data privacy, scalability, and feasibility of local deployments. This paper provides a comprehensive guide for deploying SLM + RAG systems, detailing model selection, vector database choice, embedding methods, and pipeline frameworks. We share practical insights from our deployment, including scalability concerns, accuracy versus context length trade-offs, guardrails and hallucination reduction, as well as data privacy maintenance. We address the "Impossible Triangle" in RAG systems, which states that achieving high accuracy, short context length, and low time consumption simultaneously is not feasible. Furthermore, our novel RAG framework, Intelligence Concentration (IC), categorizes information into multiple layers of abstraction within Milvus collections mitigating trade-offs and enabling educational assistants to deliver more relevant and personalized responses to students quickly.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1302–1308},
numpages = {7},
keywords = {computer science education, computing education, conversational agent, intelligence concentration, intelligent tutoring system, large language models, milvus, personalized ai agent, retrieval-augmented generation, small language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701862,
author = {Challen, Geoffrey and Nordick, Ben},
title = {Accelerating Accurate Assignment Authoring Using Solution-Generated Autograders},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701862},
doi = {10.1145/3641554.3701862},
abstract = {Students learning to program benefit from access to large numbers of practice problems. Autograders are commonly used to support programming questions by providing quick feedback on submissions. But authoring accurate autograders remains challenging. Autograders are frequently created by enumerating test cases-a tedious process that can produce inaccurate autograders that fail to correctly classify submissions. When authoring accurate autograders is slow, it is difficult to create large banks of practice problems to support beginning programmers.We present solution-generated autograding: a faster, more accurate, and more enjoyable way to create autograders. Our approach leverages a key difference between software testing and autograding: The question author can provide a solution. By starting with a solution, we can eliminate the need to manually enumerate test cases, validate the autograder's accuracy, and evaluate other aspects of submission code quality beyond behavioral correctness. We describe Questioner, an implementation of solution-generated autograding for Java and Kotlin, and share experiences from four years using Questioner to support a large CS1 course: authoring nearly 800 programming questions used by thousands of students to evaluate millions of submissions.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {227–233},
numpages = {7},
keywords = {autograding, code quality evaluation, problem authoring},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701872,
author = {McDanel, Bradley and Novak, Ed},
title = {Designing LLM-Resistant Programming Assignments: Insights and Strategies for CS Educators},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701872},
doi = {10.1145/3641554.3701872},
abstract = {The rapid advancement of Large Language Models (LLMs) like ChatGPT has raised concerns among computer science educators about how programming assignments should be adapted. This paper explores the capabilities of LLMs (GPT-3.5, GPT-4, and Claude Sonnet) in solving complete, multi-part CS homework assignments from the SIGCSE Nifty Assignments list. Through qualitative and quantitative analysis, we found that LLM performance varied significantly across different assignments and models, with Claude Sonnet consistently outperforming the others. The presence of starter code and test cases improved performance for advanced LLMs, while certain assignments, particularly those involving visual elements, proved challenging for all models. LLMs often disregarded assignment requirements, produced subtly incorrect code, and struggled with context-specific tasks. Based on these findings, we propose strategies for designing LLM-resistant assignments. Our work provides insights for instructors to evaluate and adapt their assignments in the age of AI, balancing the potential benefits of LLMs as learning tools with the need to ensure genuine student engagement and learning.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {756–762},
numpages = {7},
keywords = {ai-resistant assignments, assignment design, cs education, llm code generation, programming pedagogy},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701912,
author = {Li, Miranda and Malik, Ali and Piech, Chris},
title = {Fostering and Understanding Diverse Interpersonal Connections in a Massive Online CS1 Course},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701912},
doi = {10.1145/3641554.3701912},
abstract = {Forming social relationships is critical to student success and well-being, but is one of the first aspects to be neglected in the design of massive online courses. We present our experience deploying an in-course networking tool that enabled 1,600+ learners and teachers in a massive online CS1 course to form 2,000+ connections with other individuals. We discuss how social preferences and networking goals vary by demographics, economic factors, course goals, and course role. Contrary to usual online social behavior, users in our network sent more out-group requests than a random baseline by role (2.04x), gender (1.1x), and developing vs. developed country (1.07x). We highlight differences between developing vs. developed country users: developing country users send 2.5x requests and make, on average, 1.78x as many connections as those from developed countries. From a randomized control trial we find that random recommendations increase the volume of sent requests by 44.48\% and promote cross-group requests across developing vs. developed countries (+28.9\%), age (+15.1\%), and gender (+8.6\%). Ultimately we show that integrating socialization as a core feature of online CS1 classrooms can help support people from all backgrounds in achieving their diverse educational goals, which often extend well beyond improving coding proficiency.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {666–672},
numpages = {7},
keywords = {mooc, online learning, social network analysis, social presence},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701942,
author = {Liu, Zifeng and Jiao, Xinyue and Xing, Wanli and Zhu, Wangda},
title = {Detecting AI-Generated Pseudocode in High School Online Programming Courses Using an Explainable Approach},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701942},
doi = {10.1145/3641554.3701942},
abstract = {Despite extensive research on code plagiarism detection in higher education and for programming languages like Java and Python, limited work has focused on K-12 settings, particularly for pseudocode. This study aims to address this gap by building explainable machine learning models for pseudocode plagiarism detection in online programming education. To achieve this, we construct a comprehensive dataset comprising 7,838 pseudocode submissions from 2,578 high school students enrolled in an online programming foundations course, along with 6,300 pseudocode samples generated by three versions of generative pre-trained transformer (GPT) models. Utilizing this dataset, we develop an explainable model to detect AI-generated pseudocode across various assessments. The model not only identifies AI-generated content but also provides insights into its predictions at both the student and problem levels, thus enhancing our understanding of AI-generated pseudocode in K-12 education. Furthermore, we analyzed SHAP values and key features of the model to pinpoint student submissions that closely resemble AI-generated pseudocode. This research offers implications for developing robust educational technologies and methodologies to uphold academic integrity in online programming courses.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {701–707},
numpages = {7},
keywords = {ai-generated content, explainable ai, gpt model, online programming education, plagiarism detection, pseudocode},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701965,
author = {Miroyan, Mihran and Mitra, Chancharik and Jain, Rishi and Ranade, Gireeja and Norouzi, Narges},
title = {Analyzing Pedagogical Quality and Efficiency of LLM Responses with TA Feedback to Live Student Questions},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701965},
doi = {10.1145/3641554.3701965},
abstract = {While Large Language Models (LLMs) have emerged as promising methods for automated student question-answering, guaranteeing consistent instructional effectiveness of the response remains a key challenge. Therefore, there is a need for fine-grained analysis of State-Of-The-Art (SOTA) LLM-powered educational assistants.  This work evaluates Edison: a Retrieval Augmented Generation (RAG) pipeline based on GPT-4. We determine the pedagogical effectiveness of Edison's responses through expert Teaching Assistant (TA) evaluation of the answers. After the TA edits and improves the response, we analyze the original LLM response, the TA-assigned ratings, and the TA's edits to ascertain the essential characteristics of a high-quality response. Some key insights of our evaluation are as follows: (1) Edison can give relevant and factual answers in an educational style for conceptual and assignment questions, (2) Most TA edits are deletions made to improve the style of the response, and finally (3) Our analysis indicates that Edison improves TAs' efficiency by reducing the effort required to respond to student questions.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {770–776},
numpages = {7},
keywords = {expert feedback, instructional technologies, language models, question answering},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@proceedings{10.1145/3641555,
title = {SIGCSETS 2025: Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 56th annual SIGCSE Technical Symposium on Computer Science Education (SIGCSE TS 2025)! For the first time since 1978, our symposium is being held in the "Steel City" of Pittsburgh, Pennsylvania, at the intersection of the Allegheny, Ohio, and Monongahela rivers. We are looking forward to four days of productive and informative presentations, vibrant and engaging discussions, and an overall wonderful experience with our SIGCSE community members. We are confident that our program of events provides meaningful and productive experiences for all.Our theme for this year is "Leading the Transformation". Our theme reflects the role of the computer science education community in adapting educational practice to new technologies and challenges. With advances in Artificial Intelligence (AI) transforming both academia and the workplace, the computer science education community has a unique opportunity to help shape the future use and application of computing. Our program this year is quite diverse and offers something for everyone, so please take time to peruse the schedule and choose the sessions which appeal to you. Pittsburgh is also an exciting city with lots to see and do, so you are encouraged to enjoy all the city has to offer.The format of the 2025 Technical Symposium is similar to 2024 in many ways. We will once again have a program that extends into Saturday afternoon, including papers and the Nifty Assignment session after lunch. We will also again have three Birds-of-a-Feather sessions, two on Thursday evening and one during lunch on Friday. For online attendees, we will continue to offer streaming of keynotes, the Nifty Assignment session, the First-Timers Lunch presentation, and a small set of paper, panel, and special sessions.This year we received almost 1200 submissions. Submission statistics for all of the Technical Symposium's tracks can be found in the table that follows. Papers were submitted to one of three tracks (Computing Education Research, Experience Reports and Tools, Position and Curricula Initiatives) with reviewing tailored to each track. Each paper submission was reviewed by at least three reviewers, with a substantial proportion of papers receiving four (or more) reviews, plus a meta review. We sincerely appreciate the work of the more than 800 reviewers and 112 Associate Program Chairs who contributed to the creation of this years' program. Their reviews helped us decide which submissions were accepted while also providing detailed feedback that allowed authors to further improve the final versions of their submissions.},
location = {Pittsburgh, PA, USA}
}

@proceedings{10.1145/3646547,
title = {IMC '24: Proceedings of the 2024 ACM on Internet Measurement Conference},
year = {2024},
isbn = {9798400705922},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to ACM IMC 2024 in Madrid!We are thrilled to host you in the vibrant city of Madrid, a historical and cultural hub, for this year's ACM Internet Measurement Conference. As we gather in the iconic Espacio Telef\'{o}nica to discuss the latest advances in network measurement, we continue to face evolving challenges and opportunities in this dynamic research field. IMC 2024 maintains a strong focus on reproducibility and data sharing, aiming to foster transparency and collaboration within our community.This year, we are privileged to have an exceptional program curated by our Program Chairs, Dave Levin (University of Maryland) and Cristel Pelsser (KU Louvain). Their hard work, along with contributions from all members of the organizing committee, ensures a high-quality program with 55 insightful paper presentations, 45 posters, and discussions, covering topics from Cellular and wireless networks to Security \&amp; Privacy. The technical program is enriched by an opening keynote from Prof. Alan Mislove and several social and cultural activities, including a guided tour of the renowned art collection at the Thyssen-Bornemisza Museum. Together, these activities will not only advance our understanding of network performance, structure, and behavior but also foster new collaborations among community members.We are particularly proud of our efforts to promote diversity and inclusivity at IMC 2024, offering student travel grants, diversity grants, and expanding outreach to members of our global community, particularly in developing countries. These initiatives aim to ensure a more diverse, inclusive, and representative group of participants, enriching the conference with varied perspectives.},
location = {Madrid, Spain}
}

@inproceedings{10.1145/3646547.3688433,
author = {Yang, Han and Kuzniar, Carson and Jiang, Chengyan and Nikolaidis, Ioanis and Haque, Israat},
title = {Characterizing the Security Facets of IoT Device Setup},
year = {2024},
isbn = {9798400705922},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3646547.3688433},
doi = {10.1145/3646547.3688433},
abstract = {In this work, we characterize the potential information leakage from IoT platforms during their setup phase. Setup involves an IoT device, its ''app'', and a cloud-based service. We assume that the on-device firmware is inaccessible, e.g., read-protected. We focus on the combination of information that can be extracted from analyzing the app and the local communication between the app and the IoT device. An attacker can trivially obtain the app, analyze its operation, and potentially eavesdrop on the wireless communication occurring during the setup phase. We develop a semi-automated general methodology involving off-the-shelf tools to examine information disclosure during the setup phase. We tested our methodology on twenty commodity-grade IoT devices. The outcome reveals a wide range of device-dependent choices for encryption at various layers and the potential for exposure of, among other things, device-identifying information and local networking (WiFi) credentials. Our methodology contributes towards a means to assess and ''certify'' IoT devices.},
booktitle = {Proceedings of the 2024 ACM on Internet Measurement Conference},
pages = {612–621},
numpages = {10},
keywords = {information leakage, iot, setup security, smart home},
location = {Madrid, Spain},
series = {IMC '24}
}

@inproceedings{10.1145/3646547.3689011,
author = {Sun, Danyu and Chen, Joann Qiongna and Gong, Chen and Wang, Tianhao and Li, Zhou},
title = {NetDPSyn: Synthesizing Network Traces under Differential Privacy},
year = {2024},
isbn = {9798400705922},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3646547.3689011},
doi = {10.1145/3646547.3689011},
abstract = {As the utilization of network traces for the network measurement research becomes increasingly prevalent, concerns regarding privacy leakage from network traces have garnered the public's attention. To safeguard network traces, researchers have proposed the trace synthesis that retains the essential properties of the raw data. However, previous works also show that synthesis traces with generative models are vulnerable under linkage attacks.This paper introduces NetDPSyn, the first system to synthesize high-fidelity network traces under privacy guarantees. NetDPSyn is built with the Differential Privacy (DP) framework as its core, which is significantly different from prior works that apply DP when training the generative model. The experiments conducted on three flow and two packet datasets indicate that NetDPSyn achieves much better data utility in downstream tasks like anomaly detection. NetDPSyn is also 2.5 times faster than the other methods on average in data synthesis.},
booktitle = {Proceedings of the 2024 ACM on Internet Measurement Conference},
pages = {545–554},
numpages = {10},
keywords = {differential privacy, network flows, network packets, synthetic data generation},
location = {Madrid, Spain},
series = {IMC '24}
}

@inproceedings{10.1145/3646547.3689015,
author = {Huang, Ziyuan and Tang, Jiaming and Karir, Manish and Liu, Mingyan and Sarabi, Armin},
title = {Analyzing Corporate Privacy Policies using AI Chatbots},
year = {2024},
isbn = {9798400705922},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3646547.3689015},
doi = {10.1145/3646547.3689015},
abstract = {In this paper, we present and evaluate an automated pipeline for the large-scale analysis of corporate privacy policies. Organizations usually develop their privacy policies in isolation to best balance their business needs, user rights, as well as regulatory requirements. A wide-ranging and structured analysis of corporate privacy policies is essential to facilitate a deeper understanding of how organizations have balanced competing requirements. Our approach consists of a web crawler that can navigate to and scrape content from web pages that contain privacy policies, and a set of AI chatbot task prompts to process and extract structured/labeled annotations from the raw data. The analysis includes the types of collected user data, the purposes for which data is collected and processed, data retention and protection practices, and user rights and choices. Our validation shows that our annotations are highly accurate and consistent. We use this architecture to gather data on the privacy policies of companies in the Russell 3000 index, resulting in hundreds of thousands of annotations across all categories. Analysis of the resulting data allows us to obtain unique insights into the state of the privacy policy ecosystem as a whole.},
booktitle = {Proceedings of the 2024 ACM on Internet Measurement Conference},
pages = {505–515},
numpages = {11},
keywords = {ai chatbots, large language models, privacy policies, text annotation, web crawling},
location = {Madrid, Spain},
series = {IMC '24}
}

@proceedings{10.1145/3649165,
title = {SIGCSE Virtual 2024: Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of SIGCSE Virtual 2024 Steering, Organization, and Program Committees, we would like to welcome you to this wonderful event. SIGCSE Virtual 2024, 1st ACM Virtual Global Computing Education Conference is now a reality after over a year of work by all the committee members. We like to send our special thanks to the SIGCSE Board and ACM for their continued support, encouragement and facilitation.One of the major goals of SIGCSE Virtual is to promote an inclusive and easily accessible conference to all interested in CS education research and practice. The hope is to allow those who are not able to easily travel to SIGCSE conferences to participate virtually from around the world. For this reason, the core of the conference follows all other SIGCSE conferences by providing papers, panels, posters/lightning talks, working groups, and doctoral consortium sessions dedicated to CS education research and practice.The conference has different themes based on the global aspects of CS education while considering regional circumstances. The sessions are offered considering time-zone constraints. The online program adjusts to time zones.Several different activities are provided besides the technical sessions by conference sponsors as well as for social engagements. All these activities are included in the program.},
location = {Virtual Event, NC, USA}
}

@inproceedings{10.1145/3649165.3690094,
author = {Ma, Iris and Krone-Martins, Alberto and Videira Lopes, Cristina},
title = {Integrating AI Tutors in a Programming Course},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690094},
doi = {10.1145/3649165.3690094},
abstract = {RAGMan is an LLM-powered tutoring system that can support a variety of course-specific and homework-specific AI tutors. RAGMan leverages Retrieval Augmented Generation (RAG), as well as strict instructions, to ensure the alignment of the AI tutors' responses. By using RAGMan's AI tutors, students receive assistance with their specific homework assignments without directly obtaining solutions, while also having the ability to ask general programming-related questions.  RAGMan was deployed as an optional resource in an introductory programming course with an enrollment of 455 students. It was configured as a set of five homework-specific AI tutors. This paper describes the interactions the students had with the AI tutors, the students' feedback, and a comparative grade analysis. Overall, about half of the students engaged with the AI tutors, and the vast majority of the interactions were legitimate homework questions. When students posed questions within the intended scope, the AI tutors delivered accurate responses 98\% of the time. Among the students who used AI tutors, 78\% reported that the tutors helped their learning. Beyond AI tutors' ability to provide valuable suggestions, students reported appreciating them for fostering a safe learning environment free from judgment.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {130–136},
numpages = {7},
keywords = {education, large language models, llms, software engineering},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3649165.3703623,
author = {Ravi, Prerna and Parks, Robert and Masla, John and Abelson, Hal and Breazeal, Cynthia},
title = {"Data comes from the real world": A Constructionist Approach to Mainstreaming K12 Data Science Education},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3703623},
doi = {10.1145/3649165.3703623},
abstract = {Data science is emerging as a crucial 21st-century competence, influencing professional practices from citing evidence when advocating for social change to developing artificial intelligence (AI) models. For middle and high school students, data science can put formerly decontextualized subjects into real-world scenarios. Many existing curricula, however, lack authenticity and personal relevance for students. A critique of data science courseware cites the lack of "author proximity," in which students do not contribute to the data's production or see their personal experiences reflected in the data. This paper introduces a novel data science curriculum to scaffold middle and high school students in undertaking real-world data science practices. Through project-based learning modules, the curriculum engages students in investigating solutions to community-based problems through visualization and analysis of live sensor data and public data sets. Materials include formative assessments to help educators (especially those from non-math and computing backgrounds) measure their students' abilities to identify statistical patterns, critically evaluate data biases, and make predictions. As we pilot and co-design with teachers, we will look closely at whether the curriculum's resources can successfully support non-technical practitioners engaging in an integrated curriculum.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {271–274},
numpages = {4},
keywords = {computational action, k12 data science, participatory data collection, project-based learning, sensors},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@proceedings{10.1145/3649409,
title = {SIGCSE Virtual 2024: Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of SIGCSE Virtual 2024 Steering, Organization, and Program Committees, we would like to welcome you to this wonderful event. SIGCSE Virtual 2024, 1st ACM Virtual Global Computing Education Conference is now a reality after over a year of work by all the committee members. We like to send our special thanks to the SIGCSE Board and ACM for their continued support, encouragement and facilitation.One of the major goals of SIGCSE Virtual is to promote an inclusive and easily accessible conference to all interested in CS education research and practice. The hope is to allow those who are not able to easily travel to SIGCSE conferences to participate virtually from around the world. For this reason, the core of the conference follows all other SIGCSE conferences by providing papers, panels, posters/lightning talks, working groups, and doctoral consortium sessions dedicated to CS education research and practice.The conference has different themes based on the global aspects of CS education while considering regional circumstances. The sessions are offered considering time-zone constraints. The online program adjusts to time zones.Several different activities are provided besides the technical sessions by conference sponsors as well as for social engagements. All these activities are included in the program.},
location = {Virtual Event, NC, USA}
}

@inproceedings{10.1145/3652620.3687784,
author = {Ardimento, Pasquale and Bernardi, Mario Luca and Cimitile, Marta and Scalera, Michele},
title = {A RAG-based Feedback Tool to Augment UML Class Diagram Learning},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687784},
doi = {10.1145/3652620.3687784},
abstract = {This paper introduces an advanced functionality designed to facilitate the learning of UML class diagram construction. Built upon an integrated Retrieval Augmented Generation Large Language Model, the functionality provides enriched feedback by leveraging accumulated knowledge. The functionality is implemented in an existing tool named UML Miner, a Visual Paradigm plugin that captures and analyzes student-generated UML diagrams by applying process mining techniques. By offering personalized feedback and continuous support during modeling, the tool aims to enhance learning outcomes and students' engagement.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {26–30},
numpages = {5},
keywords = {learning, UML, software modeling, retrieval augmented generation, large language model, tool},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3652620.3687804,
author = {Birchler De Allende, Alan and Sultan, Bastien and Apvrille, Ludovic},
title = {From Attack Trees to Attack-Defense Trees with Generative AI \&amp; Natural Language Processing},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687804},
doi = {10.1145/3652620.3687804},
abstract = {Attack-defense trees, an extension of attack trees, are extensively used by security engineers to document potential countermeasures for security threats present in a system's design. These trees help integrate initial system models with countermeasures, allowing for early testing of their efficiency and impact in the design cycle. Despite advancements in automating attack tree construction, selecting the initial set of countermeasures for conversion into an attack-defense tree remains largely manual. This paper proposes an approach and a tool that extends the TTool-AI attack tree generation feature by leveraging large language models and natural language processing to create a set of countermeasures and generate attack-defense trees based on an input attack tree. To evaluate our contribution, our approach is tested using attack-defense trees generated from attack trees, each representing possible threats to an associated system specification. In addition, we introduce metrics to assess the semantic correctness and completeness of the generated attack-defense trees. We compared, using our metrics, the attack-defense trees created from our methodology to those created by an engineer and found that attack-defense trees created using AI and secondary mitigation data provided better trees than solely using AI. We also discovered that this approach generated trees that were comparable to the quality of attack-defense trees generated from a security engineer at the associate level. From these results, we believe that our contribution could aid engineers in identifying not only appropriate countermeasures for attack trees but also the optimal number of countermeasures, avoiding the complexity of redundant mitigations. Furthermore, our approach complements standard modeling practices, particularly during the initial design phase, reducing the need for time-consuming re-engineering throughout the system's lifecycle.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {561–569},
numpages = {9},
keywords = {artificial intelligence, large-language models, attack-defense trees, model-driven engineering},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3652620.3688557,
author = {Manellanga, Rajitha and David, Istvan},
title = {Participatory and Collaborative Modeling of Sustainable Systems: A Systematic Review},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3688557},
doi = {10.1145/3652620.3688557},
abstract = {Sustainability has become a key characteristic of modern systems. Unfortunately, the convoluted nature of sustainability limits its understanding and hinders the design of sustainable systems. Thus, cooperation among a diverse set of stakeholders is paramount to sound sustainability-related decisions. Collaborative modeling has demonstrated benefits in facilitating cooperation between technical experts in engineering problems; but fails to include non-technical stakeholders in the modeling endeavor. In contrast, participatory modeling excels in facilitating high-level modeling among a diverse set of stakeholders, often of non-technical profiles; but fails to generate actionable engineering models. To instigate a convergence between the two disciplines, we systematically survey the field of collaborative and participatory modeling for sustainable systems. By analyzing 24 primary studies (published until June 2024), we identify common challenges, cooperation models, modeling formalisms and tools; and recommend future avenues of research.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {645–654},
numpages = {10},
keywords = {collaboration, MDE, model-driven, model-based, participatory modeling, survey, sustainability, systematic literture review},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@proceedings{10.1145/3652988,
title = {IVA '24: Proceedings of the 24th ACM International Conference on Intelligent Virtual Agents},
year = {2024},
isbn = {9798400706257},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {GLASGOW, United Kingdom}
}

@inproceedings{10.1145/3652988.3673931,
author = {Zeng, Jie and Takahashi, Yoshiki and Nakano, Yukiko I. and Sakato, Tatsuya and Vilhj\'{a}lmsson, Hannes H\"{o}gni},
title = {Modifying Gesture Style with Impression Words},
year = {2024},
isbn = {9798400706257},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652988.3673931},
doi = {10.1145/3652988.3673931},
abstract = {When people form impressions of others in face-to-face communication, gesture style (i.e. the way of gesturing) impacts their impressions, such as being well-mannered, honest, and enthusiastic. As a mechanism for changing the gesture style, we trained a GAN-based style transfer model using a collection of video clips of speakers. Then, we collected a new speaker dataset from YouTube videos representing three different countries, and applied them to the style encoder of our style transfer model and created a gesture style latent space. However, it is difficult to select an appropriate style from a large number of style candidates to synthesize motions that would give off a specific impression. To assist users with this, we propose a method for automatically selecting an appropriate style by fine-tuning a Large Language Model (LLM) that uses a list of impression words as input. An evaluation study found that the gesture transfer model effectively changes the impression of gesture, and styles selected by the style selection mechanism produced motions that express similar impression to those that applied ground truth styles, compared to randomly selected styles.},
booktitle = {Proceedings of the 24th ACM International Conference on Intelligent Virtual Agents},
articleno = {15},
numpages = {9},
keywords = {LLM, gesture generation, gesture impression, impression words, style transfer},
location = {GLASGOW, United Kingdom},
series = {IVA '24}
}

@article{10.1145/3653670,
author = {Shen, Xudong and Brown, Hannah and Tao, Jiashu and Strobel, Martin and Tong, Yao and Narayan, Akshay and Soh, Harold and Doshi-Velez, Finale},
title = {Directions of Technical Innovation for Regulatable AI Systems},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {67},
number = {11},
issn = {0001-0782},
url = {https://doi.org/10.1145/3653670},
doi = {10.1145/3653670},
abstract = {Public sector AI procurement checklists can help guide efforts to create regulatable AI systems.},
journal = {Commun. ACM},
month = oct,
pages = {82–89},
numpages = {8}
}

@inproceedings{10.1145/3658617.3697592,
author = {Zhang, Lizi and Davoodi, Azadeh},
title = {Static IR Drop Prediction with Limited Data from Real Designs},
year = {2025},
isbn = {9798400706356},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658617.3697592},
doi = {10.1145/3658617.3697592},
abstract = {There has been significant recent progress to reduce the computational effort of static IR drop analysis using neural networks, and modeling as an image-to-image translation task. A crucial issue is lack of sufficient data from real industry designs to train these networks. In this work, we first propose a number of improvements to the state-of-the-art U-Net neural network model to achieve better IR drop prediction. First, we propose U-Net with attention gates which allows selective emphasis on relevant parts of the input data without supervision. This is desired because of the often sparse nature of the IR drop map. We also embed the U-Net model with a preprocessing convolutional block which introduces an initial perimage filter to better handle the multi-image to single-image nature of the problem. Next, to address lack of sufficient data we propose a two-phase training process which utilizes a mix of artificially-generated data and a limited number of points from real designs with custom learning and dropout rates at each phase, and a custom loss function. We also propose a data augmentation step based on image transformations to augment the training data. Based on the ICCAD 2023 contest setup, our results are on-average, 38\% (64\%) better in MAE and 26\% (142\%) in F1 score compared to the winner of the ICCAD 2023 contest (and U-Net only [3]) when only tested on the set of real designs in the testing set.},
booktitle = {Proceedings of the 30th Asia and South Pacific Design Automation Conference},
pages = {520–526},
numpages = {7},
keywords = {power delivery network, static IR drop prediction, deep learning, transfer learning, training with limited data, attention gates, U-net neural network},
location = {Tokyo, Japan},
series = {ASPDAC '25}
}

@inbook{10.1145/3658617.3697613,
author = {Liu, Shang and Fang, Wenji and Lu, Yao and Zhang, Qijun and Xie, Zhiyao},
title = {Towards Big Data in AI for EDA Research: Generation of New Pseudo Circuits at RTL Stage},
year = {2025},
isbn = {9798400706356},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658617.3697613},
abstract = {Machine learning (ML) techniques have demonstrated remarkable effectiveness in electronic design automation (EDA). ML models need to be trained on diverse circuit datasets for better accuracy and generalization capabilities. However, the availability of circuit data remains a long-standing severe issue. The strong data privacy concern in the semiconductor industry makes direct sharing of circuit IPs almost impossible. To address the data availability problem, open-source datasets like CircuitNet have been proposed, but they mostly focus on collecting labels of several existing open-source designs, instead of generating any new designs. In this work, we make an innovative exploration to directly generate new pseudo-circuits without human effort. We believe that generating pseudo-circuits is the most promising, if not the only, approach to achieving "big data" in the semiconductor industry in the foreseeable future. We demonstrate that pseudo-circuits can significantly boost the performance of ML models in early design quality predictions, as early as the pre-synthesis RTL stage.},
booktitle = {Proceedings of the 30th Asia and South Pacific Design Automation Conference},
pages = {527–533},
numpages = {7}
}

@inproceedings{10.1145/3658617.3697624,
author = {Akyash, Mohammad and Mardani Kamali, Hadi},
title = {SimEval: Investigating the Similarity Obstacle in LLM-based Hardware Code Generation},
year = {2025},
isbn = {9798400706356},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658617.3697624},
doi = {10.1145/3658617.3697624},
abstract = {The increasing use and efficiency of large language models (LLMs) in digital hardware circuit design has started to revolutionize the early stages of integrated circuit (IC) supply chain design and implementation, pushing towards enhanced automation. Despite these advances, hardware circuits' inherent complexity and limited data present significant challenges. Recent studies have begun to explore various attributes of LLM-generated hardware code, including semantics, syntax, fluency, and flexibility. Given that many code generation methodologies rely on fine-tuned LLMs and face constraints due to the limited availability of datasets for hardware designs, this paper investigates the "diversity" of codes generated by LLMs. We introduce SimEval, a comprehensive, multifaceted metric vector designed to assess the similarity of LLM-generated hardware codes at the syntactic, structural, and behavioral levels, from high-level register transfer (RT-level) to synthesized (gate-level) netlists. SimEval uniquely combines sub-tree matching from abstract syntax trees (AST) with structural similarity based on kernel graphs for control flow graphs (CFG). Our experiments focusing on samples from GPT-3.5 datasets and evaluating their similarity using SimEval, highlight the critical role of SimEval in evaluating LLM-based hardware code generators w.r.t. diversity1.},
booktitle = {Proceedings of the 30th Asia and South Pacific Design Automation Conference},
pages = {1002–1007},
numpages = {6},
keywords = {large language model (LLM), hardware design, similarity, finetuning, dataset, code synthesis},
location = {Tokyo, Japan},
series = {ASPDAC '25}
}

@inproceedings{10.1145/3658617.3697774,
author = {Wang, Kun and Chang, Kaiyan and Wang, Mengdi and Zou, Xingqi and Xu, Haobo and Han, Yinhe and Wang, Ying},
title = {RTLMarker: Protecting LLM-Generated RTL Copyright via a Hardware Watermarking Framework},
year = {2025},
isbn = {9798400706356},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658617.3697774},
doi = {10.1145/3658617.3697774},
abstract = {Recent advances of large language models in the field of Verilog generation have raised several ethical and security concerns, such as code copyright protection and dissemination of malicious code. Researchers have employed watermarking techniques to identify codes generated by large language models. However, the existing watermarking works fail to protect RTL code copyright due to the significant syntactic and semantic differences between RTL code and software code in languages such as Python. This paper proposes a hardware watermarking framework RTLMarker that embeds watermarks into RTL code and deeper into the synthesized netlist. We propose a set of rule-based Verilog code transformations, ensuring the watermarked RTL code's syntactic and semantic correctness. In addition, we consider an inherent tradeoff between watermark transparency and watermark effectiveness and jointly optimize them. The results demonstrate RTLMarker's superiority over the baseline in RTL code watermarking.},
booktitle = {Proceedings of the 30th Asia and South Pacific Design Automation Conference},
pages = {808–813},
numpages = {6},
keywords = {large language model, hardware copyright},
location = {Tokyo, Japan},
series = {ASPDAC '25}
}

@proceedings{10.1145/3658644,
title = {CCS '24: Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is with great enthusiasm that we, on behalf of the Organizing Committee, invite you to join us for the 31st ACM SIGSAC Conference on Computer and Communications Security (CCS), a premier security and privacy conference where researchers, practitioners, and educators come together to present, learn, and debate research, innovation, and trends in the field of Computer and Communications Security and Privacy.This year, we are proud to introduce our conference theme to be "Inclusion, Mentorship, Community." These three pillars reflect our collective commitment to fostering a vibrant, supportive, and forwardthinking environment within the CCS community. Particularly, we host our inaugural Doctoral Symposium, which offers PhD students a unique platform to receive timely, constructive feedback on their dissertation research from leading experts in our community. Additionally, our first-ever Diversity, Equity, and Inclusion (DEI) Workshop is designed to cultivate a culture that embraces diversity and champions equity in our field. Moreover, understanding the importance of guidance and support, we have organized panels focusing on Student Mentoring, Faculty Mentoring, and Public Service. These panels are designed to facilitate mentorship connections, share valuable experiences, and encourage service that extends the impact of our work beyond academia. These new initiatives are also opportunities to strengthen the bonds within our CCS community.Regarding the main conference, this year's main conference is our largest ever, featuring 328 paper presentations that showcase the latest research and developments in our field. We are also honored to have two distinguished keynote speakers: Dr. Dan Boneh and Dr. Gene Tsudik, who will share their invaluable insights and perspectives on pressing topics in security and privacy. Additionally, 18 specialized workshops will take place on the pre-conference and post-conference days, providing platforms for focused discussions and collaborations on numerous specialized topics.},
location = {Salt Lake City, UT, USA}
}

@inproceedings{10.1145/3658644.3670267,
author = {Gong, Xueluan and Wei, Rubin and Wang, Ziyao and Sun, Yuchen and Peng, Jiawen and Chen, Yanjiao and Wang, Qian},
title = {Beowulf: Mitigating Model Extraction Attacks Via Reshaping Decision Regions},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3670267},
doi = {10.1145/3658644.3670267},
abstract = {Machine Learning as a Service (MLaaS) enables resource-constrained users to access well-trained models through a publicly accessible Application Programming Interface (API) on a pay-per-query basis. Nevertheless, model owners may face the potential threats of model extraction attacks where malicious users replicate valuable commercial models based on query results. Existing defenses against model extraction attacks, however, either sacrifice prediction accuracy or fail to thwart more advanced attacks. In this paper, we propose a novel model extraction defense, dubbed Beowulf 1 , which draws inspiration from theoretical findings that models with complex and narrow decision regions are difficult to be reproduced. Rather than arbitrarily altering decision regions, which may jeopardize the predictive capacity of the victim model, we introduce a dummy class, carefully synthesized using both random and adversarial noises. The random noise broadens the coverage of the dummy class, and the adversarial noise impacts decision regions near decision boundaries with normal classes. To further improve the model utility, we propose to employ data augmentation methods to seamlessly integrate the dummy class and the normal classes. Extensive evaluations on CIFAR-10, GTSRB, CIFAR-100, and ImageNette datasets demonstrate that Beowulf can significantly reduce the extraction accuracy of 6 state-of-the-art model extraction attacks by as much as 80\%. Moreover, we show that Beowulf is also robust to adaptive model extraction attacks.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {3838–3852},
numpages = {15},
keywords = {decision region reshaping, machine learning as a service, model extraction attacks, model extraction defenses},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3658644.3670295,
author = {Li, Xinfeng and Yang, Yuchen and Deng, Jiangyi and Yan, Chen and Chen, Yanjiao and Ji, Xiaoyu and Xu, Wenyuan},
title = {SafeGen: Mitigating Sexually Explicit Content Generation in Text-to-Image Models},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3670295},
doi = {10.1145/3658644.3670295},
abstract = {Text-to-image (T2I) models, such as Stable Diffusion, have exhibited remarkable performance in generating high-quality images from text descriptions in recent years. However, text-to-image models may be tricked into generating not-safe-for-work (NSFW) content, particularly in sexually explicit scenarios. Existing countermeasures mostly focus on filtering inappropriate inputs and outputs, or suppressing improper text embeddings, which can block sexually explicit content (e.g., naked) but may still be vulnerable to adversarial prompts-inputs that appear innocent but are ill-intended. In this paper, we present SafeGen, a framework to mitigate sexual content generation by text-to-image models in a text-agnostic manner. The key idea is to eliminate explicit visual representations from the model regardless of the text input. In this way, the text-to-image model is resistant to adversarial prompts since such unsafe visual representations are obstructed from within. Extensive experiments conducted on four datasets and large-scale user studies demonstrate SafeGen's effectiveness in mitigating sexually explicit content generation while preserving the high-fidelity of benign images. SafeGen outperforms eight state-of-the-art baseline methods and achieves 99.4\% sexual content removal performance.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {4807–4821},
numpages = {15},
keywords = {safety, sexually explicit, text-to-image model, unsafe mitigation},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3658644.3670299,
author = {Wang, Shu and Sun, Kun and Zhai, Yan},
title = {Dye4AI: Assuring Data Boundary on Generative AI Services},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3670299},
doi = {10.1145/3658644.3670299},
abstract = {Generative artificial intelligence (AI) is versatile for various applications, but security and privacy concerns with third-party AI vendors hinder its broader adoption in sensitive scenarios. Hence, it is essential for users to validate the AI trustworthiness and ensure the security of data boundaries. In this paper, we present a dye testing system named Dye4AI, which injects crafted trigger data into human-AI dialogue and observes AI responses towards specific prompts to diagnose data flow in AI model evolution. Our dye testing procedure contains 3 stages: trigger generation, trigger insertion, and trigger retrieval. First, to retain both uniqueness and stealthiness, we design a new trigger that transforms a pseudo-random number to a intelligible format. Second, with a custom-designed three-step conversation strategy, we insert each trigger item into dialogue and confirm the model memorizes the new trigger knowledge in the current session. Finally, we routinely try to recover triggers with specific prompts in new sessions, as triggers can present in new sessions only if AI vendors leverage user data for model fine-tuning. Extensive experiments on six LLMs demonstrate our dye testing scheme is effective in ensuring the data boundary, even for models with various architectures and parameter sizes. Also, larger and premier models tend to be more suitable for Dye4AI, e.g., trigger can be retrieved in OpenLLaMa-13B even with only 2 insertions per trigger item. Moreover, we analyze the prompt selection in dye testing, providing insights for future testing systems on generative AI services.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {2281–2295},
numpages = {15},
keywords = {data boundary assurance, dye testing, generative artificial intelligence, large language models},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3658644.3670310,
author = {Li, Ruijie and Zhang, Chenyang and Chai, Huajun and Ying, Lingyun and Duan, Haixin and Tao, Jun},
title = {PowerPeeler: A Precise and General Dynamic Deobfuscation Method for PowerShell Scripts},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3670310},
doi = {10.1145/3658644.3670310},
abstract = {PowerShell is a powerful and versatile task automation tool. Unfortunately, it is also widely abused by cyber attackers. To bypass malware detection and hinder threat analysis, attackers often employ diverse techniques to obfuscate malicious PowerShell scripts. Existing deobfuscation tools suffer from the limitation of static analysis, which fails to simulate the real deobfuscation process accurately. Accurate, complete, and robust PowerShell script deobfuscation is still a challenging problem.In this paper, we propose PowerPeeler. To the best of our knowledge, it is the first dynamic PowerShell script deobfuscation approach at the instruction level. It utilizes expression-related Abstract Syntax Tree (AST) nodes to identify potential obfuscated script pieces. Then, PowerPeeler correlates the AST nodes with their corresponding instructions and monitors the script's entire execution process. Subsequently, PowerPeeler dynamically tracks the execution of these instructions and records their execution results. Finally, PowerPeeler stringifies these results to replace the corresponding obfuscated script pieces and reconstruct the deobfuscated script.To evaluate the effectiveness of PowerPeeler, we collect 1,736,669 real-world malicious PowerShell samples and distill two high-quality datasets with diversity obfuscation methods: D-Script with 4,264 obfuscated script files and D-Cmdline with 381 obfuscated samples using PowerShell command-line interface. We compare PowerPeeler with five state-of-the-art deobfuscation tools and GPT-4. The evaluation results demonstrate that PowerPeeler can effectively handle all well-known obfuscation methods. Additionally, the deobfuscation correctness rate of PowerPeeler reaches 95\%, significantly surpassing that of other tools. PowerPeeler not only recovers the highest amount of sensitive data (e.g., IPs and URLs) but also maintains a semantic consistency over 97\%, which is also the best. Moreover, PowerPeeler effectively obtains the largest quantity of valid deobfuscated results within a limited time frame (i.e., two minutes). Furthermore, PowerPeeler is extendable and can be used as a helpful tool for other cyber security solutions, such as malware analysis and threat intelligence generation.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {4539–4553},
numpages = {15},
keywords = {deobfuscation, dynamic, instruction, powershell},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3658644.3670317,
author = {Lin, Zijin and Zhao, Yue and Chen, Kai and He, Jinwen},
title = {I Don't Know You, But I Can Catch You: Real-Time Defense against Diverse Adversarial Patches for Object Detectors},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3670317},
doi = {10.1145/3658644.3670317},
abstract = {Deep neural networks (DNNs) have revolutionized the field of computer vision like object detection with their unparalleled performance. However, existing research has shown that DNNs are vulnerable to adversarial attacks. In the physical world, an adversary could exploit adversarial patches to implement a Hiding Attack (HA) which patches the target object to make it disappear from the detector, and an Appearing Attack (AA) which fools the detector into misclassifying the patch as a specific object. Recently, many defense methods for detectors have been proposed to mitigate the potential threats of adversarial patches. However, such methods still have limitations in generalization, robustness and efficiency. Most defenses are only effective against the HA, leaving the detector vulnerable to the AA.In this paper, we propose NutNet, an innovative model for detecting adversarial patches, with high generalization, robustness and efficiency. With experiments for six detectors including YOLOv2-v4, SSD, Faster RCNN and DETR on both digital and physical domains, the results show that our proposed method can effectively defend against both the HA and AA, with only 0.4\% sacrifice of the clean performance. We compare NutNet with four baseline defense methods for detectors, and our method exhibits an average defense performance that is over 2.4 times and 4.7 times higher than existing approaches for HA and AA, respectively. In addition, NutNet only increases the inference time by 8\%, which can meet the real-time requirements of the detection systems. Demos and the full paper of NutNet are available at: https://sites.google.com/view/nutnet.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {3823–3837},
numpages = {15},
keywords = {adversarial patch, object detectors, physical adversarial defense},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3658644.3670320,
author = {Bennett, Nathaniel and Zhu, Weidong and Simon, Benjamin and Kennedy, Ryon and Enck, William and Traynor, Patrick and Butler, Kevin R. B.},
title = {RANsacked: A Domain-Informed Approach for Fuzzing LTE and 5G RAN-Core Interfaces},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3670320},
doi = {10.1145/3658644.3670320},
abstract = {Cellular network infrastructure serves as the backbone of modern mobile wireless communication. As such, cellular cores must be proactively secured against external threats to ensure reliable service. Compromised base station attacks against the core are a rising threat to cellular networks, while user device inputs have long been considered as an attack vector; despite this, few techniques exist to comprehensively test RAN-Core interfaces against malicious input. In this work, we devise a fuzzing framework that performantly fuzzes cellular interfaces accessible from a base station or user device, overcoming several challenges in fuzzing specific to LTE/5G network components. We also introduce ASNFuzzGen, a tool that compiles ASN.1 specifications into structure-aware fuzzing modules, thereby facilitating effective fuzzing exploration of complex cellular protocols. We run fuzzing campaigns against seven open-source and commercial cores and discover 119 vulnerabilities, with 93 CVEs assigned. Our results reveal common implementation mistakes across several cores that lead to vulnerabilities, and the successful coordination of patches for these vulnerabilities across several vendors demonstrates the practical impact ASNFuzzGen has on hardening user-exposed cellular systems.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {2027–2041},
numpages = {15},
keywords = {cellular security, fuzzing, rogue base station},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3658644.3670325,
author = {Warren, Kevin and Tucker, Tyler and Crowder, Anna and Olszewski, Daniel and Lu, Allison and Fedele, Caroline and Pasternak, Magdalena and Layton, Seth and Butler, Kevin and Gates, Carrie and Traynor, Patrick},
title = {"Better Be Computer or I'm Dumb": A Large-Scale Evaluation of Humans as Audio Deepfake Detectors},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3670325},
doi = {10.1145/3658644.3670325},
abstract = {Audio deepfakes represent a rising threat to trust in our daily communications. In response to this, the research community has developed a wide array of detection techniques aimed at preventing such attacks from deceiving users. Unfortunately, the creation of these defenses has generally overlooked the most important element of the system - the user themselves. As such, it is not clear whether current mechanisms augment, hinder, or simply contradict human classification of deepfakes. In this paper, we perform the first large-scale user study on deepfake detection. We recruit over 1,200 users and present them with samples from the three most widely-cited deepfake datasets. We then quantitatively compare performance and qualitatively conduct thematic analysis to motivate and understand the reasoning behind user decisions and differences from machine classifications. Our results show that users correctly classify human audio at significantly higher rates than machine learning models, and rely on linguistic features and intuition when performing classification. However, users are also regularly misled by pre-conceptions about the capabilities of generated audio (e.g., that accents and background sounds are indicative of humans). Finally, machine learning models suffer from significantly higher false positive rates, and experience false negatives that humans correctly classify when issues of quality or robotic characteristics are reported. By analyzing user behavior across multiple deepfake datasets, our study demonstrates the need to more tightly compare user and machine learning performance, and to target the latter towards areas where humans are less likely to successfully identify threats.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {2696–2710},
numpages = {15},
keywords = {audio deepfake, classification, security, user study},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3658644.3670340,
author = {Xie, Danning and Zhang, Zhuo and Jiang, Nan and Xu, Xiangzhe and Tan, Lin and Zhang, Xiangyu},
title = {ReSym: Harnessing LLMs to Recover Variable and Data Structure Symbols from Stripped Binaries},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3670340},
doi = {10.1145/3658644.3670340},
abstract = {Decompilation aims to recover a binary executable to the source code form and hence has a wide range of applications in cyber security, such as malware analysis and legacy code hardening. A prominent challenge is to recover variable symbols, including both primitive and complex types such as user-defined data structures, along with their symbol information such as names and types. Existing efforts focus on solving parts of the problem, e.g., recovering only types (without names) or only local variables (without user-defined structures). In this paper, we propose ReSym, a novel hybrid technique that combines Large Language Models (LLMs) and program analysis to recover both names and types for local variables and user-defined data structures. Our method encompasses fine-tuning two LLMs to handle local variables and structures, respectively. To overcome the token limitations inherent in current LLMs, we devise a novel Prolog-based algorithm to aggregate and cross-check results from multiple LLM queries, suppressing uncertainty and hallucinations. Our experiments show that ReSym is effective in recovering variable information and user-defined data structures, substantially outperforming the state-of-the-art methods.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {4554–4568},
numpages = {15},
keywords = {large language models, program analysis, reverse engineering},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3658644.3670361,
author = {Ma, Hua and Wang, Shang and Gao, Yansong and Zhang, Zhi and Qiu, Huming and Xue, Minhui and Abuadbba, Alsharif and Fu, Anmin and Nepal, Surya and Abbott, Derek},
title = {Watch Out! Simple Horizontal Class Backdoor Can Trivially Evade Defense},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3670361},
doi = {10.1145/3658644.3670361},
abstract = {All current backdoor attacks on deep learning (DL) models fall under the category of a vertical class backdoor (VCB).In VCB attacks, any sample from a class activates the implanted backdoor when the secret trigger is present, regardless of whether it is a sub-type source-class-agnostic backdoor or a source-class-specific backdoor. For example, a trigger of sunglasses could mislead a facial recognition model when either an arbitrary (source-class-agnostic) or a specific (source-class-specific) person wears sunglasses. Existing defense strategiesoverwhelmingly focus on countering VCB attacks, especially those that are source-class-agnostic. This narrow focus neglects the potential threat of other simpler yet general backdoor types, leading to false security implications. It is, therefore, crucial to discover and elucidate unknown backdoor types, particularly those that can be easily implemented, as a mandatory step before developing countermeasures.This study introduces a new, simple, and general type of backdoor attack, the horizontal class backdoor (HCB), that trivially breaches the class dependence characteristic of the VCB, bringing a fresh perspective to the field. An HCB is activated when the trigger is presented together with an innocuous feature,regardless of class. For example, under an HCB, the trigger of sunglasses could mislead a facial recognition model in the presence of the innocuous feature smiling. Smiling is innocuous because it is irrelevant to the main task of facial recognition. The key is that these innocuous features (such as rain, fog, or snow in autonomous driving or facial expressions like smiling or sadness in facial recognition) are horizontally sharedamong classes but are only exhibited by partial samples per class. Extensive experiments on attacking performance across various tasks, including MNIST, facial recognition, traffic sign recognition, object detection, and medical diagnosis, confirm the high efficiency and effectiveness of the HCB. We rigorously evaluated the evasiveness of the HCB against a series of eleven representative countermeasures, including Fine-Pruning (RAID 18'), STRIP (ACSAC 19'), Neural Cleanse (Oakland 19'), ABS (CCS 19'), Februus (ACSAC 20'), NAD (ICLR 21'), MNTD (Oakland 21'), SCAn (USENIX SEC 21'), MOTH (Oakland 22'), Beatrix (NDSS 23'), and MM-BD (Oakland 24'). None of these countermeasures prove robustness, even when employing a simplistic trigger, such as a small and static white-square patch.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {4465–4479},
numpages = {15},
keywords = {backdoor attacks, deep learning, defenses},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3658644.3690205,
author = {Ding, Wenxin and Li, Cathy Y. and Shan, Shawn and Zhao, Ben Y. and Zheng, Haitao},
title = {Understanding Implosion in Text-to-Image Generative Models},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3690205},
doi = {10.1145/3658644.3690205},
abstract = {Recent works show that text-to-image generative models are surprisingly vulnerable to a variety of poisoning attacks. Empirical results find that these models can be corrupted by altering associations between individual text prompts and associated visual features. Furthermore, a number of concurrent poisoning attacks can induce "model implosion," where the model becomes unable to produce meaningful images for unpoisoned prompts. These intriguing findings highlight the absence of an intuitive framework to understand poisoning attacks on these models.In this work, we establish the first analytical framework on robustness of image generative models to poisoning attacks, by modeling and analyzing the behavior of the cross-attention mechanism in latent diffusion models. We model cross-attention training as an abstract problem of "supervised graph alignment" and formally quantify the impact of training data by the hardness of alignment, measured by an Alignment Difficulty (AD) metric. The higher the AD, the harder the alignment. We prove that AD increases with the number of individual prompts (or concepts) poisoned. As AD grows, the alignment task becomes increasingly difficult, yielding highly distorted outcomes that frequently map meaningful text prompts to undefined or meaningless visual representations. As a result, the generative model implodes and outputs random, incoherent images at large. We validate our analytical framework through extensive experiments, and we confirm and explain the unexpected (and unexplained) effect of model implosion while producing new, unforeseen insights. Our work provides a useful tool for studying poisoning attacks against diffusion models and their defenses.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {1211–1225},
numpages = {15},
keywords = {cross attention, model implosion, poisoning attacks, text-to-image generative models},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3658644.3690209,
author = {Bernhard, Lukas and Schiller, Nico and Schloegel, Moritz and Bars, Nils and Holz, Thorsten},
title = {DarthShader: Fuzzing WebGPU Shader Translators \&amp; Compilers},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3690209},
doi = {10.1145/3658644.3690209},
abstract = {A recent trend towards running more demanding web applications, such as video games or client-side LLMs, in the browser has led to the adoption of the WebGPU standard that provides a cross-platform API exposing the GPU to websites. This opens up a new attack surface: Untrusted web content is passed through to the GPU stack, which traditionally has been optimized for performance instead of security. Worsening the problem, most of WebGPU cannot be run in the tightly sandboxed process that manages other web content, which eases the attacker's path to compromising the client machine. Contrasting its importance, WebGPU shader processing has received surprisingly little attention from the automated testing community. Part of the reason is that shader translators expect highly structured and statically typed input, which renders typical fuzzing mutations ineffective. Complicating testing further, shader translation consists of a complex multi-step compilation pipeline, each stage presenting unique requirements and challenges.In this paper, we propose DarthShader, the first language fuzzer that combines mutators based on an intermediate representation with those using a more traditional abstract syntax tree. The key idea is that the individual stages of the shader compilation pipeline are susceptible to different classes of faults, requiring entirely different mutation strategies for thorough testing. By fuzzing the full pipeline, we ensure that we maintain a realistic attacker model. In an empirical evaluation, we show that our method outperforms the state-of-the-art fuzzers regarding code coverage. Furthermore, an extensive ablation study validates our key design. DarthShader found a total of 39 software faults in all modern browsers Chrome, Firefox, and Safari that prior work missed. For 15 of them, the Chrome team assigned a CVE, acknowledging the impact of our results.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {690–704},
numpages = {15},
keywords = {WGSL, WebGPU, browser security, fuzzing, graphics shaders, software security},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3658644.3690218,
author = {Jois, Tushar M. and Beck, Gabrielle and Kaptchuk, Gabriel},
title = {Pulsar: Secure Steganography for Diffusion Models},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3690218},
doi = {10.1145/3658644.3690218},
abstract = {Widespread efforts to subvert access to strong cryptography has renewed interest in steganography, the practice of embedding sensitive messages in mundane cover messages. Recent efforts at provably secure steganography have focused on text-based generative models and cannot support other types of models, such as diffusion models, which are used for high-quality image synthesis. In this work, we study securely embedding steganographic messages into the output of image diffusion models. We identify that the use of variance noise during image generation provides a suitable steganographic channel. We develop our construction, Pulsar, by building optimizations to make this channel practical for communication. Our implementation of Pulsar is capable of embedding ≈320--613 bytes (on average) into a single image without altering the distribution of the generated image, all in &lt; 3 seconds of online time on a laptop. In addition, we discuss how the results of Pulsar can inform future research into diffusion models. Pulsar shows that diffusion models are a promising medium for steganography and censorship resistance.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {4703–4717},
numpages = {15},
keywords = {applied cryptography, censorship resistance, diffusion models, steganography},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3658644.3690275,
author = {Sharma, Ayushi and Sharma, Shashank and Tanksalkar, Sai Ritvik and Torres-Arias, Santiago and Machiry, Aravind},
title = {Rust for Embedded Systems: Current State and Open Problems},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3690275},
doi = {10.1145/3658644.3690275},
abstract = {Embedded software is used in safety-critical systems such as medical devices and autonomous vehicles, where software defects, including security vulnerabilities, have severe consequences. Most embedded codebases are developed in unsafe languages, specifically C/C++, and are riddled with memory safety vulnerabilities. To prevent such vulnerabilities, Rust, a performant memory-safe systems language, provides an optimal choice for developing embedded software. Rust interoperability enables developing Rust applications on top of existing C codebases. Despite this, even the most resourceful organizations continue to develop embedded software in C/C++.  This paper performs the first systematic study to holistically understand the current state and challenges of using Rust for embedded systems. Our study is organized across three research questions. We collected a dataset of 6,408 Rust embedded software spanning various categories and 6 Static Application Security Testing (SAST) tools. We performed a systematic analysis of our dataset and surveys with 225 developers to investigate our research questions. We found that existing Rust software support is inadequate, SAST tools cannot handle certain features of Rust embedded software, resulting in failures, and the prevalence of advanced types in existing Rust software makes it challenging to engineer interoperable code. In addition, we found various challenges faced by developers in using Rust for embedded systems development.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {2296–2310},
numpages = {15},
keywords = {deep embedded systems, rust, security},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3658644.3690288,
author = {Wu, Yixin and Shen, Yun and Backes, Michael and Zhang, Yang},
title = {Image-Perfect Imperfections: Safety, Bias, and Authenticity in the Shadow of Text-To-Image Model Evolution},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3690288},
doi = {10.1145/3658644.3690288},
abstract = {Text-to-image models, such as Stable Diffusion (SD), undergo iterative updates to improve image quality and address concerns such as safety. Improvements in image quality are straightforward to assess. However, how model updates resolve existing concerns and whether they raise new questions remain unexplored. This study takes an initial step in investigating the evolution of text-to-image models from the perspectives of safety, bias, and authenticity. Our findings, centered on Stable Diffusion, indicate that model updates paint a mixed picture. While updates progressively reduce the generation of unsafe images, the bias issue, particularly in gender, intensifies. We also find that negative stereotypes either persist within the same Non-White race group or shift towards other Non-White race groups through SD updates, yet with minimal association of these traits with the White race group. Additionally, our evaluation reveals a new concern stemming from SD updates: State-of-the-art fake image detectors, initially trained for earlier SD versions, struggle to identify fake images generated by updated versions. We show that fine-tuning these detectors on fake images generated by updated versions achieves at least 96.6\% accuracy across various SD versions, addressing this issue. Our insights highlight the importance of continued efforts to mitigate biases and vulnerabilities in evolving text-to-image models.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {4837–4851},
numpages = {15},
keywords = {bias, fake images, text-to-image models, unsafe images},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3658644.3690305,
author = {Sharevski, Filipo and Zeidieh, Aziz and Loop, Jennifer Vander and Jachim, Peter},
title = {Blind and Low-Vision Individuals' Detection of Audio Deepfakes},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3690305},
doi = {10.1145/3658644.3690305},
abstract = {Audio deepfakes are a form of deception where convincing speech sentences are synthesized through machine learning means to give an impression of a human speaker. Audio deepfakes emerge as an attractive vector for targeting users that rely on audio accessibility, such as individuals who are blind or low vision. The critical reliance on speech both as a medium and an affordance puts this population at an undue risk of being deceived as they rely solely on themselves to detect whether a piece of audio is a deepfake or not. To better understand the nature of this risk considering the nuanced reliance on assistive technologies such as screen readers, we conducted a user study with n=16 blind and low vision individuals from the US. Our participants achieved an overall discernment accuracy of 59\%, and clips identified as deep fakes were only actually deepfakes in 50.8\% of the cases (precision). The participants that self-identified as "low vision" performed slightly better (accuracy of 61\%, precision of 64\%) compared to the ones that self-identified as "blind" (accuracy of 55\%, precision of 56\%). Our qualitative results show that the participants in the "blind" group mostly considered a combination of infliction, imperfections in the voice, and the intensity in the speech delivery as discernment factors. The participants in the "low vision" group mostly used the speaker's pitch, enunciation, emotion, and the fluency and articulation of the speaker as discernment cues. Overall, participants felt that audio deepfakes have the potential to deceive visually impaired individuals with political disinformation, impersonate their voice in authentication and smart homes, and specifically target them with voice phishing and enhanced scams.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {4867–4881},
numpages = {15},
keywords = {audio deepfakes, blind, detection, low vision, perception, users},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3658644.3690322,
author = {Wu, Jialin and Deng, Jiangyi and Pang, Shengyuan and Chen, Yanjiao and Xu, Jiayang and Li, Xinfeng and Xu, Wenyuan},
title = {Legilimens: Practical and Unified Content Moderation for Large Language Model Services},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3690322},
doi = {10.1145/3658644.3690322},
abstract = {Given the societal impact of unsafe content generated by large language models (LLMs), ensuring that LLM services comply with safety standards is a crucial concern for LLM service providers. Common content moderation methods are limited by an effectiveness-and-efficiency dilemma, where simple models are fragile while sophisticated models consume excessive computational resources. In this paper, we reveal for the first time that effective and efficient content moderation can be achieved by extracting conceptual features from chat-oriented LLMs, despite their initial fine-tuning for conversation rather than content moderation. We propose a practical and unified content moderation framework for LLM services, named Legilimens, which features both effectiveness and efficiency. Our red-team model-based data augmentation enhances the robustness of Legilimens against state-of-the-art jailbreaking. Additionally, we develop a framework to theoretically analyze the cost-effectiveness of Legilimens compared to other methodsWe have conducted extensive experiments on five host LLMs, seventeen datasets, and nine jailbreaking methods to verify the effectiveness, efficiency, and robustness of Legilimens against normal and adaptive adversaries. A comparison of Legilimens with both commercial and academic baselines demonstrates the superior performance of Legilimens. Furthermore, we confirm that Legilimens can be applied to few-shot scenarios and extended to multi-label classification tasks.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {1151–1165},
numpages = {15},
keywords = {content moderation, jailbreaking, large language model},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3658644.3690373,
author = {Zheng, Yihao and Xia, Haocheng and Pang, Junyuan and Liu, Jinfei and Ren, Kui and Chu, Lingyang and Cao, Yang and Xiong, Li},
title = {TabularMark: Watermarking Tabular Datasets for Machine Learning},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3690373},
doi = {10.1145/3658644.3690373},
abstract = {Watermarking is broadly utilized to protect ownership of shared data while preserving data utility. However, existing watermarking methods for tabular datasets fall short on the desired properties (detectability, non-intrusiveness, and robustness) and only preserve data utility from the perspective of data statistics, ignoring the performance of downstream ML models trained on the datasets. Can we watermark tabular datasets without significantly compromising their utility for training ML models while preventing attackers from training usable ML models on attacked datasets?In this paper, we propose a hypothesis testing-based watermarking scheme, TabularMark. Data noise partitioning is utilized for data perturbation during embedding, which is adaptable for numerical and categorical attributes while preserving the data utility. For detection, a custom-threshold one proportion z-test is employed, which can reliably determine the presence of the watermark. Experiments on real-world and synthetic datasets demonstrate the superiority of TabularMark in detectability, non-intrusiveness, and robustness.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {3570–3584},
numpages = {15},
keywords = {data ownership, machine learning, tabular dataset, watermark},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3658644.3691374,
author = {Xue, Di and Zhao, Gang and Fan, Zhongqi and Li, Wei and Xu, Yahong and Liu, Zhen and Liu, Yin and Yuan, Zhongliang},
title = {Poster: An Exploration of Large Language Models in Malicious Source Code Detection},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3691374},
doi = {10.1145/3658644.3691374},
abstract = {Embedding malicious code within the software supply chain has become a significant concern in the information technology field. Current methods for detecting malicious code, based on signatures, behavior analysis, and traditional machine learning models, lack result interpretability. This study proposes a novel malicious code detection framework, Mal-LLM, which leverages the cost advantages of traditional machine learning models and the interpretability of LLMs. Initially, traditional machine learning models filter vast amounts of malicious source code in the software supply chain. Subsequently, LLMs analyze and interpret the filtered malicious source code using a customized prompt template incorporating role-playing and chain-of-thought techniques. The feasibility of the Mal-LLM framework is validated through extensive experimental analyses, examining the ambiguity and redundancy of the LLM in the framework, the significance of ''experience'' and ''malicious'' prompts, and exploring methods to reduce the cost of using LLMs from an enterprise perspective.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {4940–4942},
numpages = {3},
keywords = {llms, malicious code detection, prompt engineering, software supply chain},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@proceedings{10.1145/3659154,
title = {ICEA '23: Proceedings of the 2023 International Conference on Intelligent Computing and Its Emerging Applications},
year = {2023},
isbn = {9798400709050},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3663548,
title = {ASSETS '24: Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility},
year = {2024},
isbn = {9798400706776},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {St. John's, NL, Canada}
}

@inproceedings{10.1145/3663548.3675600,
author = {Lee, Seonghee and Kohga, Maho and Landau, Steve and O'Modhrain, Sile and Subramonyam, Hari},
title = {AltCanvas: A Tile-Based Editor for Visual Content Creation with Generative AI for Blind or Visually Impaired People},
year = {2024},
isbn = {9798400706776},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663548.3675600},
doi = {10.1145/3663548.3675600},
abstract = {People with visual impairments often struggle to create content that relies heavily on visual elements, particularly when conveying spatial and structural information. Existing accessible drawing tools, which construct images line by line, are suitable for simple tasks like math but not for more expressive artwork. On the other hand, emerging generative AI-based text-to-image tools can produce expressive illustrations from descriptions in natural language, but they lack precise control over image composition and properties. To address this gap, our work integrates generative AI with a constructive approach that provides users with enhanced control and editing capabilities. Our system, AltCanvas, features a tile-based interface enabling users to construct visual scenes incrementally, with each tile representing an object within the scene. Users can add, edit, move, and arrange objects while receiving speech and audio feedback. Once completed, the scene can be rendered as a color illustration or as a vector for tactile graphic generation. Involving 14 blind or low-vision users in design and evaluation, we found that participants effectively used the AltCanvas’s workflow to create illustrations.},
booktitle = {Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility},
articleno = {70},
numpages = {22},
location = {St. John's, NL, Canada},
series = {ASSETS '24}
}

@inproceedings{10.1145/3663548.3675612,
author = {Kamikubo, Rie and Zamiri Zeraati, Farnaz and Lee, Kyungjun and Kacorri, Hernisa},
title = {AccessShare: Co-designing Data Access and Sharing with Blind People},
year = {2024},
isbn = {9798400706776},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663548.3675612},
doi = {10.1145/3663548.3675612},
abstract = {Blind people are often called to contribute image data to datasets for AI innovation with the hope for future accessibility and inclusion. Yet, the visual inspection of the contributed images is inaccessible. To this day, we lack mechanisms for data inspection and control that are accessible to the blind community. To address this gap, we engage 10 blind participants in a scenario where they wear smartglasses and collect image data using an AI-infused application in their homes. We also engineer a design probe, a novel data access interface called AccessShare, and conduct a co-design study to discuss participants’ needs, preferences, and ideas on consent, data inspection, and control. Our findings reveal the impact of interactive informed consent and the complementary role of data inspection systems such as AccessShare in facilitating communication between data stewards and blind data contributors. We discuss how key insights can guide future informed consent and data control to promote inclusive and responsible data practices in AI.},
booktitle = {Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility},
articleno = {60},
numpages = {16},
location = {St. John's, NL, Canada},
series = {ASSETS '24}
}

@inproceedings{10.1145/3663548.3675626,
author = {Gadiraju, Vinitha and Jayne, Lucia and Kane, Shaun K.},
title = {"It's an independent living skill, but covered with fun!": Prompting At-Home Skill Development for Children with Vision Impairment},
year = {2024},
isbn = {9798400706776},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663548.3675626},
doi = {10.1145/3663548.3675626},
abstract = {This study examined how to design tools that build independence with Blind or Visually Impaired (BVI) children and their families. Beyond core academics, BVI children require instruction on independent living skills, with their curriculum necessitating parent-school cooperation to support continued education at home. However, most technology for BVI children focus on academics, spatial orientation, and physical mobility. In this work, we aim to design a tool for independence that aligns with existing familial structures and activities. Through interviews and diary studies with five families, we explored development practices parents used with their BVI children, parent-teacher relationships, and how a prompting and reflection tool supported family goals. This study highlights home routines and independence skills that benefit from customized prompting, how activity prompts can encourage parents to scale back their assistance and propel independence, and how reflection builds optimism and empowers parents in the learning process.},
booktitle = {Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility},
articleno = {27},
numpages = {14},
keywords = {activity prompting, blind, collaboration, expanded core curriculum, independence, learning, parents, skill development, teachers, visual impairment},
location = {St. John's, NL, Canada},
series = {ASSETS '24}
}

@inproceedings{10.1145/3663548.3675644,
author = {Bennett, Cynthia L and Shelby, Renee and Rostamzadeh, Negar and Kane, Shaun K},
title = {Painting with Cameras and Drawing with Text: AI Use in Accessible Creativity},
year = {2024},
isbn = {9798400706776},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663548.3675644},
doi = {10.1145/3663548.3675644},
abstract = {Generative AI (GAI) is proliferating, and among its many applications are to support creative work (e.g., generating text, images, music) and to enhance accessibility (e.g., captions of images and audio). As GAI evolves, creatives must consider how (or how not) to incorporate these tools into their practices. In this paper, we present interviews at the intersection of these applications. We learned from 10 creatives with disabilities who intentionally use and do not use GAI in and around their creative work. Their mediums ranged from audio engineering to leatherwork, and they collectively experienced a variety of disabilities, from sensory to motor to invisible disabilities. We share cross-cutting themes of their access hacks, how creative practice and access work become entangled, and their perspectives on how GAI should and should not fit into their workflows. In turn, we offer qualities of accessible creativity with responsible AI that can inform future research.},
booktitle = {Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility},
articleno = {5},
numpages = {19},
keywords = {Accessibility, creativity, disability, generative AI, responsible AI},
location = {St. John's, NL, Canada},
series = {ASSETS '24}
}

@inproceedings{10.1145/3663548.3675665,
author = {Hammad, Noor and Elavsky, Frank and Moharana, Sanika and Chen, Jessie and Lee, Seyoung and Carrington, Patrick and Moritz, Dominik and Hammer, Jessica and Harpstead, Erik},
title = {Exploring The Affordances of Game-Aware Streaming to Support Blind and Low Vision Viewers: A Design Probe Study},
year = {2024},
isbn = {9798400706776},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663548.3675665},
doi = {10.1145/3663548.3675665},
abstract = {This paper explores new ways to support blind and low vision (BLV) game stream participants. Prior work on game-aware streaming systems has focused on the potential for viewer interaction and personalization for sighted viewers, but how such systems impact interaction and personalization for BLV viewers remains largely unexplored. Most streaming experiences have significant visual information but no non-visual or sensemaking alternatives, which can exclude BLV viewers from understanding and interacting with the streaming experience. Building on the pre-existing system MARS, we developed a design probe that makes game data available to stream viewers in personalizable visual and non-visual formats. We use this probe to investigate the needs of BLV game stream viewers through qualitative interviews and live prototype testing sessions on Twitch. In addition to the technical contributions of our probe, our work addresses how game-aware streaming technologies can align with the needs and motivations of BLV viewers, and paves the way for novel designs in future iterations of game-aware streaming technologies.},
booktitle = {Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility},
articleno = {16},
numpages = {13},
keywords = {Accessibility, Blind and Low Vision, Games Accessibility, Live Streaming, Twitch},
location = {St. John's, NL, Canada},
series = {ASSETS '24}
}

@proceedings{10.1145/3664647,
title = {MM '24: Proceedings of the 32nd ACM International Conference on Multimedia},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are delighted to welcome you to Melbourne, Australia for ACM Multimedia 2024, the 32nd ACM International Conference on Multimedia. ACM Multimedia is the premier international conference series in the area of multimedia within the field of computer science. Since 1993, ACM Multimedia has been bringing together worldwide researchers and practitioners from academia and industry to present their innovative research and to discuss recent advancements in multimedia.For the first time since the end of the COVID-19 pandemic, this year's conference returns to the Asia-Pacific region and resumes as a full-fledged, inperson event. With no travel restrictions or significant visa challenges, we are excited to once again experience the warmth of face-to-face gatherings, where we can reconnect with colleagues and friends.The enthusiasm and support from the community have been incredible. ACM Multimedia 2024 received over 4,300 main conference submissions, accepting more than 1,100 papers (please refer to the TPC Chairs' message for details). In addition, 10 Grand Challenges were selected from 22 submissions, 18 workshops from 30 submissions, and 8 tutorials from 13 proposals. We've prepared an exciting five-day program: workshops, grand challenges, and tutorials will be held on the 1st and 5th days, with the main conference occupying the middle three days. All accepted papers will be accessible online prior to the conference, and we are working to ensure proceedings are available through the ACM Digital Library around the conference period.This year's conference features three distinguished academic keynote speeches, several prestigious SIGMM award talks, a panel discussion on Generative AI in Multimedia, a refreshed Brave New Idea (BNI) session, and our inaugural industry program.The opening keynote will be delivered by Prof. Pascale Fung from HKUST, a Fellow of AAAI, ACL, and IEEE. Her talk will explore the pressing topic of Agents in the Large Language Model (LLM) Era. Prof. Judy Kay from the University of Sydney, a renowned expert in HCI, user modeling, and ubiquitous computing, will give the second keynote on how to empower individuals to harness and control their multimodal data. The final academic keynote will be presented by Prof. Jiebo Luo from the University of Rochester, a Fellow of ACM, AAAI, IEEE, SPIE, and IAPR, as well as a member of Academia Europaea and the US National Academy of Inventors. He will discuss leveraging LLMs as social multimedia analysis engines.This year, we continue using OpenReview to ensure an open and transparent review process. Thanks to the exceptional efforts of the technical program committee, every paper received at least three reviews before the review announcement. The BNI track has also revamped its review process to align with the main conference, promoting visionary papers. Additionally, we are excited to introduce the industry program to ACM Multimedia for the first time, featuring industry keynote speeches, expert talks, and demonstrations (please refer to the industry chairs' message for further details).We are also committed to making the conference inclusive and accessible. To support students with financial constraints, we have awarded travel grants to at least 25 students from the ACM Multimedia 2024 budget, with an additional 20+ students receiving SIGMM travel grants. Over 20 local students have also been recruited as volunteers, benefiting from complimentary registration. Furthermore, we have arranged childcare facilities to accommodate attendees with young children. A welcome reception will take place on the 2nd day of the conference, followed by a gala dinner on the 3rd day, featuring exciting cultural performances.We hope you find this year's program engaging and thought-provoking and that it offers valuable opportunities to exchange ideas with fellow researchers and practitioners from around the globe. We also encourage you to take time to explore the beautiful city of Melbourne and its surrounding regions.},
location = {Melbourne VIC, Australia}
}

@inproceedings{10.1145/3664647.3680651,
author = {Liu, Haizhuang and Zhuo, Junbao and Liang, Chen and Chen, Jiansheng and Ma, Huimin},
title = {Affinity3D: Propagating Instance-Level Semantic Affinity for Zero-Shot Point Cloud Semantic Segmentation},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3680651},
doi = {10.1145/3664647.3680651},
abstract = {Zero-shot point cloud semantic segmentation aims to recognize novel classes at the point level. Previous methods mainly transfer excellent zero-shot generalization capabilities from images to point clouds. However, directly transferring knowledge from images to point clouds faces two ambiguous problems. On the one hand, 2D models will generate wrong predictions when the image changes. On the other hand, directly mapping 3D points to 2D pixels by perspective projection fails to consider the visibility of 3D points in camera view. The wrong geometric alignment of 3D points and 2D pixels causes semantic ambiguity. To tackle these two problems, we propose a framework named Affinity3D that intends to empower 3D semantic segmentation models to perceive novel samples. Our framework aggregates instances in 3D and recognizes them in 2D, leveraging the excellent geometric separation in 3D and the zero-shot capabilities of 2D models. Affinity3D involves an affinity module that rectifies the wrong predictions by comparing them with similar instances and a visibility module preventing knowledge transfer from visible 2D pixels to invisible 3D points. Extensive experiments have been conducted on the SemanticKITTI and nuScenes datasets. Our framework achieves state-of-the-art performance on both two datasets. Code is available at https://github.com/opjang5/Affinity3D.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {9019–9028},
numpages = {10},
keywords = {affinity, cross-modal distillation, point cloud semantic segmentation, visibility, zero-shot learning},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3680665,
author = {Luo, Daqin and Feng, Chengjian and Nong, Yuxuan and Shen, Yiqing},
title = {AutoM3L: An Automated Multimodal Machine Learning Framework with Large Language Models},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3680665},
doi = {10.1145/3664647.3680665},
abstract = {Automated Machine Learning (AutoML) offers a promising approach to streamline the training of machine learning models. However, existing AutoML frameworks are often limited to unimodal scenarios and require extensive manual configuration. Recent advancements in Large Language Models (LLMs) have showcased their exceptional abilities in reasoning, interaction, and code generation, presenting an opportunity to develop a more automated and user-friendly framework. To this end, we introduce AutoM3L, an innovative Automated Multimodal Machine Learning framework that leverages LLMs as controllers to automatically construct multimodal training pipelines. AutoM3L comprehends data modalities and selects appropriate models based on user requirements, providing automation and interactivity. By eliminating the need for manual feature engineering and hyperparameter optimization, our framework simplifies user engagement and enables customization through directives, addressing the limitations of previous rule-based AutoML approaches. We evaluate the performance of AutoM3L on six diverse multimodal datasets spanning classification, regression, and retrieval tasks, as well as a comprehensive set of unimodal datasets. The results demonstrate that AutoM3L achieves competitive or superior performance compared to traditional rule-based AutoML methods. Furthermore, a user study highlights the user-friendliness and usability of our framework, compared to the rule-based AutoML methods.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {8586–8594},
numpages = {9},
keywords = {automated machine learning, human-ai interaction, large language model, usability, user study},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3680704,
author = {Wang, Tao and Zhang, Yushu and Xiao, Xiangli and Yuan, Lin and Xia, Zhihua and Weng, Jian},
title = {Make Privacy Renewable! Generating Privacy-Preserving Faces Supporting Cancelable Biometric Recognition},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3680704},
doi = {10.1145/3664647.3680704},
abstract = {The significant advancement in face recognition drives face privacy protection into a prominent research direction. Unlike de-identification, a recent class of face privacy protection schemes preserves identifiable formation for face recognition. However, these schemes fail to support the revocation of the leaked identity, causing attackers to potentially identify individuals and then pose security threats. In this paper, we explore the possibility of generating privacy-preserving faces (not features) supporting cancelable biometric recognition. Specifically, we propose a cancelable face generator (CanFG), which removes the physical identity for privacy protection and embeds the virtual identity for face recognition. Particularly, when leaked, the virtual identity can be revoked and renew as another one, preventing re-identification from attackers. Benefiting from the designed distance-preserving identity transformation, CanFG can guarantee separability and preserve recognizability of virtual identities. Moreover, to make CanFG lightweight, we design a simple but effective training strategy, which allows CanFG to require only one (rather than two) network for achieving stable multi-objective learning. Extensive experimental results and sufficient security analyses demonstrate the ability of CanFG to effectively protect physical identity and support cancelable biometric recognition. Our code is available at https://github.com/daizigege/CanFG.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {10268–10276},
numpages = {9},
keywords = {cancelable biometrics, face privacy, virtual identity},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3680745,
author = {Guo, Xiaojiao and Chen, Xuhang and Luo, Shenghong and Wang, Shuqiang and Pun, Chi-Man},
title = {Dual-Hybrid Attention Network for Specular Highlight Removal},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3680745},
doi = {10.1145/3664647.3680745},
abstract = {Specular highlight removal plays a pivotal role in multimedia applications, as it enhances the quality and interpretability of images and videos, ultimately improving the performance of downstream tasks such as content-based retrieval, object recognition, and scene understanding. Despite significant advances in deep learning-based methods, current state-of-the-art approaches often rely on additional priors or supervision, limiting their practicality and generalization capability. In this paper, we propose the Dual-Hybrid Attention Network for Specular Highlight Removal (DHAN-SHR), an end-to-end network that introduces novel hybrid attention mechanisms to effectively capture and process information across different scales and domains without relying on additional priors or supervision. DHAN-SHR consists of two key components: the Adaptive Local Hybrid-Domain Dual Attention Transformer (L-HD-DAT) and the Adaptive Global Dual Attention Transformer (G-DAT). The L-HD-DAT captures local inter-channel and inter-pixel dependencies while incorporating spectral domain features, enabling the network to effectively model the complex interactions between specular highlights and the underlying surface properties. The G-DAT models global inter-channel relationships and long-distance pixel dependencies, allowing the network to propagate contextual information across the entire image and generate more coherent and consistent highlight-free results. To evaluate the performance of DHAN-SHR and facilitate future research in this area, we compile a large-scale benchmark dataset comprising a diverse range of images with varying levels of specular highlights. Through extensive experiments, we demonstrate that DHAN-SHR outperforms 18 state-of-the-art methods both quantitatively and qualitatively, setting a new standard for specular highlight removal in multimedia applications. The code and dataset are available at https://github.com/CXH-Research/DHAN-SHR.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {10173–10181},
numpages = {9},
keywords = {dual-hybrid attention, spatial and spectral, specular highlight removal},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3680829,
author = {Qu, Xiangyan and Yu, Jing and Gai, Keke and Zhuang, Jiamin and Tang, Yuanmin and Xiong, Gang and Gou, Gaopeng and Wu, Qi},
title = {Visual-Semantic Decomposition and Partial Alignment for Document-based Zero-Shot Learning},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3680829},
doi = {10.1145/3664647.3680829},
abstract = {Recent work shows that documents from encyclopedias serve as helpful auxiliary information for zero-shot learning. Existing methods align the entire semantics of a document with corresponding images to transfer knowledge. However, they disregard that semantic information is not equivalent between them, resulting in a suboptimal alignment. In this work, we propose a novel network to extract multi-view semantic concepts from documents and images and align the matching rather than entire concepts. Specifically, we propose a semantic decomposition module to generate multi-view semantic embeddings from visual and textual sides, providing the basic concepts for partial alignment. To alleviate the issue of information redundancy among embeddings, we propose the local-to-semantic variance loss to capture distinct local details and multiple semantic diversity loss to enforce orthogonality among embeddings. Subsequently, two losses are introduced to partially align visual-semantic embedding pairs according to their semantic relevance at the view and word-to-patch levels. Consequently, we consistently outperform state-of-the-art methods under two document sources in three standard benchmarks for document-based zero-shot learning. Qualitatively, we show that our model learns the interpretable partial association. Code is available at https://github.com/MorningStarOvO/EmDepart.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {4581–4590},
numpages = {10},
keywords = {document-based zero-shot learning, partial semantic alignment, visual-semantic decomposition},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3680971,
author = {Wang, Hebaixu and Zhang, Hao and Yi, Xunpeng and Xiang, Xinyu and Fang, Leyuan and Ma, Jiayi},
title = {TeRF: Text-driven and Region-aware Flexible Visible and Infrared Image Fusion},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3680971},
doi = {10.1145/3664647.3680971},
abstract = {The fusion of visible and infrared images aims to produce high-quality fusion images with rich textures and salient target information. Existing methods lack interactivity and flexibility in the execution of fusion. It is unfeasible to express the requirements to modify the fusion effect, and the different regions in the source images are treated equally across the identical fusion model, which causes fusion homogenization and low distinction. Besides, their pre-defined fusion strategies invariably lead to monotonous effects, which are insufficiently comprehensive. They fail to adequately consider data credibility, scene illumination, and noise degradation inherent in the source information. To address these issues, we propose the Te xt-driven and Region-aware Flexible visible and infrared image fusion, termed as TeRF. On the one hand, we propose a flexible image fusion framework with multiple large language and vision models, which facilitates the visual-text interaction. On the other hand, we aggregate comprehensive fine-tuning paradigms for the different fusion requirements to build a unified fine-tuning pipeline. It allows the linguistic selection of the regions and effects, yielding visually appealing fusion outcomes. Extensive experiments demonstrate the competitiveness of our method both qualitatively and quantitatively compared to existing state-of-the-art methods. Our code is publicly available at https://github.com/Baixuzx7/TeRF.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {935–944},
numpages = {10},
keywords = {fine-tuning, image fusion, large models, text-driven},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3680972,
author = {Yang, Zhichao and Li, Leida and Chen, Pengfei and Wu, Jinjian and Dong, Weisheng},
title = {Semantics-Aware Image Aesthetics Assessment using Tag Matching and Contrastive Ranking},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3680972},
doi = {10.1145/3664647.3680972},
abstract = {The perception of image aesthetics is built upon the understanding of semantic content. However, how to evaluate the aesthetic quality of images with diversified semantic backgrounds remains challenging in image aesthetics assessment (IAA). To address the dilemma, this paper presents a semantics-aware image aesthetics assessment approach, which first analyzes the semantic content of images and then models the aesthetic distinctions among images from two perspectives, i.e., aesthetic attribute and aesthetic level. Concretely, we propose two strategies, dubbed tag matching and contrastive ranking, to extract knowledge pertaining to image aesthetics. The tag matching identifies the semantic category and the dominant aesthetic attributes based on predefined tag libraries. The contrastive ranking is designed to uncover the comparative relationships among images with different aesthetic levels but similar semantic backgrounds. In the process of contrastive ranking, the impact of long-tailed distribution of aesthetic data is also considered by balanced sampling and traversal contrastive learning. Extensive experiments and comparisons on three benchmark IAA databases demonstrate the superior performance of the proposed model in terms of both prediction accuracy and alleviating long-tailed effect. The code will be public at https://github.com/yzc-ippl/TMCR **REMOVE 2nd URL**://github.com/yzc-ippl/TMCR.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {2632–2641},
numpages = {10},
keywords = {clip, contrastive learning, image aesthetics assessment, semantic and aesthetic perception},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3681003,
author = {Yang, Chengyi and Liu, Wentao and Chen, Shisong and Qi, Jiayin and Zhou, Aimin},
title = {Generating Prompts in Latent Space for Rehearsal-free Continual Learning},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681003},
doi = {10.1145/3664647.3681003},
abstract = {Continual learning emerges as a framework that trains the model on a sequence of tasks without forgetting previously learned knowledge, which has been applied in multiple multimodal scenarios. Recently, prompt-based continual learning has achieved excellent domain adaptability and knowledge transfer through prompt generation. However, existing methods mainly focus on designing the architecture of a generator, neglecting the importance of providing effective guidance for training the generator. To address this issue, we propose Generating Prompts in Latent Space (GPLS), which considers prompts as latent variables to account for the uncertainty of prompt generation and aligns with the fact that prompts are inserted into the hidden layer outputs and exert an implicit influence on classification. GPLS adopts a trainable encoder to encode task and feature information into prompts with reparameterization technique, and provides refined and targeted guidance for the training process through the evidence lower bound (ELBO) related to Mahalanobis distance. Extensive experiments demonstrate that GPLS achieves state-of-the-art performance on various benchmarks. Our code is available at https://github.com/Hifipsysta/GPLS.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {8913–8922},
numpages = {10},
keywords = {continual learning, probability prompt learning, prompts generation, variational inference},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3681069,
author = {Zhang, Shihua and Ma, Jiayi},
title = {DiffGlue: Diffusion-Aided Image Feature Matching},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681069},
doi = {10.1145/3664647.3681069},
abstract = {As one of the most fundamental computer vision problems, image feature matching aims to establish correct correspondences between two-view images. Existing studies enhance the descriptions of feature points with graph neural network (GNN), identifying correspondences with the predicted assignment matrix. However, this pipeline easily falls into a suboptimal result during training for the solution space is extremely complex, and is inaccessible to the prior that can guide the information propagation and network convergence. In this paper, we propose a novel method called DiffGlue that introduces the Diffusion Model into the sparse image feature matching framework. Concretely, based on the incrementally iterative diffusion and denoising processes, DiffGlue can be guided by the prior from the Diffusion Model and trained step by step on the optimization path, approaching the optimal solution progressively. Besides, it contains a special Assignment-Guided Attention as a bridge to merge the Diffusion Model and sparse image feature matching, which injects the inherent prior into GNN thereby ameliorating the message delivery. Extensive experiments reveal that DiffGlue converges faster and better, outperforming state-of-the-arts on several applications such as homography estimation, relative pose estimation, and visual localization. The code is available at https://github.com/SuhZhang/DiffGlue.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {8451–8460},
numpages = {10},
keywords = {diffusion model, graph neural network, image feature matching},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3681072,
author = {Liu, Huadai and Huang, Rongjie and Liu, Yang and Cao, Hengyuan and Wang, Jialei and Cheng, Xize and Zheng, Siqi and Zhao, Zhou},
title = {AudioLCM: Efficient and High-Quality Text-to-Audio Generation with Minimal Inference Steps},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681072},
doi = {10.1145/3664647.3681072},
abstract = {Recent advancements in Latent Diffusion Models (LDMs) have propelled them to the forefront of various generative tasks. However, their iterative sampling process poses a significant computational burden, resulting in slow generation speeds and limiting their application in text-to-audio generation deployment. In this work, we introduce AudioLCM, a novel consistency-based model tailored for efficient and high-quality text-to-audio generation. Unlike prior approaches that address noise removal through iterative processes, AudioLCM integrates Consistency Models (CMs) into the generation process, facilitating rapid inference through a mapping from any point at any time step to the trajectory's initial point. To overcome the convergence issue inherent in LDMs with reduced sample iterations, we propose the Guided Latent Consistency Distillation with a multi-step Ordinary Differential Equation (ODE) solver. This innovation shortens the time schedule from thousands to dozens of steps while maintaining sample quality, thereby achieving fast convergence and high-quality generation. Furthermore, to optimize the performance of transformer-based neural network architectures, we integrate the advanced techniques pioneered by LLaMA into the foundational framework of transformers. This architecture supports stable and efficient training, ensuring robust performance in text-to-audio synthesis. Experimental results on text-to-audio generation and text-to-music synthesis tasks demonstrate that AudioLCM needs only 2 iterations to synthesize high-fidelity audios, while it maintains sample quality competitive with state-of-the-art models using hundreds of steps. AudioLCM enables a sampling speed of 333x faster than real-time on a single NVIDIA 4090Ti GPU, making generative models practically applicable to text-to-audio generation deployment. Our extensive preliminary analysis shows that each design in AudioLCM is effective. https://AudioLCM.github.io/. Code is Available https://github.com/Text-to-Audio/AudioLCM},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {7008–7017},
numpages = {10},
keywords = {consistency model, latent diffusion model, text-to-audio generation},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3681092,
author = {Wang, Ruofan and Ma, Xingjun and Zhou, Hanxu and Ji, Chuanjun and Ye, Guangnan and Jiang, Yu-Gang},
title = {White-box Multimodal Jailbreaks Against Large Vision-Language Models},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681092},
doi = {10.1145/3664647.3681092},
abstract = {Recent advancements in Large Vision-Language Models (VLMs) have underscored their superiority in various multimodal tasks. However, the adversarial robustness of VLMs has not been fully explored. Existing methods mainly assess robustness through unimodal adversarial attacks that perturb images, while assuming inherent resilience against text-based attacks. Different from existing attacks, in this work we propose a more comprehensive strategy that jointly attacks both text and image modalities to exploit a broader spectrum of vulnerability within VLMs. Specifically, we propose a dual optimization objective aimed at guiding the model to generate highly toxic affirmative responses. Our attack method begins by optimizing an adversarial image prefix from random noise to generate diverse harmful responses in the absence of text input, thus imbuing the image with toxic semantics. Subsequently, an adversarial text suffix is integrated and co-optimized with the adversarial image prefix to maximize the probability of eliciting affirmative responses to various harmful instructions. The discovered adversarial image prefix and text suffix are collectively denoted as a Universal Master Key (UMK). When integrated into various malicious queries, UMK can circumvent the alignment defenses of VLMs and lead to the generation of objectionable content, known as jailbreaks. The experimental results demonstrate that our universal attack strategy can effectively jailbreak MiniGPT-4 with a 96\% success rate, highlighting the fragility of VLMs and the exigency for new alignment strategies. Codes are available at https://github.com/roywang021/UMK. Disclaimer: This paper contains potentially disturbing and offensive content.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {6920–6928},
numpages = {9},
keywords = {multimodal jailbreak, universal adversarial attacks, vision-language models, white-box jailbreak},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3681100,
author = {Hai, Xuan and Liu, Xin and Tan, Yuan and Liu, Gang and Li, Song and Niu, Weina and Zhou, Rui and Zhou, Xiaokang},
title = {What's the Real: A Novel Design Philosophy for Robust AI-Synthesized Voice Detection},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681100},
doi = {10.1145/3664647.3681100},
abstract = {Voice is one of the most widely used media for information transmission in human society. While high-quality synthetic voices are extensively utilized in various applications, they pose significant risks to content security and trust building. Numerous studies have concentrated on AI-synthesized voice detection to mitigate these risks, with many claiming to achieve promising performance. However, recent research has demonstrated that fake voice detectors suffer from serious overfitting to speaker-irrelative features (SiFs) and cannot be used in real-world scenarios. In this paper, we analyze the limitations of existing fake voice detectors and propose a new design philosophy, guiding the detection model to prioritize learning human voice features rather than the difference between the human voice and the synthetic voice. Based on this philosophy, we propose a novel AI-synthesized voice detection framework named SiFSafer, which uses pre-trained speech representation models to enhance the learning of feature distribution in human voices and the adapter fine-tuning to optimize the performance. The evaluation shows that the average EERs of existing fake voice detectors in the ASVspoof datasets can exceed 20\% if the SiFs like silence segments are removed, while SiFSafer achieves an EER of less than 8\%, indicating that SiFSafer is robust to SiFs and strongly resistant to existing attacks.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {6900–6909},
numpages = {10},
keywords = {ai-synthesized voice, ai-synthesized voice detection, asvspoof, deepfake},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3681102,
author = {Zheng, Changmeng and Liang, Dayong and Zhang, Wengyu and Wei, Xiao-Yong and Chua, Tat-Seng and Li, Qing},
title = {A Picture Is Worth a Graph: A Blueprint Debate Paradigm for Multimodal Reasoning},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681102},
doi = {10.1145/3664647.3681102},
abstract = {This paper presents a pilot study aimed at introducing multi-agent debate into multimodal reasoning. The study addresses two key challenges: the trivialization of opinions resulting from excessive summarization and the diversion of focus caused by distractor concepts introduced from images. These challenges stem from the inductive (bottom-up) nature of existing debating schemes. To address the issue, we propose a deductive (top-down) debating approach called Blueprint Debate on Graphs (BDoG). In BDoG, debates are confined to a blueprint graph to prevent opinion trivialization through world-level summarization. Moreover, by storing evidence in branches within the graph, BDoG mitigates distractions caused by frequent but irrelevant concepts. Extensive experiments validate that BDoG is able to achieve state-of-the-art results in ScienceQA and MMBench with significant improvements over previous methods. The source code can be accessed at https://github.com/thecharm/BDoG.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {419–428},
numpages = {10},
keywords = {large language models, multi-agent debate, multi-modal reasoning},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3681219,
author = {Zhang, Zefan and Zhang, Weiqi and Li, Yanhui and Bai, Tian},
title = {Caption-Aware Multimodal Relation Extraction with Mutual Information Maximization},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681219},
doi = {10.1145/3664647.3681219},
abstract = {Multimodal Relation Extraction (MRE) has achieved great improvements. However, modern MRE models are easily affected by irrelevant objects during multimodal alignment which are called error sensitivity issues. The main reason is that visual features are not fully aligned with textual features and the reasoning process may suppress redundant and noisy information at the risk of losing critical information. In light of this, we propose a Caption-Aware Multimodal Relation Extraction Network with Mutual Information Maximization (CAMIM). Specifically, we first generate detailed image captions through the Large Language Model (LLM). Then, the Caption-Aware Module (CAM) hierarchically aligns the fine-grained visual entities and textual entities for reasoning. In addition, for preserving crucial information within different modalities, we leverage a Mutual Information Maximization method to regulate the multimodal reasoning module. Experiments show that our model outperforms the state-of-the-art MRE models on the benchmark dataset MNRE. Further ablation studies prove the pluggable and effective performance of our Caption-Aware Module and Mutual Information Maximization method. Our code is available at https://github.com/zefanZhang-cn/CAMIM.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {1148–1157},
numpages = {10},
keywords = {multimodal learning, multimodal relation extraction, mutual information maximization},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3681239,
author = {Xiao, Zeyu and Lu, Zhihe and Bi Mi, Michael and Xiong, Zhiwei and Wang, Xinchao},
title = {Unraveling Motion Uncertainty for Local Motion Deblurring},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681239},
doi = {10.1145/3664647.3681239},
abstract = {In real-world photography, local motion blur often arises from the interplay between moving objects and stationary backgrounds during exposure. Existing deblurring methods face challenges in addressing local motion deblurring due to (i) the presence of arbitrary localized blurs and uncertain blur extents; (ii) the limited ability to accurately identify specific blurs resulting from ambiguous motion boundaries. These limitations often lead to suboptimal solutions when estimating blur maps and generating final deblurred images. To that end, we propose a novel method named Motion-Uncertainty-Guided Network (MUGNet), which harnesses a probabilistic representational model to explicitly address the intricacies stemming from motion uncertainties. Specifically, MUGNet consists of two key components, i.e., motion-uncertainty quantification (MUQ) module and motion-masked separable attention (M2SA) module, serving for complementary purposes. Concretely, MUQ aims to learn a conditional distribution for accurate and reliable blur map estimation, while the M2SA module is to enhance the representation of regions influenced by local motion blur and static background, which is achieved by promoting the establishment of extensive global interactions. We demonstrate the superiority of our MUGNet with extensive experiments. The code is publicly available at: https://github.com/zeyuxiao1997/MUGNet.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {3065–3074},
numpages = {10},
keywords = {image deblurring, image restoration, local deblurring, motion uncertainty},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3681276,
author = {Huang, Shuo and Sun, Shikun and Wang, Zixuan and Qin, Xiaoyu and Xiong, Yanmin and Zhang, Yuan and Wan, Pengfei and Zhang, Di and Jia, Jia},
title = {PlacidDreamer: Advancing Harmony in Text-to-3D Generation},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681276},
doi = {10.1145/3664647.3681276},
abstract = {Recently, text-to-3D generation has attracted significant attention, resulting in notable performance enhancements. Previous methods utilize end-to-end 3D generation models to initialize 3D Gaussians, multi-view diffusion models to enforce multi-view consistency, and text-to-image diffusion models to refine details with score distillation algorithms. However, these methods exhibit two limitations. Firstly, they encounter conflicts in generation directions since different models aim to produce diverse 3D assets. Secondly, the issue of over-saturation in score distillation has not been thoroughly investigated and solved. To address these limitations, we propose PlacidDreamer, a text-to-3D framework that harmonizes initialization, multi-view generation, and text-conditioned generation with a single multi-view diffusion model, while simultaneously employing a novel score distillation algorithm to achieve balanced saturation. To unify the generation direction, we introduce the Latent-Plane module, a training-friendly plug-in extension that enables multi-view diffusion models to provide fast geometry reconstruction for initialization and enhanced multi-view images to personalize the text-to-image diffusion model. To address the over-saturation problem, we propose to view score distillation as a multi-objective optimization problem and introduce the Balanced Score Distillation algorithm, which offers a Pareto Optimal solution that achieves both rich details and balanced saturation. Extensive experiments validate the outstanding capabilities of our PlacidDreamer. The code is available at https://github.com/HansenHuang0823/PlacidDreamer.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {6880–6889},
numpages = {10},
keywords = {3d generation, score distillation, text-to-3d},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3681277,
author = {Zhou, Yanshan and Lai, Pingrui and Yu, Jiaqi and Xiong, Yingjie and Yang, Hua},
title = {Hydrodynamics-Informed Neural Network for Simulating Dense Crowd Motion Patterns},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681277},
doi = {10.1145/3664647.3681277},
abstract = {With global occurrences of crowd crushes and stampedes, dense crowd simulation has been drawing great attention. In this research, our goal is to simulate dense crowd motions under six classic motion patterns, more specifically, to generate subsequent motions of dense crowds from the given initial states. Since dense crowds share similarities with fluids, such as continuity and fluidity, one common approach for dense crowd simulation is to construct hydrodynamics-based models, which consider dense crowds as fluids, guide crowd motions with Navier-Stokes equations, and conduct dense crowd simulation by solving governing equations. Despite the proposal of these models, dense crowd simulation faces multiple challenges, including the difficulty of directly solving Navier-Stokes equations due to their nonlinear nature, the ignorance of distinctive crowd characteristics which fluids lack, and the gaps in the evaluation and validation of crowd simulation models. To address the above challenges, we build a hydrodynamic model, which captures the crowd physical properties (continuity, fluidity, etc.) with Navier-Stokes equations and reflects the crowd social properties (sociality, personality, etc.) with operators that describe crowd interactions and crowd-environment interactions. To tackle the computational problem, we propose to solve the governing equation based on Navier-Stokes equations using neural networks, and introduce the Hydrodynamics-Informed Neural Network (HINN) which preserves the structure of the governing equation in its network architecture. To facilitate the evaluation, we construct a new dense crowd motion video dataset called Dense Crowd Flow Dataset (DCFD), containing six classic motion patterns (line, curve, circle, cross, cluster and scatter) and 457 video clips, which can serve as the groundtruths for various objective metrics. Numerous experiments are conducted using HINN to simulate dense crowd motions under six motion patterns with video clips from DCFD. Objective evaluation metrics that concerns authenticity, fidelity and diversity demonstrate the superior performance of our model in dense crowd simulation compared to other simulation models. Our code and dataset are available at https://github.com/shanshan-zys/HINN.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {4553–4561},
numpages = {9},
keywords = {crowd simulation, dense crowd motion, hydrodynamic model},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3681315,
author = {Wang, Yujia and Zhang, Fang-Lue and Dodgson, Neil A.},
title = {ScanTD: 360° Scanpath Prediction based on Time-Series Diffusion},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681315},
doi = {10.1145/3664647.3681315},
abstract = {Scanpath generation in 360° images aims to model the realistic trajectories of gaze points that viewers follow when exploring panoramic environments. Existing methods for scanpath genera- tion suffer from various limitations, including a lack of global atten-tion to panoramic environments, insufficient diversity in generated scanpaths, and inadequate consideration of the temporal sequence of gaze points. To address these challenges, we propose a novel approach, named ScanTD, which employs a conditional Diffusion Model-based method to generate multiple scanpaths. Notably, a transformer-based time-series (TTS) module with a novel attention mechanism is integrated into ScanTD to capture the temporal de- pendency of gaze points effectively. Additionally, ScanTD utilizes a Vision Transformer-based method for image feature extraction, en- abling better learning of scene semantic information. Experimental results demonstrate that our approach outperforms state-of-the-art methods across three datasets. We further demonstrate its general- izability by applying it to the 360° saliency detection task.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {7764–7773},
numpages = {10},
keywords = {360 images, diffusion model, scanpath, vision transformer},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3681324,
author = {Zhang, Zerui and Yu, Jun and Cui, Liangxian and Ling, Qiang and Liu, Tianyu},
title = {Part-level Reconstruction for Self-Supervised Category-level 6D Object Pose Estimation with Coarse-to-Fine Correspondence Optimization},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681324},
doi = {10.1145/3664647.3681324},
abstract = {Self-supervised category-level 6D pose estimation stands as a fundamental task in computer vision. However, current self-supervised methods face two major challenges. Firstly, existing networks struggle to reconstruct precise object models due to significant part-level shape variations among specific categories. Secondly, they are impacted by the many-to-one ambiguity in the correspondences between pixels and point clouds. To address these challenges, we propose a novel approach that includes a Part-level Shape Reconstruction (PSR) module and a Coarse-to-Fine Correspondence Optimization (CFCO) module. In the (PSR) module, we introduce a part-level discrete shape memory to capture more fine-grained shape variations of different objects and use it to perform precise reconstruction. In the (CFCO) module, we utilize Hungarian matching to generate one-to-one pseudo labels at both region and pixel levels, which provides explicit supervision for the corresponding similarity matrices. We evaluate our method on the REAL275 and WILD6D datasets. Our extensive experiments show that our self-supervised approach outperforms existing methods and achieves new state-of-the-art results within the self-supervised framework.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {9980–9988},
numpages = {9},
keywords = {3d reconstruction, deep learning, multimodal data processing, self-supervised learning, visual-spatial correspondence},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3681339,
author = {Lu, Feihong and Wang, Weiqi and Luo, Yangyifei and Zhu, Ziqin and Sun, Qingyun and Xu, Baixuan and Shi, Haochen and Gao, Shiqi and Li, Qian and Song, Yangqiu and Li, Jianxin},
title = {Miko: Multimodal Intention Knowledge Distillation from Large Language Models for Social-Media Commonsense Discovery},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681339},
doi = {10.1145/3664647.3681339},
abstract = {Social media has become ubiquitous for connecting with others, staying updated with news, expressing opinions, and finding entertainment. However, understanding the intention behind social media posts remains challenging due to the implicit and commonsense nature of these intentions, the need for cross-modality understanding of both text and images, and the presence of noisy information such as hashtags, misspelled words, and complicated abbreviations. To address these challenges, we present MIKO, a Multimodal Intention Knowledge DistillatiOn framework that collaboratively leverages a Large Language Model (LLM) and a Multimodal Large Language Model (MLLM) to uncover users' intentions. Specifically, our approach uses an MLLM to interpret the image, an LLM to extract key information from the text, and another LLM to generate intentions. By applying MIKO to publicly available social media datasets, we construct an intention knowledge base featuring 1,372K intentions rooted in 137,287 posts. Moreover, We conduct a two-stage annotation to verify the quality of the generated knowledge and benchmark the performance of widely used LLMs for intention generation, and further apply MIKO to a sarcasm detection dataset and distill a student model to demonstrate the downstream benefits of applying intention knowledge.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {3303–3312},
numpages = {10},
keywords = {intention knowledge distillation, large language model, large vision language model, social media},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3681384,
author = {Yu, Hao and Yang, Xin and Gao, Xin and Feng, Yihui and Wang, Hao and Kang, Yan and Li, Tianrui},
title = {Overcoming Spatial-Temporal Catastrophic Forgetting for Federated Class-Incremental Learning},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681384},
doi = {10.1145/3664647.3681384},
abstract = {This paper delves into federated class-incremental learning (FCiL), where new classes appear continually or even privately to local clients. However, existing FCiL methods suffer from the problem of spatial-temporal catastrophic forgetting, i.e., forgetting the previously learned knowledge over time and the client-specific information owned by different clients. Additionally, private class and knowledge heterogeneity amongst local clients further exacerbate spatial-temporal forgetting, making FCiL challenging to apply. To address these issues, we propose Federated Class-specific Binary Classifier (FedCBC), an innovative approach to transferring and fusing knowledge across both temporal and spatial perspectives. FedCBC consists of two novel components: (1) continual personalization that distills previous knowledge from a global model to multiple local models, and (2) selective knowledge fusion that enhances knowledge integration of the same class from divergent clients and shares private knowledge with other clients. Extensive experiments using three newly-formulated metrics (termed GA, KRS, and KRT) demonstrate the effectiveness of the proposed approach. Our code is now hosted at: https://github.com/SkyOfBeginning/FedCBC.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {5280–5288},
numpages = {9},
keywords = {federated continual learning, spatial-temporal catastrophic forgetting},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3681433,
author = {Wang, Wenxuan and Bai, Haonan and Huang, Jen-tse and Wan, Yuxuan and Yuan, Youliang and Qiu, Haoyi and Peng, Nanyun and Lyu, Michael},
title = {New Job, New Gender? Measuring the Social Bias in Image Generation Models},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681433},
doi = {10.1145/3664647.3681433},
abstract = {Image generation models can generate or edit images from a given text. Recent advancements in image generation technology, exemplified by DALL-E and Midjourney, have been groundbreaking. These advanced models, despite their impressive capabilities, are often trained on massive Internet datasets, making them susceptible to generating content that perpetuates social stereotypes and biases, which can lead to severe consequences. Prior research on assessing bias within image generation models suffers from several shortcomings, including limited accuracy, reliance on extensive human labor, and lack of comprehensive analysis. In this paper, we propose BiasPainter, a novel evaluation framework that can accurately, automatically and comprehensively trigger social bias in image generation models. BiasPainter uses a diverse range of seed images of individuals and prompts the image generation models to edit these images using gender, race, and age-neutral queries. These queries span 62 professions, 39 activities, 57 types of objects, and 70 personality traits. The framework then compares the edited images to the original seed images, focusing on the significant changes related to gender, race, and age. BiasPainter adopts a key insight that these characteristics should not be modified when subjected to neutral prompts. Built upon this design, BiasPainter can trigger the social bias and evaluate the fairness of image generation models. We use BiasPainter to evaluate six widely-used image generation models, such as stable diffusion and Midjourney. Experimental results show that BiasPainter can successfully trigger social bias in image generation models. According to our human evaluation, BiasPainter can achieve 90.8\% accuracy on automatic bias detection, which is significantly higher than the results reported in previous work.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {3781–3789},
numpages = {9},
keywords = {image generation models, model evaluation, social bias},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3681466,
author = {Zhou, Pengfei and Feng, Fangxiang and Liu, Guang and Li, Ruifan and Wang, Xiaojie},
title = {DiffHarmony++: Enhancing Image Harmonization with Harmony-VAE and Inverse Harmonization Model},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681466},
doi = {10.1145/3664647.3681466},
abstract = {Latent diffusion model has demonstrated impressive efficacy in image generation and editing tasks. Recently, it has also promoted the advancement of image harmonization. However, methods involving latent diffusion model all face a common challenge: the severe image distortion introduced by the VAE component, while image harmonization is a low-level image processing task that relies on pixel-level evaluation metrics. In this paper, we propose Harmony-VAE, leveraging the input of the harmonization task itself to enhance the quality of decoded images. The input involving composite image contains the precise pixel level information, which can complement the correct foreground appearance and color information contained in denoised latents. Meanwhile, the inherent generative nature of diffusion models makes it naturally adapt to inverse image harmonization, i.e. generating synthetic composite images based on real images and foreground masks. We train an inverse harmonization diffusion model to perform data augmentation on two subsets of iHarmony4 and construct a new human harmonization dataset with prominent foreground objects. Extensive experiments demonstrate the effectiveness of our proposed Harmony-VAE and inverse harmonization model. Code and pretrained models are available at https://github.com/nicecv/DiffHarmony.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {10592–10601},
numpages = {10},
keywords = {data augmentation, image harmonization, inverse harmonization, latent diffusion model, stable diffusion, vae},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3681488,
author = {Ge, Zhiqi and Huang, Hongzhe and Zhou, Mingze and Li, Juncheng and Wang, Guoming and Tang, Siliang and Zhuang, Yueting},
title = {WorldGPT: Empowering LLM as Multimodal World Model},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681488},
doi = {10.1145/3664647.3681488},
abstract = {World models are progressively being employed across diverse fields, extending from basic environment simulation to complex scenario construction. However, existing models are mainly trained on domain-specific states and actions, and confined to single-modality state representations. In this paper, We introduce WorldGPT, a generalist world model built upon Multimodal Large Language Model (MLLM). WorldGPT acquires an understanding of world dynamics through analyzing millions of videos across various domains. To further enhance WorldGPT's capability in specialized scenarios and long-term tasks, we have integrated it with a novel cognitive architecture that combines memory offloading, knowledge retrieval, and context reflection. As for evaluation, we build WorldNet, a multimodal state transition prediction benchmark encompassing varied real-life scenarios. Conducting evaluations on WorldNet directly demonstrates WorldGPT's capability to accurately model state transition patterns, affirming its effectiveness in understanding and predicting the dynamics of complex scenarios. We further explore WorldGPT's emerging potential in serving as a world simulator, helping multimodal agents generalize to unfamiliar domains through efficiently synthesising multimodal instruction instances which are proved to be as reliable as authentic data for fine-tuning purposes. The code and dataset are available on the https://github.com/DCDmllm/WorldGPT},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {7346–7355},
numpages = {10},
keywords = {multimodal data synthesis, multimodal large language model, multimodal world model},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3681535,
author = {Zhou, Ziyin and Sun, Ke and Chen, Zhongxi and Kuang, Huafeng and Sun, Xiaoshuai and Ji, Rongrong},
title = {StealthDiffusion: Towards Evading Diffusion Forensic Detection through Diffusion Model},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681535},
doi = {10.1145/3664647.3681535},
abstract = {The rapid progress in generative models has given rise to the critical task of AI-Generated Content Stealth (AIGC-S), which aims to create AI-generated images that can evade both forensic detectors and human inspection. This task is crucial for understanding the vulnerabilities of existing detection methods and developing more robust techniques. However, current adversarial attacks often introduce visible noise, have poor transferability, and fail to address spectral differences between AI-generated and genuine images. To address this, we propose StealthDiffusion, a framework based on stable diffusion that modifies AI-generated images into high-quality, imperceptible adversarial examples capable of evading state-of-the-art forensic detectors. StealthDiffusion comprises two main components: Latent Adversarial Optimization, which generates adversarial perturbations in the latent space of stable diffusion, and Control-VAE, a module that reduces spectral differences between the generated adversarial images and genuine images without affecting the original diffusion model's generation process. Extensive experiments show that StealthDiffusion is effective in both white-box and black-box settings, transforming AI-generated images into high-quality adversarial forgeries with frequency spectra similar to genuine images. These forgeries are classified as genuine by advanced forensic classifiers and are difficult for humans to distinguish.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {3627–3636},
numpages = {10},
keywords = {adversarial attacks, ai-generated image, computer vision},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3681552,
author = {Gao, Minghe and Chen, Shuang and Pang, Liang and Yao, Yuan and Dang, Jisheng and Zhang, Wenqiao and Li, Juncheng and Tang, Siliang and Zhuang, Yueting and Chua, Tat-Seng},
title = {Fact :Teaching MLLMs with &lt;u&gt;Fa&lt;/u&gt;ithful, &lt;u&gt;C&lt;/u&gt;oncise and &lt;u&gt;T&lt;/u&gt;ransferable Rationales},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681552},
doi = {10.1145/3664647.3681552},
abstract = {The remarkable performance of Multimodal Large Language Models (MLLMs) has demonstrated their proficient understanding capabilities in handling various visual tasks. Nevertheless, the opaque nature of black-box reasoning processes persists as an enigma, rendering them uninterpretable and struggling with hallucination. Their ability to execute intricate reasoning tasks is also constrained, culminating in stagnation of progression. In this work, we introduce Fact, a novel paradigm designed to generate multimodal rationales that are faithful, concise, and transferable for teaching MLLMs. This paradigm utilizes verifiable visual programming to generate executable code guaranteeing faithfulness. Through a series of operations including pruning, merging, and bridging, the rationale enhances its conciseness. Furthermore, we filter rationales that can be transferred to end-to-end paradigms from programming paradigms to guarantee transferability. Empirical evidence from experiments demonstrates the superiority of Fact across models of varying parameter sizes, significantly enhancing their compositional reasoning and generalization ability and reducing hallucinations owing to its high correlation between images and text.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {846–855},
numpages = {10},
keywords = {distillation step-by-step, multimodel chain-of-thought, visual programming},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3681590,
author = {Chen, Jiali and Hei, Xusen and Xue, Yuqi and Wei, Yuancheng and Xie, Jiayuan and Cai, Yi and Li, Qing},
title = {Learning to Correction: Explainable Feedback Generation for Visual Commonsense Reasoning Distractor},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681590},
doi = {10.1145/3664647.3681590},
abstract = {Large multimodal models (LMMs) have shown remarkable performance in the visual commonsense reasoning (VCR) task, which aims to answer a multiple-choice question based on visual commonsense within an image. However, the ability of LMMs to correct potential visual commonsense errors in the distractor upon their occurrence is yet under-explored. Drawing inspiration from how a human teacher crafts challenging distractors to test students' comprehension of the concepts or skills and assists them in identifying and correcting errors toward the answer, we are the pioneering research for LMMs to simulate this error correction process. To this end, we employ GPT-4 as a ''teacher'' to collect the explainable feedback dataset VCR-DF for error correction, which serves as a benchmark to evaluate the ability of LMMs to identify misconceptions and clarify reasons behind the error in VCR distractors toward final answers. In addition, we propose an LMM-based Pedagogical Expert Instructed Feedback Generation (PEIFG) model to incorporate the learnable expert prompts and multimodal instruction as guidance for feedback generation. Experimental results show that our PEIFG significantly outperforms existing LMMs. We believe that our benchmark provides a new direction for evaluating the capabilities of LMMs.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {8209–8218},
numpages = {10},
keywords = {error correction, large multimodal model, visual commonsense},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3681593,
author = {Li, Haoxuan and Yang, Zhengmao and Ma, Yunshan and Bin, Yi and Yang, Yang and Chua, Tat-Seng},
title = {MM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681593},
doi = {10.1145/3664647.3681593},
abstract = {We study an emerging and intriguing problem of multimodal temporal event forecasting with large language models. Compared to using text or graph modalities, the investigation of utilizing images for temporal event forecasting has not been fully explored, especially in the era of large language models (LLMs). To bridge this gap, we are particularly interested in two key questions of: 1) why images will help in temporal event forecasting, and 2) how to integrate images into the LLM-based forecasting framework. To answer these research questions, we propose to identify two essential functions that images play in the scenario of temporal event forecasting, i.e., highlighting and complementary. Then, we develop a novel framework, named MM-Forecast. It employs an Image Function Identification module to recognize these functions as verbal descriptions using multimodal large language models (MLLMs), and subsequently incorporates these function descriptions into LLM-based forecasting models. To evaluate our approach, we construct a new multimodal dataset, MidEast-TE-mm, by extending an existing event dataset MidEast-TE-mini with images. Empirical studies demonstrate that our MM-Forecast can correctly identify the image functions, and further more, incorporating these verbal function descriptions significantly improves the forecasting performance. The dataset, code, and prompts are available at https://github.com/LuminosityX/MM-Forecast.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {2776–2785},
numpages = {10},
keywords = {multimodal event forecasting, multimodal large language model, temporal event forecasting},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3681661,
author = {Luo, Pengfei and Xu, Tong and Liu, Che and Zhang, Suojuan and Xu, Linli and Li, Minglei and Chen, Enhong},
title = {Bridging Gaps in Content and Knowledge for Multimodal Entity Linking},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681661},
doi = {10.1145/3664647.3681661},
abstract = {Multimodal Entity Linking (MEL) aims to address the ambiguity in multimodal mentions and associate them with Multimodal Knowledge Graphs (MMKGs). Existing works primarily focus on designing multimodal interaction and fusion mechanisms to enhance the performance of MEL. However, these methods still overlook two crucial gaps within the MEL task. One is the content discrepancy between mentions and entities, manifested as uneven information density. The other is the knowledge gap, indicating insufficient knowledge extraction and reasoning during the linking process. To bridge these gaps, we propose a novel framework FissFuse, as well as a plug-and-play knowledge-aware re-ranking method KAR. Specifically, FissFuse collaborates with the Fission and Fusion branches, establishing dynamic features for each mention-entity pair and adaptively learning multimodal interactions to alleviate content discrepancy. Meanwhile, KAR is endowed with carefully crafted instruction for intricate knowledge reasoning, serving as re-ranking agents empowered by Large Language Models (LLMs). Extensive experiments on two well-constructed MEL datasets demonstrate outstanding performance of FissFuse compared with various baselines. Comprehensive evaluations and ablation experiments validate the effectiveness and generality of KAR.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {9311–9320},
numpages = {10},
keywords = {content discrepancy, multimodal entity linking, multimodal fusion, multimodal knowledge graph},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3681688,
author = {Majumder, Navonil and Hung, Chia-Yu and Ghosal, Deepanway and Hsu, Wei-Ning and Mihalcea, Rada and Poria, Soujanya},
title = {Tango 2: Aligning Diffusion-based Text-to-Audio Generations through Direct Preference Optimization},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681688},
doi = {10.1145/3664647.3681688},
abstract = {Generative multimodal content is increasingly prevalent in much of the content creation arena, as it has the potential to allow artists and media personnel to create pre-production mockups by quickly bringing their ideas to life. The generation of audio from text prompts is an important aspect of such processes in the music and film industry. Many of the recent diffusion-based text-to-audio models focus on training increasingly sophisticated diffusion models on a large set of datasets of prompt-audio pairs. These models do not explicitly focus on the presence of concepts or events and their temporal ordering in the output audio with respect to the input prompt. Our hypothesis is focusing on how these aspects of audio generation could improve audio generation performance in the presence of limited data. As such, in this work, using an existing text-to-audio model Tango, we synthetically create a preference dataset where each prompt has a winner audio output and some loser audio outputs for the diffusion model to learn from. The loser outputs, in theory, have some concepts from the prompt missing or in an incorrect order. We fine-tune the publicly available Tango text-to-audio model using diffusion-DPO (direct preference optimization) loss on our preference dataset and show that it leads to improved audio output over Tango and AudioLDM2, in terms of both automatic- and manual-evaluation metrics.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {564–572},
numpages = {9},
keywords = {diffusion models, large language models, multimodal ai, preference optimization, text-to-audio generation},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3685508,
author = {de la Torre-Ortiz, Carlos and Ruotsalo, Tuukka},
title = {Perceptual Visual Similarity from EEG: Prediction and Image Generation},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3685508},
doi = {10.1145/3664647.3685508},
abstract = {Visual similarity estimation plays a fundamental role both in human cognition and multimedia information processing as it is the basis for many applications ranging from image search and recommendation to visual content generation. Existing computational models to assess visual similarity often diverge from human perception as they are typically trained solely on image data without information about how humans perceive image similarity. Here, we present an approach for learning perceptual visual similarity from brain recordings obtained via electroencephalogram (EEG). Our approach establishes a mapping between similarity reflected in the human cognitive system and a latent image representation. We evaluate the approach in two tasks. First, predicting visual distance from EEG data and second, adjusting a latent representation of a generative model to generate new images at a predicted distance from a given source image. Experiments demonstrate that the predicted distances from EEG closely align with the ground truth distances, and images generated using these predicted distances closely resemble the ground truth images. These findings open new possibilities for leveraging signals measured from human cognition to infer similarity as opposed to using only content-based models.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {11146–11155},
numpages = {10},
keywords = {eeg, generative modeling, perceptual similarity},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3666025.3699354,
author = {Sabharwal, Kanav and Ramesh, Soundarya and Wang, Jingxian and Divakaran, Dinil Mon and Chan, Mun Choon},
title = {Enhancing LoRa Reception with Generative Models: Channel-Aware Denoising of LoRaPHY Signals},
year = {2024},
isbn = {9798400706974},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3666025.3699354},
doi = {10.1145/3666025.3699354},
abstract = {The proliferation of Internet of Things (IoT) applications relying on Low Power Wide Area Networks (LPWANs) demands robust and energy-efficient communication solutions. Among various LP-WAN technologies, LoRa emerges as a prominent choice due to its long-range capabilities and low energy consumption. However, the practical deployment of LoRa is hindered by significant signal degradation caused by channel and hardware noise, especially in urban environments. We introduce GLoRiPHY, a novel generative framework designed to enhance the reception quality of LoRaPHY signals through a channel-aware denoising mechanism. Utilizing a transformer-based architecture, GLoRiPHY leverages the known preamble of LoRaPHY signals to compensate for channel-induced distortions, thereby generating a clean signal suitable for direct demodulation. The system integrates Convolutional Neural Networks (CNNs) for efficient feature encoding and decoding, maintaining a compact model footprint even at higher Spreading Factors (SFs). Evaluations on real-world and simulated datasets show that in comparison to the current state-of-the-art solution, GLoRiPHY significantly lowers the Symbol Error Rate (SER) by up to 2.85x and demonstrates generalizability in unseen environments, while reducing inference times by up to 5.75x.},
booktitle = {Proceedings of the 22nd ACM Conference on Embedded Networked Sensor Systems},
pages = {507–520},
numpages = {14},
keywords = {LoRA, error correction, signal denoising, deep learning},
location = {Hangzhou, China},
series = {SenSys '24}
}

@inproceedings{10.1145/3666025.3699355,
author = {Zhuang, Yan and Zheng, Zhenzhe and Wu, Fan and Chen, Guihai},
title = {LiteMoE: Customizing On-device LLM Serving via Proxy Submodel Tuning},
year = {2024},
isbn = {9798400706974},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3666025.3699355},
doi = {10.1145/3666025.3699355},
abstract = {Considering limited on-device resources, current practices are attempting to deploy a system-level mixture-of-experts (MoE)-based foundation LLM shared by multiple mobile apps on a device to support mobile intelligence. However, mobile apps are hard to customize their services that require tuning adapters associated with the LLM using private in-app data. The difficulty arises due to both the limited on-device resources and the restricted control that apps have over the foundation LLM. To address this issue, in this work, we propose LiteMoE, a novel proxy submodel tuning framework that supports mobile apps to efficiently fine-tune customized adapters on devices using proxy submodels. The key technique behind LiteMoE is a post-training submodel extraction method, whereby without additional re-training, we can identify and reserve critical experts, match and merge moderate experts, to extract a lightweight and effective proxy submodel from the foundation LLM for a certain app. We implemented a prototype of LiteMoE and evaluated it over various MoE-based LLMs and mobile computing tasks. The results show that with LiteMoE, mobile apps are able to fine-tune customized adapters on resource-limited devices, achieving 12.7\% accuracy improvement and 6.6\texttimes{} memory reduction compared with operating the original foundation LLM.},
booktitle = {Proceedings of the 22nd ACM Conference on Embedded Networked Sensor Systems},
pages = {521–534},
numpages = {14},
keywords = {customized LLM serving, on-device LLM fine-tuning, mixture of experts},
location = {Hangzhou, China},
series = {SenSys '24}
}

@proceedings{10.1145/3669940,
title = {ASPLOS '25: Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 1},
year = {2025},
isbn = {9798400706981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are delighted to introduce the first volume of the ASPLOS proceedings for 2025. The conference is in its third year of an experiment with a three-deadline structure: authors can submit to any of three separate review cycles handled by a single year-long program committee. This volume includes papers from the first two review cycles, which had submission deadlines in the spring and summer of 2024. We combined the two cycles because submission volumes in the spring cycle were disproportionately small.This volume contains 72 of the 74 papers accepted to ASPLOS 2025 to date. This includes papers accepted in the spring and summer cycles and those invited to submit a revision in the spring cycle that was ultimately accepted. Two of these 74 accepted papers are still undergoing artifact evaluation and will be published in a subsequent volume. The spring and summer review cycles saw a combined 586 submissions. These submissions were reviewed by a 208-person Program Committee augmented by 57 External Review Committee members. On occasion, we solicited a small number of external expert reviews. On the PC, 129 members self-reported they were in an academic role and 77 self-reported they were in an industrial role. On the ERC it was 43 and 13 respectively. The median PhD year of the combined committees was 2014. In addition to these committees, we engaged ten vice chairs, experienced and trusted reviewers who helped us monitor the review process for each paper.These committees reviewed all of the submissions that were not desk rejected (11 papers) or withdrawn (4 papers). In keeping with recent norms, the technical review happened in two phases. Each paper received three reviews in the first round, with, in most cases, two additional reviews in the second round for the 54\% of submissions that advanced. To assign reviews, we used the Toronto Paper Matching System (TPMS) to provide a preliminary review assignment that matched reviewer expertise. We then manually inspected and adjusted these assignments as needed: for example, to correct errors in TPMS's topic modeling or adjust to late-discovered conflicts. In addition, each paper was assigned a non-conflicted chair and a non-conflicted vice chair to provide two extra sets of eyes to monitor and facilitate the process. Due to the size and distribution of the PC, which spanned 14 time zones, the PC did not meet synchronously. Instead, each paper was discussed by the reviewers via comments in the HotCRP system. Ultimately, the discussion for each paper reached one of three outcomes: rejection, conditional acceptance, or major revision. All conditionally accepted papers were shepherded. Major revision papers were invited to revise and resubmit their paper for a second round of review by a subset of the original reviewers. All authors of papers that advanced to the second round of review were given the opportunity to see and respond to their reviewer questions prior to the reviewer discussion.},
location = {Rotterdam, Netherlands}
}

@inproceedings{10.1145/3669940.3707218,
author = {Ikarashi, Yuka and Qian, Kevin and Droubi, Samir and Reinking, Alex and Bernstein, Gilbert Louis and Ragan-Kelley, Jonathan},
title = {Exo 2: Growing a Scheduling Language},
year = {2025},
isbn = {9798400706981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3669940.3707218},
doi = {10.1145/3669940.3707218},
abstract = {User-schedulable languages (USLs) help programmers productively optimize programs by providing safe means of transforming them. Current USLs are designed to give programmers exactly the control they want, while automating all other concerns. However, there is no universal answer for what performance-conscious programmers want to control, how they want to control it, and what they want to automate, even in relatively narrow domains. We claim that USLs should, instead, be designed to grow. We present Exo 2, a scheduling language that enables users to define new scheduling operations externally to the compiler. By composing a set of trusted, fine-grained primitives, users can safely write their own scheduling library to build up desired automation. We identify actions (ways of modifying code), inspection (ways of interrogating code), and references (ways of pointing to code) as essential for any user-extensible USL. We fuse these ideas into a new mechanism called Cursors that enables the creation of scheduling libraries in user code. We demonstrate libraries that amortize scheduling effort across more than 80 high-performance kernels, reducing total scheduling code by an order of magnitude and delivering performance competitive with state-of-the-art implementations on three different platforms.},
booktitle = {Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 1},
pages = {426–444},
numpages = {19},
keywords = {high-performance computing, meta-programming, performance engineering, user-schedulable languages},
location = {Rotterdam, Netherlands},
series = {ASPLOS '25}
}

@inproceedings{10.1145/3669940.3707224,
author = {Tan, Yifan and Tan, Cheng and Mi, Zeyu and Chen, Haibo},
title = {PipeLLM: Fast and Confidential Large Language Model Services with Speculative Pipelined Encryption},
year = {2025},
isbn = {9798400706981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3669940.3707224},
doi = {10.1145/3669940.3707224},
abstract = {Confidential computing on GPUs, like NVIDIA H100, mitigates the security risks of outsourced Large Language Models (LLMs) by implementing strong isolation and data encryption. Nonetheless, this encryption incurs a significant performance overhead, reaching up to 52.8\% and 88.2\% throughput drop when serving OPT-30B and OPT-66B, respectively. To address this challenge, we introduce PipeLLM, a user-transparent runtime system. PipeLLM removes the overhead by overlapping the encryption and GPU computation through pipelining-an idea inspired by the CPU instruction pipelining-thereby effectively concealing the latency increase caused by encryption. The primary technical challenge is that, unlike CPUs, the encryption module lacks prior knowledge of the specific data needing encryption until it is requested by the GPUs. To this end, we propose speculative pipelined encryption to predict the data requiring encryption by analyzing the serving patterns of LLMs. Further, we have developed an efficient, low-cost pipeline relinquishing approach for instances of incorrect predictions. Our experiments show that compared with vanilla systems without confidential computing (e.g., vLLM, PEFT, and FlexGen), PipeLLM incurs modest overhead ( &lt; 19.6\% in throughput) across various LLM sizes, from 13B to 175B. PipeLLM's source code is available at https://github.com/SJTU-IPADS/PipeLLM.},
booktitle = {Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 1},
pages = {843–857},
numpages = {15},
keywords = {confidential virtual machine, large language model, nvidia confidential computing},
location = {Rotterdam, Netherlands},
series = {ASPLOS '25}
}

@inproceedings{10.1145/3669940.3707245,
author = {Xie, Minhui and Zeng, Shaoxun and Guo, Hao and Gao, Shiwei and Lu, Youyou},
title = {Frugal: Efficient and Economic Embedding Model Training with Commodity GPUs},
year = {2025},
isbn = {9798400706981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3669940.3707245},
doi = {10.1145/3669940.3707245},
abstract = {Embedding models show superiority in learning representations of massive ID-type features in sparse learning scenarios such as recommendation systems (e.g., user/item IDs) and graph learning (e.g., node/edge IDs). Commodity GPUs are highly favored for their cost-efficient computing power, which is ideally suited for the low computing demand of memory-intensive embedding models. However, directly running embedding model training on commodity GPUs yields poor performance because of their deficient communication resources (including low communication bandwidth and no PCIe P2P support).This paper presents Frugal, an embedding model training system tailored for commodity GPUs. Based on the observation that the communication between commodity GPUs must be bounced on host memory (due to no PCIe P2P support), the key idea of Frugal is proactively flushing, where each GPU proactively flushes its own parameters that other GPUs will access into host memory, thereby decoupling half of the communication overhead to non-critical paths. To alleviate the communication contention of proactively flushing on foreground training processes, Frugal assigns priorities to each flush operation, and prioritizes flushing parameters that GPUs will access while deferring others. Further, Frugal tailors a two-level priority queue to ensure high scalability for operations involving priorities. Frugal has been applied to train embedding models including recommendation models and graph embedding. Experiments indicate that Frugal can significantly increase training throughput on commodity GPUs, and achieve similar throughput compared to existing systems on datacenter GPUs with 4.0-4.3\texttimes{} improvement in cost-effectiveness.},
booktitle = {Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 1},
pages = {509–523},
numpages = {15},
keywords = {deep learning model training, embedding models, heterogeneous computing, machine learning system},
location = {Rotterdam, Netherlands},
series = {ASPLOS '25}
}

@proceedings{10.1145/3671127,
title = {BuildSys '24: Proceedings of the 11th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
year = {2024},
isbn = {9798400707063},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hangzhou, China}
}

@proceedings{10.1145/3673791,
title = {SIGIR-AP 2024: Proceedings of the 2024 Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region},
year = {2024},
isbn = {9798400707247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 2024 Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region - the Second SIGIR-AP, hosted at Waseda University Nishiwaseda Campus, Tokyo, Japan, in December 2024. Following the great success of the very first SIGIR-AP held in Beijing in November 2023, we have worked very hard with our organising team over a year so that SIGIR-AP 2024 will live up to its high expectations.As noted in the SIGIR-AP Charter and Bylaws, SIGIR-AP cares about sustainability, and is fully hybrid so that participants may choose to enjoy the conference online to avoid taking earth-unfriendly longdistance flights. Moreover, we are experimenting with a few novel approaches to running a sustainable conference, thanks to the generous support from the Tokyo Convention and Visitors Bureau: we will provide sustainable seafood lunch boxes, as well as a conference bag and a mug that are made from recycled plastic! In addition, a substantial portion of the banquet dishes will be vegetarian, which is known to be better for the environment than meat dishes (See Greta Thunberg: The Climate Book, p.249, Penguin Press, 2023).The SIGIR-AP 2024 features two keynotes from Japan: one by Dr. Momoe Makino (Institute of Developing Economies Japan External Trade Organization), titled Information Experiment: What Does Empirical Microeconomics Tell Us? and the other by Professor Sadao Kurohashi (National Institute of Informatics) titled From Data Platforms to Knowledge Infrastructure. We thank Dr. Makino and Professor Kurohashi for boosting the brilliance of our conference program.},
location = {Tokyo, Japan}
}

@inproceedings{10.1145/3673791.3698408,
author = {Si, Zihua and Sun, Zhongxiang and Chen, Jiale and Chen, Guozhang and Zang, Xiaoxue and Zheng, Kai and Song, Yang and Zhang, Xiao and Xu, Jun and Gai, Kun},
title = {Generative Retrieval with Semantic Tree-Structured Identifiers and Contrastive Learning},
year = {2024},
isbn = {9798400707247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3673791.3698408},
doi = {10.1145/3673791.3698408},
abstract = {In recommender systems, the retrieval phase is at the first stage and of paramount importance, requiring both effectiveness and very high efficiency. Recently, generative retrieval methods such as DSI and NCI, offering the benefit of end-to-end differentiability, have become an emerging paradigm for document retrieval with notable performance improvement, suggesting their potential applicability in recommendation scenarios. A fundamental limitation of these methods is their approach of generating item identifiers as text inputs, which fails to capture the intrinsic semantics of item identifiers as indices. The structural aspects of identifiers are only considered in construction and ignored during training. In addition, generative retrieval methods often generate imbalanced tree structures and yield identifiers with inconsistent lengths, leading to increased item inference time and sub-optimal performance. We introduce a novel generative retrieval framework named SEATER, which learns SEmAntic Tree-structured item identifiERs using an encoder-decoder structure. To optimize the structure of item identifiers, SEATER incorporates two contrastive learning tasks to ensure the alignment of token embeddings and the ranking orders of similar identifiers. In addition, SEATER devises a balanced k-ary tree structure of item identifiers, thus ensuring consistent semantic granularity and inference efficiency. Extensive experiments on three public datasets and an industrial dataset have demonstrated that SEATER outperforms a number of state-of-the-art models significantly.},
booktitle = {Proceedings of the 2024 Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region},
pages = {154–163},
numpages = {10},
keywords = {contrastive learning, generative retrieval, recommendation},
location = {Tokyo, Japan},
series = {SIGIR-AP 2024}
}

@inproceedings{10.1145/3673791.3698420,
author = {Chen, Nuo and Liu, Jiqun and Dong, Xiaoyu and Liu, Qijiong and Sakai, Tetsuya and Wu, Xiao-Ming},
title = {AI Can Be Cognitively Biased: An Exploratory Study on Threshold Priming in LLM-Based Batch Relevance Assessment},
year = {2024},
isbn = {9798400707247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3673791.3698420},
doi = {10.1145/3673791.3698420},
abstract = {Cognitive biases are systematic deviations in thinking that lead to irrational judgments and problematic decision-making, extensively studied across various fields. Recently, large language models (LLMs) have shown advanced understanding capabilities but may inherit human biases from their training data. While social biases in LLMs have been well-studied, cognitive biases have received less attention, with existing research focusing on specific scenarios. The broader impact of cognitive biases on LLMs in various decision-making contexts remains underexplored. We investigated whether LLMs are influenced by the threshold priming effect in relevance judgments, a core task and widely-discussed research topic in the Information Retrieval (IR) coummunity. The priming effect occurs when exposure to certain stimuli unconsciously affects subsequent behavior and decisions. Our experiment employed 10 topics from the TREC 2019 Deep Learning passage track collection, and tested AI judgments under different document relevance scores, batch lengths, and LLM models, including GPT-3.5, GPT-4, LLaMa2-13B and LLaMa2-70B. Results showed that LLMs tend to give lower scores to later documents if earlier ones have high relevance, and vice versa, regardless of the combination and model used. Our finding demonstrates that LLM's judgments, similar to human judgments, are also influenced by threshold priming biases, and suggests that researchers and system engineers should take into account potential human-like cognitive biases in designing, evaluating, and auditing LLMs in IR tasks and beyond},
booktitle = {Proceedings of the 2024 Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region},
pages = {54–63},
numpages = {10},
keywords = {cognitive bias, information retrieval evaluation, large language models, priming effect, relevance judgment, threshold priming},
location = {Tokyo, Japan},
series = {SIGIR-AP 2024}
}

@book{10.1145/3674127,
editor = {Alonso, Omar and Baeza-Yates, Ricardo},
title = {Information Retrieval: Advanced Topics and Techniques},
year = {2024},
isbn = {9798400710506},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {1},
volume = {60},
abstract = {In the last decade, deep learning and word embeddings have made significant impacts on information retrieval (IR) by adding techniques based in neural networks and language models. At the same time, certain search modalities such as neural IR and conversational search have become more popular. This book, written by international academic and industry experts, brings the field up to date with detailed discussions of these new approaches and techniques. The book is organized in three sections: Foundations, Adaptations and Concerns, and Verticals.Under Foundations, we address topics that form the basic structure of any modern IR system, including recommender systems. These new techniques are developed to augment indexing, retrieval, and ranking. Neural IR, recommender systems, evaluation, query-driven functionality, and knowledge graphs are covered in this section.IR systems need to adapt to specific user characteristics and preferences, and techniques that were considered too niche a few years ago are now a matter of system design consideration. The Adaptations and Concerns section covers the following topics: conversational search, cross-language retrieval, temporal extraction and retrieval, bias in retrieval systems, and privacy in search.While web search engines are the most popular information access point, there are cases where specific verticals provide a better experience in terms of content and relevance. The Verticals section describes eCommerce, professional search, personal collections, music retrieval, and biomedicine as examples.}
}

@inbook{10.1145/3674127.3702959,
author = {G\'{o}mez, Emilia and Cuesta, Helena and Gkiokas, Aggelos and G\'{o}mez-Ca\~{n}\'{o}n, Juan and Porcaro, Lorenzo and Yesiler, Furkan},
title = {Audio-based Music Retrieval},
year = {2024},
isbn = {9798400710506},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {1},
url = {https://doi.org/10.1145/3674127.3702959},
booktitle = {Information Retrieval: Advanced Topics and Techniques},
pages = {539–575},
numpages = {37}
}

@proceedings{10.1145/3674658,
title = {ICBBT '24: Proceedings of the 2024 16th International Conference on Bioinformatics and Biomedical Technology},
year = {2024},
isbn = {9798400717666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3674805,
title = {ESEM '24: Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Barcelona, Spain}
}

@inproceedings{10.1145/3674805.3686664,
author = {Hu, Gang and Zeng, Xiaoqin and Yu, Wanlong and Peng, Min and Yuan, Mengting and Duan, Liang},
title = {Unsupervised and Supervised Co-learning for Comment-based Codebase Refining and its Application in Code Search},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3686664},
doi = {10.1145/3674805.3686664},
abstract = {&nbsp;Background: Code pre-training and large language models are heavily dependent on data quality. These models require a vast, high-quality corpus matching text descriptions with codes to establish semantic correlations between natural and programming languages. Unlike NLP tasks, code comment heavily relies on specialized programming knowledge and is often limited in quantity and variety. Thus, most widely available open-source datasets are established with compromise and noise from platforms, such as StackOverflow, where code snippets are often incomplete. This may lead to significant errors when deploying the trained models in real-world applications. &nbsp;Aims: Comments as a substitute for queries are used to build code search datasets from GitHub. While comments describe code functionality and details, they often contain noise and differ from queries. Thus, our research focuses on improving the syntactic and semantic quality of code comments. &nbsp;Method: We propose a comment-based data refinement framework CoCoRF 1 via an unsupervised and supervised co-learning technique. It applies manually defined rules for syntax filtering and constructs a bootstrap query corpus via the WTFF algorithm for training the TVAE model for further semantic filtering. &nbsp;Results: Our study shows that CoCoRF achieves high efficiency with less computational resource, and outperforms comparison models in DeepCS code search task. &nbsp;Conclusions: Our findings indicate that the CoCoRF framework significantly improves the performance of code search tasks by enhancing the quality of code datasets.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {1–12},
numpages = {12},
keywords = {Code Search, CodeSearchNet Cleaning, Comment-Code dataset, Self-attention Mechanism},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@inproceedings{10.1145/3674805.3686684,
author = {Astekin, Merve and Hort, Max and Moonen, Leon},
title = {A Comparative Study on Large Language Models for Log Parsing},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3686684},
doi = {10.1145/3674805.3686684},
abstract = {Background: Log messages provide valuable information about the status of software systems. This information is provided in an unstructured fashion and automated approaches are applied to extract relevant parameters. To ease this process, log parsing can be applied, which transforms log messages into structured log templates. Recent advances in language models have led to several studies that apply ChatGPT to the task of log parsing with promising results. However, the performance of other state-of-the-art large language models (LLMs) on the log parsing task remains unclear. Aims: In this study, we investigate the current capability of state-of-the-art LLMs to perform log parsing. Method: We select six recent LLMs, including both paid proprietary (GPT-3.5, Claude 2.1) and four free-to-use open models, and compare their performance on system logs obtained from a selection of mature open-source projects. We design two different prompting approaches and apply the LLMs on 1,354 log templates across 16 different projects. We evaluate their effectiveness, in the number of correctly identified templates, and the syntactic similarity between the generated templates and the ground truth. Results: We found that free-to-use models are able to compete with paid models, with CodeLlama extracting 10\% more log templates correctly than GPT-3.5. Moreover, we provide qualitative insights into how usable these six models are for log parsing. Conclusions: Our results reveal that some of the smaller, free-to-use LLMs can considerably assist log parsing compared to their paid proprietary competitors, especially code-specialized models.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {234–244},
numpages = {11},
keywords = {large language models, log analysis, log parsing},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@inproceedings{10.1145/3674805.3690746,
author = {Almeida, Aylton and Xavier, Laerte and Valente, Marco Tulio},
title = {Automatic Library Migration Using Large Language Models: First Results},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3690746},
doi = {10.1145/3674805.3690746},
abstract = {Despite being introduced only a few years ago, Large Language Models (LLMs) are already widely used by developers for code generation. However, their application in automating other Software Engineering activities remains largely unexplored. Thus, in this paper, we report the first results of a study in which we are exploring the use of ChatGPT to support API migration tasks, an important problem that demands manual effort and attention from developers. Specifically, in the paper, we share our initial results involving the use of ChatGPT to migrate a client application to use a newer version of SQLAlchemy, an ORM (Object Relational Mapping) library widely used in Python. We evaluate the use of three types of prompts (Zero-Shot, One-Shot, and Chain Of Thoughts) and show that the best results are achieved by the One-Shot prompt, followed by the Chain Of Thoughts. Particularly, with the One-Shot prompt we were able to successfully migrate all columns of our target application and upgrade its code to use new functionalities enabled by SQLAlchemy’s latest version, such as Python’s asyncio and typing modules, while preserving the original code behavior.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {427–433},
numpages = {7},
keywords = {API Migration, ChatGPT, Large Language Models, Python, SQLAlchemy},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@inproceedings{10.1145/3674805.3695393,
author = {Novielli, Nicole and Oliveto, Rocco and Palomba, Fabio and Calefato, Fabio and Colavito, Giuseppe and De Martino, Vincenzo and Della Porta, Antonio and Giordano, Giammaria and Guglielmi, Emanuela and Lanubile, Filippo and Quaranta, Luigi and Recupito, Gilberto and Scalabrino, Simone and Spina, Angelica and Vitale, Antonio},
title = {Continuous Quality Improvement of AI-based Systems: the QualAI Project},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3695393},
doi = {10.1145/3674805.3695393},
abstract = {QualAI is a two-year project aimed at defining a set of recommenders to continuously monitor, assess, and improve the quality of AI-based systems, with a particular focus on machine learning (ML) applications. We will develop recommenders for the quality assurance of both data and ML models to enable practitioners to mitigate technical debt. Special attention will be paid to communication challenges that may arise in hybrid teams comprising data scientists and software developers. This paper presents the project outline, provides an executive summary of the research activities, outlines the expected project outcomes, and reports the results obtained to date.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {603–607},
numpages = {5},
keywords = {Machine Learning, Quality Assurance, Recommender Systems, Software Engineering},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@inproceedings{10.1145/3674805.3695403,
author = {Zhang, Lingzhe and Jia, Tong and Wang, Kangjin and Jia, Mengxi and Yang, Yong and Li, Ying},
title = {Reducing Events to Augment Log-based Anomaly Detection Models: An Empirical Study},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3695403},
doi = {10.1145/3674805.3695403},
abstract = {As software systems grow increasingly intricate, the precise detection of anomalies have become both essential and challenging. Current log-based anomaly detection methods depend heavily on vast amounts of log data leading to inefficient inference and potential misguidance by noise logs. However, the quantitative effects of log reduction on the effectiveness of anomaly detection remain unexplored. Therefore, we first conduct a comprehensive study on six distinct models spanning three datasets. Through the study, the impact of log quantity and their effectiveness in representing anomalies is qualifies, uncovering three distinctive log event types that differently influence model performance. Drawing from these insights, we propose LogCleaner: an efficient methodology for the automatic reduction of log events in the context of anomaly detection. Serving as middleware between software systems and models, LogCleaner continuously updates and filters anti-events and duplicative-events in the raw generated logs. Experimental outcomes highlight LogCleaner’s capability to reduce over 70\% of log events in anomaly detection, accelerating the model’s inference speed by approximately 300\%, and universally improving the performance of models for anomaly detection.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {538–548},
numpages = {11},
keywords = {Anomaly Detection, Log Analysis, Log Reduction},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@proceedings{10.1145/3675888,
title = {IC3-2024: Proceedings of the 2024 Sixteenth International Conference on Contemporary Computing},
year = {2024},
isbn = {9798400709722},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Noida, India}
}

@proceedings{10.1145/3676641,
title = {ASPLOS '25: Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
year = {2025},
isbn = {9798400710797},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the second of three volumes of the ASPLOS 2025 proceedings. This volume includes the papers from the summer submission cycle that underwent a major revision and the directly accepted papers from the fall cycle. There will be one more final volume, which will consist of the accepted revisions from the fall submission cycle.This volume's 88 papers comprise 40 revised papers from the summer cycle, 46 directly accepted papers from the fall cycle, and 2 papers that were deferred from the previous volume to accommodate artifact evaluation (one each from the spring and summer cycles). The table below shows the status so far for all three cycles of the ASPLOS 2025 conference.},
location = {Rotterdam, Netherlands}
}

@inproceedings{10.1145/3676641.3716009,
author = {He, Yintao and Mao, Haiyu and Giannoula, Christina and Sadrosadati, Mohammad and G\'{o}mez-Luna, Juan and Li, Huawei and Li, Xiaowei and Wang, Ying and Mutlu, Onur},
title = {PAPI: Exploiting Dynamic Parallelism in Large Language Model Decoding with a Processing-In-Memory-Enabled Computing System},
year = {2025},
isbn = {9798400710797},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676641.3716009},
doi = {10.1145/3676641.3716009},
abstract = {Large language models (LLMs) are widely used for natural language understanding and text generation. An LLM model relies on a time-consuming step called LLM decoding to generate output tokens. Several prior works focus on improving the performance of LLM decoding using parallelism techniques, such as batching and speculative decoding. State-of-the-art LLM decoding has both compute-bound and memory-bound kernels. Some prior works statically identify and map these different kernels to a heterogeneous architecture consisting of both processing-in-memory (PIM) units and computation-centric accelerators (e.g., GPUs). We observe that characteristics of LLM decoding kernels (e.g., whether or not a kernel is memory-bound) can change dynamically due to parameter changes to meet user and/or system demands, making (1) static kernel mapping to PIM units and computation-centric accelerators suboptimal, and (2) one-size-fits-all approach of designing PIM units inefficient due to a large degree of heterogeneity even in memory-bound kernels.In this paper, we aim to accelerate LLM decoding while considering the dynamically changing characteristics of the kernels involved. We propose PAPI (PA rallel Decoding with PI M), a PIM-enabled heterogeneous architecture that exploits dynamic scheduling of compute-bound or memory-bound kernels to suitable hardware units. PAPI has two key mechanisms: (1) online kernel characterization to dynamically schedule kernels to the most suitable hardware units at runtime and (2) a PIM-enabled heterogeneous computing system that harmoniously orchestrates both computation-centric processing units (GPU) and hybrid PIM units with different computing capabilities. Our experimental results on three broadly-used LLMs (i.e., LLaMA-65B, GPT-3 66B, and GPT-3 175B) show that PAPI achieves 1.8\texttimes{} and 11.1\texttimes{} speedups over a state-of-the-art heterogeneous LLM accelerator (i.e., GPU and PIM) and a state-of-the-art PIM-only LLM accelerator, respectively.},
booktitle = {Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
pages = {766–782},
numpages = {17},
keywords = {dynamic scheduling, generative artificial intelligence, heterogeneous systems, large language models, processing-in-memory},
location = {Rotterdam, Netherlands},
series = {ASPLOS '25}
}

@inproceedings{10.1145/3676641.3716269,
author = {Qiao, Liang and Shi, Jun and Hao, Xiaoyu and Fang, Xi and Zhang, Sen and Zhao, Minfan and Zhu, Ziqi and Chen, Junshi and An, Hong and Tang, Xulong and Li, Bing and Yuan, Honghui and Wang, Xinyang},
title = {Pruner: A Draft-then-Verify Exploration Mechanism to Accelerate Tensor Program Tuning},
year = {2025},
isbn = {9798400710797},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676641.3716269},
doi = {10.1145/3676641.3716269},
abstract = {Tensor program tuning is essential for the efficient deployment of deep neural networks. Search-based approaches have demonstrated scalability and effectiveness in automatically finding high-performance programs for specific hardware. However, the search process is often inefficient, taking hours or even days to discover optimal programs due to the exploration mechanisms guided by an accurate but slow-learned cost model. Meanwhile, the learned cost model trained on one platform cannot seamlessly adapt online to another, which we call cross-platform online unawareness. In this work, we propose Pruner and MoA-Pruner. Pruner is a ''Draft-then-Verify'' exploration mechanism that accelerates the schedule search process. Instead of applying the complex learned cost model to all explored candidates, Pruner drafts small-scale potential candidates by introducing a naive Symbol-based Analyzer (draft model), then identifies the best candidates by the learned cost model. MoA-Pruner introduces a Momentum online Adaptation strategy to address the cross-platform online unawareness.We incorporate Pruner into the TVM and conduct extensive experiments on three GPU-based platforms. Results show considerable speedup in schedule search time. In online tuning scenarios, Pruner and MoA-Pruner achieve an average speedup of 2.6 \texttimes{} and 4.82 \texttimes{} compared to Ansor. In offline tuning scenarios, Pruner achieves an average speedup of 4.75 \texttimes{} and 4.05\texttimes{} compared to TenSet and TLP, respectively. Furthermore, Pruner achieves an average speedup of 4.08 \texttimes{} compared to MetaSchedule on TensorCore.},
booktitle = {Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
pages = {949–965},
numpages = {17},
keywords = {code generation, compiler optimization, tensor program tuning},
location = {Rotterdam, Netherlands},
series = {ASPLOS '25}
}

@inproceedings{10.1145/3676641.3716278,
author = {Tan, Xin and Jiang, Yimin and Yang, Yitao and Xu, Hong},
title = {Towards End-to-End Optimization of LLM-based Applications with Ayo},
year = {2025},
isbn = {9798400710797},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676641.3716278},
doi = {10.1145/3676641.3716278},
abstract = {Large language model (LLM)-based applications consist of both LLM and non-LLM components, each contributing to the end-to-end latency. Despite great efforts to optimize LLM inference, end-to-end workflow optimization has been overlooked. Existing frameworks employ coarse-grained orchestration with task modules, which confines optimizations to within each module and yields suboptimal scheduling decisions.We propose fine-grained end-to-end orchestration, which utilizes task primitives as the basic units and represents each query's workflow as a primitive-level dataflow graph. This explicitly exposes a much larger design space, enables optimizations in parallelization and pipelining across primitives of different modules, and enhances scheduling to improve application-level performance. We build Ayo, a novel orchestration framework for LLM-based applications that implements this scheme. Comprehensive experiments show that Ayo can achieve up to 2.09x speedup over existing systems across various popular LLM applications.},
booktitle = {Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
pages = {1302–1316},
numpages = {15},
keywords = {large language model, ml inference, resource scheduling},
location = {Rotterdam, Netherlands},
series = {ASPLOS '25}
}

@proceedings{10.1145/3677052,
title = {ICAIF '24: Proceedings of the 5th ACM International Conference on AI in Finance},
year = {2024},
isbn = {9798400710810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Brooklyn, NY, USA}
}

@inproceedings{10.1145/3677052.3698602,
author = {Blanco Lambruschini, Braulio C. and Brorsson, Mats},
title = {Transforming Unstructured Sensitive Information into Structured Knowledge},
year = {2024},
isbn = {9798400710810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677052.3698602},
doi = {10.1145/3677052.3698602},
abstract = {Information is crucial in today’s context, yet less than 20\% of companies utilize their unstructured data due to its complexity. Information Extraction (IE) is vital for effective data use, but current IE models face four major issues. First, they often provide limited information, such as a simple entity-attribute relation. Second, they struggle with multiple languages. Models like GPT, Mistral, and Llama3 show promise but face a third issue: output reliability due to hallucinations. Fourth, there is a challenge in reducing sensitive data leakage after fine-tuning models. This study introduces an enhanced approach for fine-tuning GPT-based models, designed to extract and assess information involving multiple entities and attributes, performing both multientity extraction (MEE) and multirelation extraction (MRE), and presenting results in a JSON format. Our methodology evaluates the impact of using synthetic data for fine-tuning to ensure reliable outcomes. Applied to legal documents from the Luxembourg Business Registers (LBR), our findings show that replacing sensitive data with synthetic data significantly improves the fine-tuning of Llama3-based models, though not for Mistral-based models. Our top models outperform Mistral in various scenarios, requiring only 500 samples for fine-tuning and running efficiently on modest servers. This approach is suitable for multilingual Information Extraction in any domain.},
booktitle = {Proceedings of the 5th ACM International Conference on AI in Finance},
pages = {831–838},
numpages = {8},
keywords = {Finance, Information Extraction, LLM},
location = {Brooklyn, NY, USA},
series = {ICAIF '24}
}

@inproceedings{10.1145/3677052.3698612,
author = {Golgoon, Ashkan and Filom, Khashayar and Ravi Kannan, Arjun},
title = {Mechanistic interpretability of large language models with applications to the financial services industry},
year = {2024},
isbn = {9798400710810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677052.3698612},
doi = {10.1145/3677052.3698612},
abstract = {Large Language Models exhibit remarkable capabilities across a broad spectrum of applications. Nevertheless, due to their intrinsic complexity, these models present substantial challenges in interpreting their internal decision-making processes. This lack of transparency poses critical challenges when it comes to their adaptation by financial institutions, where concerns and accountability regarding bias, fairness, and reliability are of paramount importance. Mechanistic interpretability aims at reverse engineering complex AI models such as transformers. In this paper, we are pioneering the use of mechanistic interpretability to shed some light on the inner workings of large language models for use in financial services applications. We offer several examples of how algorithmic tasks can be designed for compliance monitoring purposes. In particular, we investigate GPT-2 Small’s attention pattern when prompted to identify potential violation of Fair Lending laws. Using direct logit attribution, we study the contributions of each layer and its corresponding attention heads to the logit difference in the residual stream. Finally, we design clean and corrupted prompts and use activation patching as a causal intervention method to localize our task completion components further. We observe that the (positive) heads 10.2 (head 2, layer 10), 10.7, and 11.3, as well as the (negative) heads 9.6 and 10.6 play a significant role in the task completion.},
booktitle = {Proceedings of the 5th ACM International Conference on AI in Finance},
pages = {660–668},
numpages = {9},
keywords = {FinTech, Large Language Models (LLMs), Mechanistic Interpretability, Natural Language Processing., Transformer Circuits},
location = {Brooklyn, NY, USA},
series = {ICAIF '24}
}

@inproceedings{10.1145/3677052.3698628,
author = {Noels, Sander and De Blaere, Jorne and De Bie, Tijl},
title = {A Dutch Financial Large Language Model},
year = {2024},
isbn = {9798400710810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677052.3698628},
doi = {10.1145/3677052.3698628},
abstract = {This paper presents FinGEITje, the first Dutch financial Large Language Model (LLM) specifically designed and optimized for various financial tasks. Together with the model, we release a specialized Dutch financial instruction tuning dataset with over 140,000 samples, constructed employing an automated translation and data processing method. The open-source data construction method is provided, facilitating the creation of financial instruction datasets in different languages. To evaluate model performance, the study introduces the first Dutch financial evaluation benchmark, along with an automated evaluation method that utilizes an LLM as an independent evaluator, reducing manual intervention in performance evaluation. The experimental results highlight the superior performance of FinGEITje across five critical Dutch and English financial tasks.},
booktitle = {Proceedings of the 5th ACM International Conference on AI in Finance},
pages = {283–291},
numpages = {9},
keywords = {Financial Large Language Model, Instruction Tuning., Natural Language Processing},
location = {Brooklyn, NY, USA},
series = {ICAIF '24}
}

@inproceedings{10.1145/3677052.3698640,
author = {Kubiak, Szymon and Weyde, Tillman and Galkin, Oleksandr and Philps, Daniel and Gopal, Ram},
title = {Denoising Diffusion Probabilistic Model for Realistic Financial Correlation Matrices},
year = {2024},
isbn = {9798400710810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677052.3698640},
doi = {10.1145/3677052.3698640},
abstract = {Financial correlation matrices play a vital role in various quantitative finance applications, but generating synthetic correlation matrices that accurately reflect market structures and stylized facts remains challenging. We introduce a novel application of denoising diffusion probabilistic models (DDPMs) for this task, proposing both unconditional (DM) and conditional (CDM) models. Our experimental evaluation demonstrates the superior performance of our models in generating correlation matrices that closely resemble empirical data while capturing differences across market regimes. We also present a case study highlighting the utility of our approach in assessing asset allocation frameworks and enhancing risk modeling by augmenting empirical datasets with synthetic data. Our findings showcase DDPMs’ potential in mitigating limitations of scarce financial data, enabling robust quantitative modeling and analysis.},
booktitle = {Proceedings of the 5th ACM International Conference on AI in Finance},
pages = {1–9},
numpages = {9},
keywords = {Generative machine learning models, asset allocation, correlation matrices, financial risk management, synthetic data},
location = {Brooklyn, NY, USA},
series = {ICAIF '24}
}

@inproceedings{10.1145/3677052.3698659,
author = {Schreyer, Marco and Sattarov, Timur and Sim, Alexander and Wu, Kesheng},
title = {Imb-FinDiff: Conditional Diffusion Models for Class Imbalance Synthesis of Financial Tabular Data},
year = {2024},
isbn = {9798400710810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677052.3698659},
doi = {10.1145/3677052.3698659},
abstract = {Handling imbalanced datasets remains a critical challenge in financial machine-learning applications such as loan approval, credit scoring, and fraud detection. We present Imbalanced Financial Diffusion (Imb-FinDiff), a novel denoising diffusion framework designed to address class imbalance in financial tabular data. Our framework leverages embedding encodings for categorical and numerical attributes, effectively managing the complexities of mixed-type financial datasets. By incorporating a dual learning objective, (i)&nbsp;diffusion timestep noise and (ii)&nbsp;class label prediction, we synthesize minority class samples. Extensive experiments on diverse and real-world financial datasets demonstrate that Imb-FinDiff maintains the statistical properties of the original data while reducing bias caused by class imbalance. The minority class samples generated by Imb-FinDiff enhance the utility and fidelity of downstream machine learning classifiers.},
booktitle = {Proceedings of the 5th ACM International Conference on AI in Finance},
pages = {617–625},
numpages = {9},
keywords = {denoising diffusion probabilistic models, imbalanced learning, mixed-type tabular data, neural networks, synthetic data generation},
location = {Brooklyn, NY, USA},
series = {ICAIF '24}
}

@proceedings{10.1145/3677388,
title = {MIG '24: Proceedings of the 17th ACM SIGGRAPH Conference on Motion, Interaction, and Games},
year = {2024},
isbn = {9798400710902},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Arlington, VA, USA}
}

@inbook{10.1145/3677389.3702588,
author = {Keya, Farhana and Jaradeh, Mohamad Yaser and Auer, S\'{o}ren},
title = {Leveraging LLMs for Scientific Abstract Summarization: Unearthing the Essence of Research in a Single Sentence},
year = {2025},
isbn = {9798400710933},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677389.3702588},
abstract = {There are lots of scientific articles are being published every year, it is increasingly challenging for researchers to maintain oversight and track scientific progress. Meanwhile, Large Language Models (LLMs) have revolutionized natural language processing tasks. This research focuses on generating summaries from research paper abstracts by utilizing LLMs and comprehensively evaluating the performance of the summarization. LLMs offer customizable outputs through Prompt Engineering by leveraging descriptive instructions including instructive examples and injection of context knowledge. We investigate the performance of various prompting techniques for various LLMs using both GPT-4 and human evaluation. For that purpose, we created a comprehensive benchmark dataset for scholarly summarization covering multiple scientific domains. We integrated our approach in the Open Research Knowledge Graph (ORKG) to enable quicker syn- thesis of research findings and trends across multiple studies, facilitating the dissemination of scientific knowledge to policymakers, practitioners, and the public.},
booktitle = {Proceedings of the 24th ACM/IEEE Joint Conference on Digital Libraries},
articleno = {9},
numpages = {7}
}

@inbook{10.1145/3677389.3702605,
author = {Azher, Ibrahim Al and Seethi, Venkata Devesh Reddy and Akella, Akhil Pandey and Alhoori, Hamed},
title = {LimTopic: LLM-based Topic Modeling and Text Summarization for Analyzing Scientific Articles limitations},
year = {2025},
isbn = {9798400710933},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677389.3702605},
abstract = {The "limitations" sections of scientific articles play a crucial role in highlighting the boundaries and shortcomings of research, thereby guiding future studies and improving research methods. Analyzing these limitations benefits researchers, reviewers, funding agencies, and the broader academic community. We introduce LimTopic, a strategy where Topic generation in Limitation sections in scientific articles with Large Language Models (LLMs). Here, each topic contains the title and `Topic Summary.' This study focuses on effectively extracting and understanding these limitations through topic modeling and text summarization, utilizing the capabilities of LLMs. We extracted limitations from research articles and applied an LLM-based topic modeling integrated with the BERtopic approach to generate a title for each topic and `Topic Sentences.' To enhance comprehension and accessibility, we employed LLM-based text summarization to create concise and generalizable summaries for each topic's Topic Sentences and produce a `Topic Summary.' Our experimentation involved prompt engineering, fine-tuning LLM and BERTopic, and integrating BERTopic with LLM to generate topics, titles, and a topic summary. We also experimented with various LLMs with BERTopic for topic modeling and various LLMs for text summarization tasks. Our results showed that the combination of BERTopic and GPT 4 performed the best in terms of silhouette and coherence scores in topic modeling, and the GPT4 summary outperformed other LLM tasks as a text summarizer. Our code and dataset are available at https://github.com/IbrahimAlAzhar/LimTopic/tree/master.},
booktitle = {Proceedings of the 24th ACM/IEEE Joint Conference on Digital Libraries},
articleno = {30},
numpages = {12}
}

@proceedings{10.1145/3677846,
title = {W4A '24: Proceedings of the 21st International Web for All Conference},
year = {2024},
isbn = {9798400710308},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Singapore, Singapore}
}

@proceedings{10.1145/3678610,
title = {ICSLT '24: Proceedings of the 2024 10th International Conference on e-Society, e-Learning and e-Technologies (ICSLT)},
year = {2024},
isbn = {9798400716799},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3678698,
title = {VINCI '24: Proceedings of the 17th International Symposium on Visual Information Communication and Interaction},
year = {2024},
isbn = {9798400709678},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3678717,
title = {SIGSPATIAL '24: Proceedings of the 32nd ACM International Conference on Advances in Geographic Information Systems},
year = {2024},
isbn = {9798400711077},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {These proceedings contain the papers from the 32nd ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL 2024), held as an in-person event in Atlanta, GA, USA on October 29- November 01, 2024. SIGSPATIAL academics, students, and industry practitioners could attend the technical talks in-person, meet in the hallway for further discussions, and boost their professional network over lunch.},
location = {Atlanta, GA, USA}
}

@inproceedings{10.1145/3678717.3691265,
author = {Al-Lawati, Ali and Eshra, Elsayed and Mitra, Prasenjit},
title = {WildGraph: Realistic Long-Horizon Trajectory Generation with Limited Sample Size},
year = {2024},
isbn = {9798400711077},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678717.3691265},
doi = {10.1145/3678717.3691265},
abstract = {Trajectory generation is an important task in movement studies. Generated trajectories augment the training corpus of deep learning applications, facilitate experimental and theoretical research, and mitigate the privacy concerns associated with real trajectories. This is especially significant in the wildlife domain, where trajectories are scarce due to the ethical and technical constraints of the collection process. In this paper, we consider the problem of generating long-horizon trajectories, akin to wildlife migration, based on a small set of real samples. We propose a hierarchical approach to learn the global movement characteristics of the real dataset, and recursively refine localized regions. Our solution, WildGraph discretizes the geographic path into a prototype network of H31 regions and leverages a novel recurrent VAE to probabilistically generate paths over the regions, based on occupancy. Experiments performed on two wildlife migration datasets demonstrate the remarkable capability of WildGraph to generate realistic months-long trajectories using a sample size as small as 60 while improving generalization compared to existing work. Moreover, WildGraph achieves superior or comparable performance on performance measures, including geographic imagery similarity. Our code is published on the following repository: https://github.com/aliwister/wildgraph.},
booktitle = {Proceedings of the 32nd ACM International Conference on Advances in Geographic Information Systems},
pages = {247–258},
numpages = {12},
keywords = {data mining, small data, trajectory generation, wildlife movement},
location = {Atlanta, GA, USA},
series = {SIGSPATIAL '24}
}

@inproceedings{10.1145/3678717.3691303,
author = {Hsu, Shang-Ling and Tung, Emmanuel and Krumm, John and Shahabi, Cyrus and Shafique, Khurram},
title = {TrajGPT: Controlled Synthetic Trajectory Generation Using a Multitask Transformer-Based Spatiotemporal Model},
year = {2024},
isbn = {9798400711077},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678717.3691303},
doi = {10.1145/3678717.3691303},
abstract = {Human mobility modeling from GPS-trajectories and synthetic trajectory generation are crucial for various applications, such as urban planning, disaster management and epidemiology. Both of these tasks often require filling gaps in a partially specified sequence of visits, - a new problem that we call "controlled" synthetic trajectory generation. Existing methods for next-location prediction or synthetic trajectory generation cannot solve this problem as they lack the mechanisms needed to constrain the generated sequences of visits. Moreover, existing approaches (1) frequently treat space and time as independent factors, an assumption that fails to hold true in real-world scenarios, and (2) suffer from challenges in accuracy of temporal prediction as they fail to deal with mixed distributions and the inter-relationships of different modes with latent variables (e.g., day-of-the-week). These limitations become even more pronounced when the task involves filling gaps within sequences instead of solely predicting the next visit.We introduce TrajGPT, a transformer-based, multi-task, joint spatiotemporal generative model to address these issues. Taking inspiration from large language models, TrajGPT poses the problem of controlled trajectory generation as that of text infilling in natural language. TrajGPT integrates the spatial and temporal models in a transformer architecture through a Bayesian probability model that ensures that the gaps in a visit sequence are filled in a spatiotem-porally consistent manner. Our experiments on public and private datasets demonstrate that TrajGPT not only excels in controlled synthetic visit generation but also outperforms competing models in next-location prediction tasks-Relatively, TrajGPT achieves a 26-fold improvement in temporal accuracy while retaining more than 98\% of spatial accuracy on average.},
booktitle = {Proceedings of the 32nd ACM International Conference on Advances in Geographic Information Systems},
pages = {362–371},
numpages = {10},
keywords = {Spatiotemporal modeling, Synthetic Trajectory generation, Transformers, human mobility modeling},
location = {Atlanta, GA, USA},
series = {SIGSPATIAL '24}
}

@inproceedings{10.1145/3678717.3691324,
author = {Zhang, Zheng and Amiri, Hossein and Yu, Dazhou and Hu, Yuntong and Zhao, Liang and Z\"{u}fle, Andreas},
title = {Transferable Unsupervised Outlier Detection Framework for Human Semantic Trajectories},
year = {2024},
isbn = {9798400711077},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678717.3691324},
doi = {10.1145/3678717.3691324},
abstract = {Semantic trajectories, which enrich spatial-temporal data with textual information such as trip purposes or location activities, are key for identifying outlier behaviors critical to healthcare, social security, and urban planning. Traditional outlier detection relies on heuristic rules, which requires domain knowledge and limits its ability to identify unseen outliers. Besides, there lacks a comprehensive approach that can jointly consider multi-modal data across spatial, temporal, and textual dimensions. Addressing the need for a domain-agnostic model, we propose the Transferable Outlier Detection for Human Semantic Trajectories (TOD4Traj) framework. TOD4Traj first introduces a modality feature unification module to align diverse data feature representations, enabling the integration of multi-modal information and enhancing transferability across different datasets. A contrastive learning module is further proposed for identifying regular mobility patterns both temporally and across populations, allowing for a joint detection of outliers based on individual consistency and group majority patterns. Our experimental results have shown TOD4Traj's superior performance over existing models, demonstrating its effectiveness and adaptability in detecting human trajectory outliers across various datasets.},
booktitle = {Proceedings of the 32nd ACM International Conference on Advances in Geographic Information Systems},
pages = {350–360},
numpages = {11},
keywords = {Geolife, Outlier Detection, Patern of Life, Self-Supervised Learning, Semantic Trajectory, Simulation},
location = {Atlanta, GA, USA},
series = {SIGSPATIAL '24}
}

@proceedings{10.1145/3678884,
title = {CSCW Companion '24: Companion Publication of the 2024 Conference on Computer-Supported Cooperative Work and Social Computing},
year = {2024},
isbn = {9798400711145},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 27th ACM Conference on Computer-Supported Cooperative Work and Social Computing (CSCW 2024). This year's conference is particularly special, as it marks the first time CSCW to be held in Latin America - a highly anticipated milestone for our Latin American community. We are excited to gather in San Jose, Costa Rica, and host a hybrid event that allows remote participation from community members worldwide.As in previous years, CSCW 2024 brings together a variety of disciplines, from system design to critical analysis, to propose, examine, and reimagine technologies that support groups and communities. As our discipline evolves, new topics continuously emerge and are embraced by our community. This year, we see an emphasis on issues centered around AI, including explainability, fairness, and AI-human collaboration. At the same time, our long-standing concerns remain well represented, including work on group dynamics and decision-making, social media, inclusive and culturally aware design, co-design with marginalized communities, and the creation of socially responsible tools. This year, we invited 387 PACM-HCI, TSC, and TOCHI papers to be presented alongside a diverse lineup of workshops, posters, demos, SIGs, panels, and the doctoral consortium. Below are the numbers of reviewed and accepted submissions for each track featured in this conference companion.},
location = {San Jose, Costa Rica}
}

@proceedings{10.1145/3680121,
title = {CoNEXT '24: Proceedings of the 20th International Conference on emerging Networking EXperiments and Technologies},
year = {2024},
isbn = {9798400711084},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 20th edition of the ACM Conference on Emerging Networking Experiment and Technologies (ACM CoNEXT 2024). CoNEXT is a premier and highly selective venue in computer networking. The first edition of the conference was organized in Toulouse in 2005, and this year we are in Los Angeles.CoNEXT employs a hybrid model with two submission deadlines (December and June). Two types of papers can be submitted to CoNEXT: (i) long papers presenting significant and novel research results on emerging computer networks and applications, and (ii) short papers for contributions whose novelty and impact show the same technical excellence, but whose description fits within 6 pages. CoNEXT employs a rigorous review process, including two rounds of reviews by TPC members, online discussions, and a TPC meeting. The accepted long papers are published in the journal Proceedings of the ACM on Networking (PACMNET) while the short papers appear in this conference proceedings.A total of 82 papers were submitted to the December 2023 deadline. 63 of these were long papers, and 19 were short papers. Five long papers were directly accepted and appeared in the June 2024 issue of PACMNET. Another five long papers submitted in December 2023 were revised by the authors and appeared in the September 2024 issue of PACMNET. Three short papers submitted in December 2023 were revised by the authors, and appear in these conference proceedings.},
location = {Los Angeles, CA, USA}
}

@proceedings{10.1145/3680127,
title = {ICEGOV '24: Proceedings of the 17th International Conference on Theory and Practice of Electronic Governance},
year = {2024},
isbn = {9798400717802},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3680528,
title = {SA '24: SIGGRAPH Asia 2024 Conference Papers},
year = {2024},
isbn = {9798400711312},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tokyo, Japan}
}

@proceedings{10.1145/3680530,
title = {SA '24: SIGGRAPH Asia 2024 Art Papers},
year = {2024},
isbn = {9798400711336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3680533,
title = {SA '24: SIGGRAPH Asia 2024 Educator's Forum},
year = {2024},
isbn = {9798400711367},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3681756,
title = {SA '24: SIGGRAPH Asia 2024 Posters},
year = {2024},
isbn = {9798400711381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3681758,
title = {SA '24: SIGGRAPH Asia 2024 Technical Communications},
year = {2024},
isbn = {9798400711404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3681759,
title = {SA '24: SIGGRAPH Asia 2024 XR},
year = {2024},
isbn = {9798400711411},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3681765.3698455,
author = {Stanford, Chris and Adari, Suman and Liao, Xishun and He, Yueshuai and Jiang, Qinhua and Kuai, Chenchen and Ma, Jiaqi and Tung, Emmanuel and Qian, Yinlong and Zhao, Lingyi and Zhou, Zihao and Rasheed, Zeeshan and Shafique, Khurram},
title = {NUMOSIM: A Synthetic Mobility Dataset with Anomaly Detection Benchmarks},
year = {2024},
isbn = {9798400711442},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3681765.3698455},
doi = {10.1145/3681765.3698455},
abstract = {Collecting real-world mobility data is challenging. It is often fraught with privacy concerns, logistical difficulties, and inherent biases. Moreover, accurately annotating anomalies in large-scale data is nearly impossible, as it demands meticulous effort to distinguish subtle and complex patterns. These challenges significantly impede progress in geospatial anomaly detection research by restricting access to reliable data and complicating the rigorous evaluation, comparison, and benchmarking of methodologies. To address these limitations, we introduce a synthetic mobility dataset, NUMOSIM, that provides a controlled, ethical, and diverse environment for benchmarking anomaly detection techniques. NUMOSIM simulates a wide array of realistic mobility scenarios, encompassing both typical and anomalous behaviours, generated through advanced deep learning models trained on real mobility data. This approach allows NUMOSIM to accurately replicate the complexities of real-world movement patterns while strategically injecting anomalies to challenge and evaluate detection algorithms based on how effectively they capture the interplay between demographic, geospatial, and temporal factors. Our goal is to advance geospatial mobility analysis by offering a realistic benchmark for improving anomaly detection and mobility modeling techniques. To support this, we provide open access to the NUMOSIM dataset, along with comprehensive documentation, evaluation metrics, and benchmark results.},
booktitle = {Proceedings of the 1st ACM SIGSPATIAL International Workshop on Geospatial Anomaly Detection},
pages = {68–78},
numpages = {11},
keywords = {mobility, geospatial data, anomaly detection},
location = {Atlanta, GA, USA},
series = {GeoAnomalies '24}
}

@proceedings{10.1145/3681768,
title = {GeoPrivacy '24: Proceedings of the 2nd ACM SIGSPATIAL International Workshop on Geo-Privacy and Data Utility for Smart Societies},
year = {2024},
isbn = {9798400711473},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {In an era of increasing reliance on technology, geospatial data plays a crucial role in shaping novel systems that drive decision-making, improve services, and drive innovation in fields ranging from social media and shopping to healthcare and transportation. In particular, the adoption of machine learning and deep learning techniques has heightened the demand for big geospatial data as well as magnified its transformative potential. Nevertheless, the availability and accessibility of this data, coupled with the security considerations surrounding the models that utilize it, have given rise to pressing ethical concerns that warrant our immediate attention. Striking a delicate balance between maximizing data utility and safeguarding individual privacy has become an imperative challenge. The processing of personal data poses inherent risks, including the potential infringement upon privacy rights and the potential for abuse or manipulation. As a result, profound ethical questions emerge, underscoring the interplay between utility and privacy. This workshop aims to bring together researchers and practitioners from diverse fields to delve into the multifaceted dimensions of geospatial data, unravel its potential implications and identify innovative solutions for enabling smart and safe societies.},
location = {Atlanta, GA, USA}
}

@proceedings{10.1145/3681769,
title = {GeoSearch '24: Proceedings of the 3rd ACM SIGSPATIAL International Workshop on Searching and Mining Large Collections of Geospatial Data},
year = {2024},
isbn = {9798400711480},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {To search and localize objects of interest among massive and multi-modality geospatial data is key in spatial computing. However, the effective and efficient searching among an extensive collection of geospatial data (e.g., global satellite imagery, building footprint) for interesting patterns can be challenging. In this context, not only does one need to know where to look to find objects of interest but also which model to use for different searching tasks. What if prior efforts had already created models on an exact or very similar task? How should users search for such models? When models are available, how should they be stored? Many applications become possible if we manage to make large data collections and models searchable by content, metadata, and analytic tasks. Application users would like to solve these challenges by knowing which model to use, which task the model is relevant for, and how to simultaneously search across all geospatial data representations (vector, raster, text, fields, point clouds, etc.), and finding all objects of a certain type in a huge data cube (e.g., a large point cloud or time-series EO data). In the long term, users will want to search broadly, interactively, quickly, and using different or even mixed modalities.},
location = {Atlanta, GA, USA}
}

@proceedings{10.1145/3681772,
title = {IWCTS'24: Proceedings of the 17th ACM SIGSPATIAL International Workshop on Computational Transportation Science GenAI and Smart Mobility Session},
year = {2024},
isbn = {9798400711510},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The 17th International Workshop on Computational Transportation Science (IWCTS 2024) will feature a Smart Mobility track, emphasizing the growing relevance of human mobility data from sources like cell phones, connected vehicles, and volunteered geographic information. This data integration is advancing smart city frameworks, intelligent transportation systems, and urban planning. Managing and analyzing large-scale datasets highlights the critical role of advanced computational and AI techniques, including Generative AI (GenAI), Large Language Models (LLMs), and Retrieval-Augmented Generation (RAG). The workshop builds on previous success, focusing on computational and informatics approaches for optimized urban mobility. We will build upon the success of previous workshops to continue to focus on the computational and informatics approaches for (not limited to):},
location = {Atlanta, GA, USA}
}

@proceedings{10.1145/3681773,
title = {LocalRec '24: Proceedings of the 8th ACM SIGSPATIAL International Workshop on Location-based Recommendations, Geosocial Networks and Geoadvertising},
year = {2024},
isbn = {9798400711527},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The eighth edition of the ACM SIGSPATIAL Workshop on Location-based Recommendations, Geosocial Networks and Geoadvertising (LocalRec 2024) was held as a half-day workshop, in conjunction with the 32nd ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL 2024). We have compiled these proceedings containing the papers selected for presentation.},
location = {Atlanta, GA, USA}
}

@proceedings{10.1145/3681780,
title = {UrbanAI '24: Proceedings of the 2nd ACM SIGSPATIAL International Workshop on Advances in Urban-AI},
year = {2024},
isbn = {9798400711565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The 2nd ACM SIGSPATIAL International Workshop on Advances in Urban AI (Urban-AI 2024) brings together researchers and practitioners to discuss advancements and future directions in urban AI. Urban AI is an emerging field that combines AI, spatial computing, and urban science to address complex challenges faced by cities. The availability of extensive urban data and the growth of digitized city infrastructures have opened opportunities for data-driven machine learning approaches in urban sciences. Urban AI encompasses innovative AI techniques applied to urban problems, AI-ready urban data infrastructure, and various urban applications benefiting from AI. Its applications range from urban planning and design to traffic prediction, energy management, public safety, urban agriculture, and land use.},
location = {Atlanta, GA, USA}
}

@proceedings{10.1145/3685651,
title = {eSAAM '24: Proceedings of the 4th Eclipse Security, AI, Architecture and Modelling Conference on Data Space},
year = {2024},
isbn = {9798400709845},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Mainz, Germany}
}

@proceedings{10.1145/3686081,
title = {ICDSM '24: Proceedings of the International Conference on Decision Science \&amp; Management},
year = {2024},
isbn = {9798400718151},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3686215,
title = {ICMI Companion '24: Companion Proceedings of the 26th International Conference on Multimodal Interaction},
year = {2024},
isbn = {9798400704635},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {San Jose, Costa Rica}
}

@proceedings{10.1145/3686397,
title = {ICISDM '24: Proceedings of the 2024 8th International Conference on Information System and Data Mining},
year = {2024},
isbn = {9798400717345},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3686592,
title = {ICoMS '24: Proceedings of the 2024 7th International Conference on Mathematics and Statistics},
year = {2024},
isbn = {9798400707223},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3686852,
title = {SIGITE '24: Proceedings of the 25th Annual Conference on Information Technology Education},
year = {2024},
isbn = {9798400711060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {El Paso, TX, USA}
}

@article{10.1145/3686892,
author = {Gen\c{c}, \c{C}a\u{g}lar and Spors, Velvet and Buruk, O\u{g}uz 'Oz' and Thibault, Mattia and Masek, Leland and Hamari, Juho},
title = {Transhuman Communication: Human Augmentation Technologies through Co-Speculation Workshops},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3686892},
doi = {10.1145/3686892},
abstract = {The advancement of human-computer integration as a research field promises to introduce transhumanistic ways of communicating through the enhanced abilities of augmented humans. Our work seeks to illuminate this experiential landscape, exploring a diverse set of human augmentation technologies (HATs) for communication purposes. We investigated this topic through four co-speculation workshops focusing on physical, cognitive, sensory and emotional augmentations with 35 participants. Through a reflexive thematic analysis of the workshop data, we outlined eight HAT speculations for transhuman communication, grouped into four overarching augmentation clusters: (1) Bodily Changes in/for Communication, (2) Communication with Transferrable and Collective Beings, (3) Communication through Emotion and Memory, and (4) Communication with Augmented/Altered Perception. By serving as a foundation for discussions on transhumanism and communication in CSCW and beyond, these speculations contribute to a design space highlighting design opportunities and challenges to developing and researching near-future communication technologies.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {353},
numpages = {26},
keywords = {communication, cyborg, human augmentation, human-technology integration, speculative design, transhumanism, wearables}
}

@article{10.1145/3686908,
author = {Mauri, Andrea and Hsu, Yen-Chia and Verma, Himanshu and Tocchetti, Andrea and Brambilla, Marco and Bozzon, Alessandro},
title = {Policy Sandboxing: Empathy As An Enabler Towards Inclusive Policy-Making},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3686908},
doi = {10.1145/3686908},
abstract = {Digitally-supported participatory methods are often used in policy-making to develop inclusive policies by collecting and integrating citizen's opinions. However, these methods fail to capture the complexity and nuances in citizen's needs, i.e., citizens are generally unaware of other's needs, perspectives, and experiences. Consequently, policies developed with this underlying gap tend to overlook the alignment of multistakeholder perspectives, and design policies based on the optimization of high-level demographic features. In our contribution, we propose a method to enable citizens understand other's perspectives and calibrate their positions. First, we collected requirements and design principles to develop our approach by involving stakeholders and experts in policymaking in a series of workshops. Then, we conducted a crowdsourcing study with 420 participants to compare the effect of different text and images, on people's initial and final motivations and their willingness to change opinions. We observed that both influence participant's opinion change, however, the effect is more pronounced for textual modality. Finally, we discuss overarching implications of designing with empathy to mediate alignment of citizen's perspectives.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {369},
numpages = {42},
keywords = {empathy, inclusive policies, participatory policy-making, policy sandboxing}
}

@article{10.1145/3686914,
author = {Qiwei, Li and McDonald, Allison and Haimson, Oliver L. and Schoenebeck, Sarita and Gilbert, Eric},
title = {The Sociotechnical Stack: Opportunities for Social Computing Research in Non-Consensual Intimate Media},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3686914},
doi = {10.1145/3686914},
abstract = {Non-consensual intimate media (NCIM) involves sharing intimate content without the depicted person's consent, including 'revenge porn' and sexually explicit deepfakes. While NCIM has received attention in legal, psychological, and communication fields over the past decade, it is not sufficiently addressed in computing scholarship. This paper addresses this gap by linking NCIM harms to the specific technological components that facilitate them. We introduce the sociotechnical stack, a conceptual framework designed to map the technical stack to its corresponding social impacts. The sociotechnical stack allows us to analyze sociotechnical problems like NCIM, and points toward opportunities for computing research. We propose a research roadmap for computing and social computing communities to deter NCIM perpetration and support victim-survivors through building and rebuilding technologies.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {375},
numpages = {21},
keywords = {online sexual abuse, social computing, sociotechnical systems}
}

@article{10.1145/3686962,
author = {Liu, Houjiang and Das, Anubrata and Boltz, Alexander and Zhou, Didi and Pinaroc, Daisy and Lease, Matthew and Lee, Min Kyung},
title = {Human-centered NLP Fact-checking: Co-Designing with Fact-checkers using Matchmaking for AI},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3686962},
doi = {10.1145/3686962},
abstract = {While many Natural Language Processing (NLP) techniques have been proposed for fact-checking, both academic research and fact-checking organizations report limited adoption of such NLP work due to poor alignment with fact-checker practices, values, and needs. To address this, we investigate a co-design method, Matchmaking for AI, to enable fact-checkers, designers, and NLP researchers to collaboratively identify what fact-checker needs should be addressed by technology, and to brainstorm ideas for potential solutions. Co-design sessions we conducted with 22 professional fact-checkers yielded a set of 11 design ideas that offer a "north star'', integrating fact-checker criteria into novel NLP design concepts. These concepts range from pre-bunking misinformation, efficient and personalized monitoring misinformation, proactively reducing fact-checker potential biases, and collaborative writing fact-check reports. Our work provides new insights into both human-centered fact-checking research and practice and AI co-design research.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {423},
numpages = {44},
keywords = {AI co-design, disinformation, fact-checking, misinformation, natural language processing}
}

@article{10.1145/3686970,
author = {Cheng, Zirui and Xu, Jingfei and Jin, Haojian},
title = {TreeQuestion: Assessing Conceptual Learning Outcomes with LLM-Generated Multiple-Choice Questions},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3686970},
doi = {10.1145/3686970},
abstract = {The advances of generative AI have posed a challenge for using open-ended questions to assess conceptual learning outcomes, as it is increasingly common for students to use tools like ChatGPT to generate long textual answers. However, teachers still have to spend substantial time reading the answers and inferring students' learning outcomes. We present TreeQuestion, a human-in-the-loop system designed to help teachers create a set of multiple-choice questions to assess students' conceptual learning outcomes. When a teacher seeks to assess students' comprehension of specific concepts, TreeQuestion taps into the wealth of knowledge embedded within large language models and generates a set of multiple-choice questions organized in a tree-like structure. We evaluated TreeQuestion with 96 students and 10 teachers. Results indicated that students achieved similar performance in multiple-choice questions generated by TreeQuestion and open-ended questions graded by teachers. Meanwhile, TreeQuestion could reduce teachers' efforts in creating and grading the multiple-choice questions in contrast to manually generated open-ended questions. We estimate that in a hypothetical class with 20 students, using multiple-choice questions from TreeQuestion may require only 4.6\% of the time compared to open-ended questions for assessing learning outcomes.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {431},
numpages = {29},
keywords = {education, generative AI, large language models, multiple-choice questions, open-ended questions}
}

@article{10.1145/3686986,
author = {Muralikumar, Meena Devii and McDonald, David W.},
title = {Analyzing Collaborative Challenges and Needs of UX Practitioners when Designing with AI/ML},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3686986},
doi = {10.1145/3686986},
abstract = {UX designers and researchers who work with AI/ML face different kinds of challenges throughout the design process. Though close collaborations with AI/ML developers and data scientists could address some of these challenges, such interdisciplinary collaborations are non-routine and hard to realize. In this work, we investigate barriers for effective collaboration with ML practitioners, how they affect UX practice of AI/ML applications, and what UX practitioners need to overcome these challenges. We conducted a qualitative study with 14 UX practitioners who are working on AI/ML products as designers or researchers. Our findings show that UX practitioners face challenges in communication, understanding the model and model development processes, establishing ways to collaborate, and reconciling model-centric metrics of evaluation with user-centric outcomes. They described various needs in terms of more visibility into model development processes, access to comprehensible and contextual model information, and hypothetical tools that can potentially support collaboration with ML practitioners and enhance UX design processes. We discuss implications of this research for designing collaborative tools and empowering UX practitioners.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {447},
numpages = {25},
keywords = {AI/ML development, ML practitioners, UX practitioners, collaboration}
}

@article{10.1145/3686991,
author = {Jonas, Anne and Vargas, Stefani and Hardy, Jean},
title = { 'Better than Google': Information Activism for LGBTQ+ Young Adults in a Rural Community},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3686991},
doi = {10.1145/3686991},
abstract = {For young lesbian, gay, bisexual, transgender, and queer people, and those belonging to other marginalized sexual and gender identities (LGBTQ+), accessing information to develop one's identity and community is essential. Yet information and resource access is a particularly complex process for LGBTQ+ youth living in rural areas and small towns without dense, visible LGBTQ+ networks. While efforts to remove LGBTQ+ resources and demonize LGBTQ+ people intensify, this study asks a group of young LGBTQ+ adults living in and around a college town in the rural Midwestern United States to document their experiences with navigating information landscapes in low-resource settings. Despite the remarkable everyday creativity required to craft their information practices, participants' current efforts produce several vulnerabilities that make local queer information networks precarious and often inaccessible. We lay out several patterns in this data, including experiences of both connectedness and disconnectedness, the role of organizations in information sharing, and the existence of both active and passive information search. Building on prior research that found increasing demand for multi-modal access to relevant information that is digitally enabled, but deeply embedded in localized social geography and LGBTQ+ community, we use this data and complementary interviews to identify problem areas and potential interventions to strengthen rural LGBTQ+ young people's information access. In response to the informational needs and desires of LGBTQ+ youth in this community, we propose a series of imaginative designs. These speculative artifacts are embedded in local communities to strengthen grassroots webs of knowledge. We focus on contributing solutions that fall under three problem areas in participants' information ecosystem: increasing information stumbling, building expert capacity and support, and bridging the disconnected to the connected. We propose speculative conceptual designs that address core challenges in LGBTQ+ information networks, working in the tradition of ''information activism'' to create and maintain access to otherwise precarious and ephemeral resources and spark social change.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {452},
numpages = {29},
keywords = {diary study, information activism, information searching, interviews, lgbtq, queer hci, rural}
}

@article{10.1145/3687028,
author = {Bashardoust, Amirsiavosh and Feuerriegel, Stefan and Shrestha, Yash Raj},
title = {Comparing the Willingness to Share for Human-generated vs. AI-generated Fake News},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3687028},
doi = {10.1145/3687028},
abstract = {Generative artificial intelligence (AI) presents large risks for society when it is used to create fake news. A crucial factor for fake news to go viral on social media is that users share such content. Here, we aim to shed light on the sharing behavior of users across human-generated vs. AI-generated fake news. Specifically, we study: (1) What is the perceived veracity of human-generated fake news vs. AI-generated fake news? (2) What is the user's willingness to share human-generated fake news vs. AI-generated fake news on social media? (3) What socio-economic characteristics let users fall for AI-generated fake news? To this end, we conducted a pre-registered, online experiment with N= 988 subjects and 20 fake news from the COVID-19 pandemic generated by GPT-4 vs. humans. Our findings show that AI-generated fake news is perceived as less accurate than human-generated fake news, but both tend to be shared equally. Further, several socio-economic factors explain who falls for AI-generated fake news.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {489},
numpages = {21},
keywords = {fake news, generative ai, large language model, misinformation, online experiment, survey}
}

@article{10.1145/3687048,
author = {Han, Catherine and Li, Anne and Kumar, Deepak and Durumeric, Zakir},
title = {PressProtect: Helping Journalists Navigate Social Media in the Face of Online Harassment},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3687048},
doi = {10.1145/3687048},
abstract = {Social media has become a critical tool for journalists to disseminate their work, engage with their audience, and connect with sources. Unfortunately, journalists also regularly endure significant online harassment on social media platforms, ranging from personal attacks to doxxing to threats of physical harm. In this paper, we seek to understand how to make social media usable for journalists who face constant digital harassment. To begin, we conduct a set of need-finding interviews with Asian American and Pacific Islander journalists to understand where existing platform tools and newsroom resources fall short in adequately protecting journalists, especially those of marginalized identities. We map journalists' unmet needs to concrete design goals, which we use to build PressProtect, an interface that provides journalists greater agency when engaging with readers on Twitter/X. Through user testing with eight journalists, we evaluate PressProtect and find that participants felt it effectively protected them against harassment and could also generalize to serve other visible and vulnerable groups. We conclude with a discussion of our findings and recommendations for social platforms hoping to build defensive defaults for journalists facing online harassment.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {509},
numpages = {34},
keywords = {interface design, journalists, online communities, online harassment}
}

@article{10.1145/3687061,
author = {Nova, Fayika Farhat and Pfafman, Rachel and Logan Delaney, Caralyn and Pater, Jessica},
title = {Unveiling the "Toxic" World of #Meanspo: Understanding Users' Emerging Online Eating Disorder Practices in X/Twitter},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3687061},
doi = {10.1145/3687061},
abstract = {Meanspo, an antagonistic form of online support within the eating disorder (ED) community, involves the direct solicitation or sharing of aggressive and insulting online content. This study presents findings from a comprehensive qualitative analysis of #meanspo content on X (previously Twitter) from May 2020 (N=752). Our analysis of tweets reveals that posts tagged with #meanspo can be of various natures. While commonly associated with extremely derogatory ED content, more than 80\% of posts with the meanspo tag on X were non-aggressive. The study also explores potential inconsistencies in voluntary and involuntary meanspo specific content moderation, prompting inquiries into X's regulatory policies against such content and the distinct online self-presentation strategies employed by community members. Future contextual research is needed to understand the evolving nature of this social phenomenon and its potential clinical impacts on users over time, particularly concerning the unhealthy adoption of such content. TRIGGER WARNING: Explicit language \&amp; potentially triggering content.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {522},
numpages = {27},
keywords = {Twitter, X, content moderation, eating disorder, meanspo, self-presentation}
}

@proceedings{10.1145/3687123,
title = {GeoAI '24: Proceedings of the 7th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery},
year = {2024},
isbn = {9798400711763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Advances in artificial intelligence, hardware accelerators, and data processing architectures continue to reach the geospatial information sciences, with a transformative impact on many societal challenges. Recent breakthroughs in deep learning have brought forward an automated capability to learn representational features from massive and complex data, including text, images, and videos. In tandem, rapid innovations in sensing technologies are supporting the collection of geospatial data in even higher resolution and throughput, supporting the observation, mapping, and analysis of different events/phenomena over the Earth's surface with unprecedented detail. Combined, these developments are offering the potential for breakthroughs in geographic knowledge discovery, impacting decision-making in areas such as humanitarian mapping, intelligent transport systems, urban expansion analysis, health data analysis and epidemiology, the study of climate change, handling natural disasters, the general monitoring of the Earth's surface, and achieving sustainability.},
location = {Atlanta, GA, USA}
}

@inproceedings{10.1145/3687123.3698293,
author = {Majic, Ivan and Wang, Zhangyu and Janowicz, Krzysztof and Karimi, Mina},
title = {Spatial Task-Explicity Matters in Prompting Large Multimodal Models for Spatial Planning},
year = {2024},
isbn = {9798400711763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3687123.3698293},
doi = {10.1145/3687123.3698293},
abstract = {The advance in large multimodal models (LMMs) gives rise to autonomous bots that perform complex tasks using human-like reasoning on their own. The ability of large models to understand spatial relations and perform spatial operations, however, is known to be limited. This gap hinders the development of autonomous GIS analysts, travel planning assistants, and other possibilities of spatial bots. In this paper, we explore the impact of modality on the performance of LMMs in spatial planning tasks - specifically, retrieving a target brick by first removing all other bricks on top of it. Experiments demonstrate that what matters is not only the modality of the prompts (text or image), but also how informative the spatial descriptions are for the LMMs to complete the task. We propose novel concepts of task-implicit and task-explicit spatial descriptions to qualitatively quantify the task-specific informativity of prompts. Furthermore, we develop simple techniques to increase the spatial task-explicity of image prompts, and the accuracy of spatial planning increases from 26\% to 100\% accordingly.},
booktitle = {Proceedings of the 7th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery},
pages = {99–105},
numpages = {7},
keywords = {GeoAI, large multimodal models (LMM), multi-modal prompts, spatial reasoning, task-explicity},
location = {Atlanta, GA, USA},
series = {GeoAI '24}
}

@proceedings{10.1145/3687272,
title = {HAI '24: Proceedings of the 12th International Conference on Human-Agent Interaction},
year = {2024},
isbn = {9798400711787},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Swansea, United Kingdom}
}

@proceedings{10.1145/3687488,
title = {ICCIR '24: Proceedings of the 2024 4th International Conference on Control and Intelligent Robotics},
year = {2024},
isbn = {9798400709937},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@article{10.1145/3687761,
author = {Xing, Jinbo and Liu, Hanyuan and Xia, Menghan and Zhang, Yong and Wang, Xintao and Shan, Ying and Wong, Tien-Tsin},
title = {ToonCrafter: Generative Cartoon Interpolation},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/3687761},
doi = {10.1145/3687761},
abstract = {We introduce ToonCrafter, a novel approach that transcends traditional correspondence-based cartoon video interpolation, paving the way for generative interpolation. Traditional methods, that implicitly assume linear motion and the absence of complicated phenomena like dis-occlusion, often struggle with the exaggerated non-linear and large motions with occlusion commonly found in cartoons, resulting in implausible or even failed interpolation results. To overcome these limitations, we explore the potential of adapting live-action video priors to better suit cartoon interpolation within a generative framework. ToonCrafter effectively addresses the challenges faced when applying live-action video motion priors to generative cartoon interpolation. First, we design a toon rectification learning strategy that seamlessly adapts live-action video priors to the cartoon domain, resolving the domain gap and content leakage issues. Next, we introduce a dual-reference-based 3D decoder to compensate for lost details due to the highly compressed latent prior spaces, ensuring the preservation of fine details in interpolation results. Finally, we design a flexible sketch encoder that empowers users with interactive control over the interpolation results. Experimental results demonstrate that our proposed method not only produces visually convincing and more natural dynamics, but also effectively handles dis-occlusion. The comparative evaluation demonstrates the notable superiority of our approach over existing competitors. Code and model weights are available at https://doubiiu.github.io/projects/ToonCrafter},
journal = {ACM Trans. Graph.},
month = nov,
articleno = {245},
numpages = {11},
keywords = {cartoon interpolation, generative models}
}

@article{10.1145/3687922,
author = {Ganeshan, Aditya and Huang, Ryan and Xu, Xianghao and Jones, R. Kenny and Ritchie, Daniel},
title = {ParSEL: Parameterized Shape Editing with Language},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/3687922},
doi = {10.1145/3687922},
abstract = {The ability to edit 3D assets with natural language presents a compelling paradigm to aid in the democratization of 3D content creation. However, while natural language is often effective at communicating general intent, it is poorly suited for specifying exact manipulation. To address this gap, we introduce ParSEL, a system that enables controllable editing of high-quality 3D assets with natural language. Given a segmented 3D mesh and an editing request, ParSEL produces a parameterized editing program. Adjusting these parameters allows users to explore shape variations with exact control over the magnitude of the edits. To infer editing programs which align with an input edit request, we leverage the abilities of large-language models (LLMs). However, we find that although LLMs excel at identifying the initial edit operations, they often fail to infer complete editing programs, resulting in outputs that violate shape semantics. To overcome this issue, we introduce Analytical Edit Propagation (AEP), an algorithm which extends a seed edit with additional operations until a complete editing program has been formed. Unlike prior methods, AEP searches for analytical editing operations compatible with a range of possible user edits through the integration of computer algebra systems for geometric analysis. Experimentally, we demonstrate ParSEL's effectiveness in enabling controllable editing of 3D objects through natural language requests over alternative system designs.},
journal = {ACM Trans. Graph.},
month = nov,
articleno = {197},
numpages = {14},
keywords = {shape editing, parametric editing, large language models, computer algebra systems, neuro-symbolic methods, program synthesis}
}

@article{10.1145/3687951,
author = {Tessler, Chen and Guo, Yunrong and Nabati, Ofir and Chechik, Gal and Peng, Xue Bin},
title = {MaskedMimic: Unified Physics-Based Character Control Through Masked Motion Inpainting},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/3687951},
doi = {10.1145/3687951},
abstract = {Crafting a single, versatile physics-based controller that can breathe life into interactive characters across a wide spectrum of scenarios represents an exciting frontier in character animation. An ideal controller should support diverse control modalities, such as sparse target keyframes, text instructions, and scene information. While previous works have proposed physically simulated, scene-aware control models, these systems have predominantly focused on developing controllers that each specializes in a narrow set of tasks and control modalities. This work presents MaskedMimic, a novel approach that formulates physics-based character control as a general motion inpainting problem. Our key insight is to train a single unified model to synthesize motions from partial (masked) motion descriptions, such as masked keyframes, objects, text descriptions, or any combination thereof. This is achieved by leveraging motion tracking data and designing a scalable training method that can effectively utilize diverse motion descriptions to produce coherent animations. Through this process, our approach learns a physics-based controller that provides an intuitive control interface without requiring tedious reward engineering for all behaviors of interest. The resulting controller supports a wide range of control modalities and enables seamless transitions between disparate tasks. By unifying character control through motion inpainting, MaskedMimic creates versatile virtual characters. These characters can dynamically adapt to complex scenes and compose diverse motions on demand, enabling more interactive and immersive experiences.},
journal = {ACM Trans. Graph.},
month = nov,
articleno = {209},
numpages = {21},
keywords = {reinforcement learning, animated character control, motion tracking, motion capture data}
}

@article{10.1145/3687955,
author = {Brodt, Kirill and Bessmeltsev, Mikhail},
title = {Skeleton-Driven Inbetweening of Bitmap Character Drawings},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/3687955},
doi = {10.1145/3687955},
abstract = {One of the primary reasons for the high cost of traditional animation is the inbetweening process, where artists manually draw each intermediate frame necessary for smooth motion. Making this process more efficient has been at the core of computer graphics research for years, yet the industry has adopted very few solutions. Most existing solutions either require vector input or resort to tight inbetweening; often, they attempt to fully automate the process. In industry, however, keyframes are often spaced far apart, drawn in raster format, and contain occlusions. Moreover, inbetweening is fundamentally an artistic process, so the artist should maintain high-level control over it.We address these issues by proposing a novel inbetweening system for bitmap character drawings, supporting both tight and far inbetweening. In our setup, the artist can control motion by animating a skeleton between the keyframe poses. Our system then performs skeleton-based deformation of the bitmap drawings into the same pose and employs discrete optimization and deep learning to blend the deformed images. Besides the skeleton and the two drawn bitmap keyframes, we require very little annotation.However, deforming drawings with occlusions is complex, as it requires a piecewise smooth deformation field. To address this, we observe that this deformation field is smooth when the drawing is lifted into 3D. Our system therefore optimizes topology of a 2.5D partially layered template that we use to lift the drawing into 3D and get the final piecewise-smooth deformaton, effectively resolving occlusions.We validate our system through a series of animations, qualitative and quantitative comparisons, and user studies, demonstrating that our approach consistently outperforms the state of the art and our results are consistent with the viewers' perception.Code and data for our paper are available at http://www-labs.iro.umontreal.ca/~bmpix/inbetweening/.},
journal = {ACM Trans. Graph.},
month = nov,
articleno = {246},
numpages = {19},
keywords = {cartoon inbetweening, 2D animation, mesh deformation}
}

@article{10.1145/3687957,
author = {Zhang, Zhiyuan and Chen, DongDong and Liao, Jing},
title = {SGEdit: Bridging LLM with Text2Image Generative Model for Scene Graph-based Image Editing},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/3687957},
doi = {10.1145/3687957},
abstract = {Scene graphs offer a structured, hierarchical representation of images, with nodes and edges symbolizing objects and the relationships among them. It can serve as a natural interface for image editing, dramatically improving precision and flexibility. Leveraging this benefit, we introduce a new framework that integrates large language model (LLM) with Text2Image generative model for scene graph-based image editing. This integration enables precise modifications at the object level and creative recomposition of scenes without compromising overall image integrity. Our approach involves two primary stages: 1) Utilizing a LLM-driven scene parser, we construct an image's scene graph, capturing key objects and their interrelationships, as well as parsing fine-grained attributes such as object masks and descriptions. These annotations facilitate concept learning with a fine-tuned diffusion model, representing each object with an optimized token and detailed description prompt. 2) During the image editing phase, a LLM editing controller guides the edits towards specific areas. These edits are then implemented by an attention-modulated diffusion editor, utilizing the fine-tuned model to perform object additions, deletions, replacements, and adjustments. Through extensive experiments, we demonstrate that our framework significantly outperforms existing image editing methods in terms of editing precision and scene aesthetics. Our code is available at https://bestzzhang.github.io/SGEdit.},
journal = {ACM Trans. Graph.},
month = nov,
articleno = {195},
numpages = {16},
keywords = {image editing, scene graph, diffusion model}
}

@proceedings{10.1145/3688268,
title = {ICCCM '24: Proceedings of the 2024 12th International Conference on Computer and Communications Management},
year = {2024},
isbn = {9798400718038},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3688459,
title = {EuroUSEC '24: Proceedings of the 2024 European Symposium on Usable Security},
year = {2024},
isbn = {9798400717963},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3688671,
title = {SETN '24: Proceedings of the 13th Hellenic Conference on Artificial Intelligence},
year = {2024},
isbn = {9798400709821},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3688859,
title = {ACMMM CL'24: Proceedings of the 1st on Continual Learning meets Multimodal Foundation Models: Fundamentals and Advances},
year = {2024},
isbn = {9798400711886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 2024 ACM MM Continual Learning meets Multimodal Foundation Models: Fundamentals and Advances Workshop -- ACMMM CL 2024. Our workshop will be held in Melbourne, Australia on November 1, 2024. We are focusing on exploring the integration of continual learning strategies with multimodal foundation models to address the dynamic and evolving needs of modern multimedia applications. In recent years, with the advancement of multimodal foundation models (MMFMs), there has been a growing interest in enhancing their generalization abilities through continual learning to process diverse data types, from text to visuals, and continuously update their capabilities based on real-time inputs. Despite significant advancements in theoretical research and applications of continual learning, the community remains confronted with serious challenges. The workshop aims to provide a venue for academic researchers and industry practitioners to discuss the principles, limitations, and applications of multimodal foundation models in continual learning and to promote understanding of innovative algorithms and new technologies in multimodal applications.},
location = {Melbourne VIC, Australia}
}

@proceedings{10.1145/3688862,
title = {BCIMM '24: Proceedings of the 1st International Workshop on Brain-Computer Interfaces (BCI) for Multimedia Understanding},
year = {2024},
isbn = {9798400711893},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 1st International Workshop on Brain-Computer Interfaces (BCI) for Multimedia Understanding -- BCIMM'24, co-located with ACM Multimedia 2024 in Melbourne. Our workshop strategically aligns with the ACM MM 2024 theme, engaging users with multimedia" and understanding multimedia content. In light of the significant strides made in processing human physiological signals from neuroimaging modalities, BCI emerges as a pivotal framework for modelling human behaviour and cognition patterns. Moreover, it opens avenues for establishing "direct" communication pathways between humans and machines for multimedia applications. Our workshop will share the core aspects of engaging multimedia experiences and provide insights into the cognitive understanding of multimedia content.},
location = {Melbourne VIC, Australia}
}

@proceedings{10.1145/3688866,
title = {LGM3A '24: Proceedings of the 2nd Workshop on Large Generative Models Meet Multimodal Applications},
year = {2024},
isbn = {9798400711930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of the organizing committee, it is our distinct pleasure to extend a warm welcome to the LGM3A Workshop. As Chairs of this conference, we are delighted to bring together a community of scholars, researchers, and professionals from diverse backgrounds, all driven by a shared passion for advancing the frontiers of knowledge in our field.This workshop aims to explore the potential of large generative models to revolutionize the way we interact with multimodal information. A Large Language Model (LLM) represents a sophisticated form of artificial intelligence engineered to comprehend and produce natural language text, exemplified by technologies such as GPT, LLaMA, Flan-T5, ChatGLM, and Qwen, etc. These models undergo training on extensive text datasets, exhibiting commendable attributes including robust language generation, zero-shot transfer capabilities, and In-Context Learning (ICL). With the surge in multimodal content encompassing images, videos, audio, and 3D models over the recent period, Large MultiModal Models (LMMs) have seen significant enhancements. These improvements enable the augmentation of conventional LLMs to accommodate multimodal inputs or outputs, as seen in BLIP, Flamingo, KOSMOS, LLaVA, Gemini, GPT-4, etc. Concurrently, certain research initiatives have delved into generating specific modalities, with Kosmos2 and MiniGPT-5 focusing on image generation, and SpeechGPT on speech production. There are also endeavors to integrate LLMs with external tools to achieve a near any-to-any multimodal comprehension and generation capacity, illustrated by projects like Visual-ChatGPT, ViperGPT, MMREACT, HuggingGPT, and AudioGPT. Collectively, these models, spanning not only text and image generation but also other modalities, are referred to as large generative models.},
location = {Melbourne VIC, Australia}
}

@proceedings{10.1145/3688867,
title = {McGE '24: Proceedings of the 2nd International Workshop on Multimedia Content Generation and Evaluation: New Methods and Practice},
year = {2024},
isbn = {9798400711947},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 2nd International Workshop on Multimedia Content Generation and Evaluation: New Methods and Practice- McGE 2024We believe that this workshop will provide a valuable platform for researchers and practitioners to discuss and exchange ideas on the latest advancements, challenges, and opportunities in the rapidly evolving field of multimedia content generation.},
location = {Melbourne VIC, Australia}
}

@proceedings{10.1145/3689031,
title = {EuroSys '25: Proceedings of the Twentieth European Conference on Computer Systems},
year = {2025},
isbn = {9798400711961},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are delighted to welcome you to EuroSys 2025, the 20th edition of the European Conference on Computer Systems! We are excited to host EuroSys 2025 in the modern and dynamic city of Rotterdam, Netherlands. This year's EuroSys is very special as it is co-located (for the first time) with the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS 2025). We hope you will enjoy an excellent technical program, engaging discussions, and networking opportunities in this vibrant city known for its innovative architecture, bustling port, and rich cultural scene.},
location = {Rotterdam, Netherlands}
}

@inproceedings{10.1145/3689031.3717456,
author = {Wang, Pinhuan and Huan, Chengying and Wang, Zhibin and Tian, Chen and Ji, Yuede and Liu, Hang},
title = {Bingo: Radix-based Bias Factorization for Random Walk on Dynamic Graphs},
year = {2025},
isbn = {9798400711961},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689031.3717456},
doi = {10.1145/3689031.3717456},
abstract = {Random walks are a primary means for extracting information from large-scale graphs. While most real-world graphs are inherently dynamic, state-of-the-art random walk engines failed to efficiently support such a critical use case. This paper takes the initiative to build a general random walk engine for dynamically changing graphs with two key principles: (i) This system should support both low-latency streaming updates and high-throughput batched updates. (ii) This system should achieve fast sampling speed while maintaining acceptable space consumption to support dynamic graph updates. Upholding both standards, we introduce Bingo, a GPU-based random walk engine for dynamically changing graphs. First, we propose a novel radix-based bias factorization algorithm to support constant time sampling complexity while supporting fast streaming updates. Second, we present a group-adaption design to reduce space consumption dramatically. Third, we incorporate GPU-aware designs to support high-throughput batched graph updates on massively parallel platforms. Together, Bingo outperforms existing efforts across various applications, settings, and datasets, achieving up to a 271.11x speedup compared to the state-of-the-art efforts.},
booktitle = {Proceedings of the Twentieth European Conference on Computer Systems},
pages = {605–620},
numpages = {16},
keywords = {GPUs, Monte Carlo Sampling, Random Walk},
location = {Rotterdam, Netherlands},
series = {EuroSys '25}
}

@inproceedings{10.1145/3689031.3717469,
author = {Sun, Zhenbo and Chen, Shengqi and Wang, Yuanwei and Sha, Jian and Feng, Guanyu and Chen, Wenguang},
title = {MEPipe: Democratizing LLM Training with Memory-Efficient Slice-Level Pipeline Scheduling on Cost-Effective Accelerators},
year = {2025},
isbn = {9798400711961},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689031.3717469},
doi = {10.1145/3689031.3717469},
abstract = {The training of large language models (LLMs) typically needs costly GPUs, such as NVIDIA A100 or H100. They possess substantial high-bandwidth on-chip memory and rapid interconnects like NVLinks. The exorbitant expenses associated with LLM training pose not just an economic challenge but also a societal one, as it restricts the ability to train LLMs from scratch to a selected few organizations.There is a significant interest in democratizing access to LLM training. This paper explores a potential solution by employing innovative parallel strategies on more affordable accelerators. Budget-friendly options like NVIDIA RTX 4090, while considerably less expensive and comparable in computational power to A100, are hindered by their limited memory capacity and reduced interconnect bandwidth, making the effective training of LLMs challenging.Conventional parallel strategies often result in high communication costs or excessive memory usage. Our paper introduces MEPipe, a novel approach that includes a slice-level scheduling method for sequence pipeline parallelism. This method minimizes memory consumption without incurring additional communication overhead. Besides, MEPipe utilizes fine-grained weight gradient computation to reduce idle time and mitigate imbalanced computation among slices.MEPipe has demonstrated up to 1.68\texttimes{} speedup (1.35\texttimes{} on average) on clusters equipped with 64 NVIDIA 4090 GPUs when training Llama models of varying sizes. 35\% Model FLOPS Utilization (MFU) is achieved in training Llama 13B model, being 2.5x more cost-effective than A100 clusters.},
booktitle = {Proceedings of the Twentieth European Conference on Computer Systems},
pages = {1263–1278},
numpages = {16},
keywords = {distributed deep learning, large language model},
location = {Rotterdam, Netherlands},
series = {EuroSys '25}
}

@inproceedings{10.1145/3689031.3717487,
author = {Chen, Wei and Zhang, Bowen and Wang, Chengpeng and Tang, Wensheng and Zhang, Charles},
title = {Seal: Towards Diverse Specification Inference for Linux Interfaces from Security Patches},
year = {2025},
isbn = {9798400711961},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689031.3717487},
doi = {10.1145/3689031.3717487},
abstract = {Linux utilizes interfaces as communication protocols across different subsystems while ensuring manageability. These interfaces standardize interactions between various subsystems; however, the absence of complete calling contexts can result in the mishandling of data from other entities, i.e., interaction data, thus incurring vulnerabilities. Even worse, the effectiveness of static bug detectors could be severely hindered due to the lack of interface specifications. Previous solutions, seeking to automate the inference of interface specifications, are tailored to a subset of the interaction data behavior and, hence are deficient in generalizability.This research presents Seal, a framework that leverages security patches to achieve the automatic inference of diverse interface specifications. Those specifications, formulated as value-flow properties, could adeptly characterize interaction data behaviors for individual interfaces and the synergistic relationships among multiple interfaces. Technically, Seal assesses the impact of code changes in program dependencies, abstracts specifications from changed value-flow paths, and detects bugs via reachability analysis. Experiments show Seal attains a precision of 71.9\% and the specifications could accommodate various bug types. We utilized Seal to identify 167 unseen bugs in Linux, hidden for an average of 7.7 years. So far, 95 of them are confirmed by Linux maintainers, 56 of which fixed by our patches.},
booktitle = {Proceedings of the Twentieth European Conference on Computer Systems},
pages = {1246–1262},
numpages = {17},
keywords = {Linux, Patch Analysis, Specification Inference, Static Bug Detection},
location = {Rotterdam, Netherlands},
series = {EuroSys '25}
}

@proceedings{10.1145/3689050,
title = {TEI '25: Proceedings of the Nineteenth International Conference on Tangible, Embedded, and Embodied Interaction},
year = {2025},
isbn = {9798400711978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3689061,
title = {MMSports '24: Proceedings of the 7th ACM International Workshop on Multimedia Content Analysis in Sports},
year = {2024},
isbn = {9798400711985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 7th ACM International Workshop on Multimedia Content Analysis in Sports (ACM MMSports'24). The workshop is co-located with ACM Multimedia 2024 and held on-site only, so that we can all meet and interact in person. The workshop addresses a very timely topic because the influence of rapidly developing technologies has changed the way of how we participate, watch, understand and research sports. For example, television broadcasts augment live video footage with computer vision-based graphics in real time to emphasize different aspects of a game or performance and assist focus and understanding of viewers. Moreover, the astonishing impact of wearables within the last years plays a pivotal role in how we pursue and evaluate our personal training goals. In a professional setting, coaches and training scientists directly benefit from the latest technological research, reshaping the way we think about improving the performance and technique of athletes, understand sport injuries or enhance the qualitative and quantitative analyses of performances.},
location = {Melbourne VIC, Australia}
}

@proceedings{10.1145/3689089,
title = {Meet4MM '24: Proceedings of the 2nd International Workshop on Methodologies for Multimedia},
year = {2024},
isbn = {9798400712005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Melbourne VIC, Australia}
}

@proceedings{10.1145/3689090,
title = {MIS '24: Proceedings of the 1st ACM Multimedia Workshop on Multi-modal Misinformation Governance in the Era of Foundation Models},
year = {2024},
isbn = {9798400712012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the MIS'24: 1st ACM Multimedia Workshop on Multimodal Misinformation Governance in the Era of Foundation Models. The rise of foundation models like GPT and CLIP has transformed artificial intelligence, driving significant advancements in natural language processing and computer vision. However, these large-scale models also present challenges in misinformation governance across various modalities. This workshop brings together researchers and practitioners to discuss key topics in multi-modal misinformation governance, including new datasets, evaluation techniques, ethical considerations, methodological progress, case studies, and future research directions. Aligned with the ACM Multimedia 2024, the workshop features keynote speeches, paper presentations, and interactive sessions, fostering interdisciplinary collaboration and advancing the state-of-the-art.},
location = {Melbourne VIC, Australia}
}

@proceedings{10.1145/3689091,
title = {MMGR '24: Proceedings of the 2nd International Workshop on Deep Multimodal Generation and Retrieval},
year = {2024},
isbn = {9798400712029},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 2024 ACM Multimedia Workshop - MMGR 2024. The emergence of multimodal learning offers a feasible way for multimodal IR. Within recent decades with the rapid development of deep learning techniques, the triumph of multimodal learning has been witnessed. Deep multimodal learning has been defined as to use of deep neural techniques to model and learn from multiple sources of data or modalities among others. In the context of IR, deep multimodal learning has shown great potential to improve the performance and application scope of retrieval systems, i.e., by enabling better understanding and processing of the diverse types of data. MMGR'24 workshop can be a good complementarity to place the major focus on multimodal IR. This workshop sets the goal to extend existing work in this direction, by bringing together and facilitating the community of researchers and practitioners. And meanwhile, we aim to encourage an exchange of perspectives and solutions between industry and academia to bridge the gap between academic design guidelines and the best practices in the industry regarding multimodal IR.},
location = {Melbourne VIC, Australia}
}

@proceedings{10.1145/3689092,
title = {MRAC '24: Proceedings of the 2nd International Workshop on Multimodal and Responsible Affective Computing},
year = {2024},
isbn = {9798400712036},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The 2nd MRAC workshop attracted participation across the world. These papers were peerreviewed via a double-blind process and the whole process is conducted via Microsoft CMT portal. Other than original contributions, we are hosting three keynote speakers Prof. Julian Epps, Prof. Mohammed Bennamoun, and Dr. Zitong Yu. We are also conducting a panel discussion on responsible affective computing where we will discuss the upcoming challenges and important aspects in this field.},
location = {Melbourne VIC, Australia}
}

@inproceedings{10.1145/3689092.3689410,
author = {Dragar, Luka and Rot, Peter and Peer, Peter and \v{S}truc, Vitomir and Batagelj, Borut},
title = {W-TDL: Window-Based Temporal Deepfake Localization},
year = {2024},
isbn = {9798400712036},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689092.3689410},
doi = {10.1145/3689092.3689410},
abstract = {The quality of synthetic data has advanced to such a degree of realism that distinguishing it from genuine data samples is increasingly challenging. Deepfake content, including images, videos, and audio, is often used maliciously, necessitating effective detection methods. While numerous competitions have propelled the development of deepfake detectors, a significant gap remains in accurately pinpointing the temporal boundaries of manipulations. Addressing this, we propose an approach for temporal deepfake localization (TDL) utilizing a window-based method for audio (W-TDL) and a complementary visual frame-based model. Our contributions include an effective method for detecting and localizing fake video and audio segments and addressing unbalanced training labels in spoofed audio datasets. Our approach leverages the EVA visual transformer for frame-level analysis and a modified TDL method for audio, achieving competitive results in the 1M-DeepFakes Detection Challenge. Comprehensive experiments on the AV-Deepfake1M dataset demonstrate the effectiveness of our method, providing an effective solution to detect and localize deepfake manipulations.},
booktitle = {Proceedings of the 2nd International Workshop on Multimodal and Responsible Affective Computing},
pages = {24–29},
numpages = {6},
keywords = {audio-visual analysis, deepfake detection, temporal localization},
location = {Melbourne VIC, Australia},
series = {MRAC '24}
}

@proceedings{10.1145/3689094,
title = {SUMAC '24: Proceedings of the 6th workshop on the analySis, Understanding and proMotion of heritAge Contents},
year = {2024},
isbn = {9798400712050},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to SUMAC 2024, the 6th edition of the ACM workshop on analySis, Understanding and proMotion of heritAge Contents. The workshop focuses on analyzing, processing and valorizing all types of data related to cultural heritage, including tangible and intangible heritage. As stated by UNESCO, cultural heritage provides societies with a wealth of resources inherited from the past, created in the present for the benefit of future generations. The massive digitization of historical analogue resources and production of born-digital documents provide us with large volumes of varied multimedia heritage data (images, maps, text, video, 3D objects, multi-sensor data, etc.), which represent a rich heritage that can be exploited in a wide variety of fields, from research in social sciences and computational humanities to land use and territorial policies, including urban modeling, digital simulation, archaeology, tourism, education, culture preservation, creative media and entertainment. In terms of research in computer science, artificial intelligence and digital humanities, they address challenging problems related to the diversity, specificity or volume of the media, the veracity of the data, and different user needs with respect to engaging with this rich material and the extraction of value out of the data. These challenges are reflected in the corresponding sub-fields of machine learning, signal processing, multi-modal techniques and human-machine interaction, with special focus on:Analysis of historical data,Content understanding and pattern recognition,Linking and recommendation of multi-modal digital heritage,Human-machine interaction for big data analysis and visualization,Generative modeling of cultural heritage.},
location = {Melbourne VIC, Australia}
}

@proceedings{10.1145/3689095,
title = {UAVM '24: Proceedings of the 2nd Workshop on UAVs in Multimedia: Capturing the World from a New Perspective},
year = {2024},
isbn = {9798400712067},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 2024 ACM Multimedia Workshop - UAVM 2024. In an age where innovation soars to new heights, UAVs, also known as drones, have taken center stage, revolutionizing the way we capture and interact with multimedia content from the skies. Today, we embark on a journey to uncover the latest advancements, tackle challenges, and seize opportunities in this exhilarating field. In recent years, the meteoric rise of multimedia applications such as aerial photography, cinematography, and mapping has propelled UAVs into the limelight. These versatile flying machines have emerged as formidable tools for acquiring rich and diverse multimedia content. At UAVM'24, we aim to foster collaboration and knowledge exchange among researchers, practitioners, and enthusiasts who share a common passion for UAV multimedia. Our workshop agenda spans an array of captivating topics, delving into the realm of UAV multimedia. We will explore the intricacies of aerial image and video processing, the marvels of machine learning applied to UAV data analysis, the fascinating possibilities of UAV swarm technology, and the myriad UAV-based multimedia applications that are transforming industries.},
location = {Melbourne VIC, Australia}
}

@proceedings{10.1145/3689096,
title = {VLM4Bio'24: Proceedings of the First International Workshop on Vision-Language Models for Biomedical Applications},
year = {2024},
isbn = {9798400712074},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the first International Workshop on Vision-Language Models for Biomedical Applications (VLM4Bio) 2024. Vision-Language Models (VLMs) are revolutionizing biomedical research and healthcare by enabling the integration and interpretation of multimodal data, such as medical images and clinical texts. In response to this transformative trend, VLM4Bio was held at ACM Multimedia 2024, providing a platform for interdisciplinary collaboration among experts in natural language processing, computer vision, biomedical engineering, and AI ethics. The workshop focused on advanced techniques to leverage VLMs in applications like medical imaging, diagnostics, and personalized treatment. As healthcare data increasingly involves both visual and textual information, VLM4Bio addressed the need for robust solutions that bridge these modalities, enhancing clinical decision-making and patient care.},
location = {Melbourne VIC, Australia}
}

@proceedings{10.1145/3689187,
title = {ITiCSE 2024: 2024 Working Group Reports on Innovation and Technology in Computer Science Education},
year = {2025},
isbn = {9798400712081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {In these proceedings, we present papers from the Working Groups that worked in the context of the 29th Annual Conference on Innovation \&amp; Technology in Computer Science Education (ITiCSE), held in Milan Italy, and hosted by Universit\`{a} degli Studi di Milano from the 8th to the 10th of July 2024.The concept of Working Groups has been a unique feature of the ITiCSE conference series since its inception. Working Groups are now part of CompEd and SIGCSE Virtual. An ITiCSE Working Group is typically composed of 8-12 researchers who work together for about nine months on a research project related to computing education. Working Groups provide a wonderful opportunity to work intensively on a topic of interest with an international group of computing education researchers. This unique experience is one that, in our opinion, each Computer Science Educator should strive to participate in at least once.In 2024, 13 proposals for Working Groups were received and ten Working Groups were selected by the Working Group chairs to recruit members and proceed for ITiCSE 2024. There were 166 member applications to Working Groups, with 134 being accepted including 33 Working Group leaders across the ten Working Groups. This is a record number of both Working Groups and Working Group members at a single conference.Working Groups began their work virtually from March up until the beginning of the ITiCSE conference. Their work included intensive collaboration on-site for the three days prior to the conference. A draft report was then submitted on the Sunday prior to the conference; a few weeks after the conference, the Working Groups submitted their final report for peer review.If the report was accepted for publication, the groups revised it based on the reviewers' comments and suggestions. This dedicated ITiCSE Working Group proceedings volume presents the final camera-ready version of the reports. We are glad that all ten papers were selected for publication in these proceedings for the ACM Digital Library.},
location = {Milan, Italy}
}

@inproceedings{10.1145/3689187.3709607,
author = {Clear, Tony and Cajander, \r{A}sa and Clear, Alison and McDermott, Roger and Daniels, Mats and Divitini, Monica and Forshaw, Matthew and Humble, Niklas and Kasinidou, Maria and Kleanthous, Styliani and Kultur, Can and Parvini, Ghazaleh and Polash, Mohammad and Zhu, Tingting},
title = {AI Integration in the IT Professional Workplace: A Scoping Review and Interview Study with Implications for Education and Professional Competencies},
year = {2025},
isbn = {9798400712081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689187.3709607},
doi = {10.1145/3689187.3709607},
abstract = {As Artificial Intelligence (AI) continues transforming workplaces globally, particularly within the Information Technology (IT) industry, understanding its impact on IT professionals and computing curricula is crucial. This research builds on joint work from two countries, addressing concerns about AI's increasing influence in IT sector workplaces and its implications for tertiary education. The study focuses on AI technologies such as generative AI (GenAI) and large language models (LLMs). It examines how they are perceived and adopted and their effects on workplace dynamics, task allocation, and human-system interaction.IT professionals, noted as early adopters of AI, offer valuable insights into the interplay between AI and work engagement, highlighting the significant competencies required for digital workplaces. This study employs a dual-method approach, combining a systematic and multi-vocal literature review and qualitative research methods. These included a thematic analysis of a set of 47 interviews conducted between March and May of 2024 with IT professionals in two countries (New Zealand and Sweden). The research aimed to understand the implications for computing students, education curricula, and the assessment of emerging professional competencies.The literature review found insufficient evidence addressing comprehensive AI practice methodologies, highlighting the need to both develop and regulate professional competencies for effective AI integration. Key interview findings revealed diverse levels of GenAI adoption, ranging from individual experimentation to institutional integration. Participants generally expressed positive attitudes toward the technology and were actively pursuing self-learning despite some concerns. The themes emerging from the interviews included AI's role in augmenting human tasks, privacy and security concerns, productivity enhancements, legal and ethical challenges, and the evolving need for new competencies in the workplace.The study underscores the critical role of competency frameworks in guiding professional development and ensuring preparedness for an AI-driven environment. Additionally, it highlights the need for educational institutions to adapt curricula to address these emerging demands effectively},
booktitle = {2024 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {34–67},
numpages = {34},
keywords = {artificial intelligence, computing competencies, computing curricula, generative ai, it profession, large language models},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3689187.3709610,
author = {Garcia, Rita and Csizmadia, Andrew and Pearce, Janice L. and Alshaigy, Bedour and Glebova, Olga and Harrington, Brian and Liaskos, Konstantinos and Lunn, Stephanie J. and Mackellar, Bonnie and Nasir, Usman and Pettit, Raymond and Schulz, Sandra and Stewart, Craig and Zavaleta Bernuy, Angela},
title = {An International Examination of Non-Technical Skills and Professional Dispositions in Computing -- Identifying the Present Day Academia-Industry Gap},
year = {2025},
isbn = {9798400712081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689187.3709610},
doi = {10.1145/3689187.3709610},
abstract = {Computing graduates are frequently reported by members of industry to lack in professional dispositions and/or non-technical skills (often referred to as "soft skills"). In this work, we conduct a gap analysis of the alignment between academic preparation and industry expectations through a three-pronged study. First, a literature review explored the academic perspective of how fostering professional dispositions and non-technical skills occurs in tertiary computing education. Second, a literature review identifying industry's expectations of those dispositions and skills for entry-level computing professionals. Finally, a mixed-methods approach, combining a survey and structured interviews of computing industry professionals to identify their opinions on the relative importance of those skills and dispositions. In each of these prongs, we additionally consider whether and how Diversity, Equity, Inclusion, and Accessibility (DEIA) may have been approached and/or incorporated.Our work uncovers a number of gaps. Several skills and dispositions, such as leadership, ethics, and inventiveness, are over-represented in the academic literature compared to industry's expectations, while others such as lifelong learning and professionalism are under-emphasised. Furthermore, some terms such as 'ethics' and 'professionalism' are defined differently by various stakeholder groups, leading to a gap between academic training and industry expectations. Finally, several skills and dispositions, such as collaboration, teamwork, communication, and leadership show evidence of exposure in academia, but require more scaffolded instruction to meet industry expectations. We also found a dearth of coverage in the literature and a lack of focus in industry for DEIA considerations.},
booktitle = {2024 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {124–174},
numpages = {51},
keywords = {DEIA, E&amp;I, EDI, accessibility, diversity, equity, inclusion, industry expectations, non-technical skills, professional dispositions, professionalism},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3689187.3709613,
author = {Begum, Marjahan and Crossley, Julia and Str\"{o}mb\"{a}ck, Filip and Akrida, Eleni and Alpizar-Chacon, Isaac and Evans, Abigail and Gross, Joshua B. and Haglund, Pontus and Lonati, Violetta and Satyavolu, Chandrika and Thorgeirsson, Sverrir},
title = {A Pedagogical Framework for Developing Abstraction Skills},
year = {2025},
isbn = {9798400712081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689187.3709613},
doi = {10.1145/3689187.3709613},
abstract = {Abstraction is a fundamental yet challenging skill to teach and learn in Computer Science education. Traditional frameworks of abstraction and concept formation often emphasize understanding an abstraction over its application, the latter being critical for practical Computer Science. Additionally, a common issue in education is when students may understand a concept in a classroom or a very specific setting but struggle to apply it outside of that context. In response, we present here a novel pedagogical framework designed to enhance both the development and application of abstraction skills in diverse educational contexts within the field of Computer Science. Our framework synthesizes common themes from existing models while introducing a new dimension focused explicitly on the actionable development of abstraction skills. Educators can adapt the framework to various educational contexts to support development of students' abstraction skills. Our framework was iteratively developed through a combination of theoretical analysis and reflective practice across multiple teaching contexts. We demonstrate the suitability of the framework by applying it to various case studies, demonstrating its broad applicability and practical utility. By offering a flexible yet comprehensive structure, our framework enables educators to effectively organize and deliver educational content, guiding students from abstract theoretical concepts to their practical application in Computer Science.},
booktitle = {2024 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {258–299},
numpages = {42},
keywords = {CS1 to CS3, abstraction, abstraction skills, algorithmic thinking, cognitive models, computational thinking, concurrency, data structures, educational frameworks, game theory, inferences, pedagogy, pointers, recursion},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@proceedings{10.1145/3689217,
title = {LAMPS '24: Proceedings of the 1st ACM Workshop on Large AI Systems and Models with Privacy and Safety Analysis},
year = {2024},
isbn = {9798400712098},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {This volume contains papers presented at the 1st ACM Workshop on Large AI Systems and Models with Privacy and Safety Analysis (LAMPS), which was held on October 14, 2024, in Salt Lake City, USA.This year we received 18 paper submissions from Australia, China, Italy, Luxembourg, Singapore, South Korea, USA, and Vietnam, and 11 high-quality papers were accepted. Each contributed paper was rigorously peer-reviewed by reviewers who were drawn from a pool of expert technical committee members in machine learning security and privacy. Each paper received two detailed review comments and one meta review comments that summarise the weaknesses/issues to be addressed in the camera-ready revision or future work.},
location = {Salt Lake City, UT, USA}
}

@proceedings{10.1145/3689236,
title = {ICCSIE '24: Proceedings of the 2024 9th International Conference on Cyber Security and Information Engineering},
year = {2024},
isbn = {9798400718137},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3689484,
title = {GPCE '24: Proceedings of the 23rd ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
year = {2024},
isbn = {9798400712111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 23rd ACM SIGPLAN International Conference on Generative Programming: Concepts \&amp; Experiences (GPCE’24). GPCE is the premiere venue for researchers and practitioners interested in techniques that use program generation to increase programmer productivity, improve software quality, and shorten the time-to-market of software products. In addition to exploring cutting-edge techniques of generative software, GPCE seeks to foster cross-fertilization between the programming language and software engineering research communities.},
location = {Pasadena, CA, USA}
}

@inproceedings{10.1145/3689484.3690730,
author = {Hollenbeck, Celeste and O’Boyle, Michael F. P.},
title = {Hot Call-Chain Inlining for the Glasgow Haskell Compiler},
year = {2024},
isbn = {9798400712111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689484.3690730},
doi = {10.1145/3689484.3690730},
abstract = {Inlining is a well-studied compiler transformation that can reduce call overhead and enable further optimizations. As functional programming languages such as Haskell have functions as first-class objects, they potentially have the most to gain from inlining. However, despite being acknowledged as one of the most important optimizations, there has been little recent work to significantly improve Haskell’s inlining heuristic for code performance.       This paper proposes a profile-directed technique to direct inlining decisions in the Glasgow Haskell Compiler. We show that simply inlining “hot” functions, as revealed by profiling summaries, does not lead to significant improvement. However, inlining along the hot dynamic call graph is frequently beneficial. Due to the higher-order nature of Haskell, determining this call graph is non-trivial. We develop a technique to extract call chains of hot functions and leverage the Glasgow Haskell Compiler’s existing functionality to safely influence inlining decisions through pragma placement along these chains.       We then show that hot call chain inlining yields a geometric mean speedup in run time of 9\% over GHC’s default inlining heuristics across 17 real-world Haskell packages. This method can be used in the presence of pre-existing developer pragmas to produce a mean speedup of 10\% across those same packages.},
booktitle = {Proceedings of the 23rd ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {66–79},
numpages = {14},
keywords = {Functional Programming, Inlining, Performance},
location = {Pasadena, CA, USA},
series = {GPCE '24}
}

@proceedings{10.1145/3689535,
title = {UKICER '24: Proceedings of the 2024 Conference on United Kingdom \&amp; Ireland Computing Education Research},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Manchester, United Kingdom}
}

@proceedings{10.1145/3689904,
title = {EAAMO '24: Proceedings of the 4th ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization},
year = {2024},
isbn = {9798400712227},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {San Luis Potosi, Mexico}
}

@inproceedings{10.1145/3689904.3694702,
author = {Hong, Rachel and Agnew, William and Kohno, Tadayoshi and Morgenstern, Jamie},
title = {Who's in and who's out? A case study of multimodal CLIP-filtering in DataComp},
year = {2024},
isbn = {9798400712227},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689904.3694702},
doi = {10.1145/3689904.3694702},
abstract = {As training datasets become increasingly drawn from unstructured, uncontrolled environments such as the web, researchers and industry practitioners have increasingly relied upon data filtering techniques to “filter out the noise” of web-scraped data. While datasets have been widely shown to reflect the biases and values of their creators, in this paper we contribute to an emerging body of research that assesses the filters used to create these datasets. We show that image-text data filtering also has biases and is value-laden, encoding specific notions of what is counted as “high-quality” data. In our work, we audit a standard approach of image-text CLIP-filtering on the academic benchmark DataComp’s CommonPool by analyzing discrepancies of filtering through various annotation techniques across multiple modalities of image, text, and website source. We find that data relating to several imputed demographic groups — such as LGBTQ+ people, older women, and younger men — are associated with higher rates of exclusion. We also find prevalence of Western bias, where the CLIP filter is more likely to include data related to Western countries compared to that of non-Western countries. Moreover, we demonstrate cases of exclusion amplification: not only are certain marginalized groups already underrepresented in the unfiltered data, but CLIP-filtering excludes data from these groups at higher rates. The data-filtering step in the machine learning pipeline can therefore exacerbate representation disparities already present in the data-gathering step, especially when existing filters are designed to optimize a specifically-chosen downstream performance metric like zero-shot image classification accuracy. Finally, we show that the NSFW filter fails to remove sexually-explicit content from CommonPool, and that CLIP-filtering includes several categories of copyrighted content at high rates. Our conclusions point to a need for fundamental changes in dataset creation and filtering practices. Content warning: This paper discusses societal stereotypes and sexually-explicit material that may be disturbing, distressing, and/or offensive to the reader.},
booktitle = {Proceedings of the 4th ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization},
articleno = {4},
numpages = {17},
keywords = {CLIP, Data ideology, Dataset collection, Filtering bias, Multimodal filtering, Representation disparities},
location = {San Luis Potosi, Mexico},
series = {EAAMO '24}
}

@proceedings{10.1145/3689930,
title = {RICSS '24: Proceedings of the 2024 Workshop on Re-design Industrial Control Systems with Security},
year = {2024},
isbn = {9798400712265},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 2nd International Workshop on Re-design Industrial Control Systems with Security (RICSS).As ICS software and systems are foundational to the critical infrastructure relied upon by industry, academia, and government, addressing their security challenges is more crucial than ever. Historically, these systems were not designed with security in mind, and the rapid expansion of interconnectivity has exposed significant vulnerabilities, leaving many practitioners reliant on a patchwork of security measures. While some proprietary ICS software providers have begun incorporating security features, the security of free and open-source ICS software remains underdeveloped and underappreciated. This workshop aims to change that.},
location = {Salt Lake City, UT, USA}
}

@proceedings{10.1145/3689932,
title = {AISec '24: Proceedings of the 2024 Workshop on Artificial Intelligence and Security},
year = {2024},
isbn = {9798400712289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our pleasure to welcome you to the 16th ACM Workshop on Artificial Intelligence and Security - AISec 2024. AISec, having been annually co-located with CCS for 17 consecutive years, is the premier meeting place for researchers interested in the intersection of security, privacy, AI, and machine learning. Its role as a venue has been to merge practical security problems with advances in AI and machine learning. In doing so, researchers have also been developing theories and analytics unique to this domain and have explored diverse topics such as learning in gametheoretic adversarial environments, privacy-preserving learning, and applications to malware, spam, and intrusion detection. AISec 2024 received 72 submissions, of which 18 (25\%) were selected for publication and presentation as full papers. Submissions arrived from researchers in many different countries, and from a wide variety of institutions, both academic and corporate.},
location = {Salt Lake City, UT, USA}
}

@inproceedings{10.1145/3689932.3694764,
author = {Pasquini, Dario and Strohmeier, Martin and Troncoso, Carmela},
title = {Neural Exec: Learning (and Learning from) Execution Triggers for Prompt Injection Attacks},
year = {2024},
isbn = {9798400712289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689932.3694764},
doi = {10.1145/3689932.3694764},
abstract = {We introduce a new family of prompt injection attacks, termed Neural Exec. Unlike known attacks that rely on handcrafted strings (e.g., "Ignore previous instructions and..."), we show that it is possible to conceptualize the creation of execution triggers as a differentiable search problem and use learning-based methods to autonomously generate them.Our results demonstrate that a motivated adversary can forge triggers that are not only drastically more effective than current handcrafted ones but also exhibit inherent flexibility in shape, properties, and functionality. In this direction, we show that an attacker can design and generate Neural Execs capable of persisting through multi-stage preprocessing pipelines, such as in the case of Retrieval-Augmented Generation (RAG)-based applications. More critically, our findings show that attackers can produce triggers that deviate markedly in form and shape from any known attack, sidestepping existing blacklist-based detection and sanitation approaches. Code available at https://github.com/pasquini-dario/LLM_NeuralExec},
booktitle = {Proceedings of the 2024 Workshop on Artificial Intelligence and Security},
pages = {89–100},
numpages = {12},
keywords = {adversarial inputs, ai readteam, llms, prompt injection, rag},
location = {Salt Lake City, UT, USA},
series = {AISec '24}
}

@proceedings{10.1145/3689933,
title = {AutonomousCyber '24: Proceedings of the Workshop on Autonomous Cybersecurity},
year = {2024},
isbn = {9798400712296},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the inaugural edition of the 1st International Workshop on Autonomous Cybersecurity (AutonomousCyber 2024). As part of the 31st ACM Conference on Computer and Communications Security (ACM CCS 2024), this workshop provides an important platform for researchers, practitioners, and experts in the field of cybersecurity to discuss and explore the transformative potential of autonomous systems in safeguarding digital infrastructure.Autonomous cybersecurity represents a new frontier in cybersecurity technology, where systems independently detect, respond to, and neutralize threats without human intervention. These advancements mark a significant step forward, with implications for reducing human error, enhancing adaptability, and improving response times. AutonomousCyber 2024 brings together cutting-edge research in areas such as Machine Learning (ML), Reinforcement Learning (RL), and Quantum Machine Learning (QML), integrated with advanced automation techniques for tasks like automated patch management and incident response.},
location = {Salt Lake City, UT, USA}
}

@proceedings{10.1145/3689936,
title = {CSCS '24: Proceedings of the 2024 Cyber Security in CarS Workshop},
year = {2024},
isbn = {9798400712326},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the CSCS '24 - 1st Cyber Security in CarS Workshop. CSCS '24 aims to address current issues in the rapidly advancing field of automotive cybersecurity. The aim is to bring together academia and industry to address cybersecurity problems in the automotive domain. The CSCS '24 provides a forum for deliberating on the most recent advancements, exchanging current research contributions, and encouraging networking and collaboration to devise novel solutions. The CSCS workshop builds upon the foundation laid by the "ACM Computer Science in Cars Symposium" (CSCS symposium) and advances the field of automotive cybersecurity.},
location = {Salt Lake City, UT, USA}
}

@proceedings{10.1145/3689942,
title = {HealthSec '24: Proceedings of the 2024 Workshop on Cybersecurity in Healthcare},
year = {2024},
isbn = {9798400712388},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is my great pleasure to welcome you to ACM CCS HealthSec'24 Workshop! Our desire is to bring together diverse researchers from academia, government, and the healthcare industry to report on latest research efforts. As this is the inaugural workshop, our goal is to encourage, jumpstart, grow, and support an interdisciplinary community of researchers focused on cybersecurity in healthcare. Research papers with demonstrated results were given priority. Position papers provide a unique opportunity for leaders in the field to identify new directions for research and development, bring in important ideas from other fields, and to share perspectives from decades of experience.},
location = {Salt Lake City, UT, USA}
}

@proceedings{10.1145/3689943,
title = {WPES '24: Proceedings of the 23rd Workshop on Privacy in the Electronic Society},
year = {2024},
isbn = {9798400712395},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are pleased to welcome you to the 23rd Workshop on Privacy in the Electronic Society (WPES '24). Continuing our long-standing tradition, WPES showcases novel research from academia, industry, and government on theoretical and practical aspects of electronic privacy, as well as experimental studies of real-world systems. We invited two types of submissions: full papers (up to 12 pages in the ACM double-column format, excluding bibliography and appendices) and short papers (up to 4 pages) for preliminary results or concise descriptions.This year, we received 27 submissions (21 full papers and 6 short papers) from Austria, Belgium, Germany, Japan, Luxembourg, Sweden, Switzerland, the United Kingdom, and the United States. Each paper was reviewed by at least three members of the Program Committee. After a rigorous review process, we accepted 13 full papers (acceptance rate: 66.7\%) and an additional 3 short papers (acceptance 50\%).},
location = {Salt Lake City, UT, USA}
}

@proceedings{10.1145/3690063,
title = {ICMSSP '24: Proceedings of the 2024 9th International Conference on Multimedia Systems and Signal Processing (ICMSSP)},
year = {2024},
isbn = {9798400716911},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3690134,
title = {CPSIoTSec'24: Proceedings of the Sixth Workshop on CPS&amp;IoT Security and Privacy},
year = {2024},
isbn = {9798400712449},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are delighted to extend a warm welcome to the 2024 Joint Workshop on CPS \&amp; IoT Security and Privacy (CPSIoTSec'24). The Joint Workshop on CPS&amp;IoT Security and Privacy is the result of the merger of the "Workshop on Cyber-Physical Systems Security and Privacy" and the "Workshop on the Internet of Things Security and Privacy" previously organized annually in conjunction with ACM Conference on Computer and Communications Security.},
location = {Salt Lake City, UT, USA}
}

@proceedings{10.1145/3690407,
title = {CAIBDA '24: Proceedings of the 2024 4th International Conference on Artificial Intelligence, Big Data and Algorithms},
year = {2024},
isbn = {9798400710247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3690771,
title = {ACMLC '24: Proceedings of the 2024 6th Asia Conference on Machine Learning and Computing},
year = {2024},
isbn = {9798400710018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3691422,
title = {ICEME '24: Proceedings of the 2024 15th International Conference on E-business, Management and Economics},
year = {2024},
isbn = {9798400717260},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3691555,
title = {MobiArch '24: Proceedings of the 19th Workshop on Mobility in the Evolving Internet Architecture},
year = {2024},
isbn = {9798400712470},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Washington D.C., DC, USA}
}

@inproceedings{10.1145/3691620.3694982,
author = {Jiang, Ziyou and Shi, Lin and Yang, Guowei and Wang, Qing},
title = {PatUntrack: Automated Generating Patch Examples for Issue Reports without Tracked Insecure Code},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3694982},
doi = {10.1145/3691620.3694982},
abstract = {Security patches are essential for enhancing the stability and robustness of projects in the open-source software community. While vulnerabilities are officially expected to be patched before being disclosed, patching vulnerabilities is complicated and remains a struggle for many organizations. To patch vulnerabilities, security practitioners typically track vulnerable issue reports (IRs), and analyze their relevant insecure code to generate potential patches. However, the relevant insecure code may not be explicitly specified and practitioners cannot track the insecure code in the repositories, thus limiting their ability to generate patches. In such cases, providing examples of insecure code and the corresponding patches would benefit the security developers to better locate and resolve the actual insecure code. In this paper, we propose PatUntrack, an automated approach to generating patch examples from IRs without tracked insecure code. PatUntrack utilizes auto-prompting to optimize the Large Language Model (LLM) to make it applicable for analyzing the vulnerabilities described in IRs and generating appropriate patch examples. Specifically, it first generates the completed description of the Vulnerability-Triggering Path (VTP) from vulnerable IRs. Then, it corrects potential hallucinations in the VTP description with external golden knowledge. Finally, it generates Top-K pairs of Insecure Code and Patch Example based on the corrected VTP description. To evaluate the performance of PatUntrack, we conducted experiments on 5,465 vulnerable IRs. The experimental results show that PatUntrack can obtain the highest performance and improve the traditional LLM baselines by +17.7\% (MatchFix) and +14.6\% (Fix@10) on average in patch example generation. Furthermore, PatUntrack was applied to generate patch examples for 76 newly disclosed vulnerable IRs. 27 out of 37 replies from the authors of these IRs confirmed the usefulness of the patch examples generated by PatUntrack, indicating that they can benefit from these examples for patching the vulnerabilities.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1–13},
numpages = {13},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3694986,
author = {Xiong, Yiheng and Su, Ting and Wang, Jue and Sun, Jingling and Pu, Geguang and Su, Zhendong},
title = {General and Practical Property-based Testing for Android Apps},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3694986},
doi = {10.1145/3691620.3694986},
abstract = {Finding non-crashing functional bugs for Android apps is challenging for both manual testing and automated GUI testing techniques. This paper introduces and designs a general and practical testing technique based on the idea of property-based testing for finding such bugs. Specifically, our technique incorporates (1) a property description language (PDL) to allow specifying desired app properties, and (2) two exploration strategies as the input generators for effectively validating the properties. We implemented our technique as a tool named Kea and evaluated it on 124 historical bugs from eight real-world, popular Android apps. Our evaluation shows that our PDL can specify all the app properties violated by these historical bugs, demonstrating its generability for finding functional bugs. Kea successfully found 66 (68.0\%) and 92 (94.8\%) of the 97 historical bugs in scope under the two exploration strategies, demonstrating its practicability. Moreover, Kea found 25 new functional bugs on the latest versions of these eight apps, given the specified properties. To date, all these bugs have been confirmed, and 21 have been fixed. In comparison, prior state-of-the-art techniques found only 13 (13.4\%) historical bugs and 1 new bug. We have made all the artifacts publicly available at https://github.com/ecnusse/Kea.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {53–64},
numpages = {12},
keywords = {property-based testing, Android app testing, non-crashing functional bugs},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3694994,
author = {Xiao, Yi and Le, Van-Hoang and Zhang, Hongyu},
title = {Demonstration-Free: Towards More Practical Log Parsing with Large Language Models},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3694994},
doi = {10.1145/3691620.3694994},
abstract = {Log parsing, the process of converting raw log messages into structured formats, is an important initial step for automated analysis of logs of large-scale software systems. Traditional log parsers often rely on heuristics or handcrafted features, which may not generalize well across diverse log sources or require extensive model tuning. Recently, some log parsers have utilized powerful generative capabilities of large language models (LLMs). However, they heavily rely on demonstration examples, resulting in substantial overhead in LLM invocations. To address these issues, we propose LogBatcher, a cost-effective LLM-based log parser that requires no training process or labeled data. To leverage latent characteristics of log data and reduce the overhead, we divide logs into several partitions through clustering. Then we perform a cache matching process to match logs with previously parsed log templates. Finally, we provide LLMs with better prompt context specialized for log parsing by batching a group of logs from each partition. We have conducted experiments on 16 public log datasets and the results show that LogBatcher is effective and efficient for log parsing.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {153–165},
numpages = {13},
keywords = {log parsing, batch prompting, large language models},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3694997,
author = {Lu, Jiawei and Wang, Haoye and Liu, Zhongxin and Liang, Keyu and Bao, Lingfeng and Yang, Xiaohu},
title = {Instructive Code Retriever: Learn from Large Language Model's Feedback for Code Intelligence Tasks},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3694997},
doi = {10.1145/3691620.3694997},
abstract = {Recent studies proposed to leverage large language models (LLMs) with In-Context Learning (ICL) to handle code intelligence tasks without fine-tuning. ICL employs task instructions and a set of examples as demonstrations to guide the model in generating accurate answers without updating its parameters. While ICL has proven effective for code intelligence tasks, its performance heavily relies on the selected examples. Previous work has achieved some success in using BM25 to retrieve examples for code intelligence tasks. However, existing approaches lack the ability to understand the semantic and structural information of queries, resulting in less helpful demonstrations. Moreover, they do not adapt well to the complex and dynamic nature of user queries in diverse domains. In this paper, we introduce a novel approach named Instructive Code Retriever (ICR), which is designed to retrieve examples that enhance model inference across various code intelligence tasks and datasets. We enable ICR to learn the semantic and structural information of the corpus by a tree-based loss function. To better understand the correlation between queries and examples, we incorporate the feedback from LLMs to guide the training of the retriever. Experimental results demonstrate that our retriever significantly outperforms state-of-the-art approaches. We evaluate our model's effectiveness on various tasks, i.e., code summarization, program synthesis, and bug fixing. Compared to previous state-of-the-art algorithms, our method achieved improvements of 50.0\% and 90.0\% in terms of BLEU-4 for two code summarization datasets, 74.6\% CodeBLEU on program synthesis dataset, and increases of 3.6 and 3.2 BLEU-4 on two bug fixing datasets.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {191–203},
numpages = {13},
keywords = {software engineering, large language models, in-context learning},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695001,
author = {Zhang, Quan and Zhou, Chijin and Go, Gwihwan and Zeng, Binqi and Shi, Heyuan and Xu, Zichen and Jiang, Yu},
title = {Imperceptible Content Poisoning in LLM-Powered Applications},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695001},
doi = {10.1145/3691620.3695001},
abstract = {Large Language Models (LLMs) have shown their superior capability in natural language processing, promoting extensive LLM-powered applications to be the new portals for people to access various content on the Internet. However, LLM-powered applications do not have sufficient security considerations on untrusted content, leading to potential threats. In this paper, we reveal content poisoning, where attackers can tailor attack content that appears benign to humans but causes LLM-powered applications to generate malicious responses. To highlight the impact of content poisoning and inspire the development of effective defenses, we systematically analyze the attack, focusing on the attack modes in various content, exploitable design features of LLM application frameworks, and the generation of attack content. We carry out a comprehensive evaluation on five LLMs, where content poisoning achieves an average attack success rate of 89.60\%. Additionally, we assess content poisoning on four popular LLM-powered applications, achieving the attack on 72.00\% of the content. Our experimental results also show that existing defenses are ineffective against content poisoning. Finally, we discuss potential mitigations for LLM application frameworks to counter content poisoning.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {242–254},
numpages = {13},
keywords = {LLM applications, content poisoning},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695010,
author = {Zhang, Yichi and Liu, Zixi and Feng, Yang and Xu, Baowen},
title = {Leveraging Large Language Model to Assist Detecting Rust Code Comment Inconsistency},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695010},
doi = {10.1145/3691620.3695010},
abstract = {Rust is renowned for its robust memory safety capabilities, yet its distinctive memory management model poses substantial challenges in both writing and understanding programs. Within Rust source code, comments are employed to clearly delineate conditions that might cause panic behavior, thereby warning developers about potential hazards associated with specific operations. Therefore, comments are particularly crucial for documenting Rust's program logic and design. Nevertheless, as modern software frequently undergoes updates and modifications, maintaining the accuracy and relevance of these comments becomes a labor-intensive endeavor.In this paper, inspired by the remarkable capabilities of Large Language Models (LLMs) in understanding software programs, we propose a code-comment inconsistency detection tool, namely RustC4, that combines program analysis and LLM-driven techniques to identify inconsistencies in code comments. RustC4 leverages LLMs' ability to interpret natural language descriptions within code comments, facilitating the extraction of design constraints. Program analysis techniques are then employed to accurately verify the implementation of these constraints. To evaluate the effectiveness of RustC4, we construct a dataset from 12 large-scale real-world Rust projects. The experiment results demonstrate that RustC4 is effective in detecting 176 real inconsistent cases and 23 of them have been confirmed and fixed by developers by the time this paper was submitted.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {356–366},
numpages = {11},
keywords = {code comment inconsistency, program analysis, large language model, bug detection},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695013,
author = {Wu, Yulun and Wen, Ming and Yu, Zeliang and Guo, Xiaochen and Jin, Hai},
title = {Effective Vulnerable Function Identification based on CVE Description Empowered by Large Language Models},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695013},
doi = {10.1145/3691620.3695013},
abstract = {Open-source software (OSS) has profoundly transformed the software development paradigm by facilitating effortless code reuse. However, in recent years, there has been an alarming increase in disclosed vulnerabilities within OSS, posing significant security risks to downstream users. Therefore, analyzing existing vulnerabilities and precisely assessing their threats to downstream applications become pivotal. Plenty of efforts have been made recently towards this problem, such as vulnerability reachability analysis and vulnerability reproduction. The key to these tasks is identifying the vulnerable function (i.e., the function where the root cause of a vulnerability resides). However, public vulnerability datasets (e.g., NVD) rarely include this information as pinpointing the exact vulnerable functions remains to be a longstanding challenge.Existing methods mainly detect vulnerable functions based on vulnerability patches or Proof-of-Concept (PoC). However, such methods face significant limitations due to data availability and the requirement for extensive manual efforts, thus hindering scalability. To address this issue, we propose a novel approach VFFinder that localizes vulnerable functions based on Common Vulnerabilities and Exposures (CVE) descriptions and the corresponding source code utilizing Large Language Models (LLMs). Specifically, VFFinder adopts a customized in-context learning (ICL) approach based on CVE description patterns to enable LLM to extract key entities. It then performs priority matching with the source code to localize vulnerable functions. We assess the performance of VFFinder on 75 large open-source projects. The results demonstrate that VFFinder surpasses existing baselines significantly. Notably, the Top-1 and MRR metrics have been improved substantially, averaging 4.25X and 2.37X respectively. We also integrate VFFinder with Software Composition Analysis (SCA) tools, and the results show that our tool can reduce the false positive rates of existing SCA tools significantly.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {393–405},
numpages = {13},
keywords = {vulnerability analysis, vulnerable function, large language model},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695014,
author = {Wu, Guangyuan and Cao, Weining and Yao, Yuan and Wei, Hengfeng and Chen, Taolue and Ma, Xiaoxing},
title = {LLM Meets Bounded Model Checking: Neuro-symbolic Loop Invariant Inference},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695014},
doi = {10.1145/3691620.3695014},
abstract = {Loop invariant inference, a key component in program verification, is a challenging task due to the inherent undecidability and complex loop behaviors in practice. Recently, machine learning based techniques have demonstrated impressive performance in generating loop invariants automatically. However, these methods highly rely on the labeled training data, and are intrinsically random and uncertain, leading to unstable performance. In this paper, we investigate a synergy of large language models (LLMs) and bounded model checking (BMC) to address these issues. The key observation is that, although LLMs may not be able to return the correct loop invariant in one response, they usually can provide all individual predicates of the correct loop invariant in multiple responses. To this end, we propose a "query-filter-reassemble" strategy, namely, we first leverage the language generation power of LLMs to produce a set of candidate invariants, where training data is not needed. Then, we employ BMC to identify valid predicates from these candidate invariants, which are assembled to produce new candidate invariants and checked by off-the-shelf SMT solvers. The feedback is incorporated into the prompt for the next round of LLM querying. We expand the existing benchmark of 133 programs to 316 programs, providing a more comprehensive testing ground. Experimental results demonstrate that our approach significantly outperforms the state-of-the-art techniques, successfully generating 309 loop invariants out of 316 cases, whereas the existing baseline methods are only able to tackle 219 programs at best. The code is publicly available at https://github.com/SoftWiser-group/LaM4Inv.git.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {406–417},
numpages = {12},
keywords = {loop invariant, program verification, large language model},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695020,
author = {She, Xinyu and Zhao, Yanjie and Wang, Haoyu},
title = {WaDec: Decompiling WebAssembly Using Large Language Model},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695020},
doi = {10.1145/3691620.3695020},
abstract = {WebAssembly (abbreviated Wasm) has emerged as a cornerstone of web development, offering a compact binary format that allows high-performance applications to run at near-native speeds in web browsers. Despite its advantages, Wasm's binary nature presents significant challenges for developers and researchers, particularly regarding readability when debugging or analyzing web applications. Therefore, effective decompilation becomes crucial. Unfortunately, traditional decompilers often struggle with producing readable outputs. While some large language model (LLM)-based decompilers have shown good compatibility with general binary files, they still face specific challenges when dealing with Wasm.In this paper, we introduce a novel approach, WaDec, which is the first use of a fine-tuned LLM to interpret and decompile Wasm binary code into a higher-level, more comprehensible source code representation. The LLM was meticulously fine-tuned using a specialized dataset of wat-c code snippets, employing self-supervised learning techniques. This enables WaDec to effectively decompile not only complete wat functions but also finer-grained wat code snippets. Our experiments demonstrate that WaDec markedly outperforms current state-of-the-art tools, offering substantial improvements across several metrics. It achieves a code inflation rate of only 3.34\%, a dramatic 97\% reduction compared to the state-of-the-art's 116.94\%. Unlike the output of baselines that cannot be directly compiled or executed, WaDec maintains a recompilability rate of 52.11\%, a re-execution rate of 43.55\%, and an output consistency of 27.15\%. Additionally, it significantly exceeds state-of-the-art performance in AST edit distance similarity by 185\%, cyclomatic complexity by 8\%, and cosine similarity by 41\%, achieving an average code similarity above 50\%. In summary, WaDec enhances understanding of the code's structure and execution flow, facilitating automated code analysis, optimization, and security auditing.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {481–492},
numpages = {12},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695021,
author = {Chen, Zhi and Jiang, Lingxiao},
title = {Promise and Peril of Collaborative Code Generation Models: Balancing Effectiveness and Memorization},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695021},
doi = {10.1145/3691620.3695021},
abstract = {In the rapidly evolving field of machine learning, training models with datasets from various locations and organizations presents significant challenges due to privacy and legal concerns. The exploration of effective collaborative training settings, which are capable of leveraging valuable knowledge from distributed and isolated datasets, is increasingly crucial. This study investigates key factors that impact the effectiveness of collaborative training methods in code next-token prediction, as well as the correctness and utility of the generated code, showing the promise of such methods. Additionally, we evaluate the memorization of different participant training data across various collaborative training settings, including centralized, federated, and incremental training, showing their potential risks in leaking data.Our findings indicate that the size and diversity of code datasets are pivotal factors influencing the success of collaborative trained code models. We demonstrate that federated learning achieves competitive performance compared to centralized training while offering better data protection, as evidenced by lower memorization ratios in the generated code. However, federated learning can still produce verbatim code snippets from hidden training data, potentially violating data privacy or copyright. Our study further explores the patterns of effectiveness and memorization in incremental learning, emphasizing the importance of the sequence in which individual participant datasets are introduced. Also, we identify the memorization phenomenon of cross-organizational clones as a prevalent challenge in both centralized and federated learning scenarios. Our findings highlight the persistent risk of data leakage during inference, even when training data remains unseen. We conclude with strategic recommendations for practitioners and researchers to optimize the use of multisource datasets, thereby propelling the cross-organizational collaboration forward.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {493–505},
numpages = {13},
keywords = {collaborative training, memorization, large language model, code generation},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695022,
author = {Anandayuvaraj, Dharun and Campbell, Matthew and Tewari, Arav and Davis, James C},
title = {FAIL: Analyzing Software Failures from the News Using LLMs},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695022},
doi = {10.1145/3691620.3695022},
abstract = {Software failures inform engineering work, standards, regulations. For example, the Log4J vulnerability brought government and industry attention to evaluating and securing software supply chains. Retrospective failure analysis is thus a valuable line of software engineering research. Accessing private engineering records is difficult, so such analyses tend to use information reported by the news media. However, prior works in this direction have relied on manual analysis. That has limited the scale of their analyses. The community lacks automated support to enable such analyses to consider a wide range of news sources and incidents.To fill this gap, we propose the Failure Analysis Investigation with LLMs (FAIL) system. FAIL is a novel LLM-based pipeline that collects, analyzes, and summarizes software failures as reported in the news. FAIL groups articles that describe the same incidents. It then analyzes incidents using existing taxonomies for postmortems, faults, and system characteristics. To tune and evaluate FAIL, we followed the methods of prior works by manually analyzing 31 software failures. FAIL achieved an F1 score of 90\% for collecting news about software failures, a V-measure of 0.98 for merging articles reporting on the same incident, and extracted 90\% of the facts about failures. We then applied FAIL to a total of 137,427 news articles from 11 providers published between 2010 and 2022. FAIL identified and analyzed 2,457 distinct failures reported across 4,184 articles. Our findings include: (1) current generation of large language models are capable of identifying news articles that describe failures, and analyzing them according to structured taxonomies; (2) high recurrences of similar failures within organizations and across organizations; and (3) severity of the consequences of software failures have increased over the past decade. The full FAIL database is available so that researchers, engineers, and policymakers can learn from a diversity of software failures.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {506–518},
numpages = {13},
keywords = {software failure analysis, news analysis, large language models, empirical software engineering},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695025,
author = {Huang, Zhiquan and Huang, Yuan and Chen, Xiangping and Zhou, Xiaocong and Yang, Changlin and Zheng, Zibin},
title = {An Empirical Study on Learning-based Techniques for Explicit and Implicit Commit Messages Generation},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695025},
doi = {10.1145/3691620.3695025},
abstract = {High-quality and appropriate commit messages help developers to quickly understand and track code evolution, which is crucial for the collaborative development and maintenance of software. To relieve developers of the burden of writing commit messages, researchers have proposed various techniques to generate commit messages automatically, among which learning-based techniques have proven to be promising.However, the performance of these learning-based techniques is generally low on the BLEU metric. Some reasons for low BLEU have been summarized, including the effect of noisy data, the truncation mechanism of the model, insufficient utilization of context information, etc. Through extensive empirical analysis, we find that the diversity of commits may also be one of the factors that affect the performance of existing learning-based techniques. As a result of this diversity, there are mainly two types of commit messages in the real world: one offers a superficial summary of relatively simple code changes (called the "explicit" commit message), and the other summarizes complex code changes from a global perspective, reflecting the nature or intent behind the changes (called the "implicit" commit message). Our empirical study shows that generating implicit commit messages is more challenging for these techniques, and the models have limited ability to generalize when facing cross-category generation. To fully verify these conclusions, we build a model that identifies explicit and implicit commit messages automatically, and then use it to construct our datasets. Next, we evaluate the ability of state-of-the-art learning-based techniques to generate explicit and implicit commit messages and the generalization capacity of the models. Finally, we propose a "Diversion" strategy to take advantage of the generating performance of specific models. Experimental results show that our approach improves the performance of most learning-based techniques in generating commit messages.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {544–556},
numpages = {13},
keywords = {commit-based software development, open collaboration, commit message generation, empirical study},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695054,
author = {Liu, Wei and Yu, Ailun and Zan, Daoguang and Shen, Bo and Zhang, Wei and Zhao, Haiyan and Jin, Zhi and Wang, Qianxiang},
title = {GraphCoder: Enhancing Repository-Level Code Completion via Coarse-to-fine Retrieval Based on Code Context Graph},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695054},
doi = {10.1145/3691620.3695054},
abstract = {The performance of repository-level code completion depends upon the effective leverage of both general and repository-specific knowledge. Despite the impressive capability of code LLMs in general code completion tasks, they often exhibit less satisfactory performance on repository-level completion due to the lack of repository-specific knowledge in these LLMs. To address this problem, we propose GraphCoder, a retrieval-augmented code completion framework that leverages LLMs' general code knowledge and the repository-specific knowledge via a graph-based retrieval-generation process. In particular, GraphCoder captures the context of completion target more accurately through code context graph (CCG) that consists of control-flow, data- and control-dependence between code statements, a more structured way to capture the completion target context than the sequence-based context used in existing retrieval-augmented approaches; based on CCG, GraphCoder further employs a coarse-to-fine retrieval process to locate context-similar code snippets with the completion target from the current repository. Experimental results demonstrate both the effectiveness and efficiency of GraphCoder: Compared to baseline retrieval-augmented methods, GraphCoder achieves higher exact match (EM) on average, with increases of +6.06 in code match and +6.23 in identifier match, while using less time and space.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {570–581},
numpages = {12},
keywords = {code completion, large language model, retrieval augmented generation, code graphs},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695057,
author = {Cao, Sicong and Sun, Xiaobing and Wu, Xiaoxue and Lo, David and Bo, Lili and Li, Bin and Liu, Xiaolei and Lin, Xingwei and Liu, Wei},
title = {Snopy: Bridging Sample Denoising with Causal Graph Learning for Effective Vulnerability Detection},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695057},
doi = {10.1145/3691620.3695057},
abstract = {Deep Learning (DL) has emerged as a promising means for vulnerability detection due to its ability to automatically derive features from vulnerable code. Unfortunately, current solutions struggle to focus on vulnerability-related parts of vulnerable functions, and tend to exploit spurious correlations for prediction, thus undermining their effectiveness in practice. In this paper, we propose Snopy, a novel DL-based approach, which bridges sample denoising with causal graph learning to capture real vulnerability patterns from vulnerable samples with numerous noise for effective detection. Specifically, Snopy adopts a change-based sample denoising approach to automatically weed out vulnerability-irrelevant code elements in the vulnerable functions without sacrificing the label accuracy. Then, Snopy constructs a novel Causality-Aware Graph Attention Network (CA-GAT) with Feature Caching Scheme (FCS) to learn causal vulnerability features while maintaining efficiency. Experiments on the three public benchmark datasets show that Snopy outperforms the state-of-the-art baselines by an average of 27.22\%, 85.89\%, and 75.50\% in terms of F1-score, respectively.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {606–618},
numpages = {13},
keywords = {program analysis, causal learning, graph attention network},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695058,
author = {Muttillo, Vittoriano and Di Sipio, Claudio and Rubei, Riccardo and Berardinelli, Luca and Dehghani, MohammadHadi},
title = {Towards Synthetic Trace Generation of Modeling Operations using In-Context Learning Approach},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695058},
doi = {10.1145/3691620.3695058},
abstract = {Producing accurate software models is crucial in model-driven software engineering (MDE). However, modeling complex systems is an error-prone task that requires deep application domain knowledge. In the past decade, several automated techniques have been proposed to support academic and industrial practitioners by providing relevant modeling operations. Nevertheless, those techniques require a huge amount of training data that cannot be available due to several factors, e.g., privacy issues. The advent of large language models (LLMs) can support the generation of synthetic data although state-of-the-art approaches are not yet supporting the generation of modeling operations. To fill the gap, we propose a conceptual framework that combines modeling event logs, intelligent modeling assistants, and the generation of modeling operations using LLMs. In particular, the architecture comprises modeling components that help the designer specify the system, record its operation within a graphical modeling environment, and automatically recommend relevant operations. In addition, we generate a completely new dataset of modeling events by telling on the most prominent LLMs currently available. As a proof of concept, we instantiate the proposed framework using a set of existing modeling tools employed in industrial use cases within different European projects. To assess the proposed methodology, we first evaluate the capability of the examined LLMs to generate realistic modeling operations by relying on well-founded distance metrics. Then, we evaluate the recommended operations by considering real-world industrial modeling artifacts. Our findings demonstrate that LLMs can generate modeling events even though the overall accuracy is higher when considering human-based operations. In this respect, we see generative AI tools as an alternative when the modeling operations are not available to train traditional IMAs specifically conceived to support industrial practitioners.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {619–630},
numpages = {12},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695059,
author = {Yang, Wenzhang and Gao, Cuifeng and Liu, Xiaoyuan and Li, Yuekang and Xue, Yinxing},
title = {Rust-twins: Automatic Rust Compiler Testing through Program Mutation and Dual Macros Generation},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695059},
doi = {10.1145/3691620.3695059},
abstract = {Rust is a relatively new programming language known for its memory safety and numerous advanced features. It has been widely used in system software in recent years. Thus, ensuring the reliability and robustness of the only implementation of the Rust compiler, rustc, is critical. However, compiler testing, as one of the most effective techniques to detect bugs, faces difficulties in generating valid Rust programs with sufficient diversity due to its stringent memory safety mechanisms. Furthermore, existing research primarily focuses on testing rustc to trigger crash errors, neglecting incorrect compilation results - miscompilation. Detecting miscompilation remains a challenge in the absence of multiple implementations of the Rust compiler to serve as a test oracle.This paper tackles these challenges by introducing rust-twins, a novel and effective approach to performing automated differential testing for rustc to detect both crashes and miscompilations. We devise four Rust-specific mutators and adapt fourteen general mutators for Rust, each intends to produce a syntax and semantic valid Rust program to trigger rustc crashes. Additionally, we develop a macroize approach to rewrite a regular Rust program into dual macros with equivalent behaviors but in different implementations. Furthermore, we design an assessment component to check the equivalence by comparing the expansion results with a simple macro input. Finally, rust-twins attempts to expand the two macros with numerous complex inputs to detect differences. Due to the macro expansion mechanism, the root causes of differences can arise not only from the macro expansion part but also from any other mis-implemented compiler code.We have evaluated rust-twins on the latest version of rustc. Our experimental results indicate that rust-twins achieves twice the total line coverage and identifies more crashes and differences than the best baseline technique, rustsmith, after 24 hours of testing. In total, rust-twins triggered 10 rustc crashes, and 229 of the generated macros exposed rustc differences. We analyzed and reported 12 previously unknown bugs, of which 8 have already been confirmed and fixed.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {631–642},
numpages = {12},
keywords = {rust, compiler testing, differential testing},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695060,
author = {Zhang, Zhibo and Bai, Wuxia and Li, Yuxi and Meng, Mark Huasong and Wang, Kailong and Shi, Ling and Li, Li and Wang, Jun and Wang, Haoyu},
title = {GlitchProber: Advancing Effective Detection and Mitigation of Glitch Tokens in Large Language Models},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695060},
doi = {10.1145/3691620.3695060},
abstract = {Large language models (LLMs) have achieved unprecedented success in the field of natural language processing. However, the black-box nature of their internal mechanisms has brought many concerns about their trustworthiness and interpretability. Recent research has discovered a class of abnormal tokens in the model's vocabulary space and named them "glitch tokens". Those tokens, once included in the input, may induce the model to produce incorrect, irrelevant, or even harmful results, drastically undermining the reliability and practicality of LLMs.In this work, we aim to enhance the understanding of glitch tokens and propose techniques for their detection and mitigation. We first reveal the characteristic features induced by glitch tokens on LLMs, which are evidenced by significant deviations in the distributions of attention patterns and dynamic information from intermediate model layers. Based on the insights, we develop GlitchProber, a tool for efficient glitch token detection and mitigation. GlitchProber utilizes small-scale sampling, principal component analysis for accelerated feature extraction, and a simple classifier for efficient vocabulary screening. Taking one step further, GlitchProber rectifies abnormal model intermediate layer values to mitigate the destructive effects of glitch tokens. Evaluated on five mainstream open-source LLMs, GlitchProber demonstrates higher efficiency, precision, and recall compared to existing approaches, with an average F1 score of 0.86 and an average repair rate of 50.06\%. GlitchProber unveils a novel path to address the challenges posed by glitch tokens and inspires future research toward more robust and interpretable LLMs. Our code is available at https://github.com/LLM-Integrity-Guard/GlitchProber.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {643–655},
numpages = {13},
keywords = {LLM security, glitch token, LLM analysis},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695061,
author = {Yu, Xiao and Zhang, Zexian and Niu, Feifei and Hu, Xing and Xia, Xin and Grundy, John},
title = {What Makes a High-Quality Training Dataset for Large Language Models: A Practitioners' Perspective},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695061},
doi = {10.1145/3691620.3695061},
abstract = {Large Language Models (LLMs) have demonstrated remarkable performance in various application domains, largely due to their self-supervised pre-training on extensive high-quality text datasets. However, despite the importance of constructing such datasets, many leading LLMs lack documentation of their dataset construction and training procedures, leaving LLM practitioners with a limited understanding of what makes a high-quality training dataset for LLMs. To fill this gap, we initially identified 18 characteristics of high-quality LLM training datasets, as well as 10 potential data pre-processing methods and 6 data quality assessment methods, through detailed interviews with 13 experienced LLM professionals. We then surveyed 219 LLM practitioners from 23 countries across 5 continents. We asked our survey respondents to rate the importance of these characteristics, provide a rationale for their ratings, specify the key data pre-processing and data quality assessment methods they used, and highlight the challenges encountered during these processes. From our analysis, we identified 13 crucial characteristics of high-quality LLM datasets that receive a high rating, accompanied by key rationale provided by respondents. We also identified some widely-used data pre-processing and data quality assessment methods, along with 7 challenges encountered during these processes. Based on our findings, we discuss the implications for researchers and practitioners aiming to construct high-quality training datasets for optimizing LLMs.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {656–668},
numpages = {13},
keywords = {large language models, high-quality data, practitioners' perspective, empirical study},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695068,
author = {Cui, Di and Wang, Jiaqi and Wang, Qiangqiang and Ji, Peng and Qiao, Minglang and Zhao, Yutong and Hu, Jingzhao and Wang, Luqiao and Li, Qingshan},
title = {Three Heads Are Better Than One: Suggesting Move Method Refactoring Opportunities with Inter-class Code Entity Dependency Enhanced Hybrid Hypergraph Neural Network},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695068},
doi = {10.1145/3691620.3695068},
abstract = {Methods implemented in incorrect classes will cause excessive reliance on other classes than their own, known as a typical code smell symptom: feature envy, which makes it difficult to maintain increased coupling between classes. Addressing this issue, several Move Method refactoring tools have been proposed, employing a two-phase process: identifying misplaced methods to move and appropriate classes to receive, and implementing the mechanics of refactoring. These tools traditionally use hard-coded metrics to measure correlations between movable methods and target classes and apply heuristic thresholds or trained classifiers to unearth refactoring opportunities. Yet, these approaches predominantly illuminate pairwise correlations between methods and classes while overlooking the complex and complicated dependencies binding multiple code entities within these methods/classes that are prevalent in real-world cases. This narrow focus can lead to refactoring suggestions that may diverge from developers' actual needs. To bridge this gap, our paper leverages the concept of inter-class code entity dependency hypergraph to model complicated dependency relationships involving multiple code entities within various methods/classes and proposes a hypergraph learning-based approach to suggest Move Method refactoring opportunities named HMove. We first construct inter-class code entity dependency hypergraphs from training samples and assign attributes to entities with a pre-trained code model. All the attributed hypergraphs are fed into a hybrid hypergraph neural network for training. Utilizing this trained neural network alongside a large language model, we construct a refactoring suggestion system. We trained HMove on a large-scale dataset and evaluated it on two real-world datasets. The results show that demonstrates an increase of 27.8\% in precision, 2.5\% in recall, and 18.5\% in f1-measure compared to 9 state-of-the-art refactoring tools, which is more useful for 68\% of participants. The results also unveil practical suggestions and new insights that benefit existing feature envy-related refactoring techniques.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {745–757},
numpages = {13},
keywords = {move method refactoring, hypergraph neural network},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695257,
author = {Schaef, Martin and Cirisci, Berk and Luo, Linghui and Mansur, Muhammad Numair and Tripp, Omer and Sanchez, Daniel and Zhou, Qiang and Zafar, Muhammad Bilal},
title = {Understanding Developer-Analyzer Interactions in Code Reviews},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695257},
doi = {10.1145/3691620.3695257},
abstract = {Static code analyzers are now a common part of the codereview process. These automated tools integrate into the code review process by commenting on code changes and suggesting improvements, in the same way as human reviewers. The comments made by static analyzers often trigger a conversation between developers to align on if and how the issue should be fixed. Because developers rarely give feedback directly to the tool, understanding the sentiment and intent in the conversation triggered by the tool comments can be used to measure the usefulness of the static analyzer.In this paper, we report on an experiment where we use large language models to automatically label and categorize the sentiment and intent of such conversations triggered by static analyzer comments. Our experiment demonstrates that LLMs not only classify and interpret complex developer-analyzer conversations, but can be more accurate than human experts.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1945–1955},
numpages = {11},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695260,
author = {Feng, Sidong and Lu, Haochuan and Jiang, Jianqin and Xiong, Ting and Huang, Likun and Liang, Yinglin and Li, Xiaoqin and Deng, Yuetang and Aleti, Aldeida},
title = {Enabling Cost-Effective UI Automation Testing with Retrieval-Based LLMs: A Case Study in WeChat},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695260},
doi = {10.1145/3691620.3695260},
abstract = {UI automation tests play a crucial role in ensuring the quality of mobile applications. Despite the growing popularity of machine learning techniques to generate these tests, they still face several challenges, such as the mismatch of UI elements. The recent advances in Large Language Models (LLMs) have addressed these issues by leveraging their semantic understanding capabilities. However, a significant gap remains in applying these models to industrial-level app testing, particularly in terms of cost optimization and knowledge limitation. To address this, we introduce CAT to create cost-effective UI automation tests for industry apps by combining machine learning and LLMs with best practices. Given the task description, CAT employs Retrieval Augmented Generation (RAG) to source examples of industrial app usage as the few-shot learning context, assisting LLMs in generating the specific sequence of actions. CAT then employs machine learning techniques, with LLMs serving as a complementary optimizer, to map the target element on the UI screen. Our evaluations on the WeChat testing dataset demonstrate the CAT's performance and cost-effectiveness, achieving 90\% UI automation with $0.34 cost, outperforming the state-of-the-art. We have also integrated our approach into the real-world WeChat testing platform, demonstrating its usefulness in detecting 141 bugs and enhancing the developers' testing process.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1973–1978},
numpages = {6},
keywords = {UI automation test, large language model, retrieval-augmented generation, cost optimization},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695277,
author = {Sahoo, Priyam and Pujar, Saurabh and Nalawade, Ganesh and Genhardt, Richard and Mandel, Louis and Buratti, Luca},
title = {Ansible Lightspeed: A Code Generation Service for IT Automation},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695277},
doi = {10.1145/3691620.3695277},
abstract = {The availability of Large Language Models (LLMs) which can generate code, has made it possible to create tools that improve developer productivity. Integrated development environments or IDEs which developers use to write software are often used as an interface to interact with LLMs. Although many such tools have been released, almost all of them focus on general-purpose programming languages. Domain-specific languages, such as those crucial for Information Technology (IT) automation, have not received much attention. Ansible is one such YAML-based IT automation-specific language. Ansible Lightspeed is an LLM-based service designed explicitly to generate Ansible YAML, given natural language prompt.In this paper, we present the design and implementation of the Ansible Lightspeed service. We then evaluate its utility to developers using diverse indicators, including extended utilization, analysis of user edited suggestions, as well as user sentiments analysis. The evaluation is based on data collected for 10,696 real users including 3,910 returning users. The code for Ansible Lightspeed service and the analysis framework is made available for others to use.To our knowledge, our study is the first to involve thousands of users of code assistants for domain-specific languages. We are also the first code completion tool to present N-Day user retention figures, which is 13.66\% on Day 30. We propose an improved version of user acceptance rate, called Strong Acceptance rate, where a suggestion is considered accepted only if less than 50\% of it is edited and these edits do not change critical parts of the suggestion. By focusing on Ansible, Lightspeed is able to achieve a strong acceptance rate of 49.08\% for multi-line Ansible task suggestions. With our findings we provide insights into the effectiveness of small, dedicated models in a domain-specific context. We hope this work serves as a reference for software engineering and machine learning researchers exploring code completion.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2148–2158},
numpages = {11},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695309,
author = {Hou, Xinyi and Zhao, Yanjie and Wang, Shenao and Wang, Haoyu},
title = {GPTZoo: A Large-scale Dataset of GPTs for the Research Community},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695309},
doi = {10.1145/3691620.3695309},
abstract = {The rapid advancements in Large Language Models (LLMs) have revolutionized natural language processing, with GPTs, customized versions of ChatGPT available on the GPT Store, emerging as a prominent technology for specific domains and tasks. To support academic research on GPTs, we introduce GPTZoo, a large-scale dataset comprising 730,420 GPT instances. Each instance includes rich metadata with 21 attributes describing its characteristics, as well as instructions, knowledge files, and third-party services utilized during its development. GPTZoo aims to provide researchers with a comprehensive and readily available resource to study the real-world applications, performance, and potential of GPTs. To facilitate efficient retrieval and analysis of GPTs, we also developed an automated command-line interface (CLI) that supports keyword-based searching of the dataset. To promote open research and innovation, the GPTZoo dataset will undergo continuous updates, and we are granting researchers public access to GPTZoo and its associated tools.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2329–2333},
numpages = {5},
keywords = {large language model, LLM, ChatGPT, GPTs},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695468,
author = {JianWang and Liu, Shangqing and Xie, Xiaofei and Li, Yi},
title = {An Empirical Study to Evaluate AIGC Detectors on Code Content},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695468},
doi = {10.1145/3691620.3695468},
abstract = {Artificial Intelligence Generated Content (AIGC) has garnered considerable attention for its impressive performance, with Large Language Models (LLMs), like ChatGPT, emerging as a leading AIGC model that produces high-quality responses across various applications, including software development and maintenance. Despite its potential, the misuse of LLMs, especially in security and safety-critical domains, such as academic integrity and answering questions on Stack Overflow, poses significant concerns. Numerous AIGC detectors have been developed and evaluated on natural language data. However, their performance on code-related content generated by LLMs remains unexplored.To fill this gap, in this paper, we present an empirical study evaluating existing AIGC detectors in the software domain. We select three state-of-the-art LLMs, i.e., GPT-3.5, WizardCoder and CodeLlama, for machine-content generation. We further created a comprehensive dataset including 2.23M samples comprising code-related content for each model, encompassing popular software activities like Q&amp;A (150K), code summarization (1M), and code generation (1.1M). We evaluated thirteen AIGC detectors, comprising six commercial and seven open-source solutions, assessing their performance on this dataset. Our results indicate that AIGC detectors perform less on code-related data than natural language data. Fine-tuning can enhance detector performance, especially for content within the same domain; but generalization remains a challenge.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {844–856},
numpages = {13},
keywords = {AIGC detection, code generation, large language model},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695480,
author = {Chen, Jiachi and Zhong, Qingyuan and Wang, Yanlin and Ning, Kaiwen and Liu, Yongkun and Xu, Zenan and Zhao, Zhe and Chen, Ting and Zheng, Zibin},
title = {RMCBench: Benchmarking Large Language Models' Resistance to Malicious Code},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695480},
doi = {10.1145/3691620.3695480},
abstract = {Warning: Please note that this article contains potential harmful or offensive content. This content is only for the evaluating and analysis of LLMs and does not imply any intention to promote criminal activities.The emergence of Large Language Models (LLMs) has significantly influenced various aspects of software development activities. Despite their benefits, LLMs also pose notable risks, including the potential to generate harmful content and being abused by malicious developers to create malicious code. Several previous studies have focused on the ability of LLMs to resist the generation of harmful content that violates human ethical standards, such as biased or offensive content. However, there is no research evaluating the ability of LLMs to resist malicious code generation. To fill this gap, we propose RMCBench, the first benchmark comprising 473 prompts designed to assess the ability of LLMs to resist malicious code generation. This benchmark employs two scenarios: a text-to-code scenario, where LLMs are prompted with descriptions to generate code, and a code-to-code scenario, where LLMs translate or complete existing malicious code. Based on RMCBench, we conduct an empirical study on the 11 representative LLMs to assess their ability to resist malicious code generation. Our findings indicate that current LLMs have a limited ability to resist malicious code generation with an average refusal rate of 40.36\% in text-to-code scenario and 11.52\% in code-to-code scenario. The average refusal rate of all LLMs in RMCBench is only 28.71\%; ChatGPT-4 has a refusal rate of only 35.73\%. We also analyze the factors that affect LLM's ability to resist malicious code generation and provide implications for developers to enhance model robustness.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {995–1006},
numpages = {12},
keywords = {large language models, malicious code, code generation},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695492,
author = {Huang, Yiheng and Wang, Ruisi and Zheng, Wen and Zhou, Zhuotong and Wu, Susheng and Ke, Shulin and Chen, Bihuan and Gao, Shan and Peng, Xin},
title = {SpiderScan: Practical Detection of Malicious NPM Packages Based on Graph-Based Behavior Modeling and Matching},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695492},
doi = {10.1145/3691620.3695492},
abstract = {Open source software (OSS) supply chains have been attractive targets for attacks. One of the significant, popular attacks is realized by malicious packages on package registries. NPM, as the largest package registry, has been recently flooded with malicious packages. In response to this severe security risk, many detection tools have been proposed. However, these tools do not model malicious behavior in a holistic way; only consider a predefined set of sensitive APIs; and require huge manual confirmation effort due to high false positives and binary detection results. Thus, their practical usefulness is hindered.To address these limitations, we propose a practical tool, named SpiderScan, to identify malicious NPM packages based on graph-based behavior modeling and matching. In the offline phase, given a set of malicious packages, SpiderScan models each malicious behavior in a graph that considers control flows and data dependencies across sensitive API calls, while leveraging LLM to recognize sensitive APIs in both built-in modules and third-party dependencies. In the online phase, given a target package, SpiderScan constructs its suspicious behavior graphs and matches them with malicious behavior graphs, and uses dynamic analysis and LLM to confirm the maliciousness only for certain malicious behaviors. Our extensive evaluation has demonstrated the effectiveness of SpiderScan over the state-of-the-art. SpiderScan has detected 249 new malicious packages in NPM, and received 70 thank letters from the official team of NPM.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1146–1158},
numpages = {13},
keywords = {software supply chain, malware detection, behavior modeling},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695495,
author = {Sun, Yongqian and Shi, Binpeng and Mao, Mingyu and Ma, Minghua and Xia, Sibo and Zhang, Shenglin and Pei, Dan},
title = {ART: A Unified Unsupervised Framework for Incident Management in Microservice Systems},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695495},
doi = {10.1145/3691620.3695495},
abstract = {Automated incident management is critical for large-scale microservice systems, including tasks such as anomaly detection (AD), failure triage (FT), and root cause localization (RCL). Currently, most techniques focus only on a single task, overlooking shared knowledge across closely related tasks. However, employing isolated models for managing multiple tasks may result in inefficiencies, delayed responses, a lack of systemic perspective, and complexity in updates and operations. Therefore we propose ART, an unsupervised framework that integrates a full-process solution covering Anomaly detection, failure Triage, and Root cause localization. It reaches the unification of multiple tasks by extracting the shared knowledge. Specifically, we first conduct an empirical study to analyze how the shared knowledge embedded in anomalous deviations manifests in AD, FT, and RCL. To better calculate deviations and extract shared knowledge, we sequentially model channel, temporal, and call dependencies using Transformer Encoder, GRU, and GraphSAGE, respectively. Then unified failure representations enhance the interpretability of abstract features with explicit semantic information, serving as the basis for unsupervised multitask solutions. Our evaluations on the datasets generated from two benchmark microservice systems demonstrate that ART outperforms existing methods in terms of AD (improving by 5.65\% to 60.8\%), FT (improving by 13.2\% to 95.7\%), and RCL (improving by 13.3\% to 205\%).},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1183–1194},
numpages = {12},
keywords = {microservice system, anomaly detection, failure triage, root cause localization},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695501,
author = {Wang, Zejun and Liu, Kaibo and Li, Ge and Jin, Zhi},
title = {HITS: High-coverage LLM-based Unit Test Generation via Method Slicing},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695501},
doi = {10.1145/3691620.3695501},
abstract = {Large language models (LLMs) have behaved well in generating unit tests for Java projects. However, the performance for covering the complex focal methods within the projects is poor. Complex methods comprise many conditions and loops, requiring the test cases to be various enough to cover all lines and branches. However, existing test generation methods with LLMs provide the whole method-to-test to the LLM without assistance on input analysis. The LLM has difficulty inferring the test inputs to cover all conditions, resulting in missing lines and branches. To tackle the problem, we propose decomposing the focal methods into slices and asking the LLM to generate test cases slice by slice. Our method simplifies the analysis scope, making it easier for the LLM to cover more lines and branches in each slice. We build a dataset comprising complex focal methods collected from the projects used by existing state-of-the-art approaches. Our experiment results show that our method significantly outperforms current test case generation methods with LLMs and the typical SBST method Evosuite regarding both line and branch coverage scores.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1258–1268},
numpages = {11},
keywords = {unit test generation, large language model, program decomposition, program slicing, testing and analysis, AI for SE},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695503,
author = {Huang, Junjie and Guo, Daya and Wang, Chenglong and Gu, Jiazhen and Lu, Shuai and Inala, Jeevana Priya and Yan, Cong and Gao, Jianfeng and Duan, Nan and Lyu, Michael R.},
title = {Contextualized Data-Wrangling Code Generation in Computational Notebooks},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695503},
doi = {10.1145/3691620.3695503},
abstract = {Data wrangling, the process of preparing raw data for further analysis in computational notebooks, is a crucial yet time-consuming step in data science. Code generation has the potential to automate the data wrangling process to reduce analysts' overhead by translating user intents into executable code. Precisely generating data wrangling code necessitates a comprehensive consideration of the rich context present in notebooks, including textual context, code context and data context. However, notebooks often interleave multiple non-linear analysis tasks into linear sequence of code blocks, where the contextual dependencies are not clearly reflected. Directly training models with source code blocks fails to fully exploit the contexts for accurate wrangling code generation.To bridge the gap, we aim to construct a high quality datasets with clear and rich contexts to help training models for data wrangling code generation tasks. In this work, we first propose an automated approach, CoCoMine to mine data-wrangling code generation examples with clear multi-modal contextual dependency. It first adopts data flow analysis to identify the code blocks containing data wrangling codes. Then, CoCoMine extracts the contextualized data-wrangling code examples through tracing and replaying notebooks. With CoCoMine, we construct CoCoNote, a dataset containing 58,221 examples for Contextualized Data-wrangling Code generation in Notebooks. To demonstrate the effectiveness of our dataset, we finetune a range of pretrained code models and prompt various large language models on our task. Furthermore, we also propose Data-Coder, which encodes data context and code&amp;textual contexts separately to enhance code generation. Experiment results demonstrate the significance of incorporating data context in data-wrangling code generation and the effectiveness of our model. We release code and data at https://github.com/Jun-jie-Huang/CoCoNote.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1282–1294},
numpages = {13},
keywords = {code generation, data wrangling, computational notebooks, large language models},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695512,
author = {Pirzada, Muhammad A. A. and Reger, Giles and Bhayat, Ahmed and Cordeiro, Lucas C.},
title = {LLM-Generated Invariants for Bounded Model Checking Without Loop Unrolling},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695512},
doi = {10.1145/3691620.3695512},
abstract = {We investigate a modification of the classical Bounded Model Checking (BMC) procedure that does not handle loops through unrolling but via modifications to the control flow graph (CFG). A portion of the CFG representing a loop is replaced by a node asserting invariants of the loop. We generate these invariants using Large Language Models (LLMs) and use a first-order theorem prover to ensure the correctness of the generated statements. We thus transform programs to loop-free variants in a sound manner. Our experimental results show that the resulting tool, ESBMC ibmc, is competitive with state-of-the-art formal verifiers for programs with unbounded loops, significantly improving the number of programs verified by the industrial-strength software verifier ESBMC and verifying programs that state-of-the-art software verifiers such as SeaHorn and VeriAbs could not.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1395–1407},
numpages = {13},
keywords = {program verification, large language models, bounded model checking, invariant generation},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695518,
author = {Bo, Lili and Ji, Wangjie and Sun, Xiaobing and Zhang, Ting and Wu, Xiaoxue and Wei, Ying},
title = {ChatBR: Automated assessment and improvement of bug report quality using ChatGPT},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695518},
doi = {10.1145/3691620.3695518},
abstract = {Bug reports, containing crucial information such as the Observed Behavior (OB), the Expected Behavior (EB), and the Steps to Reproduce (S2R), can help developers localize and fix bugs efficiently. However, due to the increasing complexity of some bugs and the limited experience of some reporters, large numbers of bug reports miss this crucial information. Although machine learning (ML)-based and information retrieval (IR)-based approaches are proposed to detect and supplement the missing information in bug reports, the performance of these approaches depends heavily on the size and quality of bug report datasets.In this paper, we present ChatBR, an approach for automated assessment and improvement of bug report quality using ChatGPT. First, we fine-tune a BERT model using manually annotated bug reports to create a sentence-level multi-label classifier to assess the quality of bug reports by detecting whether existing OB, EB, and S2R. Then, we use ChatGPT in a zero-shot setup to generate missing information (OB, EB, and S2R) to improve the quality of bug reports. Finally, the output of ChatGPT are fed back into the classifier for verification until ChatGPT generates the missing information. Experimental results show that, in the task of detecting missing information in bug reports, ChatBR outperforms the state-of-the-art methods by 25.38\%-29.20\% in terms of precision. In the task of generating missing information in bug reports, ChatBR can achieve an average of 84.10\% in terms of semantic similarity of the generated information and original information across six different projects. Furthermore, ChatBR can generate more than 99.9\% of high-quality bug reports (i.e., bug reports that are full of OB, EB, and S2R) within five queries to ChatGPT.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1472–1483},
numpages = {12},
keywords = {bug report, ChatGPT, pre-trained models, large language models},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695524,
author = {Zhu, Ming and Karim, Mohimenul and Lourentzou, Ismini and Yao, Daphne},
title = {Semi-Supervised Code Translation Overcoming the Scarcity of Parallel Code Data},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695524},
doi = {10.1145/3691620.3695524},
abstract = {Neural code translation is the task of converting source code from one programming language to another. One of the main challenges is the scarcity of parallel code data, which hinders the ability of translation models to learn accurate cross-language alignments. In this paper, we introduce MIRACLE, a semi-supervised approach that improves code translation through synthesizing high-quality parallel code data and curriculum learning on code data with ascending alignment levels. MIRACLE leverages static analysis and compilation to generate synthetic parallel code datasets with enhanced quality and alignment to address the challenge of data scarcity. We evaluate the proposed method along with strong baselines including instruction-tuned Large Language Models (LLMs) for code. Our analysis reveals that LLMs pre-trained on open-source code data, regardless of their size, suffer from the "shallow translation" problem. This issue arises when translated code copies keywords, statements, and even code blocks from the source language, leading to compilation and runtime errors. Extensive experiments demonstrate that our method significantly mitigates this issue, enhancing code translation performance across multiple models in C++, Java, Python, and C. Remarkably, MIRACLE outperforms code LLMs that are ten times larger in size. MIRACLE also achieves up to a 43\% improvement in C code translation with fewer than 150 annotated examples.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1545–1556},
numpages = {12},
keywords = {neural code translation, cross-language code alignment, semi-supervised learning, curriculum learning, static analysis},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695529,
author = {Yang, Lin and Yang, Chen and Gao, Shutao and Wang, Weijing and Wang, Bo and Zhu, Qihao and Chu, Xiao and Zhou, Jianyi and Liang, Guangtai and Wang, Qianxiang and Chen, Junjie},
title = {On the Evaluation of Large Language Models in Unit Test Generation},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695529},
doi = {10.1145/3691620.3695529},
abstract = {Unit testing is an essential activity in software development for verifying the correctness of software components. However, manually writing unit tests is challenging and time-consuming. The emergence of Large Language Models (LLMs) offers a new direction for automating unit test generation. Existing research primarily focuses on closed-source LLMs (e.g., ChatGPT and CodeX) with fixed prompting strategies, leaving the capabilities of advanced open-source LLMs with various prompting settings unexplored. Particularly, open-source LLMs offer advantages in data privacy protection and have demonstrated superior performance in some tasks. Moreover, effective prompting is crucial for maximizing LLMs' capabilities. In this paper, we conduct the first empirical study to fill this gap, based on 17 Java projects, five widely-used open-source LLMs with different structures and parameter sizes, and comprehensive evaluation metrics. Our findings highlight the significant influence of various prompt factors, show the performance of open-source LLMs compared to the commercial GPT-4 and the traditional Evosuite, and identify limitations in LLM-based unit test generation. We then derive a series of implications from our study to guide future research and practical use of LLM-based unit test generation.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1607–1619},
numpages = {13},
keywords = {large language model, unit test generation, empirical study},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695531,
author = {Zhou, Zhuotong and Yang, Yongzhuo and Wu, Susheng and Huang, Yiheng and Chen, Bihuan and Peng, Xin},
title = {Magneto: A Step-Wise Approach to Exploit Vulnerabilities in Dependent Libraries via LLM-Empowered Directed Fuzzing},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695531},
doi = {10.1145/3691620.3695531},
abstract = {The wide adoption of open source third-party libraries can propagate vulnerabilities that originally exist in third-party libraries through dependency chains to downstream projects. To mitigate this security risk, vulnerability exploitation analysis has been proposed to further reduce false positives of vulnerability reachability analysis. However, existing approaches work less effectively when the vulnerable function of the vulnerable library is indirectly invoked by a client project through a call chain of multiple steps.To address this problem, we propose a step-wise approach, named Magneto, to exploit vulnerabilities in dependent libraries of a client project through LLM-empowered directed fuzzing. Its core idea is to decompose the directed fuzzing for the whole call chain (from the client project to the vulnerable function) into a series of step-wise directed fuzzing for each step of the call chain. To empower directed fuzzing, it leverages LLM to facilitate the initial seed generation. Our evaluation has demonstrated the effectiveness of Magneto over the state-of-the-art; i.e., Magneto achieves an improvement of at least 75.6\% in successfully exploiting the vulnerability.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1633–1644},
numpages = {12},
keywords = {library vulnerabilities, exploit generation, directed fuzzing},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695552,
author = {Feng, Jia and Liu, Jiachen and Gao, Cuiyun and Chong, Chun Yong and Wang, Chaozheng and Gao, Shan and Xia, Xin},
title = {ComplexCodeEval: A Benchmark for Evaluating Large Code Models on More Complex Code},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695552},
doi = {10.1145/3691620.3695552},
abstract = {In recent years, with the widespread attention of academia and industry on the application of large language models (LLMs) to code-related tasks, an increasing number of large code models (LCMs) have been proposed and corresponding evaluation benchmarks have continually emerged. Although existing evaluation benchmarks are helpful for comparing different LCMs, they may not reflect the performance of LCMs in various development scenarios. Specifically, they might evaluate model performance in only one type of scenario (e.g., code generation or code completion), whereas real development contexts are diverse and may involve multiple tasks such as code generation, code completion, API recommendation, and test function generation. Additionally, the questions may not originate from actual development practices, failing to capture the programming challenges faced by developers during the development process.To address the aforementioned issues, we propose Complex-CodeEval, a new benchmark for evaluating the performance of LCMs in various development scenarios. ComplexCodeEval includes 3,897 Java samples from 1,055 high-star GitHub repositories and 7,184 Python samples from 2,107 high-star repositories. Each function sample in ComplexCodeEval contains multiple annotations (e.g., function signatures, docstrings and reference APIs) to accommodate various downstream tasks. Furthermore, to better reflect diverse development scenarios, each function sample is required to originate from a repository that depends on at least one selected library (based on popularity), and each function sample must invoke at least one API from the selected library. Additionally, each function sample has multiple timestamps to avoid data leakage. Based on ComplexCodeEval, we evaluate the performance of ten LCMs across four tasks (i.e., code generation, code completion, API recommendation, and test case generation) to explore their performance in complex development environments. Furthermore, we conduct an in-depth analysis of the impact of context and data leakage on model performance. Our experimental results reveal several key findings. For instance, LCMs exhibit varying performance across different coding tasks. Additionally, rich contextual information can greatly enhance the performance of LCMs. Moreover, using leaked data for evaluation may lead to an overestimation of model performance, resulting in inaccurate evaluation outcomes that deviate from the performance in practice.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1895–1906},
numpages = {12},
keywords = {large language models, code intelligence, benchmark},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695555,
author = {Zhang, Jian and Wang, Chong and Li, Anran and Wang, Wenhan and Li, Tianlin and Liu, Yang},
title = {VulAdvisor: Natural Language Suggestion Generation for Software Vulnerability Repair},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695555},
doi = {10.1145/3691620.3695555},
abstract = {Software vulnerabilities pose serious threats to the security of modern software systems. Deep Learning-based Automated Vulnerability Repair (AVR) has gained attention as a potential solution to accelerate the remediation of vulnerabilities. However, recent studies indicate that existing AVR approaches often only generate patches, which may not align with developers' current repair practices or expectations. In this paper, we introduce VulAdvisor, an automated approach that generates natural language suggestions to guide developers or AVR tools in repairing vulnerabilities. VulAdvisor comprises two main components: oracle extraction and suggestion learning. To address the challenge of limited historical data, we propose an oracle extraction method facilitating ChatGPT to construct a comprehensive and high-quality dataset. For suggestion learning, we take the supervised fine-tuning CodeT5 model as the basis, integrating local context into Multi-Head Attention and introducing a repair action loss, to improve the relevance and meaningfulness of the generated suggestions. Extensive experiments on a large-scale dataset from real-world C/C++ projects demonstrate the effectiveness of VulAdvisor, surpassing several alternatives in terms of both lexical and semantic metrics. Moreover, we show that the generated suggestions enhance the patch generation capabilities of existing AVR tools. Human evaluations further validate the quality and utility of VulAdvisor's suggestions, confirming their potential to improve software vulnerability repair practices.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1932–1944},
numpages = {13},
keywords = {vulnerability repair, large language models, suggestion generation, program repair},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695591,
author = {Wei, Jialiang and Courbis, Anne-Lise and Lambolais, Thomas and Xu, Binbin and Bernard, Pierre Louis and Dray, Gerard and Maalej, Walid},
title = {Getting Inspiration for Feature Elicitation: App Store- vs. LLM-based Approach},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695591},
doi = {10.1145/3691620.3695591},
abstract = {Over the past decade, app store (AppStore)-inspired requirements elicitation has proven to be highly beneficial. Developers often explore competitors' apps to gather inspiration for new features. With the advance of Generative AI, recent studies have demonstrated the potential of large language model (LLM)-inspired requirements elicitation. LLMs can assist in this process by providing inspiration for new feature ideas. While both approaches are gaining popularity in practice, there is a lack of insight into their differences. We report on a comparative study between AppStore- and LLM-based approaches for refining features into sub-features. By manually analyzing 1,200 sub-features recommended from both approaches, we identified their benefits, challenges, and key differences. While both approaches recommend highly relevant sub-features with clear descriptions, LLMs seem more powerful particularly concerning novel unseen app scopes. Moreover, some recommended features are imaginary with unclear feasibility, which suggests the importance of a human-analyst in the elicitation loop.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {857–869},
numpages = {13},
keywords = {requirements elicitation, app store mining, large language models, data-centered requirements engineering, creativity in SE},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691620.3695602,
author = {Kim, YoungJae and Park, Yechan and Han, Seungheon and Yi, Jooyong},
title = {Enhancing the Efficiency of Automated Program Repair via Greybox Analysis},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695602},
doi = {10.1145/3691620.3695602},
abstract = {In this paper, we pay attention to the efficiency of automated program repair (APR). Recently, an efficient patch scheduling algorithm, Casino, has been proposed to improve APR efficiency. Inspired by fuzzing, Casino adaptively chooses the next patch candidate to evaluate based on the results of previous evaluations. However, we observe that Casino utilizes only the test results, treating the patched program as a black box. Inspired by greybox fuzzing, we propose a novel patch-scheduling algorithm, Gresino, which leverages the internal state of the program to further enhance APR efficiency. Specifically, Gresino monitors the hit counts of branches observed during the execution of the program and uses them to guide the search for a valid patch. Our experimental evaluation on the Defects4J benchmark and eight APR tools demonstrates the efficacy of our approach.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1719–1731},
numpages = {13},
keywords = {automated program repair, patch scheduling, greybox analysis},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3691621.3694951,
author = {Alam, Khubaib Amjad and Ali, Ramsha and Kamran, Zyena and Fatima, Sabeen},
title = {Leveraging Data-Driven Analytics for Mobile App Feature Extraction and Recommendations},
year = {2024},
isbn = {9798400712494},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691621.3694951},
doi = {10.1145/3691621.3694951},
abstract = {Mobile app development necessitates extracting domain-specific, essential, and innovative features, aligning with user needs and market dynamics. However, identifying features to provide competitive edge to the app developers, is a non-trivial task often performed manually by product managers. This study addresses the challenge of mining and recommending app features by automatically identifying similar apps corresponding to the description of apps provided by the user. The proposed approach integrates Named Entity Recognition (NER) for feature extraction and BERT (Bidirectional Encoder Representations from Transformers) coupled with Topic Modeling for identifying similar apps. Our top-performing model, utilizing NMF for Topic Modeling with Sentence-BERT embeddings, achieves an F1 score of 87.38\%, demonstrating its effectiveness in accurately identifying similar apps. Our contributions include compiling a dataset of 219 apps and 43800 user reviews to support research and development in feature recommendation. We have also developed an automated tool integrating NER for feature extraction and BERT-based similarity analysis. Through rigorous evaluation, we demonstrate significant performance improvements compared to existing solutions.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering Workshops},
pages = {197–207},
numpages = {11},
keywords = {app review analytics, natural language processing, knowledge extraction, NER language models, BERT, LDA},
location = {Sacramento, CA, USA},
series = {ASEW '24}
}

@inproceedings{10.1145/3691621.3694952,
author = {Wu, Liangxuan and Zhao, Yanjie and Wang, Chao and Liu, Tianming and Wang, Haoyu},
title = {A First Look at LLM-powered Smartphones},
year = {2024},
isbn = {9798400712494},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691621.3694952},
doi = {10.1145/3691621.3694952},
abstract = {The integration of Large Language Models (LLMs) into edge devices such as smartphones represents a significant leap in mobile technology, promising enhanced user experiences and novel functionalities. This paper presents a first look at LLM-powered smartphones, addressing four key aspects: the current market landscape, core functions enabled by integrated LLMs, potential security risks, and user perceptions. The findings reveal a rapidly evolving market with major manufacturers competing to integrate LLMs, innovative features that improve user interaction, significant security challenges, and mixed user perceptions that balance enthusiasm for new capabilities with privacy concerns. This study contributes to understanding LLM integration in mobile devices and its implications for users, manufacturers, and the broader technological landscape.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering Workshops},
pages = {208–217},
numpages = {10},
location = {Sacramento, CA, USA},
series = {ASEW '24}
}

@article{10.1145/3691626,
author = {Liu, Aiwei and Pan, Leyi and Lu, Yijian and Li, Jingjing and Hu, Xuming and Zhang, Xi and Wen, Lijie and King, Irwin and Xiong, Hui and Yu, Philip},
title = {A Survey of Text Watermarking in the Era of Large Language Models},
year = {2024},
issue_date = {February 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3691626},
doi = {10.1145/3691626},
abstract = {Text watermarking algorithms are crucial for protecting the copyright of textual content. Historically, their capabilities and application scenarios were limited. However, recent advancements in large language models (LLMs) have revolutionized these techniques. LLMs not only enhance text watermarking algorithms with their advanced abilities but also create a need for employing these algorithms to protect their own copyrights or prevent potential misuse. This work conducts a comprehensive survey of the current state of text watermarking technology, covering four main aspects: (1) an overview and comparison of different text watermarking techniques; (2) evaluation methods for text watermarking algorithms, including their detectability, impact on text or LLM quality, and robustness under target or untargeted attacks; (3) potential application scenarios for text watermarking technology; and (4) current challenges and future directions for text watermarking. This survey aims to provide researchers with a thorough understanding of text watermarking technology in the era of LLMs, thereby promoting its further advancement.},
journal = {ACM Comput. Surv.},
month = nov,
articleno = {47},
numpages = {36},
keywords = {Text watermark, large language models, copyright protection}
}

@inproceedings{10.1145/3694715.3695952,
author = {Lattuada, Andrea and Hance, Travis and Bosamiya, Jay and Brun, Matthias and Cho, Chanhee and LeBlanc, Hayley and Srinivasan, Pranav and Achermann, Reto and Chajed, Tej and Hawblitzel, Chris and Howell, Jon and Lorch, Jacob R. and Padon, Oded and Parno, Bryan},
title = {Verus: A Practical Foundation for Systems Verification},
year = {2024},
isbn = {9798400712517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3694715.3695952},
doi = {10.1145/3694715.3695952},
abstract = {Formal verification is a promising approach to eliminate bugs at compile time, before they ship. Indeed, our community has verified a wide variety of system software. However, much of this success has required heroic developer effort, relied on bespoke logics for individual domains, or sacrificed expressiveness for powerful proof automation.Building on prior work on Verus, we aim to enable faster, cheaper verification of rich properties for realistic systems. We do so by integrating and optimizing the best choices from prior systems, tuning our design to overcome barriers encountered in those systems, and introducing novel techniques.We evaluate Verus's effectiveness with a wide variety of case-study systems, including distributed systems, an OS page table, a library for NUMA-aware concurrent data structure replication, a crash-safe storage system, and a concurrent memory allocator, together comprising 6.1K lines of implementation and 31K lines of proof. Verus verifies code 3--61\texttimes{} faster and with less effort than the state of the art.Our results suggest that Verus offers a platform for exploring the next frontiers in system-verification research. Because Verus builds on Rust, Verus is also positioned for wider use in production by developers who have already adopted Rust in the pursuit of more robust systems.},
booktitle = {Proceedings of the ACM SIGOPS 30th Symposium on Operating Systems Principles},
pages = {438–454},
numpages = {17},
location = {Austin, TX, USA},
series = {SOSP '24}
}

@inproceedings{10.1145/3694715.3695963,
author = {Dai, Yinwei and Pan, Rui and Iyer, Anand and Li, Kai and Netravali, Ravi},
title = {Apparate: Rethinking Early Exits to Tame Latency-Throughput Tensions in ML Serving},
year = {2024},
isbn = {9798400712517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3694715.3695963},
doi = {10.1145/3694715.3695963},
abstract = {Machine learning (ML) inference platforms are tasked with balancing two competing goals: ensuring high throughput given many requests, and delivering low-latency responses to support interactive applications. Unfortunately, existing platform knobs (e.g., batch sizes) fail to ease this fundamental tension, and instead only enable users to harshly trade off one property for the other. This paper explores an alternate strategy to taming throughput-latency tradeoffs by changing the granularity at which inference is performed. We present Apparate, a system that automatically applies and manages early exits (EEs) in ML models, whereby certain inputs can exit with results at intermediate layers. To cope with the time-varying overhead and accuracy challenges that EEs bring, Apparate repurposes exits to provide continual feedback that powers several novel runtime monitoring and adaptation strategies. Apparate lowers median response latencies by 40.5--91.5\% and 10.0--24.2\% for diverse CV and NLP classification workloads, and median time-per-token latencies by 22.6--77.9\% for generative scenarios, without affecting throughputs or violating tight accuracy constraints.},
booktitle = {Proceedings of the ACM SIGOPS 30th Symposium on Operating Systems Principles},
pages = {607–623},
numpages = {17},
location = {Austin, TX, USA},
series = {SOSP '24}
}

@inproceedings{10.1145/3694715.3695974,
author = {Qiu, Yiming and Kon, Patrick Tser Jern and Beckett, Ryan and Chen, Ang},
title = {Unearthing Semantic Checks for Cloud Infrastructure-as-Code Programs},
year = {2024},
isbn = {9798400712517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3694715.3695974},
doi = {10.1145/3694715.3695974},
abstract = {Cloud infrastructures are increasingly managed by Infrastructure-as-Code (IaC) frameworks (e.g., Terraform). IaC frameworks enable cloud users to configure their resources in a declarative manner, without having to directly work with low-level cloud API calls. However, with today's IaC tooling, IaC programs that pass the compilation phase may still incur errors at deployment time, resulting in significant disruption. We observe that this stems from a fundamental semantic gap between IaC-level programs and cloud-level requirements---even a syntactically-correct IaC program may violate cloud-level expectations. To bridge this gap, we develop Zodiac, a tool that can unearth IaC-level semantic checks on cloud-level requirements. It provides an automated pipeline to mine these checks from online IaC repositories and validate them using deployment-based testing. We have applied Zodiac to Terraform resources offered by Microsoft Azure---a leading IaC framework and a leading cloud vendor---where it found 500+ semantic checks where violation would produce deployment failures. With these checks, we have identified 200+ buggy Terraform projects and helped fix errors within official Azure provider usage examples.},
booktitle = {Proceedings of the ACM SIGOPS 30th Symposium on Operating Systems Principles},
pages = {574–589},
numpages = {16},
keywords = {infrastructure as code, cloud management, program analysis, configuration mining},
location = {Austin, TX, USA},
series = {SOSP '24}
}

@proceedings{10.1145/3694811,
title = {GNNet '24: Proceedings of the 3rd GNNet Workshop on Graph Neural Networking Workshop},
year = {2024},
isbn = {9798400712548},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the Third International Workshop on Graph Neural Networking - GNNet 2024, co-located with ACM CoNEXT 2024.Graphs are emerging as an abstraction to represent complex data. Computer Networks are fundamentally graphs, and many of their relevant characteristics - such as topology and routing - are represented as graph-structured data. Machine learning, especially deep representation learning on graphs, is an emerging field with a wide array of applications. Within this field, Graph Neural Networks (GNNs) have been recently proposed to model and learn over graph-structured data. Due to their unique ability to generalize over graph data, GNNs are a central tool to apply AI/ML techniques to networking applications.The GNNet workshop continues its tradition of providing the first dedicated venue to present and discuss the latest advancements on the emerging topic of GNNs applied to computer networking problems. GNNet brings together leaders from academia and industry to showcase recent methodological advances of GNNs and their application to computer networks, covering a wide range of applications and practical challenges for training and deployment. The GNNet workshop serves as the meeting point for the growing community on this fascinating domain, which previously did not have a specific forum for sharing ideas and discussion.The third edition of the GNNet workshop is co-located with ACM CoNEXT 2024 and held in Los Angeles, CA, USA, in December 2024. The GNNet 2024 technical program consists of 9 quality papers. The TPC was composed of 21 well-recognized researchers and practitioners in the areas of GNN and AI/ML applied to computer networks.},
location = {Los Angeles, CA, USA}
}

@proceedings{10.1145/3695794,
title = {MEMSYS '24: Proceedings of the International Symposium on Memory Systems},
year = {2024},
isbn = {9798400710919},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@article{10.1145/3695993,
author = {Yu, Yongda and Rong, Guoping and Shen, Haifeng and Zhang, He and Shao, Dong and Wang, Min and Wei, Zhao and Xu, Yong and Wang, Juhong},
title = {Fine-Tuning Large Language Models to Improve Accuracy and Comprehensibility of Automated Code Review},
year = {2024},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3695993},
doi = {10.1145/3695993},
abstract = {As code review is a tedious and costly software quality practice, researchers have proposed several machine learning-based methods to automate the process. The primary focus has been on accuracy, that is, how accurately the algorithms are able to detect issues in the code under review. However, human intervention still remains inevitable since results produced by automated code review are not 100\% correct. To assist human reviewers in making their final decisions on automatically generated review comments, the comprehensibility of the comments underpinned by accurate localization and relevant explanations for the detected issues with repair suggestions is paramount. However, this has largely been neglected in the existing research. Large language models (LLMs) have the potential to generate code review comments that are more readable and comprehensible by humans, thanks to their remarkable processing and reasoning capabilities. However, even mainstream LLMs perform poorly in detecting the presence of code issues because they have not been specifically trained for this binary classification task required in code review. In this article, we contribute Comprehensibility of Automated Code Review using Large Language Models (Carllm), a novel fine-tuned LLM that has the ability to improve not only the accuracy but, more importantly, the comprehensibility of automated code review, as compared to state-of-the-art pre-trained models and general LLMs.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
articleno = {14},
numpages = {26},
keywords = {Automated Code Review, Human-machine Collaboration, LLM, LORA}
}

@proceedings{10.1145/3696230,
title = {ICDTE '24: Proceedings of the 2024 8th International Conference on Digital Technology in Education (ICDTE)},
year = {2024},
isbn = {9798400717574},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3696271,
title = {MLMI '24: Proceedings of the 2024 7th International Conference on Machine Learning and Machine Intelligence (MLMI)},
year = {2024},
isbn = {9798400717833},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3696348,
title = {HotNets '24: Proceedings of the 23rd ACM Workshop on Hot Topics in Networks},
year = {2024},
isbn = {9798400712722},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Irvine, CA, USA}
}

@inproceedings{10.1145/3696348.3696868,
author = {He, Zhiyuan and Gottipati, Aashish and Qiu, Lili and Luo, Xufang and Xu, Kenuo and Yang, Yuqing and Yan, Francis Y.},
title = {Designing Network Algorithms via Large Language Models},
year = {2024},
isbn = {9798400712722},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696348.3696868},
doi = {10.1145/3696348.3696868},
abstract = {We introduce Nada, the first framework to autonomously design network algorithms by leveraging the generative capabilities of large language models (LLMs). Starting with an existing algorithm implementation, Nada enables LLMs to create a wide variety of alternative designs in the form of code blocks. It then efficiently identifies the top-performing designs through a series of filtering techniques, minimizing the need for full-scale evaluations and significantly reducing computational costs. Using adaptive bitrate (ABR) streaming as a case study, we demonstrate that Nada produces novel ABR algorithms---previously unknown to human developers---that consistently outperform the original algorithm in diverse network environments, including broadband, satellite, 4G, and 5G.},
booktitle = {Proceedings of the 23rd ACM Workshop on Hot Topics in Networks},
pages = {205–212},
numpages = {8},
keywords = {Large Language Models, Network Algorithms},
location = {Irvine, CA, USA},
series = {HotNets '24}
}

@article{10.1145/3696407,
author = {C\"{u}ppers, Joscha and Schoen, Adrien and Blanc, Gregory and Gimenez, Pierre-Francois},
title = {FlowChronicle: Synthetic Network Flow Generation through Pattern Set Mining},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {CoNEXT4},
url = {https://doi.org/10.1145/3696407},
doi = {10.1145/3696407},
abstract = {Network traffic datasets are regularly criticized, notably for the lack of realism and diversity in their attack or benign traffic. Generating synthetic network traffic using generative machine learning techniques is a recent area of research that could complement experimental test beds and help assess the efficiency of network security tools such as network intrusion detection systems. Most methods generating synthetic network flows disregard the temporal dependencies between them, leading to unrealistic traffic. To address this issue, we introduce FlowChronicle, a novel synthetic network flow generation tool from mined patterns and Bayesian networks. As a core component, we propose a novel pattern miner in combination with statistical models to preserve temporal dependencies. We empirically compare our method against state-of-the-art techniques on several criteria, namely realism, diversity, compliance, and novelty. This evaluation demonstrates the capability of FlowChronicle to achieve high-quality generation while significantly outperforming the other methods in preserving temporal dependencies between flows. Besides, in contrast to deep learning methods, the patterns identified by FlowChronicle are explainable, and experts can verify their soundness. Our work substantially advances synthetic network traffic generation, offering a method that enhances both the utility and trustworthiness of the generated network flows.},
journal = {Proc. ACM Netw.},
month = nov,
articleno = {26},
numpages = {20},
keywords = {minimum description length, network simulation, network traffic, pattern mining, synthetic data generation}
}

@proceedings{10.1145/3696409,
title = {MMAsia '24: Proceedings of the 6th ACM International Conference on Multimedia in Asia},
year = {2024},
isbn = {9798400712739},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3696443,
title = {CGO '25: Proceedings of the 23rd ACM/IEEE International Symposium on Code Generation and Optimization},
year = {2025},
isbn = {9798400712753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 23nd ACM/IEEE International Symposium on Code Generation and Optimization (CGO ’25), where we invite you to fabulous Las Vegas.},
location = {Las Vegas, NV, USA}
}

@inproceedings{10.1145/3696443.3708929,
author = {Taneja, Jubi and Laird, Avery and Yan, Cong and Musuvathi, Madan and Lahiri, Shuvendu K.},
title = {LLM-Vectorizer: LLM-Based Verified Loop Vectorizer},
year = {2025},
isbn = {9798400712753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696443.3708929},
doi = {10.1145/3696443.3708929},
abstract = {Vectorization is a powerful optimization technique that significantly boosts the performance of high performance computing applications operating on large data arrays. Despite decades of research on auto-vectorization, compilers frequently miss opportunities to vectorize code. On the other hand, writing vectorized code manually using compiler intrinsics is still a complex, error-prone task that demands deep knowledge of specific architecture and compilers.  In this paper, we evaluate the potential of large-language models (LLMs) to generate vectorized (Single Instruction Multiple Data) code from scalar programs that process individual array elements.   We propose a novel finite-state-machine multi-agents based approach that harnesses LLMs and test-based feedback to generate vectorized code.  Our findings indicate that LLMs are capable of producing high-performance vectorized code with run-time speedup ranging from 1.1x to 9.4x as compared to the state-of-the-art compilers such as Intel Compiler, GCC, and Clang.  To verify the correctness of vectorized code, we use Alive2, a leading bounded translation validation tool for LLVM IR. We describe a few domain-specific techniques to improve the scalability of Alive2 on our benchmark dataset. Overall, our approach is able to verify 38.2\% of vectorizations as correct on the TSVC benchmark dataset.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Symposium on Code Generation and Optimization},
pages = {137–149},
numpages = {13},
keywords = {AI Agents, Large language model, Loop Vectorization, Translation Validation},
location = {Las Vegas, NV, USA},
series = {CGO '25}
}

@inproceedings{10.1145/3696443.3708943,
author = {He, Guoliang and Yoneki, Eiko},
title = {CuAsmRL: Optimizing GPU SASS Schedules via Deep Reinforcement Learning},
year = {2025},
isbn = {9798400712753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696443.3708943},
doi = {10.1145/3696443.3708943},
abstract = {Large language models (LLMs) are remarked by their substantial computational requirements. To mitigate the cost, researchers develop specialized CUDA kernels, which often fuse several tensor operations to maximize the utilization of GPUs as much as possible. However, those specialized kernels may still leave performance on the table as CUDA assembly experts show that manual optimization of GPU SASS schedules can lead to better performance, and trial-and-error is largely employed to manually find the best GPU SASS schedules. In this work, we employ an automatic approach to optimize GPU SASS schedules, which thus can be integrated into existing compiler frameworks. The key to automatic optimization is training an RL agent to mimic how human experts perform manual scheduling. To this end, we formulate an assembly game, where RL agents can play to find the best GPU SASS schedules. The assembly game starts from a -O3 optimized SASS schedule, and the RL agents can iteratively apply actions to mutate the current schedules. Positive rewards are generated if the mutated schedules get higher throughput by executing on GPUs. Experiments show that CuAsmRL can further improve the performance of existing specialized CUDA kernels transparently by up to 26\%, and on average 9\%. Moreover, it is used as a tool to reveal potential optimization moves learned automatically},
booktitle = {Proceedings of the 23rd ACM/IEEE International Symposium on Code Generation and Optimization},
pages = {493–506},
numpages = {14},
keywords = {GPU Instruction Scheduling, Reinforcement Learning},
location = {Las Vegas, NV, USA},
series = {CGO '25}
}

@inproceedings{10.1145/3696443.3708954,
author = {Ullrich, Marcel and Hack, Sebastian},
title = {Synthesis of Sorting Kernels},
year = {2025},
isbn = {9798400712753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696443.3708954},
doi = {10.1145/3696443.3708954},
abstract = {Recently, AlphaDev has shown significant advances in the synthesis of branchless sorting kernels for arrays of lengths&nbsp;3 to&nbsp;5.                In this paper, we propose an enumerative search technique based on A* search and present novel optimality-pre­serving heuristics and non-optimality-preserving cuts for sorting kernel synthesis. Our algorithm outperforms AlphaDev in synthesis time by two orders of magnitude ran on a standard notebook instead of a TPU cluster.                Because our algorithm can explore the solution space, we are able to enumerate all correct sorting kernels for length&nbsp;3 and simply select the best-performing one.                For larger array lengths, we intelligently sample the solution space and find a sorting kernel that outperforms the state-of-the-art.                Furthermore, we establish a new tight lower bound for the shortest sorting kernel for length&nbsp;4.                Finally, we provide a comprehensive comparison against several other existing synthesis techniques and show that none of them is able to synthesize sorting kernels for arrays longer than&nbsp;3.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Symposium on Code Generation and Optimization},
pages = {1–14},
numpages = {14},
keywords = {instruction-level optimizations, sorting kernels, super optimization, synthesis},
location = {Las Vegas, NV, USA},
series = {CGO '25}
}

@article{10.1145/3696457,
author = {Fabris, Alessandro and Baranowska, Nina and Dennis, Matthew J. and Graus, David and Hacker, Philipp and Saldivar, Jorge and Zuiderveen Borgesius, Frederik and Biega, Asia J.},
title = {Fairness and Bias in Algorithmic Hiring: A Multidisciplinary Survey},
year = {2025},
issue_date = {February 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {2157-6904},
url = {https://doi.org/10.1145/3696457},
doi = {10.1145/3696457},
abstract = {Employers are adopting algorithmic hiring technology throughout the recruitment pipeline. Algorithmic fairness is especially applicable in this domain due to its high stakes and structural inequalities. Unfortunately, most work in this space provides partial treatment, often constrained by two competing narratives, optimistically focused on replacing biased recruiter decisions or pessimistically pointing to the automation of discrimination. Whether, and more importantly what types of, algorithmic hiring can be less biased and more beneficial to society than low-tech alternatives currently remains unanswered, to the detriment of trustworthiness. This multidisciplinary survey caters to practitioners and researchers with a balanced and integrated coverage of systems, biases, measures, mitigation strategies, datasets, and legal aspects of algorithmic hiring and fairness. Our work supports a contextualized understanding and governance of this technology by highlighting current opportunities and limitations, providing recommendations for future work to ensure shared benefits for all stakeholders.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = jan,
articleno = {16},
numpages = {54},
keywords = {Algorithmic hiring, Online recruitment, Algorithmic fairness, Bias, Anti-discrimination}
}

@proceedings{10.1145/3696474,
title = {JCRAI '24: Proceedings of the 2024 4th International Joint Conference on Robotics and Artificial Intelligence},
year = {2024},
isbn = {9798400710100},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3696762,
title = {ISS Companion '24: Companion Proceedings of the 2024 Conference on Interactive Surfaces and Spaces},
year = {2024},
isbn = {9798400712784},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Vancouver, BC, Canada}
}

@proceedings{10.1145/3696843,
title = {HASP '24: Proceedings of the International Workshop on Hardware and Architectural Support for Security and Privacy 2024},
year = {2024},
isbn = {9798400712210},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3696952,
title = {ICIIP '24: Proceedings of the 2024 9th International Conference on Intelligent Information Processing},
year = {2024},
isbn = {9798400718076},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3697090,
title = {LADC '24: Proceedings of the 13th Latin-American Symposium on Dependable and Secure Computing},
year = {2024},
isbn = {9798400717406},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3697294,
title = {CVMP '24: Proceedings of 21st ACM SIGGRAPH Conference on Visual Media Production},
year = {2024},
isbn = {9798400712814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {London, United Kingdom}
}

@inproceedings{10.1145/3697294.3697299,
author = {Gu, Kai and Maugey, Thomas and Sebastian, Knorr and Guillemot, Christine},
title = {RegSegField: Mask-Regularization and Hierarchical Segmentation for Novel View Synthesis from Sparse Inputs},
year = {2024},
isbn = {9798400712814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3697294.3697299},
doi = {10.1145/3697294.3697299},
abstract = {Radiance Field (RF) representations and their latest variant, 3D-Gaussian Splatting (3D-GS), have revolutionized the field of 3D vision. Novel View Synthesis (NVS) from RF typically requires dense inputs, and for 3D-GS in particular, a high-quality point cloud from a multi-view stereo model is usually necessary. Sparse input RFs are commonly regularized by various priors, such as smoothness, depth, and appearance. Meanwhile, 3D scene segmentation has also achieved significant results with the aid of RFs, and combining the field with different semantic and physical attributes has become a trend. To further tackle NVS and 3D segmentation problems under sparse-input conditions, we introduce RegSegField, a novel pipeline to utilize 2D segmentations to aid the reconstruction of objects and parts. This method introduces a novel mask-visibility loss by matching 2D segments across different views, thus defining the 3D regions for different objects. To further optimize the correspondence of 2D segments, we introduce a hierarchical feature field supervised by a contrastive learning method, allowing iterative updates of matched mask areas. To resolve the inconsistent segmentation across different views and refine the mask matching with the help of RF geometry, we also employed a multi-level hierarchy loss. With the help of the hierarchy loss, our method facilitates scene segmentation at discrete granularity levels, whereas other methods require sampling at different scales or determining similarity thresholds. Our experiments show that our regularization approach outperforms various depth-guided NeRF methods and even enables sparse reconstruction of 3D-GS with random initialization.},
booktitle = {Proceedings of 21st ACM SIGGRAPH Conference on Visual Media Production},
articleno = {3},
numpages = {10},
keywords = {(neural) radiance field, Gaussian splatting, View synthesis, deep learning, light field, regularization.},
location = {London, United Kingdom},
series = {CVMP '24}
}

@proceedings{10.1145/3697355,
title = {BDIOT '24: Proceedings of the 2024 8th International Conference on Big Data and Internet of Things},
year = {2024},
isbn = {9798400717529},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3697467,
title = {IoTML '24: Proceedings of the 2024 4th  International Conference on Internet of Things and Machine Learning},
year = {2024},
isbn = {9798400710353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3698038,
title = {SoCC '24: Proceedings of the 2024 ACM Symposium on Cloud Computing},
year = {2024},
isbn = {9798400712869},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Redmond, WA, USA}
}

@inproceedings{10.1145/3698038.3698548,
author = {Zhao, Xiaoyang and Yang, Siran and Wang, Jiamang and Diao, Lansong and Qu, Lin and Wu, Chuan},
title = {FaPES: Enabling Efficient Elastic Scaling for Serverless Machine Learning Platforms},
year = {2024},
isbn = {9798400712869},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698038.3698548},
doi = {10.1145/3698038.3698548},
abstract = {Serverless computing platforms have become increasingly popular for running machine learning (ML) tasks due to their user-friendliness and decoupling from underlying infrastructure. However, auto-scaling to efficiently serve incoming requests still remains a challenge, especially for distributed ML training or inference jobs in a serverless GPU cluster. Distributed training and inference jobs are highly sensitive to resource configurations, and demand high model efficiency throughout their lifecycle. We propose FaPES, a FaaS-oriented Performance-aware Elastic Scaling system to enable efficient resource allocation in serverless platforms for ML jobs. FaPES enables flexible resource loaning between virtual clusters for running training and inference jobs. For running inference jobs, servers are reclaimed on demand with minimal preemption overhead to guarantee service level objective (SLO); for training jobs, optimal GPU allocation and model hyperparameters are jointly adapted based on an ML-based performance model and a resource usage prediction board, alleviating users from model tuning and resource specification. Evaluation on a 128-GPU testbed demonstrates up to 24.8\% job completion time reduction and \texttimes{}1.8 Goodput improvement, as compared to representative elastic scaling schemes.},
booktitle = {Proceedings of the 2024 ACM Symposium on Cloud Computing},
pages = {443–459},
numpages = {17},
keywords = {Cluster Scheduling, Distributed System},
location = {Redmond, WA, USA},
series = {SoCC '24}
}

@proceedings{10.1145/3698062,
title = {WSSE '24: Proceedings of the 2024 The 6th World Symposium on Software Engineering (WSSE)},
year = {2024},
isbn = {9798400717086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3698300,
title = {ICBDT '24: Proceedings of the 2024 7th International Conference on Big Data Technologies},
year = {2024},
isbn = {9798400717512},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3698322,
title = {EuroPLoP '24: Proceedings of the 29th European Conference on Pattern Languages of Programs, People, and Practices},
year = {2024},
isbn = {9798400716836},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3698364,
title = {ISPD '25: Proceedings of the 2025 International Symposium on Physical Design},
year = {2025},
isbn = {9798400712937},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of the organizing committee, we are delighted to welcome you to the 34th ACM International Symposium on Physical Design (ISPD), held in Austin, Texas, providing a premier forum to exchange ideas, highlight key technology challenges, present leading-edge theoretical and experimental contributions, and identify future research directions in this field. We extend the good practice of having a YouTube channel to view the talks during the symposium and afterward, improving access to the presentations.Across three days, ISPD 2025 has 3 keynotes, 18 accepted papers, 13 invited talks; one panel on Monday with 4 panelists; and 4 speakers with longer talks in Professor Jason Cong''s commemorative session, and finally the ISPD 2025 contest results.This year, we received a total of 64 abstracts and we received 48 full manuscripts, from which 18 were selected - a 37.5\% acceptance rate. The regular papers in the ISPD 2025 program were selected, after a rigorous month-long double-blind review process and virtual meetings, by the Technical Program Committee with 20 outstanding international professionals from both academia and industry. These papers exhibit the latest advancements in a variety of topics in physical design, including global placement; mixed cell-height legalization; PCB placement; inverse lithography; quantum layout; photonic integrated circuits and side channel analysis; timing propagation; logic optimization; crosstalk mitigation; DRC checking; gate sizing; standard cell layout; CFET cell design; timing rule generation; analog cell design; 3D net-to-pad assignment, and 3D power delivery. A number of these papers utilize advanced mathematical programming, satisfiability modulo theories, GPU acceleration, and machine learning techniques.We are delighted to host three distinguished keynote speakers. The Monday keynote "Towards Designing and Deploying Ising Machines" will be given by Professor Sachin Sapatnekar of the University of Minnesota. He will explore opportunities for solving complex combinatorial optimization problems using Ising machines. The discussion will emphasize the layout and timing challenges specific to Ising machines that are based on coupled CMOS ring oscillators. On Tuesday morning, Dr. Charles J Alpert of Cadence Design Systems will present "How Automotive Functional Safety is Disrupting Digital Implementation". He will provide an overview of the challenges in achieving functional-safe ICs for automotive applications and discuss their impact on the digital implementation flow, including synthesis, placement, and routing. Wednesday's keynote is given by Dr. Henry Sheng from Synopsys on "Automation and Optimization of Heterogeneous Systems". He will explore the challenges and strategies for automating heterogeneous integration, an area that has traditionally relied on disconnected workflows and significant manual effort.The ISPD 2025 program is complemented by invited talks on topics ranging across design technology co-optimization; systolic array-based ICs; ECO automation, ML \&amp; AI methods in design automation; 3D IC design and integration; power design and analysis; and an analysis of the historical impact of ISPD. Additionally, we have a panel discussing EDA challenges in heterogeneous integration.In the ISPD Lifetime Achievement Award session on Tuesday, we will pay tribute to Professor Jason Cong. This session highlights Professor Cong's pioneering contributions in the algorithmic aspects of the physical design of silicon chips. This session has talks from his mentor, labmate and former students. Dr Bryan Preas will present the Innovation in Times of Technology Disruption. Followed by the talk from Professor Martin Wong from Hong Kong Baptist University. Professor David Pan, from University of Texas at Austin, will discuss the future of interconnected Physical Design. Finally, Professor Jason Cong will also grace the symposium with a delightful talk on coping with interconnects and a recount of his numerous contributions in EDA and Physical Design..Since 2005, ISPD has organized highly competitive contests to promote and advance research in placement, global routing, clock network synthesis, gate sizing, detailed routing-driven placement, and hardware security. The contest this year features the second contest on GPU-accelerated and machine learning-enhanced large scale global routing. This time the contest integrates timing and power metric. The contest is again organized by NVIDIA. The contest aims to not only deliver substantial reductions in global routing runtime but take performance and power into account as required in real-world applications. This year's contest attracted 46 teams from all over the world, reaching a record high.This year, we continue with a short format for the invited talks and regular papers. Presentations are 12 minutes in length, plus about 5 minutes for questions and answers after each talk, and some time at the end of each session for open discussion. This format is intended to encourage discussion among our research community. The talks in the lifetime achievement session are 20 minutes in length, with 5 minutes for questions and answers. Keynotes remain about 40 minutes in length, with 10 minutes for discussion.},
location = {Austin, TX, USA}
}

@inproceedings{10.1145/3698364.3709125,
author = {Wang, Qijing and Xiao, Liang and Young, Evangeline F.Y.},
title = {Invited: AI-assisted Routing},
year = {2025},
isbn = {9798400712937},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698364.3709125},
doi = {10.1145/3698364.3709125},
abstract = {Routing is an important but complicated step in physical synthesis. Considering the potential of leveraging AI to seek higher efficiency and better quality in solving routing problems, we study in this work the methodology of AI-assisted routing in a systematic way. Decoupling the functionalities of different routing components will give a high flexibility in determining where and how AI can be used in an effective manner, while maintaining a high degree of interpretability. Two applications along this direction are presented, aiming at tackling the difficulties in routing with AI assistance. These provide examples of how to implement the methodology in practice, while revealing its effectiveness and potential.},
booktitle = {Proceedings of the 2025 International Symposium on Physical Design},
pages = {134–142},
numpages = {9},
keywords = {artificial intelligence, assistance, design automation, routing},
location = {Austin, TX, USA},
series = {ISPD '25}
}

@proceedings{10.1145/3698385,
title = {IOTMMIM '24: Proceedings of the First International Workshop on IoT Datasets for Multi-modal Large Model},
year = {2024},
isbn = {9798400712975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hangzhou, China}
}

@proceedings{10.1145/3698587,
title = {BCB '24: Proceedings of the 15th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics},
year = {2024},
isbn = {9798400713026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Shenzhen, China}
}

@article{10.1145/3698826,
author = {Zhang, Jiachi and Zhou, Wenchao and Ujcich, Benjamin E.},
title = {Provenance-Enabled Explainable AI},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {6},
url = {https://doi.org/10.1145/3698826},
doi = {10.1145/3698826},
abstract = {Machine learning (ML) algorithms have advanced significantly in recent years, progressively evolving into artificial intelligence (AI) agents capable of solving complex, human-like intellectual challenges. Despite the advancements, the interpretability of these sophisticated models lags behind, with many ML architectures remaining "black boxes" that are too intricate and expansive for human interpretation. Recognizing this issue, there has been a revived interest in the field of explainable AI (XAI) aimed at explaining these opaque ML models. However, XAI tools often suffer from being tightly coupled with the underlying ML models and are inefficient due to redundant computations. We introduce provenance-enabled explainable AI (PXAI). PXAI decouples XAI computation from ML models through a provenance graph that tracks the creation and transformation of all data within the model. PXAI improves XAI computational efficiency by excluding irrelevant and insignificant variables and computation in the provenance graph. Through various case studies, we demonstrate how PXAI enhances computational efficiency when interpreting complex ML models, confirming its potential as a valuable tool in the field of XAI.},
journal = {Proc. ACM Manag. Data},
month = dec,
articleno = {250},
numpages = {27},
keywords = {data provenance, explainable ai, k-means clustering, multi-layer perceptron, probabilistic graphical model}
}

@proceedings{10.1145/3699432,
title = {WUWNET '24: Proceedings of the 18th International Conference on Underwater Networks \&amp; Systems},
year = {2024},
isbn = {9798400711602},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3699538,
title = {Koli Calling '24: Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@article{10.1145/3699759,
author = {Arakawa, Riku and Lehman, Jill Fain and Goel, Mayank},
title = {PrISM-Q&amp;A: Step-Aware Voice Assistant on a Smartwatch Enabled by Multimodal Procedure Tracking and Large Language Models},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
url = {https://doi.org/10.1145/3699759},
doi = {10.1145/3699759},
abstract = {Voice assistants capable of answering user queries during various physical tasks have shown promise in guiding users through complex procedures. However, users often find it challenging to articulate their queries precisely, especially when unfamiliar with the specific terminologies required for machine-oriented tasks. We introduce PrISM-Q&amp;A, a novel question-answering (Q&amp;A) interaction termed step-aware Q&amp;A, which enhances the functionality of voice assistants on smartwatches by incorporating Human Activity Recognition (HAR) and providing the system with user context. It continuously monitors user behavior during procedural tasks via audio and motion sensors on the watch and estimates which step the user is performing. When a question is posed, this contextual information is supplied to Large Language Models (LLMs) as part of the context used to generate a response, even in the case of inherently vague questions like "What should I do next with this?" Our studies confirmed that users preferred the convenience of our approach compared to existing voice assistants. Our real-time assistant represents the first Q&amp;A system that provides contextually situated support during tasks without camera use, paving the way for the ubiquitous, intelligent assistant.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = nov,
articleno = {180},
numpages = {26},
keywords = {context-aware, large language models, procedure tracking, question answering, task assistance}
}

@article{10.1145/3699775,
author = {Kalanadhabhatta, Manasa and Rastikerdar, Mohammad Mehdi and Rahman, Tauhidur and Grabell, Adam S. and Ganesan, Deepak},
title = {Playlogue: Dataset and Benchmarks for Analyzing Adult-Child Conversations During Play},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
url = {https://doi.org/10.1145/3699775},
doi = {10.1145/3699775},
abstract = {There has been growing interest in developing ubiquitous technologies to analyze adult-child speech in naturalistic settings such as free play in order to support children's social and academic development, language acquisition, and parent-child interactions. However, these technologies often rely on off-the-shelf speech processing tools that have not been evaluated on child speech or child-directed adult speech, whose unique characteristics might result in significant performance gaps when using models trained on adult speech. This work introduces the Playlogue dataset containing over 33 hours of long-form, naturalistic, play-based adult-child conversations from three different corpora of preschool-aged children. Playlogue enables researchers to train and evaluate speaker diarization and automatic speech recognition models on child-centered speech. We demonstrate the lack of generalizability of existing state-of-the-art models when evaluated on Playlogue, and show how fine-tuning models on adult-child speech mitigates the performance gap to some extent but still leaves considerable room for improvement. We further annotate over 5 hours of the Playlogue dataset with 8668 validated adult and child speech act labels, which can be used to train and evaluate models to provide clinically relevant feedback on parent-child interactions. We investigate the performance of state-of-the-art language models at automatically predicting these speech act labels, achieving significant accuracy with simple chain-of-thought prompting or minimal fine-tuning. We use inhome pilot data to validate the generalizability of models trained on Playlogue, demonstrating its utility in improving speech and language technologies for child-centered conversations. The Playlogue dataset is available for download at https://huggingface.co/datasets/playlogue/playlogue-v1.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = nov,
articleno = {173},
numpages = {34},
keywords = {Child speech, adult-child interaction, audio dataset, automatic speech recognition, large language models, play, speaker diarization, speech classification}
}

@proceedings{10.1145/3700003,
title = {ICVISP '24: Proceedings of the 2024 International Conference on Virtual Reality, Image and Signal Processing},
year = {2024},
isbn = {9798400710926},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3700035,
title = {IPPR '24: Proceedings of the 2024 International Conference on Intelligent Perception and Pattern Recognition},
year = {2024},
isbn = {9798400707315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3700058,
title = {DEBAI '24: Proceedings of the International Conference on Digital Economy, Blockchain and Artificial Intelligence},
year = {2024},
isbn = {9798400710261},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3700297,
title = {ISAIE '24: Proceedings of the 2024 International Symposium on Artificial Intelligence for Education},
year = {2024},
isbn = {9798400707100},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3700410,
title = {MMAsia '24 Workshops: Proceedings of the 6th ACM International Conference on Multimedia in Asia Workshops},
year = {2024},
isbn = {9798400713149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3700486,
title = {ICBIT '24: Proceedings of the 2024 International Conference on Biomedicine and Intelligent Technology},
year = {2024},
isbn = {9798400710063},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3700523,
title = {AI2A '24: Proceedings of the 2024 4th International Conference on Artificial Intelligence, Automation and Algorithms},
year = {2024},
isbn = {9798400717840},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3700666,
title = {ICBRA '24: Proceedings of the 11th International Conference on Bioinformatics Research and Applications},
year = {2024},
isbn = {9798400717536},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3700706,
title = {ICISS '24: Proceedings of the 2024 7th International Conference on Information Science and Systems},
year = {2024},
isbn = {9798400717567},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3700794,
title = {ICTD '24: Proceedings of the 13th International Conference on Information \&amp; Communication Technologies and Development},
year = {2024},
isbn = {9798400710414},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3700794.3700804,
author = {Jain, Saurabh and Panjal, Paramita and Sultan Ahmad, Md and Ahmad Siddiqi, Rafi and Seth, Aaditeshwar},
title = {Filter-in or Filter-out: Complexities and Implications of Content Moderation Processes in a Voice-based Participatory Media Platform in India},
year = {2025},
isbn = {9798400710414},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700794.3700804},
doi = {10.1145/3700794.3700804},
abstract = {Participatory media platforms are digital technology platforms that enable users to participate in online communities and allow them to contribute content that helps in the exchange of views. Content contributions by community members result in diverse content, some of which may be illegal, harmful or hurtful to some community groups, obscene, or not aligned with platform policy, thus requiring the need to moderate this content. We study the content moderation policies of four voice-based participatory media platforms in rural India, namely ‘Shramik Vaani’, ‘Meri Awaz Meri Pahchaan’, ‘Kahi Ankahi Baatein’, and ‘Jamui News (JNews)’, which operate on a common underlying technology framework Mobile Vaani1 We address two research questions. First, we identify various complexities in the automation and people processes involved in content moderation on these platforms. Second, we explore the relationship between content moderation policies and user behavior. We study these platforms using a mixed-methods approach. We use a four-step research design that consists of thematic analysis, qualitative content analysis of accepted and rejected content, a user survey, and semi-structured interviews with the content moderation team to investigate the first research question. For the second research question, we use platform logs of user interactions to understand the impact of various moderation decisions on user engagement. This paper is a unique contribution to literature on content moderation, as it presents an insider view of content moderation policies on a popular voice-based participatory media platform in rural North India. We bring out deep complexities in the moderation process and highlight multiple concerns that platform moderators face in their decision making and tasks, the relevance of guiding users to contribute better content rather than simply reviewing the content, and the influence of having in-person field teams in the same communities that engage on the online platform. These findings will be relevant to other participatory and social media platforms to take such aspects into consideration in their own operations.},
booktitle = {Proceedings of the 13th International Conference on Information \&amp; Communication Technologies and Development},
pages = {84–109},
numpages = {26},
keywords = {Content recommendation, Mobile Vaani, Gram Vaani, Alternative platforms, Voice based Participatory media platform, Thematic analysis, Content moderation},
location = {
},
series = {ICTD '24}
}

@inproceedings{10.1145/3700794.3700820,
author = {Mayeesha, Tasmiah Tahsin and Islam, Farzana and Ahmed, Nova},
title = {AI4Bangladesh: AI Ethics for Bangladesh - Challenges, Risks, Principles, and Suggestions},
year = {2025},
isbn = {9798400710414},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700794.3700820},
doi = {10.1145/3700794.3700820},
abstract = {In recent times, the term AI ethics caught the attention among the academics, legislators, developers, and among AI users to promote ethical AI development. While countries in the North have led the way in discussions about the direction of ethical and responsible artificial intelligence development and deployment, perspectives from developing countries like Bangladesh are underrepresented. Based on 32 qualitative interviews with different stakeholders, including machine learning practitioners, academic researchers, and policymakers in the emerging AI ecosystem in Bangladesh, this work closely examines the ongoing challenges and opportunities to ensure AI ethics in Bangladesh with emerging AI usage. In Bangladesh, the government has not yet fully implemented measures to empower citizens with AI-related skills, policies, resources, and data ethics, and a significant portion of the population lacks knowledge in AI. In this paper, we are presenting the findings of AI4Bangladesh project that intend to create the roadmap for ethical AI in Bangladesh. We outline the core challenges, present situation, and risks of AI for Bangladesh; propose seven AI ethics principles, and offer suggestions to ensure a transparent, accountable, and fair AI ecosystem for Bangladesh.},
booktitle = {Proceedings of the 13th International Conference on Information \&amp; Communication Technologies and Development},
pages = {260–272},
numpages = {13},
keywords = {AI Ethics, Ethics principles, Human Centered AI, AI Governance},
location = {
},
series = {ICTD '24}
}

@proceedings{10.1145/3700824,
title = {Middleware Industrial Track '24: Proceedings of the 25th International Middleware Conference Industrial Track},
year = {2024},
isbn = {9798400713194},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hong Kong, Hong Kong}
}

@proceedings{10.1145/3700838,
title = {ICDCN '25: Proceedings of the 26th International Conference on Distributed Computing and Networking},
year = {2025},
isbn = {9798400710629},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3700906,
title = {IPMLP '24: Proceedings of the International Conference on Image Processing, Machine Learning and Pattern Recognition},
year = {2024},
isbn = {9798400707032},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3701047,
title = {CNML '24: Proceedings of the 2024 2nd International Conference on Communication Networks and Machine Learning},
year = {2024},
isbn = {9798400711688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3701100,
title = {ADMIT '24: Proceedings of the 2024 3rd International Conference on Algorithms, Data Mining, and Information Technology},
year = {2024},
isbn = {9798400718120},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@article{10.1145/3701182,
author = {Kabir, Kazi Sinthia and Cohoon, Johanna and Lund, John R. and Chen, Jacqueline M. and Metz, A.J. and Wiese, Jason},
title = {Balancing Care Responsibilities with Remote Work},
year = {2025},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {1},
url = {https://doi.org/10.1145/3701182},
doi = {10.1145/3701182},
abstract = {The upsurge in remote and hybrid work practices has prompted researchers to explore the technological, organizational, and psychological dimensions of remote work. However, the nuanced dynamics of balancing familial duties, especially care work for older adults, and professional work is often overlooked in the literature. This balancing act introduces unique stressors, blurring work and personal life boundaries, potentially causing physical stress or prompting care providers to leave their jobs. The inherent nature of remote work executed within the familial sphere underscores the importance of understanding how care responsibilities impact the remote work experience. This study addresses this gap by focusing on informal care providers, an understudied population in the CSCW remote work literature. Through a diary study and interviews, we investigate challenges remote workers face and the role of technology in their work. Findings highlight the prevalence of care work, emphasizing the need for targeted technological interventions to support the well-being and productivity of remote workers managing care duties. Critical challenges include familial responsibilities on higher-stress days, lack of communication regarding availability, personal time sacrifices for productivity, coordination in place making among care providers, and multitasking on days with familial responsibilities or distractions. This exploratory study underscores the importance of assisting care providers in a way that embraces their (possible) role as remote workers, offering insights for future research and technological interventions to support remote workers navigating the complexities of care work.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = jan,
articleno = {GROUP3},
numpages = {21},
keywords = {boundary management, care work, caregiving, childcare, diary study, place making, remote work, stress}
}

@article{10.1145/3701201,
author = {Schofield, Alexandra and Wu, Siqi and Bayard de Volo, Theo and Kuze, Tatsuki and Gomez, Alfredo and Sultana, Sharifa},
title = {"My Very Subjective Human Interpretation": Domain Expert Perspectives on Navigating the Text Analysis Loop for Topic Models},
year = {2025},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {1},
url = {https://doi.org/10.1145/3701201},
doi = {10.1145/3701201},
abstract = {Practitioners dealing with large text collections frequently use topic models such as Latent Dirichlet Allocation (LDA) and Non-negative Matrix Factorization (NMF) in their projects to explore trends. Despite twenty years of accrued advancement in natural language processing tools, these models are found to be slow and challenging to apply to text exploration projects. In our work, we engaged with practitioners (n=15) who use topic modeling to explore trends in large text collections to understand their project workflows and investigate which factors often slow down the processes and how they deal with such errors and interruptions in automated topic modeling. Our findings show that practitioners are required to diagnose and resolve context-specific problems with preparing data and models and need control for these steps, especially for data cleaning and parameter selection. Our major findings resonate with existing work across CSCW, computational social science, machine learning, data science, and digital humanities. They also leave us questioning whether automation is actually a useful goal for tools designed for topic models and text exploration.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = jan,
articleno = {GROUP22},
numpages = {30},
keywords = {computational social science, cultural analytics, digital humanities, text pre-processing, topic models}
}

@article{10.1145/3701211,
author = {Ankenbauer, Sam Addison and Brewer, Robin N.},
title = {Time's Sublimest Target: Practices of Forgetting in HCI and CSCW},
year = {2025},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {1},
url = {https://doi.org/10.1145/3701211},
doi = {10.1145/3701211},
abstract = {In our contemporary moment, there exists a hegemonic design practice and a general social desire to retain information. With the help of sociotechnical platforms and other contemporary technologies, information has changed its temporal and spatial boundaries, creating unbounded, algorithmic, and emergent forms of retention. The consequences of such retention are numerous, ranging from an overabundance of autobiographical information that cannot be fully understood by the individual to the improper use and economization of such information by state and corporation alike. Within this context, this paper investigates a counter-hegemonic practice of forgetting, specifically from the perspective of human-computer interaction and computer-supported cooperative work research, with additional insight drawn from adjacent fields. In doing so, we present forgetting as a significant area of research with HCI and CSCW, a burgeoning and contradictory space that may offer solutions to issues we face within a moment of persistence by default. This paper also explores potential directions for future research and design on forgetting in HCI and CSCW through an investigation of an art piece by Chinese artist Song Dong.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = jan,
articleno = {GROUP32},
numpages = {24},
keywords = {deletion, forgetting, intent, retention, spatial, temporal}
}

@inproceedings{10.1145/3701551.3703488,
author = {Qiao, Yiran and Ao, Xiang and Liu, Yang and Xu, Jiarong and Sun, Xiaoqian and He, Qing},
title = {LOGIN: A Large Language Model Consulted Graph Neural Network Training Framework},
year = {2025},
isbn = {9798400713293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701551.3703488},
doi = {10.1145/3701551.3703488},
abstract = {Recent prevailing works on graph machine learning typically follow a similar methodology that involves designing advanced variants of graph neural networks (GNNs) to maintain the superior performance of GNNs on different graphs. In this paper, we aim to streamline the GNN design process and leverage the advantages of Large Language Models (LLMs) to improve the performance of GNNs on downstream tasks. We formulate a new paradigm, coined "LLMs-as-Consultants", which integrates LLMs with GNNs in an interactive manner. A framework named LOGIN (LLM cOnsulted GNN traINing) is instantiated, empowering the interactive utilization of LLMs within the GNN training process. First, we attentively craft concise prompts for spotted nodes, carrying comprehensive semantic and topological information, and serving as input to LLMs. Second, we refine GNNs by devising a complementary coping mechanism that utilizes the responses from LLMs, depending on their correctness. We empirically evaluate the effectiveness of Lalebox1 [0.8]O Galebox1 [0.8]IN on node classification tasks across both homophilic and heterophilic graphs. The results illustrate that even basic GNN architectures, when employed within the proposed LLMs-as-Consultants paradigm, can achieve comparable performance to advanced GNNs with intricate designs. Our code is available at https://github.com/QiaoYRan/LOGIN.},
booktitle = {Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining},
pages = {232–241},
numpages = {10},
keywords = {graph neural network, large language model},
location = {Hannover, Germany},
series = {WSDM '25}
}

@inproceedings{10.1145/3701551.3703532,
author = {Zhang, Shuai and Chu, Hua and Li, Jianan and Zhou, Yangtao and Wang, Shirong and Sun, Qiaofei},
title = {DeMBR: Denoising Model with Memory Pruning and Semantic Guidance for Multi-Behavior Recommendation},
year = {2025},
isbn = {9798400713293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701551.3703532},
doi = {10.1145/3701551.3703532},
abstract = {Multi-behavior recommendation systems aim to incorporate auxiliary behaviors (e.g., click, cart, etc.) to enhance the understanding of sparse target behaviors (e.g., purchase), thereby capturing user preferences more accurately. Currently, multi-behavior recommendation research focuses on modeling the associations between different user behaviors, but ignores the large amount of noise in user interaction data. This noise may come from accidental touches, curiosity, or ineffective operations during the purchasing process, and can be further categorized into two types: 1) hard noise is significantly deviates from the user's true preferences, and 2) soft noise is closer to the user's true preferences. The presence of noise can interfere with the model's ability to accurately identify the user's true preferences. To overcome the aforementioned issue, we innovatively propose a Denoising Model with Memory Pruning and Semantic Guidance for Multi-Behavior Recommendation (DeMBR). The model eliminates different types of noise at the data level and the representation level, respectively. Specifically, since hard noise significantly deviates from user preferences, we design a pruning-based denoising module that leverages a memory bank, which identifies and removes hard noise interactions from the data. Since soft noise reflects some user preferences, we design a semantic guidance denoising module that leverages behaviors with strong expressive ability (e.g., purchase) to guide those with weaker ability (e.g., click), effectively suppressing noise while preserving true's preferences. Finally, we designed a cross-learning module that allows noise-identifying signals to be exchanged between the two modules, and ultimately learn representations that accurately reflect user's preferences. Extensive experiments conducted on two public datasets demonstrate that our model substantially surpasses the state-of-the-art recommendation models. Our code is publicly available at: https://github.com/DeMBR2024/DeMBR.git},
booktitle = {Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining},
pages = {521–529},
numpages = {9},
keywords = {denoising, graph convolutional networks, multi-behavior},
location = {Hannover, Germany},
series = {WSDM '25}
}

@inproceedings{10.1145/3701551.3703535,
author = {Wang, Yidan and Ge, Xuri and Chen, Xin and Xie, Ruobing and Yan, Su and Zhang, Xu and Chen, Zhumin and Ma, Jun and Xin, Xin},
title = {Exploration and Exploitation of Hard Negative Samples for Cross-Domain Sequential Recommendation},
year = {2025},
isbn = {9798400713293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701551.3703535},
doi = {10.1145/3701551.3703535},
abstract = {Negative sampling plays a crucial role for cross-domain recommendation as it provides contrastive signals to learn user preference. Existing methods usually select items with high predicted scores or popularity as hard negative samples to improve model training. However, such methods suffer from choosing false negative samples since items with high predicted scores or popularity could also indicate potential positive user preference. Although several studies devoted to discovering true negative samples, few of them leverage user cross-domain behaviors to alleviate the false negative issue. How to effectively mine and utilize hard negative samples to improve cross-domain recommendation remains an open question.In this work, we propose exploration and exploitation of hard negative samples (EXHANS) for cross-domain sequential recommendation. For better exploration, we utilize the user preference from the source domain to guide negative sampling in the target domain. The key idea is that compared with hard negative samples, false negative samples have higher probability to be consistent with the user preference in both domains. Besides, we propose adaptive popularity-based score correction to account for users' different tastes of popular items. The idea is that for users who favor popular items, such items are more likely to be false negatives rather than hard negatives. For better exploitation, we design a replay buffer to cache the obtained negative samples and further propose a curriculum learning framework to balance exploration and exploitation of hard negative samples. Extensive experiments on three real-world datasets show that our method significantly outperforms state-of-the-art negative sampling methods for cross-domain sequential recommendation, which verify the effectiveness of EXHANS.},
booktitle = {Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining},
pages = {669–677},
numpages = {9},
keywords = {cross domain recommendation, negative sampling, recommender system, sequential recommendation},
location = {Hannover, Germany},
series = {WSDM '25}
}

@inproceedings{10.1145/3701551.3703536,
author = {Chen, Guoxuan and Xia, Lianghao and Huang, Chao},
title = {LightGNN: Simple Graph Neural Network for Recommendation},
year = {2025},
isbn = {9798400713293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701551.3703536},
doi = {10.1145/3701551.3703536},
abstract = {Graph neural networks (GNNs) have demonstrated superior performance in collaborative recommendation through their ability to conduct high-order representation smoothing, effectively capturing structural information within users' interaction patterns. However, existing GNN paradigms face significant challenges in scalability and robustness when handling large-scale, noisy real-world datasets. To address these challenges, we present LightGNN, a lightweight and distillation-based GNN pruning framework designed to substantially reduce model complexity while preserving essential collaboration modeling capabilities. Our LightGNN framework introduces a computationally efficient pruning module that adaptively identifies and removes adverse edges and embedding entries for model compression. The framework is guided by a resource-friendly hierarchical knowledge distillation objective, whose intermediate layer augments the observed graph to maintain performance, particularly in high-rate compression scenarios. Extensive experiments on public datasets demonstrate LightGNN's effectiveness, significantly improving both computational efficiency and recommendation accuracy. Notably, LightGNN achieves an 80\% reduction in edge count and 90\% reduction in embedding entries while maintaining performance comparable to more complex state-of-the-art baselines. The implementation of our LightGNN model is available at the github repository: https://github.com/HKUDS/LightGNN.},
booktitle = {Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining},
pages = {549–558},
numpages = {10},
keywords = {graph learning, knowledge distillation, recommendation},
location = {Hannover, Germany},
series = {WSDM '25}
}

@inproceedings{10.1145/3701551.3703563,
author = {Sagtani, Hitesh and Mehrotra, Rishabh and Liu, Beyang},
title = {Improving FIM Code Completions via Context \&amp; Curriculum Based Learning},
year = {2025},
isbn = {9798400713293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701551.3703563},
doi = {10.1145/3701551.3703563},
abstract = {Fill-in-the-Middle (FIM) models play a vital role in code completion tasks, leveraging both prefix and suffix context to provide more accurate and contextually relevant suggestions. This paper presents approaches to improve FIM code completion while addressing the challenge of maintaining low latency for real-time coding assistance. We enhance FIM code completion by incorporating context and curriculum examples in the training process. We identify patterns where completion suggestions fail more frequently, revealing complexities that smaller language models struggle with. To address these challenges, we develop a curriculum dataset by extracting hard-to-complete patterns from code repositories and generate context examples using semantic and static analysis tools (e.g. TSC compiler). We fine-tune various sized models, including StarCoder and DeepSeek, on this enhanced dataset. Our evaluation encompasses three key dimensions: the Santa Coder FIM task, the Amazon CCEval benchmark, and a new Multi-Line Infilling evaluation benchmark derived from SWE-bench. Comprehensive ablation studies across multiple model sizes reveal that while all fine-tuned models show improvements, the performance gains are more pronounced for smaller parameter models and that incorporating difficult-to-complete examples as part of curriculum learning improves completion performance. This finding is particularly sig- nificant given the latency constraints of code completion tasks. While larger models like GPT and Claude perform well in multi- line completions but are prohibitively challenging to use given high latency, and our fine-tuned models achieve a balance between per- formance and latency. Finally, we validate our approach through online A/B testing, demonstrating tangible improvements in Completion Acceptance Rate (CAR) and Completion Persistence Rate (CPR), with zero latency impact.},
booktitle = {Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining},
pages = {801–810},
numpages = {10},
keywords = {a/b-testing, code completions, large language model},
location = {Hannover, Germany},
series = {WSDM '25}
}

@inbook{10.1145/3701551.3703573,
author = {He, Zhankui and Xie, Zhouhang and Steck, Harald and Liang, Dawen and Jha, Rahul and Kallus, Nathan and McAuley, Julian},
title = {Reindex-Then-Adapt: Improving Large Language Models for Conversational Recommendation},
year = {2025},
isbn = {9798400713293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701551.3703573},
abstract = {Large Language Models (LLMs) are revolutionizing conversational recommender systems (CRS) by effectively indexing item content, understanding complex conversational contexts, and generating relevant item titles. However, the autoregressive nature of LLMs, which outputs item titles as a long sequence of subtokens, hinders the ability to efficiently obtain and control recommendations across the entire item set. This challenge in calculating probabilities over all items limits LLMs' potential, such as (1) limiting control over recommendation popularities and (2) preventing the synergy of marrying LLMs and traditional recommender systems (RecSys).To address this challenge, we propose the Reindex-Then-Adapt (RTA) framework. It consists of two steps: (1) Reindex: a lightweight network learns to condense multi-token item titles into single tokens within the LLM and distills LLM-generated recommendations as ranked lists. This bypasses the autoregressive nature of LLMs while trying to preserve their CRS abilities; (2) Adapt: LLMs after reindexing enable efficient adjustment of probability distributions over single-token titles, further enhanced through RecSys integration. RTA bridges the strengths of LLMs and RecSys, enabling understanding of complex queries as LLMs do, while efficiently controlling recommended item distributions as in traditional RecSys. We show the effectiveness of our RTA over base LLMs across three CRS datasets with negligible additional parameters.},
booktitle = {Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining},
pages = {866–875},
numpages = {10}
}

@proceedings{10.1145/3701571,
title = {MUM '24: Proceedings of the International Conference on Mobile and Ubiquitous Multimedia},
year = {2024},
isbn = {9798400712838},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3701625,
title = {SBQS '24: Proceedings of the XXIII Brazilian Symposium on Software Quality},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3702038,
title = {IHC '24: Proceedings of the XXIII Brazilian Symposium on Human Factors in Computing Systems},
year = {2024},
isbn = {9798400712241},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3702138,
title = {ASSE '24: Proceeding of the 2024 5th Asia Service Sciences and Software Engineering Conference},
year = {2024},
isbn = {9798400717543},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3702163,
title = {ICETC '24: Proceedings of the 2024 16th International Conference on Education Technology and Computers},
year = {2024},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3702191,
title = {ICDIS '24: Proceedings of the 2024 International Symposium on Integrated Circuit Design and Integrated Systems},
year = {2024},
isbn = {9798400718229},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3702250,
title = {ICVGIP '24: Proceedings of the Fifteenth Indian Conference on Computer Vision Graphics and Image Processing},
year = {2024},
isbn = {9798400710759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@article{10.1145/3702320,
author = {Vasconcelos, Helena and Bansal, Gagan and Fourney, Adam and Liao, Q. Vera and Vaughan, Jennifer Wortman},
title = {Generation Probabilities Are Not Enough: Uncertainty Highlighting in AI Code Completions},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1073-0516},
url = {https://doi.org/10.1145/3702320},
doi = {10.1145/3702320},
abstract = {Large-scale generative models have enabled the development of AI-powered code completion tools to assist programmers in writing code. Like all AI-powered tools, these code completion tools are not always accurate and can introduce bugs or even security vulnerabilities into code if not properly detected and corrected by a human programmer. One technique that has been proposed and implemented to help programmers locate potential errors is to highlight uncertain tokens. However, little is known about the effectiveness of this technique. Through a mixed-methods study with 30 programmers, we compare three conditions: providing the AI system's code completion alone, highlighting tokens with the lowest likelihood of being generated by the underlying generative model, and highlighting tokens with the highest predicted likelihood of being edited by a programmer. We find that highlighting tokens with the highest predicted likelihood of being edited leads to faster task completion and more targeted edits, and is subjectively preferred by study participants. In contrast, highlighting tokens according to their probability of being generated does not provide any benefit over the baseline with no highlighting. We further explore the design space of how to convey uncertainty in AI-powered code completion tools and find that programmers prefer highlights that are granular, informative, interpretable, and not overwhelming. This work contributes to building an understanding of what uncertainty means for generative models and how to convey it effectively.},
note = {Just Accepted},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = oct,
keywords = {human-AI programming, generative AI, uncertainty}
}

@article{10.1145/3702326,
author = {Khelifati, Adel and Boukala-Ioualalen, Malika and Hammad, Ahmed},
title = {Construction of consistent SysML models applied to the CPS},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1550-4832},
url = {https://doi.org/10.1145/3702326},
doi = {10.1145/3702326},
abstract = {With the increasing complexity of cyber-physical systems (CPS), it is interesting to decompose a CPS into sub-systems. This provides greater modularity and flexibility so that each system can be developed independently, making it easier to maintain. Also, it can improve its fault tolerance. However, this decomposition of the system can lead to inconsistency. This paper proposes an approach for early verification of cyber-physical systems decomposition using SysML. We address the limitations of SysML as a semi-formal language by introducing syntax and static semantics for its structural diagrams. The aim is to verify structural consistency before defining behavioral aspects. For that, the proposed approach verifies a set of structural consistency rules within a refinement relation to ensure that sub-components offer at least the same services as the abstract block and require the same services. Furthermore, the sub-blocks must satisfy all the requirements that the abstract block is supposed to verify. We used the CyCab as a case study to demonstrate the effectiveness of this approach.},
note = {Just Accepted},
journal = {J. Emerg. Technol. Comput. Syst.},
month = oct,
keywords = {Cyber-Physical System, SysML, Components, Early verification}
}

@proceedings{10.1145/3702336,
title = {ACI '24: Proceedings of the International Conference on Animal-Computer Interaction},
year = {2024},
isbn = {9798400711756},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3702359,
title = {AIBC '24: Proceedings of the 2024 5th International Artificial Intelligence and Blockchain Conference},
year = {2024},
isbn = {9798400710780},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3702370,
title = {ICAIP '24: Proceedings of the 2024 8th International Conference on Advances in Image Processing (ICAIP)},
year = {2024},
isbn = {9798400717505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3702386,
title = {ICAITE '24: Proceedings of the 2024 International Conference on Artificial Intelligence and Teacher Education},
year = {2024},
isbn = {9798400710131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3702468,
title = {ICRSA '24: Proceedings of the 2024 7th International Conference on Robot Systems and Applications},
year = {2024},
isbn = {9798400717031},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3702879,
title = {IoTCCT '24: Proceedings of the 2024 2nd International Conference on Internet of Things and Cloud Computing Technology},
year = {2024},
isbn = {9798400710148},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@article{10.1145/3702979,
author = {Kabir, Azmain and Wang, Shaowei and Tian, Yuan and Chen, Tse-Hsun (Peter) and Asaduzzaman, Muhammad and Zhang, Wenbin},
title = {ZS4C: Zero-Shot Synthesis of Compilable Code for Incomplete Code Snippets using LLMs},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3702979},
doi = {10.1145/3702979},
abstract = {Technical Q&amp;A sites are valuable for software developers seeking knowledge, but the code snippets they provide are often uncompilable and incomplete due to unresolved types and missing libraries. This poses a challenge for users who wish to reuse or analyze these snippets. Existing methods either do not focus on creating compilable code or have low success rates. To address this, we propose ZS4C, a lightweight approach for zero-shot synthesis of compilable code from incomplete snippets using Large Language Models (LLMs). ZS4C operates in two stages: first, it uses an LLM, like GPT-3.5, to identify missing import statements in a snippet; second, it collaborates with a validator (e.g., compiler) to fix compilation errors caused by incorrect imports and syntax issues. We evaluated ZS4C on the StatType-SO benchmark and a new dataset, Python-SO, which includes 539 Python snippets from Stack Overflow across the 20 most popular Python libraries. ZS4C significantly outperforms existing methods, improving the compilation rate from 63\% to 95.1\% compared to the state-of-the-art SnR, marking a 50.1\% improvement. On average, ZS4C can infer more accurate import statements (with an F1 score of 0.98) than SnR, with an improvement of 8.5\% in the F1.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = nov,
keywords = {Incomplete code snippets, Large Language Model, Program synthesis, API inference, Prompt engineering, ChatGPT}
}

@article{10.1145/3702980,
author = {Majdinasab, Vahid and Nikanjam, Amin and Khomh, Foutse},
title = {Trained Without My Consent: Detecting Code Inclusion In Language Models Trained on Code},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3702980},
doi = {10.1145/3702980},
abstract = {Code auditing ensures that the developed code adheres to standards, regulations, and copyright protection by verifying that it does not contain code from protected sources. The recent advent of Large Language Models (LLMs) as coding assistants in the software development process poses new challenges for code auditing. The dataset for training these models is mainly collected from publicly available sources. This raises the issue of intellectual property infringement as developers’ codes are already included in the dataset. Therefore, auditing code developed using LLMs is challenging, as it is difficult to reliably assert if an LLM used during development has been trained on specific copyrighted codes, given that we do not have access to the training datasets of these models. Given the non-disclosure of the training datasets, traditional approaches such as code clone detection are insufficient for asserting copyright infringement. To address this challenge, we propose a new approach, TraWiC; a model-agnostic and interpretable method based on membership inference for detecting code inclusion in an LLM’s training dataset. We extract syntactic and semantic identifiers unique to each program to train a classifier for detecting code inclusion. In our experiments, we observe that TraWiC is capable of detecting 83.87\% of codes that were used to train an LLM. In comparison, the prevalent clone detection tool NiCad is only capable of detecting 47.64\%. In addition to its remarkable performance, TraWiC has low resource overhead in contrast to pair-wise clone detection that is conducted during the auditing process of tools like CodeWhisperer reference tracker, across thousands of code snippets.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = nov,
keywords = {Large Language Models, Intellectual Property Infringement, Code Licensing, Dataset Inclusion Detection, Membership Inference Attack}
}

@article{10.1145/3702984,
author = {Sun, Yongqian and Liang, Minghan and Zhang, Shenglin and Che, Zeyu and Luo, Zhiyao and Li, Dongwen and Zhang, Yuzhi and Pei, Dan and Pan, Lemeng and Hou, Liping},
title = {Efficient Multivariate Time Series Anomaly Detection Through Transfer Learning for Large-Scale Software Systems},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3702984},
doi = {10.1145/3702984},
abstract = {Timely anomaly detection of multivariate time series (MTS) is of vital importance for managing large-scale software systems. However, many deep learning-based MTS anomaly detection models require long-term MTS training data to achieve optimal performance, which often conflicts with the frequent pattern changes observed in software systems. Moreover, the training overhead of vast MTS in large-scale software systems is unacceptably high. To address these issues, we design OmniTransfer, a model-agnostic framework that combines weighted hierarchical agglomerative clustering with an adaptive transfer learning strategy, making many state-of-the-art (SOTA) MTS anomaly detection models efficient and effective. Extensive experiments using real-world data from a large web content service provider and a network operator show that OmniTransfer significantly reduces the model initialization time by 46.49\% and the training cost by 74.51\%, while maintaining high accuracy in detecting anomalies.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = nov,
keywords = {Transfer Learning, Multivariate Time Series, Multivariate Time Series Clustering, Anomaly Detection}
}

@article{10.1145/3702988,
author = {Sha, Zihan and Wang, Hao and Gao, Zeyu and Shu, Hui and Zhang, Bolun and Wang, Ziqing and Zhang, Chao},
title = {llasm: Naming Functions in Binaries by Fusing Encoder-only and Decoder-only LLMs},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3702988},
doi = {10.1145/3702988},
abstract = {Predicting function names in stripped binaries, which requires succinctly summarizing semantics of binary code in natural languages, is a crucial but challenging task. Recently, many machine learning based solutions have been proposed. However, they have poor generalizability, i.e., fail to handle unseen binaries. To advance the state of the art, we present llasm (Large ASsembly Language Model), a novel framework which fuses encoder-only and decoder-only LLMs for function name prediction. It refines encoder-only models to preserve more binary information and learn better binary representations. Then it adopts a novel architecture to project the encoding to the input space of a decoder-only natural language model, which enables it to have better capability of inferring general knowledge and better generalizability. We have evaluated llasm in the BinaryCorp and Debin datasets. llasm outperforms the state-of-the-art function name prediction tools by up to 19.9\%, 40.7\%, and 36.5\% in precision, recall, and F1 score, with significantly better generalizability in unseen binaries. Our case studies further demonstrate the practical use cases of llasm in analyzing real-world malware, showing the usefulness of function name prediction.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = nov,
keywords = {Large Language Model, Assembly Language Model, Program Comprehension, Neural Networks}
}

@article{10.1145/3702993,
author = {Wei, Jialiang and Courbis, Anne-Lise and Lambolais, Thomas and Xu, Binbin and Bernard, Pierre Louis and Dray, G\'{e}rard and Maalej, Walid},
title = {GUing: A Mobile GUI Search Engine using a Vision-Language Model},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3702993},
doi = {10.1145/3702993},
abstract = {Graphical User Interfaces (GUIs) are central to app development projects. App developers may use the GUIs of other apps as a means of requirements refinement and rapid prototyping or as a source of inspiration for designing and improving their own apps. Recent research has thus suggested retrieving relevant GUI designs that match a certain text query from screenshot datasets acquired through crowdsourced or automated exploration of GUIs. However, such text-to-GUI retrieval approaches only leverage the textual information of the GUI elements, neglecting visual information such as icons or background images. In addition, retrieved screenshots are not steered by app developers and lack app features that require particular input data.To overcome these limitations, this paper proposes GUing, a GUI search engine based on a vision-language model called GUIClip, which we trained specifically for the problem of designing app GUIs. For this, we first collected from Google Play app introduction images which display the most representative screenshots and are often captioned (i.e. labelled) by app vendors. Then, we developed an automated pipeline to classify, crop, and extract the captions from these images. This resulted in a large dataset which we share with this paper: including 303k app screenshots, out of which 135k have captions. We used this dataset to train a novel vision-language model, which is, to the best of our knowledge, the first of its kind for GUI retrieval. We evaluated our approach on various datasets from related work and in a manual experiment. The results demonstrate that our model outperforms previous approaches in text-to-GUI retrieval achieving a Recall@10 of up to 0.69 and a HIT@10 of 0.91. We also explored the performance of GUIClip for other GUI tasks including GUI classification and sketch-to-GUI retrieval with encouraging results.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = nov
}

@article{10.1145/3702999,
author = {Zhang, Yue and Wang, Chao and Fang, Feifei and Zhuge, Yunzhi and Fan, Hehe and Chang, Xiaojun and Deng, Cheng and Yang, Yi},
title = {SAMControl: Controlling Pose and Object for Image Editing with Soft Attention Mask},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1551-6857},
url = {https://doi.org/10.1145/3702999},
doi = {10.1145/3702999},
abstract = {To achieve content-consistent results in text-conditioned image editing, existing methods typically employ a reconstruction branch to capture the source image details via diffusion inversion and a generation branch to synthesize the target image based on the given textual prompt and the masked source image details. However, accurately segmenting source details is challenging with the current fixed-threshold mask strategy. Additionally, the inadequacies in the inversion process can lead to insufficient retention of source details. In this paper, we propose a method called SAMControl (Soft Attention Mask) to adaptively control the pose and object details for image editing. SAMControl dynamically learns flexible attention masks for different images at various diffusion steps. Furthermore, in the reconstruction branch, we utilize a direct inversion technique to ensure the fidelity of source details within SAM. Extensive qualitative and quantitative results demonstrate the effectiveness of the proposed method.},
note = {Just Accepted},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = nov,
keywords = {Text-Guided Image Editing, Soft Attention Mask, Diffusion, Image Synthesis}
}

@article{10.1145/3703157,
author = {Adhikari, Saugat and Yan, Da and Jiang, Zhe and Han, Jiao and Xu, Zelin and Zhang, Yupu and Sainju, Arpan and Zhou, Yang},
title = {Scaling Terrain-Aware Spatial Machine Learning for Flood Mapping on Large Scale Earth Imagery Data},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2374-0353},
url = {https://doi.org/10.1145/3703157},
doi = {10.1145/3703157},
abstract = {The accurate and prompt mapping of flood-affected regions is important for effective disaster management, including damage assessment and relief efforts. While high-resolution optical imagery from satellites during disasters presents an opportunity for automated flood inundation mapping, existing segmentation models face challenges due to noises like cloud cover and tree canopies. Thanks to the digital elevation model (DEM) data readily available from sources such as United States Geological Survey (USGS), terrain guidance was utilized by recent graphical models such as hidden Markov trees (HMTs) to improve segmentation quality. Unfortunately, these methods either can only handle a small area where water levels at different locations are assumed to be consistent, or require restricted assumptions such as there is only one river channel. This paper presents an algorithm for flood extent mapping on large-scale Earth imagery, applicable to a large geographic area with multiple river channels. Since water level can vary a lot from upstream to downstream, we propose to detect river pixels in order to partition the remaining pixels into localized zones, each with a unique water level. In each zone, water at all locations flow to the same river entry point. Pixels in each zone are organized by an HMT to capture water flow directions guided by elevations. Moreover, a novel regularization scheme is designed to enforce inter-zone consistency by penalizing pixel-pairs of adjacent zones that violate terrain guidance. Efficient parallelization is made possible by coloring the zone adjacency graph to identify zones and zone-pairs that have no dependency and hence can be processed in parallel, and incremental one-pass terrain-guided scanning is conducted wherever applicable to reuse computations. Experiments demonstrate that our solution is more accurate than existing solutions, and can efficiently and accurately map out flooding pixels in a giant area of size 24,805 \texttimes{} 40,129. Despite the imbalanced workloads caused by a few large zonal HMTs dominating the serial computing time, our parallelization approach is effective and manages to achieve up to 14.3 \texttimes{} speedup on a machine with Intel Xeon Gold 6126 CPU @ 2.60GHz (24 cores, 48 threads) using 32 threads.},
note = {Just Accepted},
journal = {ACM Trans. Spatial Algorithms Syst.},
month = nov,
keywords = {Flood Extent Mapping, Digital Elevation Model, Parallelization}
}

@article{10.1145/3703162,
author = {Connolly, Randy},
title = {Public Computing Intellectuals in the Age of AI Crisis},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {4},
url = {https://doi.org/10.1145/3703162},
doi = {10.1145/3703162},
abstract = {The belief that AI technology is on the cusp of causing a generalized social crisis became a popular one in 2023. While there was no doubt an element of hype and exaggeration to some of these accounts, they do reflect the fact that there are troubling ramifications to this technology stack. This conjunction of shared concerns about social, political, and personal futures presaged by current developments in AI presents the academic discipline of computing with a renewed opportunity for self-examination and reconfiguration. This position article endeavors to do so in four sections. The first section explores what is at stake for computing in the narrative of an AI crisis. The second section articulates possible educational responses to this crisis and advocates for a broader analytic focus on power relations. The third section presents a novel characterization of academic computing’s field of practice, one which includes not only the discipline’s usual instrumental forms of practice but reflexive practice as well. This reflexive dimension integrates both the critical and public functions of the discipline as equal intellectual partners and a necessary component of any contemporary academic field. The final section will advocate for a conceptual archetype—the Public Computer Intellectual and its less conspicuous but still essential cousin, the Almost-Public Computer Intellectual—as a way of practically imagining the expanded possibilities of academic practice in our discipline, one that provides both self-critique and an outward-facing orientation toward the public good. It will argue that the computer education research community can play a vital role in this regard. Recommendations for pedagogical change within computing to develop more reflexive capabilities are also provided.},
journal = {ACM Trans. Comput. Educ.},
month = dec,
articleno = {53},
numpages = {26},
keywords = {AI, ethics, social issues, crisis, intellectuals, critique, public good, critical theory, social theory}
}

@proceedings{10.1145/3703187,
title = {CISAI '24: Proceedings of the 2024 7th International Conference on Computer Information Science and Artificial Intelligence},
year = {2024},
isbn = {9798400707254},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@article{10.1145/3703405,
author = {Chugunov, Ilya},
title = {The Inverse Problems You Carry in Your Pocket},
year = {2025},
issue_date = {Winter 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {2},
issn = {1528-4972},
url = {https://doi.org/10.1145/3703405},
doi = {10.1145/3703405},
abstract = {In the spaces between data-hungry generative models and measurement-rich computational imaging, we can find the field of computational photography. Can cell phone cameras be an accessible and affordable bridge between modern computer vision and traditional inverse imaging problems?},
journal = {XRDS},
month = jan,
pages = {44–49},
numpages = {6}
}

@proceedings{10.1145/3703412,
title = {AIMLSystems '24: Proceedings of the 4th International Conference on AI-ML Systems},
year = {2024},
isbn = {9798400711619},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3703465,
title = {NSPW '24: Proceedings of the New Security Paradigms Workshop},
year = {2024},
isbn = {9798400711282},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3703619,
title = {VRCAI '24: Proceedings of the 19th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and its Applications in Industry},
year = {2024},
isbn = {9798400713484},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Nanjing, Guangdong Province, China}
}

@article{10.1145/3703626,
author = {Wang, Tao and Zhang, Yushu and Qi, Shuren and Zhao, Ruoyu and Xia, Zhihua and Weng, Jian},
title = {Security and Privacy on Generative Data in AIGC: A Survey},
year = {2024},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3703626},
doi = {10.1145/3703626},
abstract = {The advent of artificial intelligence-generated content (AIGC) represents a pivotal moment in the evolution of information technology. With AIGC, it can be effortless to generate high-quality data that is challenging for the public to distinguish. Nevertheless, the proliferation of generative data across cyberspace brings security and privacy issues, including privacy leakages of individuals and media forgery for fraudulent purposes. Consequently, both academia and industry begin to emphasize the trustworthiness of generative data, successively providing a series of countermeasures for security and privacy. In this survey, we systematically review the security and privacy on generative data in AIGC, particularly for the first time analyzing them from the perspective of information security properties. Specifically, we reveal the successful experiences of state-of-the-art countermeasures in terms of the foundational properties of privacy, controllability, authenticity, and compliance, respectively. Finally, we show some representative benchmarks, present a statistical analysis, and summarize the potential exploration directions from each of these properties.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {82},
numpages = {34},
keywords = {Information security, AIGC, generative data, privacy, controllability, authenticity, compliance}
}

@proceedings{10.1145/3703790,
title = {IoT '24: Proceedings of the 14th International Conference on the Internet of Things},
year = {2024},
isbn = {9798400712852},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3703847,
title = {SHWID '24: Proceedings of the 2024 International Conference on Smart Healthcare and Wearable Intelligent Devices},
year = {2024},
isbn = {9798400709746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3704137,
title = {ICAAI '24: Proceedings of the 2024 8th International Conference on Advances in Artificial Intelligence},
year = {2024},
isbn = {9798400718014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3704217,
title = {ESET '24: Proceedings of the 2024 8th International Conference on E-Society, E-Education and E-Technology},
year = {2024},
isbn = {9798400707094},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3704239,
title = {ICHSM '24: Proceedings of the 2024 7th International Conference on Healthcare Service Management},
year = {2024},
isbn = {9798400710162},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3704253,
title = {PEPM '25: Proceedings of the 2025 ACM SIGPLAN International Workshop on Partial Evaluation and Program Manipulation},
year = {2025},
isbn = {9798400713507},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are pleased to present the proceedings of the 2025 ACM SIGPLAN Workshop on Partial Evaluation and Program Manipulation (PEPM 2025), held in Denver, Colorado, January 21st, 2025, in affiliation with the annual Symposium on Principles of Programming Languages (POPL 2025). PEPM has a history going back to 1991, and originates in the discoveries of practically useful automated techniques for evaluating programs with only partial input. Over the years, the scope of PEPM has expanded to include a variety of research areas centered around the theme of semantics-based program manipulation --- the systematic exploitation of treating programs not only as subject to black-box execution, but also as data structures that can be generated, analyzed, and transformed while establishing or maintaining important semantic properties.},
location = {Denver, CO, USA}
}

@proceedings{10.1145/3704289,
title = {ICBDE '24: Proceedings of the 2024 7th International Conference on Big Data and Education},
year = {2024},
isbn = {9798400716980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3704323,
title = {ICCPR '24: Proceedings of the 2024 13th International Conference on Computing and Pattern Recognition},
year = {2024},
isbn = {9798400717482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3704391,
title = {ITCC '24: Proceeding of the 2024 6th International Conference on Information Technology and Computer Communications},
year = {2024},
isbn = {9798400717789},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@article{10.1145/3704437,
author = {Lautrup, Anton Danholt and Hyrup, Tobias and Zimek, Arthur and Schneider-Kamp, Peter},
title = {Systematic Review of Generative Modelling Tools and Utility Metrics for Fully Synthetic Tabular Data},
year = {2024},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3704437},
doi = {10.1145/3704437},
abstract = {Sharing data with third parties is essential for advancing science, but it is becoming more and more difficult with the rise of data protection regulations, ethical restrictions, and growing fear of misuse. Fully synthetic data, which transcends anonymisation, may be the key to unlocking valuable untapped insights stored away in secured data vaults. This review examines current synthetic data generation methods and their utility measurement. We found that more traditional generative models such as Classification and Regression Tree models alongside Bayesian Networks remain highly relevant and are still capable of surpassing deep learning alternatives like Generative Adversarial Networks. However, our findings also display the same lack of agreement on metrics for evaluation, uncovered in earlier reviews, posing a persistent obstacle to advancing the field. We propose a tool for evaluating the utility of synthetic data and illustrate how it can be applied to three synthetic data generation models. By streamlining evaluation and promoting agreement on metrics, researchers can explore novel methods and generate compelling results that will convince data curators and lawmakers to embrace synthetic data. Our review emphasises the potential of synthetic data and highlights the need for greater collaboration and standardisation to unlock its full potential.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {90},
numpages = {38},
keywords = {Synthetic data, generative modelling, tabular data, models and metrics, utility and privacy, model benchmark, privacy enhancing technologies}
}

@proceedings{10.1145/3704440,
title = {Middleware '24: Proceedings of the 25th International Middleware Conference: Demos, Posters and Doctoral Symposium},
year = {2024},
isbn = {9798400713545},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hong Kong, Hong Kong}
}

@proceedings{10.1145/3704522,
title = {NSysS '24: Proceedings of the 11th International Conference on Networking, Systems, and Security},
year = {2024},
isbn = {9798400711589},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3704558,
title = {CFIMA '24: Proceedings of the 2024 2nd International Conference on Frontiers of Intelligent Manufacturing and Automation},
year = {2024},
isbn = {9798400710681},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3704814,
title = {CSAE '24: Proceedings of the 8th International Conference on Computer Science and Application Engineering},
year = {2024},
isbn = {9798400718090},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@article{10.1145/3704902,
author = {Blaudeau, Cl\'{e}ment and R\'{e}my, Didier and Radanne, Gabriel},
title = {Avoiding Signature Avoidance in ML Modules with Zippers},
year = {2025},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {POPL},
url = {https://doi.org/10.1145/3704902},
doi = {10.1145/3704902},
abstract = {We present ZipML, a new path-based type system for a fully fledged ML-module language that avoids the signature avoidance problem. This is achieved by introducing floating fields, which act as additional fields of a signature, invisible to the user but still accessible to the typechecker. In practice, they are handled as zippers on signatures, and can be seen as a lightweight extension of existing signatures. Floating fields allow to delay the resolution of instances of the signature avoidance problem as long as possible or desired. Since they do not exist at runtime, they can be simplified along type equivalence, and dropped once they became unreachable. We give four rules for the simplification of floating fields without loss of type-sharing and present an algorithm that implements those rules. Remaining floating fields may fully disappear at signature ascription, especially in the presence of toplevel interfaces. Residual unavoidable floating fields can be shown to the user as a last resort, improving the quality of error messages. Besides, ZipML implements early and lazy strengthening, as well as lazy inlining of definitions, preventing duplication of signatures inside the typechecker. The correctness of the type system is proved by elaboration into M𝜔 , which has itself been proved sound by translation to F𝜔. ZipML has been designed to be an improvement over OCaml that could be retrofitted into the existing implementation.},
journal = {Proc. ACM Program. Lang.},
month = jan,
articleno = {66},
numpages = {30},
keywords = {ML, Modules, OCaml, Signature avoidance, Strengthening, Zippers}
}

@article{10.1145/3704912,
author = {Poiret, Josselin and Gilbert, Ga\"{e}tan and Maillard, Kenji and P\'{e}drot, Pierre-Marie and Sozeau, Matthieu and Tabareau, Nicolas and Tanter, \'{E}ric},
title = {All Your Base Are Belong to Us: Sort Polymorphism for Proof Assistants},
year = {2025},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {POPL},
url = {https://doi.org/10.1145/3704912},
doi = {10.1145/3704912},
abstract = {Proof assistants based on dependent type theory, such as Coq, Lean and Agda, use different universes to classify types, typically combining a predicative hierarchy of universes for computationally-relevant types, and an impredicative universe of proof-irrelevant propositions. In general, a universe is characterized by its sort, such as Type or Prop, and its level, in the case of a predicative sort. Recent research has also highlighted the potential of introducing more sorts in the type theory of the proof assistant as a structuring means to address the coexistence of different logical or computational principles, such as univalence, exceptions, or definitional proof irrelevance. This diversity raises concrete and subtle issues from both theoretical and practical perspectives. In particular, in order to avoid duplicating definitions to inhabit all (combinations of) universes, some sort of polymorphism is needed. Universe level polymorphism is well-known and effective to deal with hierarchies, but the handling of polymorphism between sorts is currently ad hoc and limited in all major proof assistants, hampering reuse and extensibility. This work develops sort polymorphism and its metatheory, studying in particular monomorphization, large elimination, and parametricity. We implement sort polymorphism in Coq and present examples from a new sort-polymorphic prelude of basic definitions and automation. Sort polymorphism is a natural solution that effectively addresses the limitations of current approaches and prepares the ground for future multi-sorted type theories.},
journal = {Proc. ACM Program. Lang.},
month = jan,
articleno = {76},
numpages = {29},
keywords = {proof assistants, type theory}
}

@article{10.1145/3704922,
author = {Garcia, Cristiano Mesquita and Abilio, Ramon and Koerich, Alessandro Lameiras and Britto, Alceu de Souza and Barddal, Jean Paul},
title = {Concept Drift Adaptation in Text Stream Mining Settings: A Systematic Review},
year = {2025},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {2},
issn = {2157-6904},
url = {https://doi.org/10.1145/3704922},
doi = {10.1145/3704922},
abstract = {The society produces textual data online in several ways, e.g., via reviews and social media posts. Therefore, numerous researchers have been working on discovering patterns in textual data that can indicate peoples’ opinions, interests, and so on. Most tasks regarding natural language processing are addressed using traditional machine learning methods and static datasets. This setting can lead to several problems, e.g., outdated datasets and models, which degrade in performance over time. This is particularly true regarding concept drift, in which the data distribution changes over time. Furthermore, text streaming scenarios also exhibit further challenges, such as the high speed at which data arrive over time. Models for stream scenarios must adhere to the aforementioned constraints while learning from the stream, thus storing texts for limited periods and consuming low memory. This study presents a systematic literature review regarding concept drift adaptation in text stream scenarios. Considering well-defined criteria, we selected 48 papers published between 2018 and August 2024 to unravel aspects such as text drift categories, detection types, model update mechanisms, stream mining tasks addressed, and text representation methods and their update mechanisms. Furthermore, we discussed drift visualization and simulation and listed real-world datasets used in the selected papers. Finally, we brought forward a discussion on existing works in the area, also highlighting open challenges and future research directions for the community.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = feb,
articleno = {27},
numpages = {67},
keywords = {Concept drift, text stream mining, semantic shift, representation shift, drift detection}
}

@article{10.1145/3705300,
author = {Xu, Xiaodan and Ni, Chao and Guo, Xinrong and Liu, Shaoxuan and Wang, Xiaoya and Liu, Kui and Yang, Xiaohu},
title = {Distinguishing LLM-generated from Human-written Code by Contrastive Learning},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3705300},
doi = {10.1145/3705300},
abstract = {Large language models (LLMs), such as ChatGPT released by OpenAI, have attracted significant attention from both industry and academia due to their demonstrated ability to generate high-quality content for various tasks. Despite the impressive capabilities of LLMs, there are growing concerns regarding their potential risks in various fields, such as news, education, and software engineering. Recently, several commercial and open-source LLM-generated content detectors have been proposed, which, however, are primarily designed for detecting natural language content without considering the specific characteristics of program code. This paper aims to fill this gap by proposing a novel ChatGPT-generated code detector, CodeGPTSensor, based on a contrastive learning framework and a semantic encoder built with UniXcoder. To assess the effectiveness of CodeGPTSensor on differentiating ChatGPT-generated code from human-written code, we first curate a large-scale Human and Machine comparison Corpus (HMCorp), which includes 550K pairs of human-written and ChatGPT-generated code (i.e., 288K Python code pairs and 222K Java code pairs). Based on the HMCorp dataset, our qualitative and quantitative analysis of the characteristics of ChatGPT-generated code reveals the challenge and opportunity of distinguishing ChatGPT-generated code from human-written code with their representative features. Our experimental results indicate that CodeGPTSensor can effectively identify ChatGPT-generated code, outperforming all selected baselines.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
keywords = {Large Language Model, ChatGPT, AI-generated Code Detection, Contrastive Learning}
}

@article{10.1145/3705302,
author = {Zhang, Lehuan and Guo, Shikai and Guo, Yi and Li, Hui and Chai, Yu and Chen, Rong and Li, Xiaochen and Jiang, He},
title = {Context-based Transfer Learning for Structuring Fault Localization and Program Repair Automation},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3705302},
doi = {10.1145/3705302},
abstract = {Automated software debugging plays a crucial role in aiding software developers to swiftly identify and attempt to rectify faults, thereby significantly reducing developers’ workload. Previous researches have predominantly relied on simplistic semantic deep learning or statistical analysis methods to locate faulty statements in diverse projects. However, code repositories often consist of lengthy sequences with long-distance dependencies, posing challenges for accurately modeling fault localization using these methods. In addition, the lack of joint reasoning among various faults prevents existing models from deeply capturing fault information. To address these challenges, we propose a method named CodeHealer to achieve accurate fault localization and program repair. CodeHealer comprises three components: a Deep Semantic Information Extraction Component that effectively extracts deep semantic features from suspicious code statements using classifiers based on Joint-attention mechanisms; a Suspicious Statement Ranking Component that combines various fault localization features and employs multilayer perceptrons to derive multidimensional vectors of suspicion values; and a Fault Repair Component that, based on ranked suspicious statements generated by fault localization, adopts a top-down approach using multiple classifiers based on Co-teaching mechanisms to select repair templates and generate patches. The experimental results indicate that when applied to fault localization, CodeHealer outperforms the best baseline method with improvements of 11.4\%, 2.7\%, and 1.6\% on Top-1/3/5 metrics, respectively. It also reduces the MFR and MAR by 9.8\% and 2.1\%, where lower values denote better fault localization effectiveness. Additionally, in automated software debugging, CodeHealer fixes an additional 6 faults compared to the current best method, totaling 53 faults repaired.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = nov,
keywords = {Software debugging, Fault Localization, Transfer learning}
}

@article{10.1145/3705306,
author = {Reiss, Steven P. and Wei, Xuan and Yuan, Jiahao and Xin, Qi},
title = {ROSE: An IDE-Based Interactive Repair Framework for Debugging},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3705306},
doi = {10.1145/3705306},
abstract = {Debugging is costly. Automated program repair (APR) holds the promise of reducing its cost by automatically fixing errors. However, current techniques are not easily applicable in a realistic debugging scenario because they assume a high-quality test suite and frequent program re-execution, have low repair efficiency, and only handle a limited set of errors. To improve the practicality of APR for debugging, we propose ROSE, an interactive repair framework that is able to suggest quick and effective repairs of semantic errors while debugging in an Integrated Development Environment (IDE). ROSE allows an easy integration of existing APR patch generators and can do program repair without assuming the existence of a test suite and without requiring program re-execution. It works in conjunction with an IDE debugger and assumes a debugger stopping point where a problem symptom is observed. ROSE asks the developer to quickly describe the symptom. Then it uses the stopping point, the identified symptom, and the current environment to identify potentially faulty lines, uses a variety of APR techniques to suggest repairs at those lines, and validates those repairs without re-executing the program. Finally, it presents the results so the developer can examine, select, and make the appropriate repair. ROSE uses novel approaches to achieve effective fault localization and patch validation without a test suite or program re-execution. For fault localization, ROSE builds on a fast abstract-interpretation-based flow analysis to compute a static backward slice approximating the real dynamic slice while taking into account the symptom and the current execution. For patch validation without re-running the program, ROSE generates simulated traces based on a live-programming system for both the original and repaired executions and compares the traces with respect to the problem symptoms to infer patch correctness. We implemented a prototype of ROSE that works in an Eclipse-based IDE and evaluated its potency and utility with an effectiveness study and a user study. We found that ROSE's fault localization and validation are highly effective and a ROSE-based tool using existing APR patch generators generated correct repair suggestions for many errors in only seconds. Moreover, the user study demonstrated that ROSE was helpful for debugging and developers liked to use it.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = nov,
keywords = {Debugging, Interactive Repair Framework, Automated Program Repair, Integrated Development Environment}
}

@article{10.1145/3705308,
author = {Chen, Xiangxiang and Lin, Xingwei and Wang, Jingyi and Sun, Jun and Wang, Jiashui and Wang, Wenhai},
title = {Scuzer: A Scheduling Optimization Fuzzer for TVM},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3705308},
doi = {10.1145/3705308},
abstract = {The concept of deep learning (DL) compiler was proposed to deploy DL models more efficiently on diverse hardware through optimization techniques. As one of the most popular DL compilers, TVM incorporates three levels (high-level, schedule, and low-level) of optimizations, which can inadvertently introduce code logic bugs and build failure bugs. Among these optimizations, scheduling optimization is the core component of DL compilers, which ensures the acceleration of models on all devices. However, the existing works only focus on the testing of high-level and low-level optimizations in TVM, fail to take the most important and challenging intermediate scheduling optimization layer into consideration.To fill the gap, we propose a Scheduling optimization oriented fuzzer for TVM, named Scuzer, which is specially designed to effectively detect bugs introduced by the scheduling optimization. In particular, Scuzer first proposes a set of schedule-triggering mutators to actively trigger many scheduling optimizations. Meanwhile, observing that scheduling optimization is closely coupled with program data flow and operator type, Scuzer additionally proposes a set of structure-enriching mutators to enrich the structure of data flows and operators. Based on these carefully designed mutators, Scuzer then devises a multi-objective algorithm that can adaptively select different combinations of objectives at each period to guide the selection of seeds and mutators during fuzzing. We conduct extensive experiments comparing with three state-of-the-art fuzzers that can be applied in testing scheduling optimization to evaluate the effectiveness of Scuzer. The experimental results demonstrate that Scuzer outperforms the 2nd-best state-of-the-art fuzzer by 7.4\% in edge coverage and achieves 7 (times)  improvement in rule-operator coverage. Scuzer has successfully detected 17 previously unknown bugs (9 are inconsistent results and 5 are inconsistent compilations) in TVM, out of which 10 have been confirmed and 5 been fixed.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
keywords = {Deep Learning Compiler, Fuzzing, Scheduling Optimization, TVM}
}

@proceedings{10.1145/3705391,
title = {ICTCE '24: Proceedings of the 2024 6th International Conference on Telecommunications and Communication Engineering},
year = {2024},
isbn = {9798400709630},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3705618,
title = {DECS '24: Proceedings of the 2024 International Conference on Digital Economy and Computer Science},
year = {2024},
isbn = {9798400711855},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@article{10.1145/3705727,
author = {Tang, Zuoli and Huan, Zhaoxin and Li, Zihao and Zhang, Xiaolu and Hu, Jun and Fu, Chilin and Zhou, Jun and Zou, Lixin and Li, Chenliang},
title = {One Model for All: Large Language Models are Domain-Agnostic Recommendation Systems},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1046-8188},
url = {https://doi.org/10.1145/3705727},
doi = {10.1145/3705727},
abstract = {Sequential recommendation systems aim to predict users’ next likely interaction based on their history. However, these systems face data sparsity and cold-start problems. Utilizing data from other domains, known as multi-domain methods, is useful for alleviating these problems. However, traditional multi-domain methods rely on meaningless ID-based item representation, which makes it difficult to align items with similar meanings from different domains, yielding sup-optimal knowledge transfer. This paper introduces LLM-Rec, a framework that utilizes pre-trained large language models (LLMs) for domain-agnostic recommendation. Specifically, we mix user's behaviors from multiple domains and concatenate item titles into a sentence, then use LLMs for generating user and item representations. By mixing behaviors across different domains, we can exploit the knowledge encoded in LLMs to bridge the semantic across over multi-domain behaviors, thus obtaining semantically rich representations and improving performance in all domains. Furthermore, we explore the underlying reasons why LLMs are effective and investigate whether LLMs can understand the semantic correlations as the recommendation model, and if advanced techniques like scaling laws in NLP also work in recommendations. We conduct extensive experiments with LLMs ranging from 40M to 6.7B to answer the above questions and to verify the effectiveness of LLM-Rec in multi-domain recommendation ({}^{ddagger}) .},
note = {Just Accepted},
journal = {ACM Trans. Inf. Syst.},
month = nov,
keywords = {Large Language Model, Multi-Domain Recommendation, Sequential Recommendation}
}

@proceedings{10.1145/3705754,
title = {CECCT '24: Proceedings of the 2024 2nd International Conference on Electronics, Computers and Communication Technology},
year = {2024},
isbn = {9798400710193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3705927,
title = {DMIP '24: Proceedings of the 2024 7th International Conference on Digital Medicine and Image Processing},
year = {2024},
isbn = {9798400709586},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3706468,
title = {LAK '25: Proceedings of the 15th International Learning Analytics and Knowledge Conference},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3706628,
title = {FPGA '25: Proceedings of the 2025 ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
year = {2025},
isbn = {9798400713965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 33rd ACM/SIGDA International Symposium on Field-Programmable Gate Arrays (FPGA 2025)! We are thrilled to host the premier forum for the presentation of new and exciting research across various facets of FPGA technology. These include:Novel FPGA architectures and circuits.Advances in CAD tools for FPGAs, in areas such as technology mapping, placement, and routing.High-level design methodologies that permit FPGA design at higher levels of abstraction.New applications for FPGAs, particularly for energy-efficient and high-performance computation.Uses of FPGAs in reconfigurable computing, datacenter, and cloud.AI and Machine Learning on and for FPGAs.This year, our program committee diligently reviewed 82 papers with 27\% of them earning acceptance for presentation. The symposium spans three days: Saturday features 8 invited tutorials and workshops, while the main event on Thursday and Friday includes 17 full research papers (10 pages), 5 short research papers (6 pages), and 2 invited keynotes. Keynote abstracts are published in the proceedings. Additionally, 21 submissions are presented as posters, appearing in the proceedings as extended abstracts (1 page). We encourage you to make the most of live presentations, engage with authors and fellow researchers during breaks and poster sessions, and take advantage of social opportunities offered by an in-person conference.},
location = {Monterey, CA, USA}
}

@proceedings{10.1145/3706890,
title = {ISAIMS '24: Proceedings of the 2024 5th International Symposium on Artificial Intelligence for Medicine Science},
year = {2024},
isbn = {9798400717826},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3707127,
title = {ICBBE '24: Proceedings of the 2024 11th International Conference on Biomedical and Bioinformatics Engineering},
year = {2024},
isbn = {9798400718274},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3707292,
title = {AIIIP '24: Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Intelligent Information Processing},
year = {2024},
isbn = {9798400707308},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@article{10.1145/3707457,
author = {Vitale, Antonio and Oliveto, Rocco and Scalabrino, Simone},
title = {A Catalog of Data Smells for Coding Tasks},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3707457},
doi = {10.1145/3707457},
abstract = {Large Language Models (LLMs) are increasingly becoming fundamental in supporting software developers in coding tasks. The massive datasets used for training LLMs are often collected automatically, leading to the introduction of data smells. Previous work addressed this issue by using quality filters to handle some specific smells. Still, the literature lacks a systematic catalog of the data smells for coding tasks currently known. This paper presents a Systematic Literature Review (SLR) focused on articles that introduce LLMs for coding tasks. We first extracted the quality filters adopted for training and testing such LLMs, inferred the root problem behind their adoption (data smells for coding tasks), and defined a taxonomy of such smells. Our results highlight discrepancies in the adoption of quality filters between pre-training and fine-tuning stages and across different coding tasks, shedding light on areas for improvement in LLM-based software development support.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
keywords = {LLMs for coding tasks, data smells, data quality, Systematic Literature Review}
}

@proceedings{10.1145/3708036,
title = {ICCSMT '24: Proceedings of the 2024 5th International Conference on Computer Science and Management Technology},
year = {2024},
isbn = {9798400709999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3708282,
title = {AITC '24: Proceedings of the 2024 International Conference on Artificial Intelligence of Things and Computing},
year = {2024},
isbn = {9798400709869},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3708359,
title = {IUI '25: Proceedings of the 30th International Conference on Intelligent User Interfaces},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3708360,
title = {ICMML '24: Proceedings of the 2024 International Conference on Mathematics and Machine Learning},
year = {2024},
isbn = {9798400711657},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3708394,
title = {AIFE '24: Proceeding of the 2024 International Conference on Artificial Intelligence and Future Education},
year = {2024},
isbn = {9798400710650},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3708468,
title = {HotMobile '25: Proceedings of the 26th International Workshop on Mobile Computing Systems and Applications},
year = {2025},
isbn = {9798400714030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {La Quinta, CA, USA}
}

@article{10.1145/3708473,
author = {Manke, Ruchira and Wardat, Mohammad and Khomh, Foutse and Rajan, Hridesh},
title = {Leveraging Data Characteristics for Bug Localization in Deep Learning Programs},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3708473},
doi = {10.1145/3708473},
abstract = {Deep Learning (DL) is a class of machine learning algorithms that are used in a wide variety of applications. Like any software system, DL programs can have bugs. To support bug localization in DL programs, several tools have been proposed in the past. As most of the bugs that occur due to improper model structure known as structural bugs lead to inadequate performance during training, it is challenging for developers to identify the root cause and address these bugs. To support bug detection and localization in DL programs, in this paper, we propose Theia, which detects and localizes structural bugs in DL programs. Unlike the previous works, Theia considers the training dataset characteristics to automatically detect bugs in DL programs developed using two deep learning libraries, Keras and PyTorch. Since training the DL models is a time-consuming process, Theia detects these bugs at the beginning of the training process and alerts the developer with informative messages containing the bug's location and actionable fixes which will help them to improve the structure of the model. We evaluated Theia on a benchmark of 40 real-world buggy DL programs obtained from Stack Overflow. Our results show that Theia successfully localizes 57/75 structural bugs in 40 buggy programs, whereas NeuraLint, a state-of-the-art approach capable of localizing structural bugs before training localizes 17/75 bugs.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
keywords = {deep learning bugs, bug localization, debugging, program analysis}
}

@proceedings{10.1145/3708493,
title = {CC '25: Proceedings of the 34th ACM SIGPLAN International Conference on Compiler Construction},
year = {2025},
isbn = {9798400714078},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 34th ACM SIGPLAN International Conference on Compiler Construction (CC 2025), held in Las Vegas, Nevada, USA over March 1-2, 2025. As has been the case for the last 10 years, CC is part of a co-located cluster together with IEEE HPCA, IEEE/ACM CGO, and ACM PPoPP. The co-location brings together researchers with complementary expertise in compilation, architecture, and parallel programming, creating a thriving and unique ecosystem for scientific discovery and advancement.},
location = {Las Vegas, NV, USA}
}

@inproceedings{10.1145/3708493.3712686,
author = {Italiano, Davide and Cummins, Chris},
title = {Finding Missed Code Size Optimizations in Compilers using Large Language Models},
year = {2025},
isbn = {9798400714078},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708493.3712686},
doi = {10.1145/3708493.3712686},
abstract = {Compilers are complex, and significant effort has been expended on testing them. Techniques such as random program generation and differential testing have proved highly effective and have uncovered thousands of bugs in production compilers. The majority of effort has been expended on validating that a compiler produces correct code for a given input, while less attention has been paid to ensuring that the compiler produces performant code. In this work we adapt differential testing to the task of identifying missed optimization opportunities in compilers. We develop a novel testing approach which combines large language models (LLMs) with a series of differential testing strategies and use them to find missing code size optimizations in C / C++ compilers. The advantage of our approach is its simplicity. We offload the complex task of generating random code to an off-the-shelf LLM, and use heuristics and analyses to identify anomalous compiler behavior. Our approach requires fewer than 150 lines of code to implement. This simplicity makes it extensible. By simply changing the target compiler and initial LLM prompt we port the approach from C / C++ to Rust and Swift, finding bugs in both. To date we have reported 24 confirmed bugs in production compilers, and conclude that LLM-assisted testing is a promising avenue for detecting optimization bugs in real world compilers.},
booktitle = {Proceedings of the 34th ACM SIGPLAN International Conference on Compiler Construction},
pages = {81–91},
numpages = {11},
keywords = {compiler testing, large language models},
location = {Las Vegas, NV, USA},
series = {CC '25}
}

@article{10.1145/3708518,
author = {Widyasari, Ratnadira and Zhang, Ting and Bouraffa, Abir and Maalej, Walid and Lo, David},
title = {Explaining Explanations: An Empirical Study of Explanations in Code Reviews},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3708518},
doi = {10.1145/3708518},
abstract = {Code reviews are central for software quality assurance. Ideally, reviewers should explain their feedback to enable authors of code changes to understand the feedback and act accordingly. Different developers might need different explanations in different contexts. Therefore, assisting this process first requires understanding the types of explanations reviewers usually provide. The goal of this paper is to study the types of explanations used in code reviews and explore the potential of Large Language Models (LLMs), specifically ChatGPT, in generating these specific types. We extracted 793 code review comments from Gerrit and manually labeled them based on whether they contained a suggestion, an explanation, or both. Our analysis shows that 42\% of comments only include suggestions without explanations. We categorized the explanations into seven distinct types including rule or principle, similar examples, and future implications. When measuring their prevalence, we observed that some explanations are used differently by novice and experienced reviewers. Our manual evaluation shows that, when the explanation type is specified, ChatGPT can correctly generate the explanation in 88 out of 90 cases. This foundational work highlights the potential for future automation in code reviews, which can assist developers in sharing and obtaining different types of explanations as needed, thereby reducing back-and-forth communication.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
keywords = {code review, explanation, empirical study, large language model}
}

@article{10.1145/3708519,
author = {Lyu, Michael R. and Ray, Baishakhi and Roychoudhury, Abhik and Tan, Shin Hwei and Thongtanunam, Patanamon},
title = {Automatic Programming: Large Language Models and Beyond},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3708519},
doi = {10.1145/3708519},
abstract = {Automatic programming has seen increasing popularity due to the emergence of tools like GitHub Copilot which rely on Large Language Models (LLMs). At the same time, automatically generated code faces challenges during deployment due to concerns around quality and trust. In this article, we study automated coding in a general sense and study the concerns around code quality, security and related issues of programmer responsibility. These are key issues for organizations while deciding on the usage of automatically generated code. We discuss how advances in software engineering such as program repair and analysis can enable automatic programming. We conclude with a forward looking view, focusing on the programming environment of the near future, where programmers may need to switch to different roles to fully utilize the power of automatic programming. Automated repair of automatically generated programs from LLMs, can help produce higher assurance code from LLMs, along with evidence of assurance.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
keywords = {AI-based coding, Automated Program Repair, Trustworthy Software}
}

@article{10.1145/3708521,
author = {Li, Rui and Liu, Huai and Poon, Pak-Lok and Towey, Dave and Sun, Chang-Ai and Zheng, Zheng and Zhou, Zhi Quan and Chen, Tsong Yueh},
title = {Metamorphic Relation Generation: State of the Art and Research Directions},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3708521},
doi = {10.1145/3708521},
abstract = {Metamorphic testing has become one mainstream technique to address the notorious oracle problem in software testing, thanks to its great successes in revealing real-life bugs in a wide variety of software systems. Metamorphic relations, the core component of metamorphic testing, have continuously attracted research interests from both academia and industry. In the last decade, a rapidly increasing number of studies have been conducted to systematically generate metamorphic relations from various sources and for different application domains. In this article, based on the systematic review on the state of the art for metamorphic relations’ generation, we summarize and highlight visions for further advancing the theory and techniques for identifying and constructing metamorphic relations, and discuss promising research directions in related areas.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
keywords = {Metamorphic testing, Metamorphic relation, Metamorphic relation generation}
}

@article{10.1145/3708522,
author = {Zhou, Xin and Cao, Sicong and Sun, Xiaobing and Lo, David},
title = {Large Language Model for Vulnerability Detection and Repair: Literature Review and the Road Ahead},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3708522},
doi = {10.1145/3708522},
abstract = {The significant advancements in Large Language Models (LLMs) have resulted in their widespread adoption across various tasks within Software Engineering (SE), including vulnerability detection and repair. Numerous studies have investigated the application of LLMs to enhance vulnerability detection and repair tasks. Despite the increasing research interest, there is currently no existing survey that focuses on the utilization of LLMs for vulnerability detection and repair. In this paper, we aim to bridge this gap by offering a systematic literature review of approaches aimed at improving vulnerability detection and repair through the utilization of LLMs. The review encompasses research work from leading SE, AI, and Security conferences and journals, encompassing 43 papers published across 25 distinct venues, along with 15 high-quality preprint papers, bringing the total to 58 papers. By answering three key research questions, we aim to (1) summarize the LLMs employed in the relevant literature, (2) categorize various LLM adaptation techniques in vulnerability detection, and (3) classify various LLM adaptation techniques in vulnerability repair. Based on our findings, we have identified a series of limitations of existing studies. Additionally, we have outlined a roadmap highlighting potential opportunities that we believe are pertinent and crucial for future research endeavors.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
keywords = {Literature review, vulnerability detection, vulnerability repair, large language models}
}

@article{10.1145/3708530,
author = {Zhao, Yanjie and Hou, Xinyi and Wang, Shenao and Wang, Haoyu},
title = {LLM App Store Analysis: A Vision and Roadmap},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3708530},
doi = {10.1145/3708530},
abstract = {The rapid growth and popularity of large language model (LLM) app stores have created new opportunities and challenges for researchers, developers, users, and app store managers. As the LLM app ecosystem continues to evolve, it is crucial to understand the current landscape and identify potential areas for future research and development. This paper presents a forward-looking analysis of LLM app stores, focusing on key aspects such as data mining, security risk identification, development assistance, and market dynamics. Our comprehensive examination extends to the intricate relationships between various stakeholders and the technological advancements driving the ecosystem’s growth. We explore the ethical considerations and potential societal impacts of widespread LLM app adoption, highlighting the need for responsible innovation and governance frameworks. By examining these aspects, we aim to provide a vision for future research directions and highlight the importance of collaboration among stakeholders to address the challenges and opportunities within the LLM app ecosystem. The insights and recommendations provided in this paper serve as a foundation for driving innovation, ensuring responsible development, and creating a thriving, user-centric LLM app landscape.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec
}

@proceedings{10.1145/3708557,
title = {IUI '25 Companion: Companion Proceedings of the 30th International Conference on Intelligent User Interfaces},
year = {2025},
isbn = {9798400714092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3708568,
title = {VSIP '24: Proceedings of the 2024 6th International Conference on Video, Signal and Image Processing},
year = {2024},
isbn = {9798400709647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3708597,
title = {ICACS '24: Proceedings of the 2024 8th International Conference on Algorithms, Computing and Systems},
year = {2024},
isbn = {9798400718304},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3708778,
title = {CIIS '24: Proceedings of the 2024 7th International Conference on Computational Intelligence and Intelligent Systems},
year = {2024},
isbn = {9798400717437},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3709025,
title = {CSLAW '25: Proceedings of the 2025 Symposium on Computer Science and Law},
year = {2025},
isbn = {9798400714214},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Munich, Germany}
}

@inproceedings{10.1145/3709025.3712206,
author = {Xiao, Madelyne and Sellars, Andrew and Scheffler, Sarah},
title = {When Anti-Fraud Laws Become a Barrier to Computer Science Research},
year = {2025},
isbn = {9798400714214},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3709025.3712206},
doi = {10.1145/3709025.3712206},
abstract = {Computer science research sometimes brushes with the law, from red-team exercises that probe the boundaries of authentication mechanisms, to AI research processing copyrighted material, to platform research measuring the behavior of algorithms and users. U.S.-based computer security research is no stranger to the Computer Fraud and Abuse Act (CFAA) and the Digital Millennium Copyright Act (DMCA) in a relationship that is still evolving through case law, research practices, changing policies, and legislation.Amid the landscape computer scientists, lawyers, and policymakers have learned to navigate, anti-fraud laws are a surprisingly under-examined challenge for computer science research. Fraud brings separate issues that are not addressed by the methods for navigating CFAA, DMCA, and Terms of Service that are more familiar in the computer security literature. Although anti-fraud laws have been discussed to a limited extent in older research on phishing attacks, modern computer science researchers are left with little guidance when it comes to navigating issues of deception outside the context of pure laboratory research.In this paper, we analyze and taxonomize the anti-fraud and deception issues that arise in several areas of computer science research. We find that, despite the lack of attention to these issues in the legal and computer science literature, issues of misrepresented identity or false information that could implicate anti-fraud laws are actually relevant to many methodologies used in computer science research, including penetration testing, web scraping, user studies, sock puppets, social engineering, auditing AI or socio-technical systems, and attacks on artificial intelligence. We especially highlight the importance of anti-fraud laws in two particular research fields that are of great policy importance in the current moment: attacking or auditing AI systems, and research involving legal identification.Finally, guided by principles in research ethics, we suggest methods for computer scientists to navigate fraud and identity issues, as well as possible legal paths forward for policymakers to consider.},
booktitle = {Proceedings of the 2025 Symposium on Computer Science and Law},
pages = {1–16},
numpages = {16},
keywords = {computer science research, deception, ethics, fraud, law, methodology},
location = {Munich, Germany},
series = {CSLAW '25}
}

@inproceedings{10.1145/3709025.3712208,
author = {Goodyear, Michael P.},
title = {Artificial Infringement},
year = {2025},
isbn = {9798400714214},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3709025.3712208},
doi = {10.1145/3709025.3712208},
abstract = {By examining the historical and doctrinal response of copyright law to new technologies, this Article offers a new analytical framework for determining liability for what it terms artificial infringement, or infringing outputs created by generative AI systems. Time and again, new technologies have posed challenges to existing copyright law, straining its capacity to balance protecting authors' rights to incentivize new expression and providing public access to their works. Courts and Congress have been able to maintain this balance by using a variety of doctrinal tools, including fair use, compulsory licensing, and secondary liability. One underexamined tool, however, is the refinement of direct liability. This Article reveals how courts introduced the causation requirement to maintain copyright's balance in response to complex machine-generated infringements.Together, direct liability's causation requirement and other doctrinal tools provide a viable framework for maintaining copyright's incentives-access balance despite the acute challenges of artificial infringement. By holding the AI system directly liable, courts can utilize and refine secondary liability doctrines to conduct a more nuanced analysis of user and developer liability for AI-generated infringements. Along with fair use, these refinements to copyright doctrine provide a more comprehensive resolution to the battles between copyright and AI.},
booktitle = {Proceedings of the 2025 Symposium on Computer Science and Law},
pages = {26–38},
numpages = {13},
location = {Munich, Germany},
series = {CSLAW '25}
}

@proceedings{10.1145/3709026,
title = {CSAI '24: Proceedings of the 2024 8th International Conference on Computer Science and Artificial Intelligence},
year = {2024},
isbn = {9798400718182},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@article{10.1145/3709153,
author = {Sprint, Gina and Schmitter-Edgecombe, Maureen and Weaver, Raven and Wiese, Lisa and Cook, Diane J.},
title = {CogProg: Utilizing Large Language Models to Forecast In-the-moment Health Assessment},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3709153},
doi = {10.1145/3709153},
abstract = {Forecasting future health status is beneficial for understanding health patterns and providing anticipatory support for cognitive and physical health difficulties. In recent years, generative large language models (LLMs) have shown promise as forecasters. Though not traditionally considered strong candidates for numeric tasks, LLMs demonstrate emerging abilities to address various forecasting problems. They also provide the ability to incorporate unstructured information and explain their reasoning process. In this paper, we explore whether LLMs can effectively forecast future self-reported health state. To do this, we utilized in-the-moment assessments of mental sharpness, fatigue, and stress from multiple studies, utilizing daily responses (N=106 participants) and responses that are accompanied by text descriptions of activities (N=32 participants). With these data, we constructed prompt/response pairs to predict a participant’s next answer. We fine-tuned several LLMs and applied chain-of-thought prompting evaluating forecasting accuracy and prediction explainability. Notably, we found that LLMs achieved the lowest mean absolute error (MAE) overall (0.851), while gradient boosting achieved the lowest overall root mean squared error (RMSE) (1.356). When additional text context was provided, LLM forecasts achieved the lowest MAE for predicting mental sharpness (0.862), fatigue (1.000), and stress (0.414). These multimodal LLMs further outperformed the numeric baselines in terms of RMSE when predicting stress (0.947), although numeric algorithms achieved the best RMSE results for mental sharpness (1.246) and fatigue (1.587). This study offers valuable insights for future applications of LLMs in health-based forecasting. The findings suggest that LLMs, when supplemented with additional text information, can be effective tools for improving health forecasting accuracy.},
note = {Just Accepted},
journal = {ACM Trans. Comput. Healthcare},
month = dec,
keywords = {Cognitive health, ecological momentary assessment, forecasting, large language models}
}

@article{10.1145/3709358,
author = {Fan, Lishui and Liu, Jiakun and Liu, Zhongxin and Lo, David and Xia, Xin and Li, Shanping},
title = {Exploring the Capabilities of LLMs for Code Change Related Tasks},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3709358},
doi = {10.1145/3709358},
abstract = {Developers deal with code-change-related tasks daily, e.g., reviewing code. Pre-trained code and code-change-oriented models have been adapted to help developers with such tasks. Recently, large language models (LLMs) have shown their effectiveness in code-related tasks. However, existing LLMs for code focus on general code syntax and semantics rather than the differences between two code versions. Thus, it is an open question how LLMs perform on code-change-related tasks.To answer this question, we conduct an empirical study using &gt;1B parameters LLMs on three code-change-related tasks, i.e., code review generation, commit message generation, and just-in-time comment update, with in-context learning (ICL) and parameter-efficient fine-tuning (PEFT, including LoRA and prefix-tuning). We observe that the performance of LLMs is poor without examples and generally improves with examples, but more examples do not always lead to better performance. LLMs tuned with LoRA have comparable performance to the state-of-the-art small pre-trained models. Larger models are not always better, but Llama 2 and Code Llama families are always the best. The best LLMs outperform small pre-trained models on the code changes that only modify comments and perform comparably on other code changes. We suggest future work should focus more on guiding LLMs to learn the knowledge specific to the changes related to code rather than comments for code-change-related tasks.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
keywords = {Code-change-related task, large language model, empirical study}
}

@article{10.1145/3709679,
author = {Yin, Ziqi and Gao, Jianyang and Balsebre, Pasquale and Cong, Gao and Long, Cheng},
title = {DEG: Efficient Hybrid Vector Search Using the Dynamic Edge Navigation Graph},
year = {2025},
issue_date = {February 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {1},
url = {https://doi.org/10.1145/3709679},
doi = {10.1145/3709679},
abstract = {Bimodal data, such as image-text pairs, has become increasingly prevalent in the digital era. The Hybrid Vector Query (HVQ) is an effective approach for querying such data and has recently garnered considerable attention from researchers. It calculates similarity scores for objects represented by two vectors using a weighted sum of each individual vector's similarity, with a query-specific parameter α to determine the weight. Existing methods for HVQ typically construct Approximate Nearest Neighbors Search (ANNS) indexes with a fixed α value. This leads to significant performance degradation when the query's α dynamically changes based on the different scenarios and needs.In this study, we introduce the Dynamic Edge Navigation Graph ( DEG ), a graph-based ANNS index that maintains efficiency and accuracy with changing α values. It includes three novel components: (1) a greedy Pareto frontier search algorithm to compute a candidate neighbor set for each node, which comprises the node's approximate nearest neighbors for all possible α values; (2) a dynamic edge pruning strategy to determine the final edges from the candidate set and assign each edge an active range. This active range enables the dynamic use of the Relative Neighborhood Graph's pruning strategy based on the query's α values, skipping redundant edges at query time and achieving a better accuracy-efficiency trade-off; and (3) an edge seed method that accelerates the querying process. Extensive experiments on real-world datasets show that DEG demonstrates superior performance compared to existing methods under varying α values.},
journal = {Proc. ACM Manag. Data},
month = feb,
articleno = {29},
numpages = {28},
keywords = {approximate nearest neighbor search, graph-based index, hybrid vector search}
}

@article{10.1145/3709681,
author = {Omar, Reham and Mangukiya, Omij and Mansour, Essam},
title = {Dialogue Benchmark Generation from Knowledge Graphs with Cost-Effective Retrieval-Augmented LLMs},
year = {2025},
issue_date = {February 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {1},
url = {https://doi.org/10.1145/3709681},
doi = {10.1145/3709681},
abstract = {Dialogue benchmarks are crucial in training and evaluating chatbots engaging in domain-specific conversations. Knowledge graphs (KGs) represent semantically rich and well-organized data spanning various domains, such as DBLP, DBpedia, and YAGO. Traditionally, dialogue benchmarks have been manually created from documents, neglecting the potential of KGs in automating this process. Some question-answering benchmarks are automatically generated using extensive preprocessing from KGs, but they do not support dialogue generation. This paper introduces Chatty-Gen, a novel multi-stage retrieval-augmented generation platform for automatically generating high-quality dialogue benchmarks tailored to a specific domain using a KG. Chatty-Gen decomposes the generation process into manageable stages and uses assertion rules for automatic validation between stages. Our approach enables control over intermediate results to prevent time-consuming restarts due to hallucinations. It also reduces reliance on costly and more powerful commercial LLMs. Chatty-Gen eliminates upfront processing of the entire KG using efficient query-based retrieval to find representative subgraphs based on the dialogue context. Our experiments with several real and large KGs demonstrate that Chatty-Gen significantly outperforms state-of-the-art systems and ensures consistent model and system performance across multiple LLMs of diverse capabilities, such as GPT-4o, Gemini 1.5, Llama 3, and Mistral.},
journal = {Proc. ACM Manag. Data},
month = feb,
articleno = {31},
numpages = {26},
keywords = {assertion-based validation, benchmarking, conversational question answering, cost-effecive inference, graph serialization, knowledge graphs (kgs), large language models (llms), retrieval-augumented generation (rag)}
}

@article{10.1145/3709734,
author = {Ko, Ronny and Xiao, Chuan and Onizuka, Makoto and Lin, Zhiqiang and Huang, Yihe},
title = {Ultraverse: An Efficient What-if Analysis Framework for Software Applications Interacting with Database Systems},
year = {2025},
issue_date = {February 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {1},
url = {https://doi.org/10.1145/3709734},
doi = {10.1145/3709734},
abstract = {Existing what-if analysis systems are predominantly tailored to operate on either only the application layer or only the database layer of software. This isolated approach limits their effectiveness in scenarios where intensive interaction between applications and database systems occurs. To address this gap, we introduce Ultraverse, a what-if analysis framework that seamlessly integrates both application and database layers. Ultraverse employs dynamic symbolic execution to effectively translate application code into compact SQL procedure representations, thereby synchronizing application semantics at both SQL and application levels during what-if replays. A novel aspect of Ultraverse is its use of advanced query dependency analysis, which serves two key purposes: (1) it eliminates the need to replay irrelevant transactions that do not influence the outcome, and (2) it facilitates parallel replay of mutually independent transactions, significantly enhancing the analysis efficiency. Ultraverse is applicable to existing unmodified database systems and legacy application codes. Our extensive evaluations of the framework have demonstrated remarkable improvements in what-if analysis speed, achieving performance gains ranging from 7.7x to 291x across diverse benchmarks.},
journal = {Proc. ACM Manag. Data},
month = feb,
articleno = {84},
numpages = {27},
keywords = {data provenance, query dependency analysis, what-if analysis}
}

@proceedings{10.1145/3710848,
title = {PPoPP '25: Proceedings of the 30th ACM SIGPLAN Annual Symposium on Principles and Practice of Parallel Programming},
year = {2025},
isbn = {9798400714436},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Las Vegas, NV, USA}
}

@proceedings{10.1145/3711129,
title = {EITCE '24: Proceedings of the 2024 8th International Conference on Electronic Information Technology and Computer Engineering},
year = {2024},
isbn = {9798400710094},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3711403,
title = {ICETM '24: Proceedings of the 2024 7th International Conference on Educational Technology Management},
year = {2024},
isbn = {9798400717468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3711496,
title = {ICVRT '24: Proceedings of the 2024 International Conference on Virtual Reality Technology},
year = {2024},
isbn = {9798400710186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@article{10.1145/3711667,
author = {Boz, Artun and Zorgdrager, Wouter and Kotti, Zoe and Harte, Jesse and Louridas, Panos and Karakoidas, Vassilios and Jannach, Dietmar and Fragkoulis, Marios},
title = {Improving Sequential Recommendations with LLMs},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711667},
doi = {10.1145/3711667},
abstract = {The sequential recommendation problem has attracted considerable research attention in the past few years, leading to the rise of numerous recommendation models. In this work, we explore how Large Language Models (LLMs), which are nowadays introducing disruptive effects in many AI-based applications, can be used to build or improve sequential recommendation approaches. Specifically, we design three orthogonal approaches and hybrids of those to leverage the power of LLMs in different ways. In addition, we investigate the potential of each approach by focusing on its comprising technical aspects and determining an array of alternative choices for each one. We conduct extensive experiments on three datasets and explore a large variety of configurations, including different language models and baseline recommendation models, to obtain a comprehensive picture of the performance of each approach. Among other observations, we highlight that initializing state-of-the-art sequential recommendation models such as BERT4Rec or SASRec with embeddings obtained from an LLM can lead to substantial performance gains in terms of accuracy. Furthermore, we find that fine-tuning an LLM for recommendation tasks enables it to learn not only the tasks, but also concepts of a domain to some extent. We also show that fine-tuning OpenAI GPT leads to considerably better performance than fine-tuning Google PaLM 2. Overall, our extensive experiments indicate a huge potential value of leveraging LLMs in future recommendation approaches. We publicly share the code and data of our experiments to ensure reproducibility.},
note = {Just Accepted},
journal = {ACM Trans. Recomm. Syst.},
month = jan,
keywords = {Recommender Systems, Large Language Models, Sequential Recommendation, Evaluation}
}

@article{10.1145/3711903,
author = {Song, Leo and Ding, Steven H. H. and Tian, Yuan and Li, Li Tao and Ou, Weihan and Charland, Philippe and Walenstein, Andrew},
title = {Obfuscated Clone Search in JavaScript based on Reinforcement Subsequence Learning},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3711903},
doi = {10.1145/3711903},
abstract = {Finding similar code is important for software engineering, defense of intellectual property, and security, and one of the increasingly common ways adversaries use to defeat the detection of similar code is through obfuscations such as code transformation and scattering the code they wish to hide amongst long sequences. Moving code far enough apart poses a specific challenge for solutions with localized features (e.g., n-grams) or attention mechanisms as the code parts are distributed beyond the local context window. We introduce a neural network solution pattern called “Cybertron” that addresses this problem by utilizing reinforcement learning to train a code abstraction and summarization function; this converts arbitrarily long code into fixed-length real vectors in a way that is optimized for similarity search. The key to the design is the smart selection of important elements of the code and abstraction to preserve semantic function while minimizing syntactic feature information. We evaluated the approach on a three-challenge benchmark of obfuscated JavaScript, a scripting language that is commonly obfuscated and for which code-mixing is a rising challenge. The evaluation shows our approach identifies obfuscated code within even large scripts with an AUC of 78\%, which outperforms current state-of-the-art sequence models by 7-35\%.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = feb,
keywords = {Clone Search, Deep Learning, Code Obfuscation}
}

@article{10.1145/3712003,
author = {He, Junda and Treude, Christoph and Lo, David},
title = {LLM-Based Multi-Agent Systems for Software Engineering: Literature Review, Vision and the Road Ahead},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3712003},
doi = {10.1145/3712003},
abstract = {Integrating Large Language Models (LLMs) into autonomous agents marks a significant shift in the research landscape by offering cognitive abilities that are competitive with human planning and reasoning. This paper explores the transformative potential of integrating Large Language Models into Multi-Agent (LMA) systems for addressing complex challenges in software engineering (SE). By leveraging the collaborative and specialized abilities of multiple agents, LMA systems enable autonomous problem-solving, improve robustness, and provide scalable solutions for managing the complexity of real-world software projects. In this paper, we conduct a systematic review of recent primary studies to map the current landscape of LMA applications across various stages of the software development lifecycle (SDLC). To illustrate current capabilities and limitations, we perform two case studies to demonstrate the effectiveness of state-of-the-art LMA frameworks. Additionally, we identify critical research gaps and propose a comprehensive research agenda focused on enhancing individual agent capabilities and optimizing agent synergy. Our work outlines a forward-looking vision for developing fully autonomous, scalable, and trustworthy LMA systems, laying the foundation for the evolution of Software Engineering 2.0.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
keywords = {Large Language Models, Autonomous Agents, Multi-Agent Systems, Software Engineering}
}

@article{10.1145/3712005,
author = {Gao, Cuiyun and Hu, Xing and Gao, Shan and Xia, Xin and Jin, Zhi},
title = {The Current Challenges of Software Engineering in the Era of Large Language Models},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3712005},
doi = {10.1145/3712005},
abstract = {With the advent of large language models (LLMs) in the artificial intelligence (AI) area, the field of software engineering (SE) has also witnessed a paradigm shift. These models, by leveraging the power of deep learning and massive amounts of data, have demonstrated an unprecedented capacity to understand, generate, and operate programming languages. They can assist developers in completing a broad spectrum of software development activities, encompassing software design, automated programming, and maintenance, which potentially reduces huge human efforts. Integrating LLMs within the SE landscape (LLM4SE) has become a burgeoning trend, necessitating exploring this emergent landscape’s challenges and opportunities.The paper aims at revisiting the software development life cycle (SDLC) under LLMs, and highlighting challenges and opportunities of the new paradigm. The paper first summarizes the overall process of LLM4SE, and then elaborates on the current challenges based on a through discussion. The discussion was held among more than 20 participants from academia and industry, specializing in fields such as software engineering and artificial intelligence. Specifically, we achieve 26 key challenges from seven aspects, including software requirement \&amp; design, coding assistance, testing code generation, code review, code maintenance, software vulnerability management, and data, training, and evaluation. We hope the achieved challenges would benefit future research in the LLM4SE field.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
keywords = {Large Language Models, Challenges, LLM4SE}
}

@proceedings{10.1145/3712031,
title = {HPCASIA '25: Proceedings of the International Conference on High Performance Computing in Asia-Pacific Region},
year = {2025},
isbn = {9798400713354},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@article{10.1145/3712063,
author = {Sun, Zhengwentai and Zhou, Yanghong and Mok, P. Y.},
title = {CoDE-GAN: Content Decoupled and Enhanced GAN for Sketch-guided Flexible Fashion Editing},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1551-6857},
url = {https://doi.org/10.1145/3712063},
doi = {10.1145/3712063},
abstract = {Rapid advancements in generative models, including generative adversarial networks (GANs) and diffusion models, have made possible of automated image editing through the use of text descriptions, semantic segmentation, and/or reference style images. Nevertheless, in terms of fashion image editing, it often requires more flexible, and typically iterative, modifications to the image content that existing methods struggle to achieve. This paper proposes a new model called Content Decoupled and Enhanced GAN (CoDE-GAN), which is formulated and trained for the task of image editing, drawing on methods from image reconstruction, more specifically, image inpainting with sketch-guidance. Through this proxy task, the trained model can be used for flexible image editing, generating new images with consistent colours and required textures based on sketch inputs. In this new model, a content decoupling block is introduced including specially designed dual encoders, which pre-process inputs and transform into separated structure and texture representations. Moreover, a content enhancing module is designed and applied to the decoder, improving the colour consistency and refining the texture of the generated images. The proposed CoDE-GAN can achieve coarse-to-fine results in one single stage. Extensive experiments on three datasets, covering human, garment-only and scene images, show that CoDE-GAN outperforms other state-of-the-art methods in terms of both generated image quality and editing flexibility. The code and dataset are available at:},
note = {Just Accepted},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = jan,
keywords = {Fashion image editing, content decoupling, content enhancement, GAN-based}
}

@article{10.1145/3712187,
author = {Pian, Weiguo and Li, Yinghua and Tian, Haoye and Sun, Tiezhu and Song, Yewei and Tang, Xunzhu and Habib, Andrew and Klein, Jacques and Bissyand\'{e}, Tegawend\'{e} F.},
title = {You Don’t Have to Say Where to Edit! jLED – Joint Learning to Localize and Edit Source Code},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3712187},
doi = {10.1145/3712187},
abstract = {Learning to edit code automatically is becoming more and more feasible. Thanks to recent advances in Neural Machine Translation (NMT), various case studies are being investigated where patches are automatically produced and assessed either automatically (using test suites) or by developers themselves. An appealing setting remains when the developer must provide a natural language input of the requirement for the code change. A recent proof of concept in the literature showed that it is indeed feasible to translate these natural language requirements into code changes. A recent advancement, MODIT [8], has shown promising results in code editing by leveraging natural language, code context, and location information as input. However, it struggles when location information is unavailable. While several studies [29, 81] have demonstrated the ability to edit source code without explicitly specifying the edit location, they still tend to generate edits with less accuracy at the line level. In this work, we address the challenge of generating code edits without precise location information, a scenario we consider crucial for the practical adoption of NMT in code development. To that end, we develop a novel joint training approach for both localization and source code editions. Building a benchmark based on over 70k commits (patches and messages), we demonstrate that our jLED (joint Localize and EDit) approach is effective. An ablation study further demonstrates the importance of our design choice in joint training.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
keywords = {Source Code Edition, Joint Learning, Automated Programming, Neural Machine Translation}
}

@article{10.1145/3712188,
author = {Nan, Siyu and Wang, Jian and Zhang, Neng and Li, Duantengchuan and Li, Bing},
title = {DDASR: Deep Diverse API Sequence Recommendation},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3712188},
doi = {10.1145/3712188},
abstract = {Recommending API sequences is crucial in software development, saving developers time and effort. While previous studies primarily focus on accuracy, often recommending popular APIs, they tend to overlook less frequent, or ‘tail,’ APIs. This oversight, often a result of limited historical data, consequently diminishes the diversity of recommender systems. In this paper, we propose DDASR, a framework for recommending API sequences containing both popular and tail APIs. To accurately capture developer intent, we utilize recent Large Language Models for learning query representations. To gain a better understanding of tail APIs, DDASR clusters tail APIs with similar functionality and replaces them with cluster centers to produce a pseudo ground truth. Moreover, a loss function is defined based on learning-to-rank to achieve an equilibrium in accuracy and diversity due to the inherent trade-off between them. To evaluate DDASR, we conduct extensive experiments on Java and Python open-source datasets. Results demonstrate that DDASR significantly achieves the best diversity without sacrificing accuracy. Compared to seven state-of-the-art approaches, DDASR improves accuracy metrics BLEU, ROUGE, MAP, and NDCG and diversity metric coverage by 108.28\%, 67.30\%, 88.59\%, and 45.83\%, respectively on the Java dataset, as well as 9.83\%, 2.45\%, 8.06\%, and 8.03\%, respectively on the Python dataset.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
keywords = {API Sequence Recommendation, Long-tail Distribution, Clustering, Diversity}
}

@article{10.1145/3712190,
author = {Fu, Michael and Pasuksmit, Jirat and Tantithamthavorn, Chakkrit},
title = {AI for DevSecOps: A Landscape and Future Opportunities},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3712190},
doi = {10.1145/3712190},
abstract = {DevOps has emerged as one of the most rapidly evolving software development paradigms. With the growing concerns surrounding security in software systems, the DevSecOps paradigm has gained prominence, urging practitioners to incorporate security practices seamlessly into the DevOps workflow. However, integrating security into the DevOps workflow can impact agility and impede delivery speed. Recently, the advancement of artificial intelligence (AI) has revolutionized automation in various software domains, including software security. AI-driven security approaches, particularly those leveraging machine learning or deep learning, hold promise in automating security workflows. They have the potential to reduce manual efforts and can be incorporated into DevOps practices to support consistent delivery speed while aligning with the principles of the DevSecOps paradigm. This paper seeks to contribute to the critical intersection of AI and DevSecOps by presenting a comprehensive landscape of AI-driven security techniques applicable to DevOps and identifying avenues for enhancing security, trust, and efficiency in software development processes. We analyzed 99 research papers spanning from 2017 to 2023. Specifically, we address two key research questions (RQs). In RQ1, we identified 12 security tasks associated with the DevSecOps process and reviewed existing AI-driven security approaches, the problems they addressed, and the 65 benchmarks used to evaluate those approaches. Drawing insights from our findings, in RQ2, we discussed state-of-the-art AI-driven security approaches, highlighted 15 challenges in existing research, and proposed 15 corresponding avenues for future opportunities.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
keywords = {DevOps, DevSecOps, Artificial Intelligence, Deep Learning, Machine Learning, AI Security, Vulnerability, Supply Chain Security}
}

@article{10.1145/3712191,
author = {Wang, Taiming and Liu, Hui and Zhang, Yuxia and Jiang, Yanjie},
title = {Recommending Variable Names for Extract Local Variable Refactorings},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3712191},
doi = {10.1145/3712191},
abstract = {Extract local variable is one of the most popular refactorings. It is frequently employed to replace occurrences of a complex expression with simple accesses to a newly introduced variable that is initialized by the original complex expression. Consequently, most IDEs and refactoring tools provide automated support for this refactoring, e.g., to suggest names for the newly extracted variables. However, we find approximately 70\% of the names recommended by these IDEs are different from what developers manually constructed, adding additional renaming burdens to developers and providing limited assistance. In this paper, we introduce VarNamer, an automated approach designed to recommend variable names for extract local variable refactorings. Through a large-scale empirical study, we identify key contexts, such as variable initializations and homogeneous variables (variables whose initializations are identical to that of the newly extracted variable), that are useful for composing variable names. Leveraging these insights, we developed a set of heuristic rules through program static analysis techniques, e.g., lexical analysis, syntax analysis, control flow analysis, and data flow analysis, and employ data mining techniques, i.e., FP-growth algorithm, to recommend variable names effectively. Notably, some of our heuristic rules have been successfully integrated into Eclipse, where they are now distributed with the latest releases of the IDE. Evaluation of VarNamer on a dataset of 27,158 real-world extract local variable refactorings in Java applications demonstrates its superiority over state-of-the-art IDEs. Specifically, VarNamer significantly increases the chance of exact match by 52.6\% compared to Eclipse and 40.7\% compared to IntelliJ IDEA. We also evaluated the proposed approach with real-world extract local variable refactorings conducted in C++ projects, and the results suggest that the approach can achieve comparable performance on programming languages besides Java. It may suggest the generalizability of VarNamer. Finally, we designed and conducted a user study to investigate the impact of VarNamer on developers’ productivity. The results of the user study suggest that our approach can speed up the refactoring by 27.8\% and reduce 49.3\% edits on the recommended variable names.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
keywords = {Refactoring, Extract Local Variable, Name Recommendation, IDE}
}

@article{10.1145/3712195,
author = {He, Zilong and Chen, Pengfei and Zheng, Zibin},
title = {On the Practicability of Deep Learning based Anomaly Detection for Modern Online Software Systems: A Pre-Train-and-Align Framework},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3712195},
doi = {10.1145/3712195},
abstract = {Operation and maintenance are critical activities in the whole life cycle of modern online software systems, and anomaly detection is a crucial step of these activities. Recent studies mainly develop deep learning techniques to complete this task. Notably, though these techniques have achieved promising results in experimental evaluations, there are still several practicality gaps for them to be successfully applied in a real-world online system, including the scalability gap, availability gap and alignment gap. To bridge these gaps, we propose an anomaly detection framework, namely ShareAD, based on a pre-train-and-align paradigm. Specifically, we argue that pre-training a shared model for anomaly detection is an effective way to bridge the scalability gap and the availability gap. To support this argument, we systematically study the necessity and feasibility of model sharing for online system maintenance. We further propose a novel model based upon Transformer encoder layers and Base layers, which works well for anomaly detection pre-training. Then, to bridge the alignment gap, we propose ShareAD alignment to align the pre-trained model with operator preference by jointly considering the local observation context and sensitivity of each monitor entity. Extensive experiments on two real-world large-scale datasets demonstrate the effectiveness and practicality of ShareAD.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
keywords = {anomaly detection, deep learning, pre-training, preference alignment, online software systems}
}

@article{10.1145/3712277,
author = {Chiu, Ka Ho and Yin, Handi and Zhuo, Weipeng and Lee, Chul-Ho and Chan, S.-H. Gary},
title = {Graph-based Fingerprint Update Using Unlabelled WiFi Signals},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {1},
url = {https://doi.org/10.1145/3712277},
doi = {10.1145/3712277},
abstract = {WiFi received signal strength (RSS) environment evolves over time due to the movement of access points (APs), AP power adjustment, installation and removal of APs, etc. We study how to effectively update an existing database of fingerprints, defined as the RSS values of APs at designated locations, using a batch of newly collected unlabelled (possibly crowdsourced) WiFi signals. Prior art either estimates the locations of the new signals without updating the existing fingerprints or filters out the new APs without sufficiently embracing their features. To address that, we propose GUFU, a novel effective graph-based approach to update WiFi fingerprints using unlabelled signals with possibly new APs. Based on the observation that similar signal vectors likely imply physical proximity, GUFU employs a graph neural network (GNN) and a link prediction algorithm to retrain an incremental network given the new signals and APs. After the retraining, it then updates the signal vectors at the designated locations. Through extensive experiments in four large representative sites, GUFU is shown to achieve remarkably higher fingerprint adaptivity as compared with other state-of-the-art approaches, with error reduction of 21.4\% and 29.8\% in RSS values and location prediction, respectively.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {3},
numpages = {26},
keywords = {Crowdsourcing, Fingerprint update, Graph Neural Network, WiFi Fingerprinting}
}

@proceedings{10.1145/3712335,
title = {SPCNC '24: Proceedings of the 3rd International Conference on Signal Processing, Computer Networks and Communications},
year = {2024},
isbn = {9798400710834},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3712464,
title = {SPCT '24: Proceedings of the 2024 4th International Conference on Signal Processing and Communication Technology},
year = {2024},
isbn = {9798400710636},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3712623,
title = {AAIA '24: Proceedings of the 2024 2nd International Conference on Advances in Artificial Intelligence and Applications},
year = {2024},
isbn = {9798400712883},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@article{10.1145/3712701,
author = {Lee, Seungpil and Sim, Woochang and Shin, Donghyeon and Seo, Wongyu and Park, Jiwon and Lee, Seokki and Hwang, Sanha and Kim, Sejin and Kim, Sundong},
title = {Reasoning Abilities of Large Language Models: In-Depth Analysis on the Abstraction and Reasoning Corpus},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3712701},
doi = {10.1145/3712701},
abstract = {The existing methods for evaluating the inference abilities of Large Language Models (LLMs) have been predominantly results-centric, making it challenging to assess the inference process comprehensively. We introduce a novel approach using the Abstraction and Reasoning Corpus (ARC) benchmark to evaluate the inference and contextual understanding abilities of LLMs in a process-centric manner, focusing on three key components from the Language of Thought Hypothesis (LoTH): Logical Coherence, Compositionality, and Productivity. Our carefully designed experiments reveal that while LLMs demonstrate some inference capabilities, they still significantly lag behind human-level reasoning in these three aspects. The main contribution of this paper lies in introducing the LoTH perspective, which provides a method for evaluating the reasoning process that conventional results-oriented approaches fail to capture, thereby offering new insights into the development of human-level reasoning in artificial intelligence systems.},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = jan,
keywords = {Large Language Models, Abstraction and Reasoning Corpus, Language of Thought Hypothesis, Logical Coherence, Compositionality, Productivity}
}

@article{10.1145/3712704,
author = {Papicchio, Simone and Papotti, Paolo and Cagliero, Luca},
title = {QATCH: Automatic Evaluation of SQL-centric Tasks on Proprietary Data},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3712704},
doi = {10.1145/3712704},
abstract = {Tabular Representation Learning (TRL) and Large Language Models (LLMs) have become established for tackling Question Answering (QA) and Semantic Parsing (SP) tasks on tabular data. State-of-the-art models are pre-trained and evaluated on large open-domain datasets. However, the performance on existing QA and SP benchmarks is not necessarily representative of that achieved on proprietary data as the characteristics of the input and the complexity of the posed queries show high variability. To tackle this challenge, our goal is to allow end-users to evaluate TRL and LLM performance on their own proprietary data. We present QATCH (Query-Aided TRL Checklist), a toolbox to automatically generate a testing checklist tailored to QA and SP. QATCH provides a testing suite highlighting models’ strengths and weaknesses on relational tables unseen at training time. The proposed toolbox relies on a SQL query generator that crafts tests of varying types and complexity including, amongst others, tests on null values, projection, selections, joins, group by, and having clauses. QATCH also supports a set of general cross-task performance metrics providing more insights into SQL-related model capabilities than currently used metrics. The empirical results, achieved by state-of-the-art TRL models and LLMs, show substantial performance differences (1) between existing benchmarks and proprietary data, (2) across queries of different complexity.},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = jan,
keywords = {Tabular Representation Learning, Semantic Parsing, Text2SQL, Table Question Answering, Large Language Models, Query Generation}
}

@article{10.1145/3712710,
author = {Santos, Joana Cristo and Tom\'{a}s Pereira Alexandre, Hugo and Seoane Santos, Miriam and Henriques Abreu, Pedro},
title = {The Role of Deep Learning in Medical Image Inpainting: A Systematic Review},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3712710},
doi = {10.1145/3712710},
abstract = {Image inpainting is a crucial technique in computer vision, particularly for reconstructing corrupted images. In medical imaging, it addresses issues from instrumental errors, artifacts, or human factors. The development of deep learning techniques has revolutionized image inpainting, allowing for the generation of high-level semantic information to ensure structural and textural consistency in restored images. This paper presents a comprehensive review of 53 studies on deep image inpainting in medical imaging, analyzing its evolution, impact, and limitations. The findings highlight the significance of deep image inpainting in artifact removal and enhancing the performance of multi-task approaches by localizing and inpainting regions of interest. Furthermore, the study identifies magnetic resonance imaging and computed tomography as the predominant modalities and highlights generative adversarial networks and U-Net as preferred architectures. Future research directions include the development of blind inpainting techniques, the exploration of techniques suitable for 3D/4D images, multiple artifacts, and multi-task applications, and the improvement of architectures.},
note = {Just Accepted},
journal = {ACM Trans. Comput. Healthcare},
month = jan,
keywords = {Artifact, Deep Learning, Image Inpainting, Medical Imaging, Multi-Task}
}

@proceedings{10.1145/3712716,
title = {DFDS '25: Proceedings of the Digital Forensics Doctoral Symposium},
year = {2025},
isbn = {9798400710766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3714334,
title = {AISNS '24: Proceedings of the 2024 2nd International Conference on Artificial Intelligence, Systems and Network Security},
year = {2024},
isbn = {9798400711237},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@article{10.1145/3714462,
author = {Wang, Chong and Zhang, Jian and Feng, Yebo and Li, Tianlin and Sun, Weisong and Liu, Yang and Peng, Xin},
title = {Teaching Code LLMs to Use Autocompletion Tools in Repository-Level Code Generation},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3714462},
doi = {10.1145/3714462},
abstract = {Recent code large language models (LLMs) have shown promising performance in generating standalone functions. However, they face limitations in repository-level code generation due to their lack of awareness of repository-level dependencies (e.g., user-defined attributes), resulting in dependency errors such as undefined-variable and no-member errors. In this work, we introduce ToolGen, an approach that integrates autocompletion tools into the code LLM generation process to address these dependencies. ToolGen comprises two main phases: Trigger Insertion and Model Fine-tuning (Offline), and Tool-integrated Code Generation (Online). During the offline phase, ToolGen augments functions within a given code corpus with a special mark token, indicating positions to trigger autocompletion tools. These augmented functions, along with their corresponding descriptions, are then used to fine-tune a selected code LLM. In the online phase, ToolGen iteratively generates functions by predicting tokens step-by-step using the fine-tuned LLM. Whenever a mark token is encountered, ToolGen invokes the autocompletion tool to suggest code completions and selects the most appropriate one through constrained greedy search.We conduct comprehensive experiments to evaluate ToolGen’s effectiveness in repository-level code generation across three distinct code LLMs: CodeGPT, CodeT5, and CodeLlama. To facilitate this evaluation, we create a benchmark comprising 671 real-world code repositories and introduce two new dependency-based metrics: Dependency Coverage and Static Validity Rate. The results demonstrate that ToolGen significantly improves Dependency Coverage by 31.4\% to 39.1\% and Static Validity Rate by 44.9\% to 57.7\% across the three LLMs, while maintaining competitive or improved performance in widely recognized similarity metrics such as BLEU-4, CodeBLEU, Edit Similarity, and Exact Match. On the CoderEval dataset, ToolGen achieves improvements of 40.0\% and 25.0\% in test pass rate (Pass@1) for CodeT5 and CodeLlama, respectively, while maintaining the same pass rate for CodeGPT. ToolGen also demonstrates high efficiency in repository-level code generation, with latency ranging from 0.63 to 2.34 seconds for generating each function. Furthermore, our generalizability evaluation confirms ToolGen’s consistent performance when applied to diverse code LLMs, encompassing various model architectures and scales.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
keywords = {repository-level code generation, code LLMs, tool integration}
}

@article{10.1145/3714464,
author = {Williams, Laurie and Benedetti, Giacomo and Hamer, Sivana and Paramitha, Ranindya and Rahman, Imranur and Tamanna, Mahzabin and Tystahl, Greg and Zahan, Nusrat and Morrison, Patrick and Acar, Yasemin and Cukier, Michel and K\"{a}stner, Christian and Kapravelos, Alexandros and Wermke, Dominik and Enck, William},
title = {Research Directions in Software Supply Chain Security},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3714464},
doi = {10.1145/3714464},
abstract = {Reusable software libraries, frameworks, and components, such as those provided by open-source ecosystems and third-party suppliers, accelerate digital innovation. However, recent years have shown almost exponential growth in attackers leveraging these software artifacts to launch software supply chain attacks. Past well-known software supply chain attacks include the SolarWinds, log4j, and xz utils incidents. Supply chain attacks are considered to have three major attack vectors: through vulnerabilities and malware accidentally or intentionally injected into open-source and third-party dependencies/components/containers; by infiltrating the build infrastructure during the build and deployment processes; and through targeted techniques aimed at the humans involved in software development, such as through social engineering. Plummeting trust in the software supply chain could decelerate digital innovation if the software industry reduces its use of open-source and third-party artifacts to reduce risks. This paper contains perspectives and knowledge obtained from intentional outreach with practitioners to understand their practical challenges and from extensive research efforts. We then provide an overview of current research efforts to secure the software supply chain. Finally, we propose a future research agenda to close software supply chain attack vectors and support the software industry.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan
}

@article{10.1145/3714465,
author = {Zhang, Yixuan and Liu, Mugeng and Wang, Haoyu and Ma, Yun and Huang, Gang and Liu, Xuanzhe},
title = {Research on WebAssembly Runtimes: A Survey},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3714465},
doi = {10.1145/3714465},
abstract = {WebAssembly (abbreviated as Wasm) was initially introduced for the Web and quickly extended its reach into various domains beyond the Web. To create Wasm applications, developers can compile high-level programming languages into Wasm binaries or manually write the textual format of Wasm and translate it into Wasm binaries by the toolchain. Regardless of whether it is utilized within or outside the Web, the execution of Wasm binaries is supported by the Wasm runtime. Such a runtime provides a secure, memory-efficient, and sandboxed execution environment to execute Wasm binaries. This paper provides a comprehensive survey of research on Wasm runtimes with 103 collected research papers related to Wasm runtimes following the traditional systematic literature review process. It characterizes existing studies from two different angles, including the internal research of Wasm runtimes (Wasm runtime design, testing, and analysis) and the external research (applying Wasm runtimes to various domains). This paper also proposes future research directions about Wasm runtimes.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
keywords = {WebAssembly, WebAssembly runtime, WebAssembly System Interface}
}

@article{10.1145/3715102,
author = {Li, Cong and Jiang, Yanyan and Xu, Chang and Su, Zhendong},
title = {Validating JIT Compilers via Compilation Space Exploration},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {0734-2071},
url = {https://doi.org/10.1145/3715102},
doi = {10.1145/3715102},
abstract = {We introduce the concept of compilation space as a new pivot for the comprehensive validation of just-in-time (JIT) compilers in modern language virtual machines (LVMs). The compilation space of a program, encompasses a wide range of equivalent JIT-compilation choices, which can be cross-validated to ensure the correctness of the program’s JIT compilations. To thoroughly explore the compilation space in a lightweight and LVM-agnostic manner, we strategically mutate test programs with JIT-relevant but semantics-preserving code constructs, aiming to provoke diverse JIT compilation optimizations. We primarily implement this approach in Artemis, a tool for validating Java Virtual Machines (JVMs). Within three months, Artemis successfully discovered 85 bugs in three widely used production JVMs — HotSpot, OpenJ9, and the Android Runtime — where 53 were already confirmed or fixed and many of which were classified as critical. It is noteworthy that all reported bugs concern JIT compilers, highlighting the effectiveness and practicality of our technique. Building on the promising results with JVMs, we experimentally applied our technique to a state-of-the-art JavaScript Engine (JSE) fuzzer called Fuzzilli, aiming to augment it to find mis-compilation bugs without significantly sacrificing its ability to detect crashes. Our experiments demonstrate that our enhanced version of Fuzzilli namely Apollo could achieve comparable code coverage with a considerably smaller number of generated programs with a similar number of crashes. Additionally, Apollo successfully uncovered four mis-compilations in JavaScriptCore and SpiderMonkey within seven days. Following Artemis’ and Apollo’s success, we are expecting that the generality and practicability of our approach will make it broadly applicable for understanding and validating the JIT compilers of other LVMs.},
note = {Just Accepted},
journal = {ACM Trans. Comput. Syst.},
month = feb,
keywords = {Just-in-time compilers, Java virtual machines, JavaScript engines, testing}
}

@article{10.1145/3715108,
author = {Mo, Ran and Wang, Dongyu and Zhan, Wenjing and Jiang, Yingjie and Wang, Yepeng and Zhao, Yuqi and Li, Zengyang and Ma, Yutao},
title = {Assessing and Analyzing the Correctness of GitHub Copilot’s Code Suggestions},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3715108},
doi = {10.1145/3715108},
abstract = {AI programming has become a popular topic in recent years. Code suggestion, with code suggestion being a key capability of AI programming. Copilot, an “AI programmer” that provides code suggestions from natural language descriptions, has been launched by GitHub and OpenAI. By far, Copilot has been widely used by millions of developers. However, little work has systematically evaluated the correctness of Copilot's suggestions. We conducted an empirical study on all 2,033 LeetCode problems to assess Copilot's code generation across four mainstream languages: C, Java, JavaScript, and Python. We have found that: 1) 70.0\% of problems received at least one correct suggestion, with language-specific rates of 29.7\% (C), 57.7\% (Java), 54.1\% (JavaScript), and 41.0\% (Python); 2) Correctness decreases as problem difficulty increases, with acceptance rates of 89.3\% (Easy), 72.1\% (Medium), and 43.4\% (Hard); 3) Acceptance rates vary across problem domains from 49.5\% to 90.1\%, while Graph problems challenge C and Python most, and Prefix Sum and Heap challenge Java and JavaScript most; 4) For the incorrect suggestions, we further summarize 17 types of error reasons accounting for their incorrectness and analyzed possible causes for why these errors occur. We believe our study can provide valuable insights into Copilot's capabilities and limitations.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
keywords = {Code Suggestion, Github Copilot, LeetCode, Code Error Analysis, Empirical Study}
}

@article{10.1145/3715109,
author = {Wu, Jie Jw and Fard, Fatemeh H.},
title = {HumanEvalComm: Benchmarking the Communication Competence of Code Generation for LLMs and LLM Agent},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3715109},
doi = {10.1145/3715109},
abstract = {Large language models (LLMs) have significantly improved their ability to perform tasks in the field of code generation. However, there is still a gap between LLMs being capable coders and being top-tier software engineers. The most recent trend is using LLM-based agents to iterate the code generation process. Based on the observation that top-level software engineers often ask clarifying questions to reduce Ambiguity in both requirements and coding solutions, we argue that the same should be applied to LLMs for code generation tasks. For this purpose, we define the communication skills of LLMs as “being able to ask clarifying questions when the description of the code generation problem has issues”. In this study, we restrict these issues to three matters from the software requirement engineering field: inconsistent requirements, ambiguous requirements, and incomplete requirements. By asking probing questions about the requirements of problem descriptions before generating the final code, the challenges of programming with LLMs, such as unclear intent specification may be alleviated, resulting to a correct code in the initial iterations.In this work, we conducted an empirical study on the benchmark and analysis of the communication skills of LLMs for code generation. We created a new benchmark, HumanEvalComm, by modifying problem descriptions according to three issues mentioned above, Inconsistency, Ambiguity, Incompleteness. We then experimented on HumanEvalComm with different Code LLMs, and a new LLM agent approach, Code Clarification and Generation Agent (Okanagan), to identify and ask questions in ambiguous parts from code and descriptions for further refining the generated code. In the evaluation, we introduced an LLM-based evaluator and created Communication Rate and Good Question Rate as the evaluation metrics to represent the ratio of questions asked and questions with good quality in responses. We found that more than 60\% of responses from Code LLMs still generate code rather than ask questions when the problem descriptions are manually modified according to different clarification categories. The Pass@1 and Test Pass Rate of most Code LLMs drop by 35\%  (sim)  52\% and by 17\%  (sim)  35\% respectively, with statistical significance in each category for over 75\% numbers. Okanagan, as an LLM agent approach that uses LLM such as ChatGPT 3.5, effectively increases the Communication Rate and Good Question Rate by an absolute 58\% and 38\%, respectively. Thus, Okanagan boosts Pass@1 and Test Pass Rate by an absolute 8\% and 7\%, respectively, when the problem descriptions are modified based on given clarification categories. This result indicates the potential for achieving more effective communication capability using LLM agent. Our benchmark and full code are publicly available at .},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan
}

@article{10.1145/3715111,
author = {Abrah\~{a}o, Silvia and Grundy, John and Pezz\`{e}, Mauro and Storey, Margaret-Anne and Andrew Tamburri, Damian},
title = {Software Engineering by and for Humans in an AI Era},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3715111},
doi = {10.1145/3715111},
abstract = {The landscape of software engineering is undergoing a transformative shift driven by advancements in machine learning, artificial intelligence (AI), and autonomous systems. This roadmap paper explores how these technologies are reshaping the field, positioning humans not only as end users but also as critical components within expansive software ecosystems. We examine the challenges and opportunities arising from this human-centered paradigm, including ethical considerations, fairness, and the intricate interplay between technical and human factors. By recognizing humans at the heart of the software lifecycle —spanning professional engineers, end users, and end-user developers —we emphasize the importance of inclusivity, human-aligned workflows, and the seamless integration of AI-augmented socio-technical systems. As software systems evolve to become more intelligent and human-centric, software engineering practices must adapt to this new reality. This paper provides a comprehensive examination of this transformation, outlining current trends, key challenges, and opportunities that define the emerging research and practice landscape, and envisioning a future where software engineering and AI work synergistically to place humans at the core of the ecosystem.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = feb
}

@article{10.1145/3715326,
author = {Xiao, Zhe and He, Xu and Wu, Haoying and Yu, Bei and Guo, Yang},
title = {EDA-Copilot: A RAG-Powered Intelligent Assistant for EDA Tools},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1084-4309},
url = {https://doi.org/10.1145/3715326},
doi = {10.1145/3715326},
abstract = {With the rise of Large Language Models (LLMs), researchers have become increasingly interested in their applications in EDA flows, particularly in specific subdomains like serving as knowledge assistants and generating RTL code. In this study, we present a Retrieval-Augmented Generation (RAG) framework tailored to EDA task processing, named EDA-Adaptive RAG. This framework addresses the implicit semantics of EDA data and facilitates efficient knowledge acquisition through classification and enhanced retrieval, significantly enhancing LLMs ability to acquire EDA knowledge. Furthermore, we aim to integrate RAG into the design process as an EDA assistant application. Using RTL code generation as a case study, we demonstrate that the performance of RTL code generation can be enhanced through highly relevant retrievals provided by our RAG. The experimental analysis involves EDA Q&amp;A tasks and RTL code generation evaluation. It is shown that our method outperforms the latest works in terms of both answer stability and code quality.},
note = {Just Accepted},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = jan,
keywords = {Large Language Models, Electronic design automation, RTL-to-GDSII, Retrieval-Augmented Generation}
}

@proceedings{10.1145/3715675,
title = {MHV '25: Proceedings of the 4th Mile-High Video Conference},
year = {2025},
isbn = {9798400714887},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the fourth edition of the ACM Mile-High Video Conference (MHV/2025), which serves as a premier platform where professionals from academia and industry come together to showcase, exchange, and explore the latest innovations in multimedia content creation, distribution, and consumption. ACM MHV continues to push the boundaries of video streaming and coding technologies, fostering discussions that shape the future of the field.},
location = {Denver, CO, USA}
}

@proceedings{10.1145/3715885,
title = {ICSeB '24: Proceedings of the 2024 8th International Conference on Software and e-Business},
year = {2024},
isbn = {9798400712463},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@article{10.1145/3715909,
author = {Wu, Chunlian and Chen, Sen and Li, Jiaming and Chai, Renchao and Fan, Lingling and Xie, Xiaofei and Feng, Ruitao},
title = {Beyond Decision: Android Malware Description Generation through Profiling Malicious Behavior Trajectory},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3715909},
doi = {10.1145/3715909},
abstract = {Malware family labels and key features used for the decision-making of Android malware detection models fall short of precise comprehension of malicious behaviors due to their coarse granularity. To solve these problems, in this paper, we first introduce the concept of the malicious behavior trajectory (MBT) and propose an innovative approach called ProMal. ProMal aims to automatically generate malware descriptions with fine granularity through extracted MBTs from malware for users. Specifically, a labeled dataset of MBTs is constructed through substantial human efforts to build a behavioral knowledge graph (BxKG). The BxKG is scalable and can be automatically updated using two strategies to ensure its completeness and timeliness: 1) taking into consideration the evolution of Android SDKs, and 2) mining new MBTs by leveraging the widely-used malware datasets. We highlight that the knowledge graph is essential in ProMal, which can reason new MBTs based on existing MBTs because of its structured data representation and semantic relation modeling, and thus helps effectively extract real MBTs in Android malware. We evaluated ProMal on a recent malware dataset where researcher-crafted malware descriptions are available, and the Precision, Recall, and F1-Score of MBT identification based on BxKG reached 96.97\%, 91.43\%, and 0.94, respectively, outperforming the state-of-the-art approaches. Taking MBTs identified from Android malware as inputs, precise, fine-grained, and human-readable descriptions can be generated using the large language model, whose readability and usability are verified through a user study. The generated descriptions play a significant role in interpreting and comprehending malware behaviors.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
keywords = {Android Malware, Malicious Behavior Analysis, Knowledge Graph}
}

@article{10.1145/3715916,
author = {Wang, Miaohui and Huang, Runnan and Xie, Wuyuan and Ma, Zhan and Ma, Siwei},
title = {Compression Approaches for LiDAR Point Clouds and Beyond: A Survey},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1551-6857},
url = {https://doi.org/10.1145/3715916},
doi = {10.1145/3715916},
abstract = {With the widespread use of LiDAR sensors in autonomous driving, LiDAR point cloud compression (LPCC) plays an important role in effectively managing the storage, transmission, and perception of the growing volume of LiDAR data. Despite this need, there has been a noticeable absence of comprehensive investigations specifically dedicated to LPCC methods. To address this issue, this paper presents a systematic survey of existing LPCCs, aiming to summarize recent progress and inspire future research in this field. We begin by providing a general introduction of LPCC fundamentals, covering the latest LiDAR point cloud (LPC) datasets, distinctive attributes, evaluation metrics, and data formats. We then conduct a careful review and comparison of LPCCs, examining image-based, octree-based, deep-learned, and other approaches, offering valuable insights into the strengths and weaknesses of cutting-edge models. Finally, we propose future research directions based on the limitations of recent LPCCs. We believe that the findings presented in this paper will contribute to a deeper understanding of LPCCs and promote further development of LiDAR sensor-based systems.},
note = {Just Accepted},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = jan,
keywords = {LiDAR point cloud compression, LiDAR data attributes, LiDAR coding survey}
}

@article{10.1145/3716132,
author = {Huang, Tian and Yu, Chun and Shi, Weinan and Peng, Zijian and Yang, David and Sun, Weiqi and Shi, Yuanchun},
title = {Prompt2Task: Automating UI Tasks on Smartphones from Textual Prompts},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1073-0516},
url = {https://doi.org/10.1145/3716132},
doi = {10.1145/3716132},
abstract = {UI task automation enables efficient task execution by simulating human interactions with graphical user interfaces (GUIs), without modifying the existing application code. However, its broader adoption is constrained by the need for expertise in both scripting languages and workflow design. To address this challenge, we present Prompt2Task, a system designed to comprehend various task-related textual prompts (e.g., goals, procedures), thereby generating and performing the corresponding automation tasks. Prompt2Task incorporates a suite of intelligent agents that mimic human cognitive functions, specializing in interpreting user intent, managing external information for task generation, and executing operations on smartphones. The agents can learn from user feedback and continuously improve their performance based on the accumulated knowledge. Experimental results indicated a performance jump from a 22.28\% success rate in the baseline to 95.24\% with Prompt2Task, requiring an average of 0.69 user interventions for each new task. Prompt2Task presents promising applications in fields such as tutorial creation, smart assistance, and customer service.},
note = {Just Accepted},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = feb,
keywords = {UI task automation, UI navigation, natural language, UI understanding, large language models}
}

@article{10.1145/3716135,
author = {Halperin, Brett A. and Rosner, Daniela K.},
title = {‘AI is Soulless’: Hollywood Film Workers Strike and Emerging Perceptions of Generative Cinema},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1073-0516},
url = {https://doi.org/10.1145/3716135},
doi = {10.1145/3716135},
abstract = {Why were Hollywood film workers striking or supporting strikes against artificial intelligence (AI) in 2023? To investigate this question, we conduct participant observation on the picket line and interview 15 film workers, including 12 union members from SAG-AFTRA, WGA, and IATSE, as well as 3 non-unionized workers, across roles. From screenwriting to acting, our interlocutors described how studio use of AI might exacerbate wage squeeze, estrangement from embodied co-creation, rush for results, and inauthentic creativity. We find that film worker resistance to emergent and projected uses of AI echoes earlier technical developments, such as the incorporation of sound, color, HD, DVD, and CGI. These innovations initially sparked anxieties about the demise of cinema, but ultimately created new aesthetic possibilities and professions. We end with a reflection on core concerns for worker engagement, including topics of prophesy and the “soul” of sociotechnical labor.},
note = {Just Accepted},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = feb,
keywords = {AI Art, Artificial Intelligence, Algorithmic Resistance, Cinema, Cinematography, Computational Creativity, Creative Labor, Generative AI, Film, Filmmaking, Future of Work, IATSE, Labor, Labor Organizing, Resistance, Unions, SAG-AFTRA, Soul, Text-to-Image, Text-to-Video, WGA, Work}
}

@article{10.1145/3716500,
author = {Thieme, Anja and Rajamohan, Abhijith and Cooper, Benjamin and Groombridge, Heather and Simister, Robert and Wong, Barney and Woznitza, Nicholas and Pinnock, Mark A. and Wetscherek, Maria T. and Morrison, Cecily and Richardson, Hannah and P\'{e}rez-Garc\'{\i}a, Fernando and Hyland, Stephanie L. and Bannur, Shruthi and Castro, Daniel C. and Bouzid, Kenza and Schwaighofer, Anton and Ranjit, Mercy P. and Sharma, Harshita and Lungren, Matthew P. and Oktay, Ozan and Alvarez-Valle, Javier and Nori, Aditya and Harris, Stephen and Jacob, Joseph},
title = {Challenges for Responsible AI Design and Workflow Integration in Healthcare: A Case Study of Automatic Feeding Tube Qualification in Radiology},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1073-0516},
url = {https://doi.org/10.1145/3716500},
doi = {10.1145/3716500},
abstract = {Nasogastric tubes (NGTs) are feeding tubes that are inserted through the nose into the stomach to deliver nutrition or medication. If not placed correctly, they can cause serious harm, even death to patients. Recent AI developments demonstrate the feasibility of robustly detecting NGT placement from Chest X-ray images to reduce risks of sub-optimally or critically placed NGTs being missed or delayed in their detection, but gaps remain in clinical practice integration. In this study, we present a human-centered approach to the problem and describe insights derived following contextual inquiry and in-depth interviews with 15 clinical stakeholders. The interviews helped understand challenges in existing workflows, and how best to align technical capabilities with user needs and expectations. We discovered the trade-offs and complexities that need consideration when choosing suitable workflow stages, target users, and design configurations for different AI proposals. We explored how to balance AI benefits and risks for healthcare staff and patients within broader organizational, technical, and medical-legal constraints. We also identified data issues related to edge cases and data biases that affect model training and evaluation; how data documentation practices influence data preparation and labelling; and how to measure relevant AI outcomes reliably in future evaluations. We discuss how our work informs design and development of AI applications that are clinically useful, ethical, and acceptable in real-world healthcare services.},
note = {Just Accepted},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = feb,
keywords = {Radiology, AI, healthcare, responsible AI, socio-technical systems, feeding tubes, NGT}
}

@article{10.1145/3716848,
author = {Fu, Yujia and Liang, Peng and Tahir, Amjed and Li, Zengyang and Shahin, Mojtaba and Yu, Jiaxin and Chen, Jinfu},
title = {Security Weaknesses of Copilot-Generated Code in GitHub Projects: An Empirical Study},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3716848},
doi = {10.1145/3716848},
abstract = {Modern code generation tools utilizing AI models like Large Language Models (LLMs) have gained increased popularity due to their ability to produce functional code. However, their usage presents security challenges, often resulting in insecure code merging into the code base. Thus, evaluating the quality of generated code, especially its security, is crucial. While prior research explored various aspects of code generation, the focus on security has been limited, mostly examining code produced in controlled environments rather than open source development scenarios. To address this gap, we conducted an empirical study, analyzing code snippets generated by GitHub Copilot and two other AI code generation tools (i.e., CodeWhisperer and Codeium) from GitHub projects. Our analysis identified 733 snippets, revealing a high likelihood of security weaknesses, with 29.5\% of Python and 24.2\% of JavaScript snippets affected. These issues span 43 Common Weakness Enumeration (CWE) categories, including significant ones like CWE-330: Use of Insufficiently Random Values, CWE-94: Improper Control of Generation of Code, and CWE-79: Cross-site Scripting. Notably, eight of those CWEs are among the 2023 CWE Top-25, highlighting their severity. We further examined using Copilot Chat to fix security issues in Copilot-generated code by providing Copilot Chat with warning messages from the static analysis tools, and up to 55.5\% of the security issues can be fixed. We finally provide the suggestions for mitigating security issues in generated code.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = feb,
keywords = {Code Generation, Security Weakness, CWE, GitHub Copilot, GitHub Project}
}

@article{10.1145/3716850,
author = {Williams, Edward C. and Su, Grace and Schloen, Sandra R. and Prosser, Miller C. and Paulus, Susanne and Krishnan, Sanjay},
title = {DeepScribe: Localization and Classification of Elamite Cuneiform Signs Via Deep Learning},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1556-4673},
url = {https://doi.org/10.1145/3716850},
doi = {10.1145/3716850},
abstract = {Twenty-five hundred years ago, the “paperwork” of the Achaemenid Empire was recorded on clay tablets. In 1933, archaeologists from the University of Chicago’s Institute for the Study of Ancient Cultures (ISAC, formerly Oriental Institute) found tens of thousands of these tablets and fragments during the excavation of Persepolis. Many of these tablets have been painstakingly photographed and annotated by expert cuneiformists, and now provide a rich dataset consisting of over 5,000 annotated tablet images and 100,000 cuneiform sign bounding boxes encoding the Elamite language. We leverage this dataset to develop DeepScribe, the first computer vision pipeline capable of localizing Elamite cuneiform signs and providing suggestions for the identity of each sign. We investigate the difficulty of learning subtasks relevant to Elamite cuneiform tablet transcription on ground-truth data, finding that a RetinaNet object detector achieves a localization mAP of 0.78 and a ResNet classifier achieves a top-5 sign classification accuracy of 0.89. The end-to-end pipeline achieves a top-5 classification accuracy of 0.80. As part of the classification module, DeepScribe groups cuneiform signs into morphological clusters. We consider how this automatic clustering approach differs from the organization of standard, printed sign lists and what we learn from it. These components, trained individually, are sufficient to produce a system that can analyze photos of cuneiform tablets from the Achaemenid period and provide useful transliteration suggestions to researchers. We evaluate the model’s end-to-end performance on locating and classifying signs, providing a roadmap to a linguistically-aware transliteration system, then consider the model’s potential utility when applied to other periods of cuneiform writing.},
note = {Just Accepted},
journal = {J. Comput. Cult. Herit.},
month = mar
}

@article{10.1145/3716856,
author = {Yang, Ruichao and Ma, Jing and Gao, Wei and Lin, Hongzhan},
title = {LLM-enhanced Multiple Instance Learning for Joint Rumor and Stance Detection with Social Context Information},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3716856},
doi = {10.1145/3716856},
abstract = {The proliferation of misinformation, such as rumors on social media, has drawn significant attention, prompting various expressions of stance among users. Although rumor detection and stance detection are distinct tasks, they can complement each other. Rumors can be identified by cross-referencing stances in related posts, and stances are influenced by the nature of the rumor. However, existing stance detection methods often require post-level stance annotations, which are costly to obtain. We propose a novel LLM-enhanced MIL approach to jointly predict post stance and claim class labels, supervised solely by claim labels, using an undirected microblog propagation model. Our weakly supervised approach relies only on bag-level labels of claim veracity, aligning with multi-instance learning (MIL) principles. To achieve this, we transform the multi-class problem into multiple MIL-based binary classification problems. We then employ a discriminative attention layer to aggregate the outputs from these classifiers into finer-grained classes. Experiments conducted on three rumor datasets and two stance datasets demonstrate the effectiveness of our approach, highlighting strong connections between rumor veracity and expressed stances in responding posts. Our method shows promising performance in joint rumor and stance detection compared to the state-of-the-art methods.},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = feb,
keywords = {Multiple Instance Learning, Rumor Detection, Stance Detection, Propagation Structure, Hierarchical Attention Mechanism}
}

@proceedings{10.1145/3716895,
title = {ICAICE '24: Proceedings of the 5th International Conference on Artificial Intelligence and Computer Engineering},
year = {2024},
isbn = {9798400718007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@article{10.1145/3717060,
author = {Chen, Tianyu and Li, Lin and Shan, Bingjie and Liang, Guangtai and Li, Ding and Wang, Qianxiang and Xie, Tao},
title = {Identifying Affected Third-Party Java Libraries from Textual Descriptions of Vulnerabilities and Libraries},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3717060},
doi = {10.1145/3717060},
abstract = {To address security vulnerabilities arising from third-party libraries, security researchers maintain databases monitoring and curating vulnerability reports. Application developers can identify libraries affected by vulnerability reports (in short, affected libraries) by directly querying the databases with their used libraries. However, the querying results of affected libraries are not reliable due to the incompleteness of vulnerability reports. Thus, current approaches model the task of identifying affected libraries as a named-entity-recognition (NER) task or an extreme multi-label learning (XML) task. These approaches suffer from highly inaccurate results in identifying affected libraries with complex and similar names, e.g., Java libraries. To address these limitations, in this article, we propose VulLibMiner, the first to identify affected libraries from textual descriptions of both vulnerabilities and libraries, together with VulLib, a Java vulnerability dataset with their affected libraries. VulLibMiner consists of a TF-IDF matcher to efficiently screen out a small set of candidate libraries and a BERT-FNN model to effectively identify affected libraries from these candidates. We evaluate VulLibMiner using four state-of-the-art/practice approaches of identifying affected libraries on both their dataset named VeraJava and our VulLib dataset. Our evaluation results show that VulLibMiner can effectively identify affected libraries with an average F1 score of 0.669 while the state-of-the-art/practice approaches achieve only 0.547.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = feb,
keywords = {Application Security, Open-source Software, Machine learning}
}

@article{10.1145/3717062,
author = {Ma, Wei and Zhu, Chenguang and Liu, Ye and Xie, Xiaofei and Li, Yi},
title = {A Comprehensive Study of Governance Issues in Decentralized Finance Applications},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3717062},
doi = {10.1145/3717062},
abstract = {Decentralized Finance (DeFi) is a prominent application of smart contracts, representing a novel financial paradigm in contrast to centralized finance. While DeFi applications are rapidly emerging on mainstream blockchain platforms, their quality varies greatly, presenting numerous challenges, particularly in terms of their governance mechanisms. In this paper, we present a comprehensive study of governance issues in DeFi applications. Initially, we collected 3,165 academic papers and numerous industry reports. After thorough screening, we selected 44 academic papers and 11 industry reports for detailed analysis. Drawing upon insights from industry reports and academic research articles, we develop a taxonomy to categorize these governance issues. We collect and build a dataset of 4,446 audit reports from seventeen Web3 security companies, categorizing their governance issues according to our constructed taxonomy. We conducted a thorough analysis of governance issues and identified vulnerabilities in the governance design and implementation, e.g., voting sybil attack and proposal front-running. Our statistical analysis indicates that a significant portion (35.48\%) of governance-related issues is classified as severe. Within these, ownership-related problems constitute the largest share (65.38\%). Despite DeFi governance being essential for the long-term success of DeFi projects, our data shows that both auditors and development teams have not fully grasped its significance. Based on audit reports, we also analyzed common vulnerabilities and issues in the governance domain. Our research identifies two primary categories of DeFi governance issues: technology-centric and human-centric. Technology-centric issues can be addressed through technology updates and iterations, whereas human-centric issues are influenced not only by the development team's technical skills but also by their understanding of DeFi governance. Data analysis reveals that design and implementation issues are frequently overlooked; although not directly associated with vulnerabilities, these issues can impact the equitable distribution of project benefits. Furthermore, our analysis of 104 projects’ tokenomics configurations, including 15 collected from DeFi platforms, uncovered 27 inconsistent configurations, with only two projects exhibiting no issues. This suggests that such issues are relatively common. We therefore advise project teams to ensure consistency between their tokenomics design and the actual code. Our study culminates in providing several key practical implications for various DeFi stakeholders, including developers, users, researchers, and regulators, aiming to deepen the understanding of DeFi governance issues and contribute to the robust growth of DeFi systems.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = feb,
keywords = {Decentralized Finance (DeFi), DeFi Security, DeFi Governance, Governance Tokenomics, DeFi Economic Model Security, Software Governance, Blockchain Governance}
}

@proceedings{10.1145/3717664,
title = {EDAI '24: Proceedings of the 2024 International Conference on Economic Data Analytics and Artificial Intelligence},
year = {2024},
isbn = {9798400713255},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@article{10.1145/3717830,
author = {Li, Dongyang and Sun, Jianshan and Gao, Chongming and Feng, Fuli and Yuan, Kun},
title = {Independent or Social Driven Decision? A Counterfactual Refinement Strategy for Graph-Based Social Recommendation},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1046-8188},
url = {https://doi.org/10.1145/3717830},
doi = {10.1145/3717830},
abstract = {Social recommendation models have traditionally relied on social homophily to enhance user preference prediction by incorporating information from socially connected friends. However, this approach neglects the diverse nature of social relationships. Some individuals with independent personalities often prioritize their own interests over friends’ advice when making purchase decisions. Conversely, those who seek advice from others are more susceptible to social influence. Moreover, existing methods tend to overlook redundant and noisy social relationships within the network, hindering their ability to achieve accurate recommendations. In response, this paper proposes a novel counterfactual method to understand the causal factors driving purchase behaviors, thereby identifying the influence of users’ friends on their purchase decisions. By answering counterfactual questions about the influence of a friend's purchase behavior on the user's choices, we develop a causal model to represent social influence in the network. Our proposed refinement strategy, grounded in causal inference, generates counterfactual purchase behavior and guides the refinement of the social graph. Moreover, we present tailored graph refinement methods at various levels, ensuring fine-grained improvements. Experimental results on benchmark data demonstrate that the application of our strategy to different social recommendation models significantly enhances their predictive performance. The source code has been made available on .},
note = {Just Accepted},
journal = {ACM Trans. Inf. Syst.},
month = feb,
keywords = {social recommendation, graph denoising, causal inference}
}

@article{10.1145/3718083,
author = {Jiang, Yanjie and Liu, Hui and Liu, Jinyan and Zhang, Yuxia and Ji, Weixing and Zhong, Hao and Zhang, Lu},
title = {An Empirical Study on the Relationship Between Defects and Source Code’s Unnaturalness},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3718083},
doi = {10.1145/3718083},
abstract = {Natural languages are “natural” in that texts in natural languages are repetitive and predictable. Recent research indicates that programming languages share similar characteristics (naturalness), with source code displaying patterns of repetition and predictability. Notably, studies have shown that buggy code deviates from these natural patterns in that buggy code is significantly less natural than bug-free one. In this paper, we conduct a large-scale and extensive empirical study to investigate whether code defects lead to unnaturalness of source code. Different from existing studies, we leverage multiple large-scale and high-quality bug repositories where bug-irrelevant changes in bug-fixing commits have been explicitly excluded. The leveraged software applications cover different programming languages, and the empirical study involves real-world software defects as well as defects injected automatically with well-known mutation operators. On one side, our evaluation results confirm existing studies in that buggy source code lines are often less natural than bug-free ones. On the other side, our evaluation reveals some interesting new findings. First, fixing bugs does not significantly improve the naturalness of code lines and the fixed lines on average are as unnatural as buggy ones. This finding may suggest that software defects are not the root causes of source code’s unnaturalness although there does existing statistically significant correlation between software defects and source code’s naturalness. Second, defects in different programming languages have similar effect on source code’s naturalness. The conclusions (i.e., buggy code is less natural but fixing the bugs cannot improve source code’s naturalness) hold regardless of the programming languages. Third, injecting defects automatically by well-known mutation operators does not significantly reduce the naturalness of involved source code lines. This suggests that automatically injected defects may have a similar impact on the naturalness of source code as real-world defects inadvertently introduced by developers. Fourth, the detects’ impact on source code’s naturalness varies slightly among different categories of software defects. Although fixing bugs on average does not significantly improve the naturalness of involved source code, fixing ”checking” related bugs does significantly improve the naturalness of source code. Finally, locating buggy code lines according to naturalness alone is inaccurate, resulting in extremely low precision (less than one percent).},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = feb,
keywords = {Code Entropy, Bugs, Source Code, Bug Fixing, Naturalness}
}

@proceedings{10.1145/3718491,
title = {AIBDF '24: Proceedings of the 4th Asia-Pacific Artificial Intelligence and Big Data Forum},
year = {2024},
isbn = {9798400710865},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3718677,
title = {ICPHDS '24: Proceedings of the 2024 3rd International Conference on Public Health and Data Science},
year = {2024},
isbn = {9798400711671},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@article{10.1145/3719206,
author = {Cremaschi, Marco and D'Adda, Fabio and Maurino, Andrea},
title = {stEELlm: An LLM for Generating Semantic Annotations of Tabular Data},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3719206},
doi = {10.1145/3719206},
abstract = {The capabilities of LLMs represent a pivotal step in transforming how we manage and interact with information and data. We witness an increasingly pervasive use of such models in various computational tasks. In some preliminary works, attempts to integrate Knowledge Graphs and Large Language Models (LLMs) can be identified, in particular, to perform the classic tasks related to the construction of Knowledge Graphs through semantic annotation of texts. Nowadays, tables are widely used and play a crucial role in creating, organising, and sharing information that could be used to produce factual knowledge to be integrated into a Knowledge Graph. However, table-to-KG techniques through LLM have not been extensively investigated. This paper presents stEELlm, an innovative Semantic Table Interpretation approach obtained by fine-tuning the Mixtral 8x7B model. Conducted experiments demonstrate the capabilities of our model to successfully create semantic annotations of heterogeneous datasets, a scenario where classic approaches based on heuristics tend to fail.},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = feb,
keywords = {Large Language Models, Knowledge Graphs, Pre-training, Fine-tuning, Prompt Engineering, Semantic Table Interpretation}
}

@article{10.1145/3719345,
author = {Kong, Jiaolong and Xie, Xiaofei and Cheng, Mingfei and Liu, Shangqing and Du, Xiaoning and Guo, Qi},
title = {ContrastRepair: Enhancing Conversation-Based Automated Program Repair via Contrastive Test Case Pairs},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3719345},
doi = {10.1145/3719345},
abstract = {Automated Program Repair (APR) aims to automatically generate patches for rectifying software bugs. Recent strides in Large Language Models (LLM), such as ChatGPT, have yielded encouraging outcomes in APR, especially within the conversation-driven APR framework. Nevertheless, the efficacy of conversation-driven APR is contingent on the quality of the feedback information. In this paper, we propose ContrastRepair, a novel conversation-based APR approach that augments conversation-driven APR by providing LLMs with contrastive test pairs. A test pair consists of a failing test and a passing test, which offer contrastive feedback to the LLM. Our key insight is to minimize the difference between the generated passing test and the given failing test, which can better isolate the root causes of bugs. By providing such informative feedback, ContrastRepair enables the LLM to produce effective bug fixes. The implementation of ContrastRepair is based on the state-of-the-art LLM, ChatGPT, and it iteratively interacts with ChatGPT until plausible patches are generated. We evaluate ContrastRepair on multiple benchmark datasets, including Defects4J, QuixBugs, and HumanEval-Java. The results demonstrate that ContrastRepair significantly outperforms existing methods, achieving a new state-of-the-art in program repair. For instance, among Defects4J 1.2 and 2.0, ContrastRepair correctly repairs 143 out of all 337 bug cases, while the best-performing baseline fixes 124 bugs.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = mar,
keywords = {Program Repair, Large Language Model}
}

@article{10.1145/3721128,
author = {Zhang, Quanjun and Fang, Chunrong and Zheng, Yi and Zhang, Yaxin and Zhao, Yuan and Huang, Rubing and Zhou, Jianyi and Yang, Yun and Zheng, Tao and Chen, Zhenyu},
title = {Improving Deep Assertion Generation via Fine-Tuning Retrieval-Augmented Pre-trained Language Models},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3721128},
doi = {10.1145/3721128},
abstract = {Unit testing validates the correctness of the units of the software system under test and serves as the cornerstone in improving software quality and reliability. To reduce manual efforts in writing unit tests, some techniques have been proposed to generate test assertions automatically, including deep learning (DL)-based, retrieval-based, and integration-based ones. Among them, recent integration-based approaches inherit from both DL-based and retrieval-based approaches and are considered state-of-the-art. Despite being promising, such integration-based approaches suffer from inherent limitations, such as retrieving assertions with lexical matching while ignoring meaningful code semantics, and generating assertions with a limited training corpus.In this paper, we propose a novel Retrieval-Augmented Deep Assertion Generation approach, namely RetriGen, based on a hybrid assertion retriever and a pre-trained language model (PLM)-based assertion generator. Given a focal-test, RetriGen first builds a hybrid assertion retriever to search for the most relevant test-assert pair from external codebases. The retrieval process takes both lexical similarity and semantical similarity into account via a token-based and an embedding-based retriever, respectively. RetriGen then treats assertion generation as a sequence-to-sequence task and designs a PLM-based assertion generator to predict a correct assertion with historical test-assert pairs and the retrieved external assertion. Although our concept is general and can be adapted to various off-the-shelf encoder-decoder PLMs, we implement RetriGen to facilitate assertion generation based on the recent CodeT5 model. We conduct extensive experiments to evaluate RetriGen against six state-of-the-art approaches across two large-scale datasets and two metrics. The experimental results demonstrate that RetriGen achieves 57.66\% and 73.24\% in terms of accuracy and CodeBLEU, outperforming all baselines with an average improvement of 50.66\% and 14.14\%, respectively. Furthermore, RetriGen generates 1598 and 1818 unique correct assertions that all baselines fail to produce, 3.71X and 4.58X more than the most recent approach EditAS. We also demonstrate that adopting other PLMs can provide substantial advancement, e.g., four additionally-utilized PLMs outperform EditAS by 7.91\% (sim) 12.70\% accuracy improvement, indicating the generalizability of RetriGen. Overall, our study highlights the promising future of fine-tuning off-the-shelf PLMs to generate accurate assertions by incorporating external knowledge sources.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = feb,
keywords = {Unit Testing, Assertion Generation, Pre-trained Language Models, AI4SE}
}

@article{10.1145/3721138,
author = {Busch, Peter Andr\'{e}},
title = {The Artificial Bureaucrat: Artificial Intelligence in Street-Level Work},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3721138},
doi = {10.1145/3721138},
abstract = {Public service provision in the frontline, coined street-level bureaucracy, has been gradually impacted by information and communications technology (ICT) for decades. This impact, however, has mostly considered ICT as a tool suitable for tasks with low complexity. With recent advances in artificial intelligence (AI), there are examples of AI use for more complex street-level work. Examples include cases where AI is used for assessing eligibility for social benefits, predictive policing models, automated grading, and diagnostics in healthcare. While these applications demonstrate potential benefits, they also introduce new challenges related to privacy, accountability, corporatization and alienation of street-level work, and client service experiences. This article is a critical reflection on the street-level potential of AI in providing public services. This study contributes to the ongoing debate on AI's impact in street-level work by emphasizing both the potential benefits and risks associated with AI integration in frontline service provision. While AI may mitigate some limitations of human decision-making (e.g., subjectivity, inconsistency, and bias), it can also introduce challenges that require careful consideration (e.g., lack of transparency, data-driven bias, and limited contextual adaptation). By critically reflecting on AI's street-level potential, this article calls for a balanced approach to AI adoption in street-level work.},
note = {Just Accepted},
journal = {Digit. Gov.: Res. Pract.},
month = mar,
keywords = {artificial intelligence, algorithm, street-level bureaucracy, public service provision, policy implementation, client}
}

@inproceedings{10.1145/3721146.3721957,
author = {Sheikholeslami, Sina and Ghasemirahni, Hamid and Payberah, Amir H. and Wang, Tianze and Dowling, Jim and Vlassov, Vladimir},
title = {Utilizing Large Language Models for Ablation Studies in Machine Learning and Deep Learning},
year = {2025},
isbn = {9798400715389},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3721146.3721957},
doi = {10.1145/3721146.3721957},
abstract = {In Machine Learning (ML) and Deep Learning (DL) research, ablation studies are typically performed to provide insights into the individual contribution of different building blocks and components of an ML/DL system (e.g., a deep neural network), as well as to justify that certain additions or modifications to an existing ML/DL system can result in the proposed improved performance. Although dedicated frameworks for performing ablation studies have been introduced in recent years, conducting such experiments is still associated with requiring tedious, redundant work, typically involving maintaining redundant and nearly identical versions of code that correspond to different ablation trials. Inspired by the recent promising performance of Large Language Models (LLMs) in the generation and analysis of ML/DL code, in this paper we discuss the potential of LLMs as facilitators of ablation study experiments for scientific research projects that involve or deal with ML and DL models. We first discuss the different ways in which LLMs can be utilized for ablation studies and then present the prototype of a tool called AblationMage, that leverages LLMs to semi-automate the overall process of conducting ablation study experiments. We showcase the usability of AblationMage as a tool through three experiments, including one in which we reproduce the ablation studies from a recently published applied DL paper.},
booktitle = {Proceedings of the 5th Workshop on Machine Learning and Systems},
pages = {230–237},
numpages = {8},
keywords = {ablation studies, machine learning, deep learning, deep neural networks, feature ablation, model ablation, large language models},
location = {World Trade Center, Rotterdam, Netherlands},
series = {EuroMLSys '25}
}

@inproceedings{10.1145/3721146.3721958,
author = {Wang, Yifan and Birman, Kenneth P.},
title = {Diagnosing and Resolving Cloud Platform Instability with Multi-modal RAG LLMs},
year = {2025},
isbn = {9798400715389},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3721146.3721958},
doi = {10.1145/3721146.3721958},
abstract = {Today's cloud-hosted applications and services are complex systems, and a performance or functional instability can have dozens or hundreds of potential root causes. Our hypothesis is that by combining the pattern matching capabilities of modern AI tools with a natural multi-modal RAG LLM interface, problem identification and resolution can be simplified. ARCA is a new multi-modal RAG LLM system that targets this domain. Step-wise evaluations show that ARCA outperforms state-of-the-art alternatives.},
booktitle = {Proceedings of the 5th Workshop on Machine Learning and Systems},
pages = {139–147},
numpages = {9},
keywords = {root cause analysis, RAG LLM, AI-Ops},
location = {World Trade Center, Rotterdam, Netherlands},
series = {EuroMLSys '25}
}

@article{10.1145/3721976,
author = {Kemmerzell, Nils and Schreiner, Annika and Khalid, Haroon and Schalk, Michael and Bordoli, Letizia},
title = {Towards a Better Understanding of Evaluating Trustworthiness in AI Systems},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {0360-0300},
url = {https://doi.org/10.1145/3721976},
doi = {10.1145/3721976},
abstract = {With the increasing integration of artificial intelligence into various applications across industries, numerous institutions are striving to establish requirements for AI systems to be considered trustworthy, such as fairness, privacy, robustness, or transparency. For the implementation of Trustworthy AI into real-world applications, these requirements need to be operationalized, which includes evaluating the extent to which these criteria are fulfilled. This survey contributes to the discourse by outlining the current understanding of trustworthiness and its evaluation. Initially, existing evaluation frameworks are analyzed, from which common dimensions of trustworthiness are derived. For each dimension, the literature is surveyed for evaluation strategies, specifically focusing on quantitative metrics. By mapping these strategies to the machine learning lifecycle, an evaluation framework is derived, which can serve as a foundation towards the operationalization of Trustworthy AI.},
note = {Just Accepted},
journal = {ACM Comput. Surv.},
month = mar,
keywords = {trustworthy AI, evaluation, strategy, framework, quantitative, metrics}
}

@article{10.1145/3722105,
author = {Yu, Shengcheng and Fang, Chunrong and Liu, Jia and Chen, Zhenyu},
title = {Test Script Intention Generation for Mobile Application via GUI Image and Code Understanding},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3722105},
doi = {10.1145/3722105},
abstract = {Testing is the most direct and effective technique to ensure software quality. Test scripts always play a more important role in mobile app testing than test cases for source code, due to the GUI-intensive and event-driven characteristics of mobile applications (app). Test scripts focus on user interactions and the corresponding response events, which is significant for testing the target app functionalities. Therefore, it is critical to understand the test scripts for better script maintenance and modification. There exist some mature code understanding (i.e., code comment generation, code summarization) technologies that can be directly applied to functionality source code with business logic. However, such technologies will have difficulties when being applied to test scripts, because test scripts are loosely linked to apps under test (AUT) by widget selectors, and do not contain business logic themselves.In order to solve the test script understanding gap, this paper presents a novel approach, namely TestIntention, to infer the intention of GUI test scripts. Test intention refers to the user expectations of app behaviors for specific operations. TestIntention formalizes test scripts with an operation sequence model. For each operation within the sequence, TestIntention extracts the target widget selector and links the selector to the GUI layout information or the corresponding response events. For widgets identified by XPath, TestIntention utilizes the image understanding technologies to explore the detailed information of the widget images, the intention of which is understood with a deep learning model. For widgets identified by ID, TestIntention first maps the selectors to the response methods with business logic, and then adopts code understanding technologies to describe code in natural language form. Results of all operations are combined to generate test intention for test scripts. An empirical experiment including different metrics proves the outstanding performance of TestIntention, outperforming baselines by much. Also, it is shown that TestIntention can save about 80\% developers’ time to understand test scripts.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = mar,
keywords = {Mobile App Testing, GUI Understanding, Code Understanding}
}

@article{10.1145/3722215,
author = {Lewis, Noah and Bez, Jean Luca and Byna, Surendra},
title = {I/O in Machine Learning Applications on HPC Systems: A 360-degree Survey},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {0360-0300},
url = {https://doi.org/10.1145/3722215},
doi = {10.1145/3722215},
abstract = {Growing interest in Artificial Intelligence (AI) has resulted in a surge in demand for faster methods of Machine Learning (ML) model training and inference. This demand for speed has prompted the use of high performance computing (HPC) systems that excel in managing distributed workloads. Because data is the main fuel for AI applications, the performance of the storage and I/O subsystem of HPC systems is critical. In the past, HPC applications accessed large portions of data written by simulations or experiments or ingested data for visualizations or analysis tasks. ML workloads perform small reads spread across a large number of random files. This shift of I/O access patterns poses several challenges to modern parallel storage systems. In this paper, we survey I/O in ML applications on HPC systems, and target literature within a 6-year time window from 2019 to 2024. We define the scope of the survey, provide an overview of the common phases of ML, review available profilers and benchmarks, examine the I/O patterns encountered during offline data preparation, training, and inference, and explore I/O optimizations utilized in modern ML frameworks and proposed in recent literature. Lastly, we seek to expose research gaps that could spawn further R&amp;D.},
note = {Just Accepted},
journal = {ACM Comput. Surv.},
month = mar,
keywords = {I/O access pattern, HPC I/O, storage, machine learning}
}

@article{10.1145/3722229,
author = {AlOmar, Eman Abdullah},
title = {Nurturing Code Quality: Leveraging Static Analysis and Large Language Models for Software Quality in Education},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722229},
doi = {10.1145/3722229},
abstract = {Large Language Models (LLMs), such as ChatGPT, have become widely popular for various software engineering tasks, including programming, testing, code review, and program comprehension. However, their impact on improving software quality in educational settings remains uncertain. This paper explores our experience teaching the use of Programming Mistake Detector (PMD) to foster a culture of bug fixing and leverage LLM to improve software quality in the classroom. This paper discusses the results of an experiment involving 155 submissions that carried out a code review activity of 1,658 rules. Our quantitative and qualitative analysis reveals that a set of PMD quality issues influences the acceptance or rejection of the issues, and design-related categories that take longer to resolve. Although students acknowledge the potential of using ChatGPT during code review, some skepticism persists. Further, constructing prompts for ChatGPT that possess clarity, complexity, and context nurtures vital learning outcomes, such as enhanced critical thinking, and among the 1,658 issues analyzed, 93\% of students indicated that ChatGPT did not identify any additional issues beyond those detected by PMD. Conversations between students and ChatGPT encompass five categories, including ChatGPT’s use of affirmation phrases like ‘certainly’ regarding bug fixing decisions, and apology phrases such as ‘apologize’ when resolving challenges. Through this experiment, we demonstrate that code review can become an integral part of the educational computing curriculum. We envision our findings to enable educators to support students with effective code review strategies, increasing awareness of LLMs, and promoting software quality in education.},
note = {Just Accepted},
journal = {ACM Trans. Comput. Educ.},
month = mar,
keywords = {large language models, education, bugfix, static analysis, code quality}
}

@article{10.1145/3722231,
author = {Cimino, Gaetano and Deufemia, Vincenzo},
title = {SIGFRID: Unsupervised, Platform-Agnostic Interference Detection in IoT Automation Rules},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722231},
doi = {10.1145/3722231},
abstract = {Smart home technology has profoundly changed modern living by interconnecting devices, services, data flows, and user interactions into integrated, automated environments. Homeowners can easily program smart devices using conditional IF-THEN rules, where triggers prompt corresponding actions. However, as smart homes incorporate more multifunctional devices, conflicting trigger-action rules can simultaneously control devices in inconsistent ways, causing unexpected and potentially unsafe interference situations. This paper introduces Sigfrid, a novel interference detection approach using scene interaction graphs constructed through Large Language Models (LLMs). To enhance LLM reasoning, we propose a new prompt engineering methodology that integrates automated and manual editing techniques to formulate queries for deriving causal insights in the smart home domain. Interferences are identified through efficient exploration of the graph constructed from the extracted relations. We evaluate Sigfrid on real-world If-This-Then-That (IFTTT) and SmartThings rule sets, demonstrating its superiority over state-of-the-art methods by more than  (21\% )  in F1-score.},
note = {Just Accepted},
journal = {ACM Trans. Internet Things},
month = mar,
keywords = {IoT, trigger-action platforms, interference detection, behavioral modeling, smart home.}
}

@article{10.1145/3723005,
author = {Zhang, Xinjie and Zhang, Tenggan and Sun, Lei and Zhao, Jinming and Jin, Qin},
title = {Exploring Interpretability in Deep Learning for Affective Computing: A Comprehensive Review},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1551-6857},
url = {https://doi.org/10.1145/3723005},
doi = {10.1145/3723005},
abstract = {Deep learning has shown impressive performance in affective computing, but its black-box characteristic limits the model’s interpretability, posing a challenge to further development and application. Compared with objective recognition tasks such as image recognition, emotion perception as a high-level cognition is more subjective, making it particularly important to enhance the interpretability of deep learning in affective computing. In recent years, some interpretability-related works have emerged, but there are few reviews on this topic yet. This paper summarizes the explainable deep learning methods in affective computing from two aspects: first, the application of general explainable deep learning methods in affective computing from the perspectives of model-agnostic and model-specific is introduced; second, emotion-specific interpretability research that combines emotional psychology theories, physiological studies, and human cognition, covering task design, model design, and result analysis methods, is systematically reviewed. There are new explainable deep learning methods for multimodal and large language models in the context of emotion. Finally, we discuss five specific challenges and propose corresponding future directions to provide insights and references for subsequent research on affective computing interpretability.},
note = {Just Accepted},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = mar,
keywords = {Affective computing, Explainable methods, Deep learning, Multimodal}
}

@article{10.1145/3724117,
author = {Huang, Dong and Zhang, Jie M. and Bu, Qingwen and Xie, Xiaofei and Chen, Junjie and Cui, Heming},
title = {Bias Testing and Mitigation in LLM-based Code Generation},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3724117},
doi = {10.1145/3724117},
abstract = {As the adoption of LLMs becomes more widespread in software coding ecosystems, a pressing issue has emerged: does the generated code contain social bias and unfairness, such as those related to age, gender, and race? This issue concerns the integrity, fairness, and ethical foundation of software applications that depend on the code generated by these models but are underexplored in the literature. This paper presents a novel bias testing framework that is specifically designed for code generation tasks. Based on this framework, we conduct an extensive empirical study on the biases in code generated by five widely studied LLMs (i.e., PALM-2-CodeChat-bison, Claude-instant-1, GPT-3.5-turbo, GPT-4-turbo, and GPT-4). Our findings reveal that biases are prevalent. For example, 13.47\% to 49.10\% of the codes generated by these LLMs have biased behaviors towards gender. Moreover, we study five bias mitigation prompt strategies that are commonly used in current code generation scenarios, i.e., zero-shot, one-shot, few-shot, and two Chain-of-Thought (CoT) prompts, with and without provided feedback-driven refinement. Our evaluation results illustrate that using direct prompt engineering strategies has limited effectiveness in mitigating bias, but our test execution feedback can help to reduce the ratio of code biases to a large extent (e.g., from 59.88\% to 4.79\% for GPT-4)1.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = mar,
keywords = {Fairness testing, code generation}
}

@article{10.1145/3724393,
author = {Zhang, Xiaoyu and Zhang, Cen and Li, Tianlin and Huang, Yihao and Jia, Xiaojun and Hu, Ming and Zhang, Jie and Liu, Yang and Ma, Shiqing and Shen, Chao},
title = {JailGuard: A Universal Detection Framework for Prompt-based Attacks on LLM Systems},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3724393},
doi = {10.1145/3724393},
abstract = {The systems and software powered by Large Language Models (LLMs) and Multi-Modal LLMs (MLLMs) have played a critical role in numerous scenarios. However, current LLM systems are vulnerable to prompt-based attacks, with jailbreaking attacks enabling the LLM system to generate harmful content, while hijacking attacks manipulate the LLM system to perform attacker-desired tasks, underscoring the necessity for detection tools. Unfortunately, existing detecting approaches are usually tailored to specific attacks, resulting in poor generalization in detecting various attacks across different modalities. To address it, we propose JailGuard, a universal detection framework deployed on top of LLM systems for prompt-based attacks across text and image modalities. JailGuard operates on the principle that attacks are inherently less robust than benign ones. Specifically, JailGuard mutates untrusted inputs to generate variants and leverages the discrepancy of the variants’ responses on the target model to distinguish attack samples from benign samples. We implement 18 mutators for text and image inputs and design a mutator combination policy to further improve detection generalization. The evaluation on the dataset containing 15 known attack types suggests that JailGuard achieves the best detection accuracy of 86.14\%/82.90\% on text and image inputs, outperforming state-of-the-art methods by 11.81\%-25.73\% and 12.20\%-21.40\%.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = mar,
keywords = {LLM Security, Software and Application Security, Large Language Model System, LLM Defense}
}

@article{10.1145/3725221,
author = {Liu, Qi and Wang, Zhilu and Zhou, Xiaokang and Zhang, Yonghong and Liu, Xiaodong and Lin, Haiyang},
title = {GSFL: A Privacy-preserving Grouping-Split Federated Learning Approach in Resource-constrained Edge Computing Scenarios},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1556-4665},
url = {https://doi.org/10.1145/3725221},
doi = {10.1145/3725221},
abstract = {The advancement of mobile multimedia communications, 5G, and Internet of Things (IoT) has led to the widespread use of edge devices, including sensors, smartphones, and wearables. This has generated in a large amount of distributed data, leading to new prospects for deep learning. However, this data is confined within data silos and contains sensitive information, making it difficult to be processed in a centralized manner, particularly under stringent data privacy regulations. Federated learning (FL) offers a solution by enabling collaborative learning while ensuring privacy. Nonetheless, data and device heterogeneity complicate FL implementation. This research presents a specialized FL algorithm for heterogeneous edge computing. It integrates a lightweight grouping strategy for homogeneous devices, a scheduling algorithm within groups, and a Split Learning (SL) approach. These contributions enhance model accuracy and training speed, alleviate the burden on resource-constrained devices, and strengthen privacy. Experimental results demonstrate that the GSFL outperforms FedAvg and SplitFed by 6.53\texttimes{} and 1.18\texttimes{}. Under experimental conditions with  (alpha=0.05) , representing a highly heterogeneous data distribution typical of extreme Non-IID scenarios, GSFL showed better accuracy compared to FedAvg by 10.64\%, HACCS by 4.53\%, and Cluster-HSFL by 1.16\%. GSFL effectively balances privacy protection and computational efficiency for real-world applications in mobile multimedia communications.},
note = {Just Accepted},
journal = {ACM Trans. Auton. Adapt. Syst.},
month = mar,
keywords = {Federated learning, Split learning, Non-IID, Clustering}
}

@article{10.1145/3725816,
author = {Cruickshank, Iain J. and Ng, Lynnette Hui Xian},
title = {Prompting and Fine-Tuning Open-Sourced Large Language Models for Stance Classification},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3725816},
doi = {10.1145/3725816},
abstract = {Stance classification, the task of predicting the viewpoint of an author on a subject of interest, has long been a focal point of research in domains ranging from social science to machine learning. Current stance detection methods rely predominantly on manual annotation of sentences, followed by training a supervised machine learning model. However, this manual annotation process requires laborious annotation effort, and thus hampers its potential to generalize across different contexts. In this work, we investigate the use of Large Language Models (LLMs) as a stance detection methodology that can reduce or even eliminate the need for manual annotations. We investigate 10 open-source models and 7 prompting schemes, finding that LLMs are competitive with in-domain supervised models but are not necessarily consistent in their performance. We also fine-tuned the LLMs, but discovered that fine-tuning process does not necessarily lead to better performance. In general, we discover that LLMs do not routinely outperform their smaller supervised machine learning models, and thus call for stance detection to be a benchmark for which LLMs also optimize for. The code used in this study is available at .},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = mar,
keywords = {stance detection, stance classification, large language models, prompting}
}

@article{10.1145/3725856,
author = {Civitarese, Gabriele and Fiori, Michele and Choudhary, Priyankar and Bettini, Claudio},
title = {Large Language Models are Zero-Shot Recognizers for Activities of Daily Living},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3725856},
doi = {10.1145/3725856},
abstract = {The sensor-based recognition of Activities of Daily Living (ADLs) in smart home environments enables several applications in the areas of energy management, safety, well-being, and healthcare. ADL recognition is typically based on deep learning methods requiring large datasets to be trained. Recently, several studies proved that Large Language Models (LLMs) effectively capture common-sense knowledge about human activities. However, the effectiveness of LLMs for ADL recognition in smart home environments still deserves to be investigated. In this work, we propose ADL-LLM, a novel LLM-based ADL recognition system. ADL-LLM transforms raw sensor data into textual representations, that are processed by an LLM to perform zero-shot ADL recognition. Moreover, in the scenario where a small labeled dataset is available, ADL-LLM can also be empowered with few-shot prompting. We evaluated ADL-LLM on two public datasets, showing its effectiveness in this domain.},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = mar,
keywords = {Human Activity Recognition, Large Language Models, Smart Home, Activities of Daily Living}
}

@article{10.1145/3726871,
author = {Xu, Lanling and Zhang, Junjie and Li, Bingqian and Wang, Jinpeng and Chen, Sheng and Zhao, Wayne Xin and Wen, Ji-Rong},
title = {Tapping the Potential of Large Language Models as Recommender Systems: A Comprehensive Framework and Empirical Analysis},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1556-4681},
url = {https://doi.org/10.1145/3726871},
doi = {10.1145/3726871},
abstract = {Recently, Large Language Models (LLMs) such as ChatGPT have showcased remarkable abilities in solving general tasks, demonstrating the potential for applications in recommender systems. To assess how effectively LLMs can be used in recommendation tasks, our study primarily focuses on employing LLMs as recommender systems through prompt engineering. We propose a general framework for leveraging LLMs in recommendation tasks, focusing on the capabilities of LLMs as recommenders. To conduct our analysis, we formalize the input of LLMs for recommendation into natural language prompts with two key aspects, and explain how our framework can be generalized to various recommendation scenarios. As for the use of LLMs as recommenders, we analyze the impact of public availability, tuning strategies, model architecture, parameter scale, and context length on recommendation results based on the classification of LLMs. As for prompt engineering, we further analyze the impact of four important components of prompts, i.e., task descriptions, user interest modeling, candidate items construction and prompting strategies. In each section, we first define and categorize concepts in line with the existing literature. Then, we propose inspiring research questions followed by detailed experiments on two public datasets, in order to systematically analyze the impact of different factors on recommendation performance. Based on our empirical analysis, we finally summarize promising directions to shed lights on future research.},
note = {Just Accepted},
journal = {ACM Trans. Knowl. Discov. Data},
month = mar,
keywords = {Large Language Models, Recommender Systems, Empirical Study}
}

@article{10.1145/3727145,
author = {Tang, Ye and Chen, Honghao and He, Zhixing and Zhong, Hao},
title = {Understanding Mirror Bugs in Multiple-Language Projects},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3727145},
doi = {10.1145/3727145},
abstract = {As software is widely used in daily life, bugs can introduce catastrophic consequences. Researchers have conducted empirical studies to delve into bug characteristics, exploring topics such as buggy locations, symptoms, causes, and repair patterns. To attract users, many applications have implementations in different languages. If an implementation has a bug, other implementations can have similar bugs. In this paper, we call such cross-language clone bugs mirror bugs. Understanding mirror bugs is crucial, as they offer insights into broader bug patterns. Still, no prior study has explored mirror bugs, leaving several research questions unanswered. For instance, can bug fixes in one language help detect and repair bugs in other languages?To address these questions, we conducted the first empirical study analyzing mirror bugs. Our investigation focused on 638 bugs from four projects, implemented in both Java and C#. Our study presents answers to five interesting research questions. For instance, some programmers actively fix mirror bugs even without tool support. Consequently, there is a timely need for tools that assist in detecting mirror bugs. Following this insight, we manually identified and implemented the patches of 9 new mirror bugs. Among them, 5 patches are already accepted by programmers.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = mar,
keywords = {Mirror bug, Bug detection, Automatic program repair}
}

@article{10.1145/3727640,
author = {Jin, Lingxin and Wen, Xiangyu and Jiang, Wei and Zhan, Jinyu and Zhou, Xingzhi},
title = {Trojan Attacks and Countermeasures on Deep Neural Networks from Life-Cycle Perspective: A Review},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {0360-0300},
url = {https://doi.org/10.1145/3727640},
doi = {10.1145/3727640},
abstract = {Deep Neural Networks (DNNs) have been widely deployed in security-critical artificial intelligence systems, such as autonomous driving and facial recognition systems. However, recent research has revealed their susceptibility to Trojan information maliciously injected by attackers. This vulnerability is caused, on the one hand, by the complex architecture and non-interpretability of DNNs. On the other hand, external open-source datasets, pre-trained models, and intelligent service platforms further exacerbate the threat of Trojan attacks. This article presents the first comprehensive survey of Trojan attacks against DNNs from a lifecycle perspective, including training, post-training, and inference (deployment) stages. Specifically, this article reformulates the relationships of Trojan attacks with poisoning attacks, adversarial example attacks, and bit-flip attacks. Then, research on Trojan attacks against newly emerged model architectures (e.g., vision transformers and spiking neural networks) and in other research fields is investigated. Moreover, this article also provides a comprehensive review of countermeasures (including detection and elimination) against Trojan attacks. Further, it evaluates the practical effectiveness of existing defense strategies against Trojan attacks at different lifecycle stages. Finally, we conclude the survey and provide constructive insights to advance research on Trojan attacks and countermeasures.},
note = {Just Accepted},
journal = {ACM Comput. Surv.},
month = mar,
keywords = {deep learning, deep neural networks, backdoor attack, Trojan attack, Trojan detection, Trojan Elimination}
}

@article{10.1145/3727643,
author = {Uddin, Md Palash and Xiang, Yong and Hasan, Mahmudul and Bai, Jun and Zhao, Yao and Gao, Longxiang},
title = {A Systematic Literature Review of Robust Federated Learning: Issues, Solutions, and Future Research Directions},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {0360-0300},
url = {https://doi.org/10.1145/3727643},
doi = {10.1145/3727643},
abstract = {Federated Learning (FL) has emerged as a promising paradigm for training machine learning models across distributed devices while preserving their data privacy. However, the robustness of FL models against adversarial data and model attacks, noisy updates, and label-flipped data issues remain a critical concern. In this paper, we present a systematic literature review using the PRISMA framework to comprehensively analyze existing research on robust FL. Through a rigorous selection process using six key databases (ACM Digital Library, IEEE Xplore, ScienceDirect, Springer, Web of Science, and Scopus), we identify and categorize 244 studies into eight themes of ensuring robustness in FL: objective regularization, optimizer modification, differential privacy employment, additional dataset requirement and decentralization orchestration, manifold, client selection, new aggregation algorithms, and aggregation hyperparameter tuning. We synthesize the findings from these themes, highlighting the various approaches and their potential gaps proposed to enhance the robustness of FL models. Furthermore, we discuss future research directions, focusing on the potential of hybrid approaches, ensemble techniques, and adaptive mechanisms for addressing the challenges associated with robust FL. This review not only provides a comprehensive overview of the state-of-the-art in robust FL but also serves as a roadmap for researchers and practitioners seeking to advance the field and develop more robust and resilient FL systems.},
note = {Just Accepted},
journal = {ACM Comput. Surv.},
month = mar,
keywords = {Federated Learning, Robustness, Attack, Countermeasure, Defence.}
}

@article{10.1145/3727980,
author = {Chang, Kaiyan and Zhu, Wenlong and Wang, Kun and He, Xinyang and Yang, Nan and Chen, Zhirong and Jin, Dantong and Li, Cangyuan and Zhou, Yunhao and Yan, Hao and Zhao, Zhuoliang and Cheng, Yuan and Wang, Mengdi and Liang, Shengwen and Han, Yinhe and Li, Xiaowei and Li, Huawei and Wang, Ying},
title = {A data-centric chip design agent framework for Verilog code generation},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1084-4309},
url = {https://doi.org/10.1145/3727980},
doi = {10.1145/3727980},
abstract = {Recent advances in large language models (LLMs) have demonstrated significant potential for automated hardware description language (HDL) code generation from high-level specifications. However, two critical challenges limit further progress in this domain: the scarcity of quality Verilog training data and the inability of current approaches to generate RTL code optimized for power, performance, and area (PPA) metrics. This paper presents a comprehensive data-centric framework that addresses these limitations through innovations in both pre-fine-tuning data preparation and after-fine-tuning optimization strategies. In the pre-fine-tuning phase, we tackle the data scarcity problem with an automated design-data augmentation framework that generates high-volume, high-quality natural language specifications aligned with corresponding Verilog code and EDA scripts. Our approach creates a complete RTL-level feedback loop by augmenting EDA scripts, RTL code, and EDA tool feedback. In the after-fine-tuning phase, we focus on generating PPA-aware RTL code through a novel search and prompt framework. Our approach implements iterative filtering and selection of LLM-generated Verilog variants while providing high-quality predefined prompts, including composition and interface specifications. To evaluate the effectiveness of our data augmentation method, we fine-tune Llama 2-13B and Llama 2-7B models using the dataset generated by our augmentation framework. The results demonstrate a significant improvement in the Verilog generation tasks with LLMs. Moreover, the accuracy of Verilog generation surpasses that of the current state-of-the-art open-source Verilog generation model, increasing from 58.8\% to 70.6\% with the same benchmark. Our 13B model has a pass rate improvement compared with GPT-3.5 in Verilog generation and outperforms in EDA script (i.e., SiliconCompiler) generation with only 200 EDA script data. Additionally, to evaluate the effectiveness of the our agent framework, we compare the PPA on the GPT-3.5, where the results show that the agent refined RTL code can have a better quality than the generated RTL code only with GPT-3.5.},
note = {Just Accepted},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = apr,
keywords = {Large Language Model, Hardware Generation, Data Augmentation}
}

@article{10.14778/3705829.3705832,
author = {Tang, Xiu and Liu, Wenhao and Wu, Sai and Yao, Chang and Yuan, Gongsheng and Ying, Shanshan and Chen, Gang},
title = {QueryArtisan: Generating Data Manipulation Codes for Ad-hoc Analysis in Data Lakes},
year = {2025},
issue_date = {October 2024},
publisher = {VLDB Endowment},
volume = {18},
number = {2},
issn = {2150-8097},
url = {https://doi.org/10.14778/3705829.3705832},
doi = {10.14778/3705829.3705832},
abstract = {Query processing over data lakes is a challenging task, often requiring extensive data pre-processing activities such as data cleaning, transformation, and loading. However, the advent of Large Language Models (LLMs) has illuminated a new pathway to address these complexities by offering a unified approach to understanding the diverse datasets submerged in data lakes. In this paper, we introduce QueryArtisan, a novel LLM-powered analytic tool specifically designed for data lakes. QueryArtisan transcends traditional ETL (Extract, Transform, Load) processes by generating just-intime code for dataset-specific queries. It eliminates the need for an intermediary schema, enabling users to query the data lake directly using natural language. To achieve this, we have developed a suite of heterogeneous operators capable of processing data across various modalities. Additionally, QueryArtisan incorporates a cost model-based query optimization technique, significantly enhancing its code generation capabilities for efficient query resolution. Our extensive experimental evaluations, conducted with real-life datasets, demonstrate that QueryArtisan markedly outperforms existing solutions in terms of effectiveness, efficiency and usability.},
journal = {Proc. VLDB Endow.},
month = feb,
pages = {108–116},
numpages = {9}
}

@article{10.14778/3705829.3705836,
author = {Markakis, Markos and Youngmann, Brit and Gao, Trinity and Zhang, Ziyu and Shahout, Rana and Chen, Peter Baile and Liu, Chunwei and Sabek, Ibrahim and Cafarella, Michael},
title = {From Logs to Causal Inference: Diagnosing Large Systems},
year = {2025},
issue_date = {October 2024},
publisher = {VLDB Endowment},
volume = {18},
number = {2},
issn = {2150-8097},
url = {https://doi.org/10.14778/3705829.3705836},
doi = {10.14778/3705829.3705836},
abstract = {Causal inference can quantify cause-effect relationships in domains as varied as medicine, economics and public policy. Production computer systems exhibit a similar level of complexity and a recurring need to diagnose problems quickly. However, systems are only observed imperfectly, often via long, messy, semi-structured logs.In this work, we want to accelerate large systems debugging by applying causal inference over logs, enabling engineers to diagnose problems and assess interventions in a principled manner. Our framework achieves this through two human-in-the-loop modules: (1) The Candidate Cause Ranker, through which one can determine the causes of a variable without running a full causal discovery algorithm; and (2) the Interactive Causal Graph Refiner, which helps engineers compute an unbiased estimation of their effect of interest without extensive manual causal graph verification. Both modules are powered by the insight that only part of the causal graph of the system is needed to correctly quantify a given effect of interest. We also provide a data preparation pipeline, the Log Converter, which transforms raw, messy, real-world logs into an appropriate tabular input for causal inference, using methods drawn from data transformation, cleaning, and extraction.We evaluate LOGos, a prototype implementation, on both real-world and synthetic logs and find that: (1) The Candidate Cause Ranker achieved an average precision 1.08\texttimes{}-18\texttimes{} higher than the baselines, in interactive time; (2) The Interactive Causal Graph Refiner required a number of causal judgments 1.61 \texttimes{} - 16.83\texttimes{} lower than the baselines; and (3) The latency of Log Converter scaled linearly with three measures of the complexity of a log: length, distinct templates, and fraction of tokens that are variables.},
journal = {Proc. VLDB Endow.},
month = feb,
pages = {158–172},
numpages = {15}
}

@article{10.14778/3705829.3705843,
author = {Hu, Chuxuan and Peters, Austin and Kang, Daniel},
title = {LEAP: LLM-Powered End-to-End Automatic Library for Processing Social Science Queries on Unstructured Data},
year = {2025},
issue_date = {October 2024},
publisher = {VLDB Endowment},
volume = {18},
number = {2},
issn = {2150-8097},
url = {https://doi.org/10.14778/3705829.3705843},
doi = {10.14778/3705829.3705843},
abstract = {Social scientists are increasingly interested in analyzing the semantic information (e.g., emotion) of unstructured data (e.g., Tweets), where the semantic information is not natively present. Performing this analysis in a cost-efficient manner requires using machine learning (ML) models to extract the semantic information and subsequently analyze the now structured data. However, this process remains challenging for domain experts.To demonstrate the challenges in social science analytics, we collect a dataset, QUIET-ML, of 120 real-world social science queries in natural language and their ground truth answers. Existing systems struggle with these queries since (1) they require selecting and applying ML models, and (2) more than a quarter of these queries are vague, making standard tools like natural language to SQL systems unsuited. To address these issues, we develop LEAP, an end-to-end library that answers social science queries in natural language with ML. LEAP filters vague queries to ensure that the answers are deterministic and selects from internally supported and user-defined ML functions to extend the unstructured data to structured tables with necessary annotations. LEAP further generates and executes code to respond to these natural language queries. LEAP achieves a 100\% pass @ 3 and 92\% pass @ 1 on QUIET-ML, with a $1.06 average end-to-end cost, of which code generation costs $0.02.},
journal = {Proc. VLDB Endow.},
month = feb,
pages = {253–264},
numpages = {12}
}

@article{10.14778/3705829.3705844,
author = {Kieu, Duc and Kieu, Tung and Han, Peng and Yang, Bin and Jensen, Christian S. and Le, Bac},
title = {TEAM: Topological Evolution-Aware Framework for Traffic Forecasting},
year = {2025},
issue_date = {October 2024},
publisher = {VLDB Endowment},
volume = {18},
number = {2},
issn = {2150-8097},
url = {https://doi.org/10.14778/3705829.3705844},
doi = {10.14778/3705829.3705844},
abstract = {Due to the global trend towards urbanization, people increasingly move to and live in cities that then continue to grow. Traffic forecasting plays an important role in the intelligent transportation systems of cities as well as in spatio-temporal data mining. State-of-the-art forecasting is achieved by deep-learning approaches due to their ability to contend with complex spatio-temporal dynamics. However, existing methods assume the input is fixed-topology road networks and static traffic time series. These assumptions fail to align with urbanization, where time series are collected continuously and road networks evolve over time. In such settings, deep-learning models require frequent re-initialization and re-training, imposing high computational costs. To enable much more efficient training without jeopardizing model accuracy, we propose the Topological Evolution-aware Framework (TEAM) for traffic forecasting that incorporates convolution and attention. This combination of mechanisms enables better adaptation to newly collected time series while being able to maintain learned knowledge from old time series. TEAM features a continual learning module based on the Wasserstein metric that acts as a buffer that can identify the most stable and the most changing network nodes. Then, only data related to stable nodes is employed for re-training when consolidating a model. Further, only data of new nodes and their adjacent nodes as well as data pertaining to changing nodes are used to re-train the model. Empirical studies with two real-world traffic datasets offer evidence that TEAM is capable of much lower re-training costs than existing methods are, without jeopardizing forecasting accuracy.},
journal = {Proc. VLDB Endow.},
month = feb,
pages = {265–278},
numpages = {14}
}

@article{10.14778/3705829.3705858,
author = {Song, Yumeng and Gu, Yu and Li, Tianyi and Li, Yushuai and Jensen, Christian S. and Yu, Ge},
title = {Quantifying Point Contributions: A Lightweight Framework for Efficient and Effective Query-Driven Trajectory Simplification},
year = {2025},
issue_date = {October 2024},
publisher = {VLDB Endowment},
volume = {18},
number = {2},
issn = {2150-8097},
url = {https://doi.org/10.14778/3705829.3705858},
doi = {10.14778/3705829.3705858},
abstract = {As large volumes of trajectory data accumulate, simplifying trajectories to reduce storage and querying costs is increasingly studied. Existing proposals face three main problems. First, they require numerous iterations to decide which GPS points to delete. Second, they focus only on the relationships between neighboring points (local information) while neglecting the overall structure (global information), reducing the global similarity between the simplified and original trajectories and making it difficult to maintain consistency in query results, especially for similarity-based queries. Finally, they fail to differentiate the importance of points with similar features, leading to suboptimal selection of points to retain the original trajectory information.We propose MLSimp, a novel Mutual Learning query-driven trajectory simplification framework that integrates two distinct models: GNN-TS, based on graph neural networks, and Diff-TS, based on diffusion models. GNN-TS evaluates the importance of a point according to its globality, capturing its correlation with the entire trajectory, and its uniqueness, capturing its differences from neighboring points. It also incorporates attention mechanisms in the GNN layers, enabling simultaneous data integration from all points within the same trajectory and refining representations, thus avoiding iterative processes. Diff-TS generates amplified signals to enable the retention of the most important points at low compression rates. Experiments involving eight baselines on three databases show that MLSimp reduces the simplification time by 42\%--70\% and improves query accuracy over simplified trajectories by up to 34.6\%.},
journal = {Proc. VLDB Endow.},
month = feb,
pages = {453–465},
numpages = {13}
}

@article{10.1613/jair.1.17654,
author = {Lin, Lizhi and Mu, Honglin and Zhai, Zenan and Wang, Minghan and Wang, Yuxia and Wang, Renxi and Gao, Junjie and Zhang, Yixuan and Che, Wanxiang and Baldwin, Timothy and Han, Xudong and Li, Haonan},
title = {Against The Achilles' Heel: A Survey on Red Teaming for Generative Models},
year = {2025},
issue_date = {Apr 2025},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {82},
issn = {1076-9757},
url = {https://doi.org/10.1613/jair.1.17654},
doi = {10.1613/jair.1.17654},
abstract = {Generative models are rapidly gaining popularity and being integrated into everyday applications, raising concerns over their safe use as various vulnerabilities are exposed. In light of this, the field of red teaming is undergoing fast-paced growth, highlighting the need for a comprehensive survey covering the entire pipeline and addressing emerging topics. Our extensive survey, which examines over 120 papers, introduces a taxonomy of fine-grained attack strategies grounded in the inherent capabilities of language models. Additionally, we have developed the “searcher” framework to unify various automatic red teaming approaches. Moreover, our survey covers novel areas including multimodal attacks and defenses, risks around LLM-based agents, overkill of harmless queries, and the balance between harmlessness and helpfulness. Warning: This paper contains examples that may be offensive, harmful, or biased.},
journal = {J. Artif. Int. Res.},
month = feb,
numpages = {89},
keywords = {decision trees, machine learning, neural networks, probabilistic reasoning}
}

@proceedings{10.5555/3715674,
title = {SC-W '24: Proceedings of the SC '24 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
year = {2024},
isbn = {9798350355543},
publisher = {IEEE Press},
location = {Atlanta, GA, USA}
}

@inbook{10.5555/3716662.3716679,
author = {Bommasani, Rishi and Klyman, Kevin and Longpre, Shayne and Xiong, Betty and Kapoor, Sayash and Maslej, Nestor and Narayanan, Arvind and Liang, Percy},
title = {Foundation Model Transparency Reports},
year = {2025},
publisher = {AAAI Press},
abstract = {Foundation models are critical digital technologies with sweeping societal impact that necessitates transparency. To codify how foundation model developers should provide transparency about the development and deployment of their models, we propose Foundation Model Transparency Reports, drawing upon the transparency reporting practices in social media. While external documentation of societal harms prompted social media transparency reports, our objective is to institutionalize transparency reporting for foundation models while the industry is still nascent. To design our reports, we identify 6 design principles given the successes and shortcomings of social media transparency reporting. To further schematize our reports, we draw upon the 100 transparency indicators from the Foundation Model Transparency Index. Given these indicators, we measure the extent to which they overlap with the transparency requirements included in six prominent government policies (e.g. the EU AI Act, the US Executive Order on Safe, Secure, and Trustworthy AI). Well-designed transparency reports could reduce compliance costs, in part due to overlapping regulatory requirements across different jurisdictions. We encourage foundation model developers to regularly publish transparency reports, building upon recommendations from the G7 and the White House.},
booktitle = {Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {181–195},
numpages = {15}
}

@inbook{10.5555/3716662.3716728,
author = {Klyman, Kevin},
title = {Acceptable Use Policies for Foundation Models},
year = {2025},
publisher = {AAAI Press},
abstract = {As foundation models have accumulated hundreds of millions of users, developers have begun to take steps to prevent harmful types of uses. One salient intervention that foundation model developers adopt is acceptable use policies---legally binding policies that prohibit users from using a model for specific purposes. This paper identifies acceptable use policies from 30 foundation model developers, analyzes the use restrictions they contain, and argues that acceptable use policies are an important lens for understanding the regulation of foundation models. Taken together, developers' acceptable use policies include 127 distinct use restrictions; the wide variety in the number and type of use restrictions may create fragmentation across the AI supply chain. Companies also employ acceptable use policies to prevent competitors or specific industries from making use of their models. Developers alone decide what constitutes acceptable use, and rarely provide transparency about how they enforce their policies. In practice, acceptable use policies are difficult to enforce, and scrupulous enforcement can act as a barrier to researcher access and limit beneficial uses of foundation models. Acceptable use policies for foundation models are an early example of self-regulation that have a significant impact on the market for foundation models and the AI ecosystem.},
booktitle = {Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {752–767},
numpages = {16}
}

@inproceedings{10.5555/3716662.3716810,
author = {Yew, Rui-Jie and Qin, Lucy and Venkatasubramanian, Suresh},
title = {You Still See Me: How Data Protection Supports the Architecture of AI Surveillance},
year = {2025},
publisher = {AAAI Press},
abstract = {Data forms the backbone of artificial intelligence (AI). Privacy and data protection laws thus have strong bearing on AI systems. Shielded by the rhetoric of compliance with data protection and privacy regulations, privacy-preserving techniques have enabled the extraction of more and new forms of data. We illustrate how the application of privacy-preserving techniques in the development of AI systems-from private set intersection as part of dataset curation to homomorphic encryption and federated learning as part of model computation-can further support surveillance infrastructure under the guise of regulatory permissibility. Finally, we propose technology and policy strategies to evaluate privacy-preserving techniques in light of the protections they actually confer. We conclude by highlighting the role that technologists could play in devising policies that combat surveillance AI technologies.},
booktitle = {Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {1709–1722},
numpages = {14},
location = {San Jose, California, USA},
series = {AIES '24}
}

@article{10.5555/3717781.3717798,
author = {Dogan, Gulustan and Sahin, Elif and Wilkinson, Catherine Fay and Moody, Amelia K. and Song, Yang},
title = {BlueAI: Designing Artificial Intelligence for Environment Science and Climate Change Learning Experiences for K12 Students},
year = {2024},
issue_date = {November 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {5},
issn = {1937-4771},
abstract = {The subject of teaching artificial intelligence (AI) in K-12 settings is rapidly expanding and will significantly affect computer education. While AI is currently a required part of computing curricula at universities, there are unique challenges in incorporating AI into K-12 education. The goal of BlueAI is to prepare K-12 educators to use game-based lessons to teach computational thinking, AI, and computer science skills that will interest children while incorporating important environmental and marine science subjects. We conducted assessments where we taught lessons at two different schools, and presented our findings.},
journal = {J. Comput. Sci. Coll.},
month = nov,
pages = {127–137},
numpages = {11}
}

