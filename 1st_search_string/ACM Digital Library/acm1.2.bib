@inproceedings{10.1145/3539618.3591629,
author = {Salemi, Alireza and Altmayer Pizzorno, Juan and Zamani, Hamed},
title = {A Symmetric Dual Encoding Dense Retrieval Framework for Knowledge-Intensive Visual Question Answering},
year = {2023},
isbn = {9781450394086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539618.3591629},
doi = {10.1145/3539618.3591629},
abstract = {Knowledge-Intensive Visual Question Answering (KI-VQA) refers to answering a question about an image whose answer does not lie in the image. This paper presents a new pipeline for KI-VQA tasks, consisting of a retriever and a reader. First, we introduce DEDR, a symmetric dual encoding dense retrieval framework in which documents and queries are encoded into a shared embedding space using uni-modal (textual) and multi-modal encoders. We introduce an iterative knowledge distillation approach that bridges the gap between the representation spaces in these two encoders. Extensive evaluation on two well-established KI-VQA datasets, i.e., OK-VQA and FVQA, suggests that DEDR outperforms state-of-the-art baselines by 11.6\% and 30.9\% on OK-VQA and FVQA, respectively.Utilizing the passages retrieved by DEDR, we further introduce MM-FiD, an encoder-decoder multi-modal fusion-in-decoder model, for generating a textual answer for KI-VQA tasks. MM-FiD encodes the question, the image, and each retrieved passage separately and uses all passages jointly in its decoder. Compared to competitive baselines in the literature, this approach leads to 5.5\% and 8.5\% improvements in terms of question answering accuracy on OK-VQA and FVQA, respectively.},
booktitle = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {110–120},
numpages = {11},
keywords = {dense retrieval, knowledge distillation, multi-modal retrieval, visual question answering},
location = {Taipei, Taiwan},
series = {SIGIR '23}
}

@inproceedings{10.1145/3539618.3591633,
author = {Lin, Dengtian and Jing, Liqiang and Song, Xuemeng and Liu, Meng and Sun, Teng and Nie, Liqiang},
title = {Adapting Generative Pretrained Language Model for Open-domain Multimodal Sentence Summarization},
year = {2023},
isbn = {9781450394086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539618.3591633},
doi = {10.1145/3539618.3591633},
abstract = {Multimodal sentence summarization, aiming to generate a brief summary of the source sentence and image, is a new yet challenging task. Although existing methods have achieved compelling success, they still suffer from two key limitations: 1) lacking the adaptation of generative pre-trained language models for open-domain MMSS, and 2) lacking the explicit critical information modeling. To address these limitations, we propose a BART-MMSS framework, where BART is adopted as the backbone. To be specific, we propose a prompt-guided image encoding module to extract the source image feature. It leverages several soft to-be-learned prompts for image patch embedding, which facilitates the visual content injection to BART for open-domain MMSS tasks. Thereafter, we devise an explicit source critical token learning module to directly capture the critical tokens of the source sentence with the reference of the source image, where we incorporate explicit supervision to improve performance. Extensive experiments on a public dataset fully validate the superiority of our proposed method. In addition, the predicted tokens by the vision-guided key-token highlighting module can be easily understood by humans and hence improve the interpretability of our model.},
booktitle = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {195–204},
numpages = {10},
keywords = {multimodal summarization, pre-trained language model, prompt learning},
location = {Taipei, Taiwan},
series = {SIGIR '23}
}

@inproceedings{10.1145/3539618.3591658,
author = {Ghasemi, Negin and Aliannejadi, Mohammad and Bonab, Hamed and Kanoulas, Evangelos and de Vries, Arjen P. and Allan, James and Hiemstra, Djoerd},
title = {Cross-Market Product-Related Question Answering},
year = {2023},
isbn = {9781450394086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539618.3591658},
doi = {10.1145/3539618.3591658},
abstract = {Online shops such as Amazon, eBay, and Etsy continue to expand their presence in multiple countries, creating new resource-scarce marketplaces with thousands of items. We consider a marketplace to be resource-scarce when only limited user-generated data is available about the products (e.g., ratings, reviews, and product-related questions). In such a marketplace, an information retrieval system is less likely to help users find answers to their questions about the products. As a result, questions posted online may go unanswered for extended periods. This study investigates the impact of using available data in a resource-rich marketplace to answer new questions in a resource-scarce marketplace, a new problem we call cross-market question answering. To study this problem's potential impact, we collect and annotate a new dataset, XMarket-QA, from Amazon's UK (resource-scarce) and US (resource-rich) local marketplaces. We conduct a data analysis to understand the scope of the cross-market question-answering task. This analysis shows a temporal gap of almost one year between the first question answered in the UK marketplace and the US marketplace. Also, it shows that the first question about a product is posted in the UK marketplace only when 28 questions, on average, have already been answered about the same product in the US marketplace. Human annotations demonstrate that, on average, 65\% of the questions in the UK marketplace can be answered within the US marketplace, supporting the concept of cross-market question answering. Inspired by these findings, we develop a new method, CMJim, which utilizes product similarities across marketplaces in the training phase for retrieving answers from the resource-rich marketplace that can be used to answer a question in the resource-scarce marketplace. Our evaluations show CMJim's significant improvement compared to competitive baselines.},
booktitle = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1293–1302},
numpages = {10},
keywords = {cross-market question answering, product-related question answering, similar question retrieval},
location = {Taipei, Taiwan},
series = {SIGIR '23}
}

@inproceedings{10.1145/3539618.3591677,
author = {Mysore, Sheshera and Jasim, Mahmood and Mccallum, Andrew and Zamani, Hamed},
title = {Editable User Profiles for Controllable Text Recommendations},
year = {2023},
isbn = {9781450394086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539618.3591677},
doi = {10.1145/3539618.3591677},
abstract = {Methods for making high-quality recommendations often rely on learning latent representations from interaction data. These methods, while performant, do not provide ready mechanisms for users to control the recommendation they receive. Our work tackles this problem by proposing LACE, a novel concept value bottleneck model for controllable text recommendations. LACE represents each user with a succinct set of human-readable concepts through retrieval given user-interacted documents and learns personalized representations of the concepts based on user documents. This concept based user profile is then leveraged to make recommendations. The design of our model affords control over the recommendations through a number of intuitive interactions with a transparent user profile. We first establish the quality of recommendations obtained from LACE in an offline evaluation on three recommendation tasks spanning six datasets in warm-start, cold-start, and zero-shot setups. Next, we validate the controllability of LACE under simulated user interactions. Finally, we implement LACE in an interactive controllable recommender system and conduct a user study to demonstrate that users are able to improve the quality of recommendations they receive through interactions with an editable user profile.},
booktitle = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {993–1003},
numpages = {11},
keywords = {concept bottleneck models, interactive recommendation systems, pre-trained language models, text recommendations},
location = {Taipei, Taiwan},
series = {SIGIR '23}
}

@inproceedings{10.1145/3539618.3591682,
author = {Christmann, Philipp and Saha Roy, Rishiraj and Weikum, Gerhard},
title = {Explainable Conversational Question Answering over Heterogeneous Sources via Iterative Graph Neural Networks},
year = {2023},
isbn = {9781450394086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539618.3591682},
doi = {10.1145/3539618.3591682},
abstract = {In conversational question answering, users express their information needs through a series of utterances with incomplete context. Typical ConvQA methods rely on a single source (a knowledge base (KB), or a text corpus, or a set of tables), thus being unable to benefit from increased answer coverage and redundancy of multiple sources. Our method EXPLAIGNN overcomes these limitations by integrating information from a mixture of sources with user-comprehensible explanations for answers. It constructs a heterogeneous graph from entities and evidence snippets retrieved from a KB, a text corpus, web tables, and infoboxes. This large graph is then iteratively reduced via graph neural networks that incorporate question-level attention, until the best answers and their explanations are distilled. Experiments show that EXPLAIGNN improves performance over state-of-the-art baselines. A user study demonstrates that derived answers are understandable by end users.},
booktitle = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {643–653},
numpages = {11},
keywords = {explainability, graph neural networks, question answering},
location = {Taipei, Taiwan},
series = {SIGIR '23}
}

@inproceedings{10.1145/3539618.3591692,
author = {Ye, Yaowen and Xia, Lianghao and Huang, Chao},
title = {Graph Masked Autoencoder for Sequential Recommendation},
year = {2023},
isbn = {9781450394086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539618.3591692},
doi = {10.1145/3539618.3591692},
abstract = {While some powerful neural network architectures (e.g., Transformer, Graph Neural Networks) have achieved improved performance in sequential recommendation with high-order item dependency modeling, they may suffer from poor representation capability in label scarcity scenarios. To address the issue of insufficient labels, Contrastive Learning (CL) has attracted much attention in recent methods to perform data augmentation through embedding contrasting for self-supervision. However, due to the hand-crafted property of their contrastive view generation strategies, existing CL-enhanced models i) can hardly yield consistent performance on diverse sequential recommendation tasks; ii) may not be immune to user behavior data noise. In light of this, we propose a simple yet effective Graph Masked AutoEncoder-enhanced sequential Recommender system (MAERec) that adaptively and dynamically distills global item transitional information for self-supervised augmentation. It naturally avoids the above issue of heavy reliance on constructing high-quality embedding contrastive views. Instead, an adaptive data reconstruction paradigm is designed to be integrated with the long-range item dependency modeling, for informative augmentation in sequential recommendation. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art baseline models and can learn more accurate representations against data noise and sparsity. Our implemented model code is available at https://github.com/HKUDS/MAERec.},
booktitle = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {321–330},
numpages = {10},
keywords = {graph neural networks, masked autoencoder, self-supervised learning, sequential recommendation},
location = {Taipei, Taiwan},
series = {SIGIR '23}
}

@inproceedings{10.1145/3539618.3591710,
author = {Peng, Wei and Li, Wanshui and Hu, Yue},
title = {Leader-Generator Net: Dividing Skill and Implicitness for Conquering FairytaleQA},
year = {2023},
isbn = {9781450394086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539618.3591710},
doi = {10.1145/3539618.3591710},
abstract = {Machine reading comprehension requires systems to understand the given passage and answer questions. Previous methods mainly focus on the interaction between the question and passage. However, they ignore the deep exploration of cognitive elements behind questions, such as fine-grained reading skills (this paper focuses on narrative comprehension skills) and implicitness or explicitness of the question (whether the answer can be found in the passage). Grounded in prior literature on reading comprehension, the understanding of a question is a complex process where human beings need to understand the semantics of the question, use different reading skills for different questions, and then judge the implicitness of the question. To this end, a simple but effective Leader-Generator Network is proposed to explicitly separate and extract fine-grained reading skills and the implicitness or explicitness of the question. Specifically, the proposed skill leader accurately captures the semantic representation of fine-grained reading skills with contrastive learning. And the implicitness-aware pointer-generator adaptively extracts or generates the answer based on the implicitness or explicitness of the question. Furthermore, to validate the generalizability of the methodology, we annotate a new dataset named NarrativeQA 1.1. Experiments on the FairytaleQA and NarrativeQA 1.1 show that the proposed model achieves the state-of-the-art performance (about 5\% gain on Rouge-L) on the question answering task. Our annotated data and code are available at https://github.com/pengwei-iie/Leader-Generator-Net.},
booktitle = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {791–801},
numpages = {11},
keywords = {implicit or explicit question, machine reading comprehension, question answering, reading skills},
location = {Taipei, Taiwan},
series = {SIGIR '23}
}

@inproceedings{10.1145/3539618.3591723,
author = {Li, Chaoliu and Xia, Lianghao and Ren, Xubin and Ye, Yaowen and Xu, Yong and Huang, Chao},
title = {Graph Transformer for Recommendation},
year = {2023},
isbn = {9781450394086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539618.3591723},
doi = {10.1145/3539618.3591723},
abstract = {This paper presents a novel approach to representation learning in recommender systems by integrating generative self-supervised learning with graph transformer architecture. We highlight the importance of high-quality data augmentation with relevant self-supervised pretext tasks for improving performance. Towards this end, we propose a new approach that automates the self-supervision augmentation process through a rationale-aware generative SSL that distills informative user-item interaction patterns. The proposed recommender with Graph Transformer (GFormer) that offers parameterized collaborative rationale discovery for selective augmentation while preserving global-aware user-item relationships. In GFormer, we allow the rationale-aware SSL to inspire graph collaborative filtering with task-adaptive invariant rationalization in graph transformer. The experimental results reveal that our GFormer has the capability to consistently improve the performance over baselines on different datasets. Several in-depth experiments further investigate the invariant rationale-aware augmentation from various aspects. The source code for this work is publicly available at: https://github.com/HKUDS/GFormer.},
booktitle = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1680–1689},
numpages = {10},
keywords = {graph transformer, masked autoencoder, recommendation},
location = {Taipei, Taiwan},
series = {SIGIR '23}
}

@inproceedings{10.1145/3539618.3591781,
author = {Li, Mingchen and Huang, Lifu},
title = {Understand the Dynamic World: An End-to-End Knowledge Informed Framework for Open Domain Entity State Tracking},
year = {2023},
isbn = {9781450394086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539618.3591781},
doi = {10.1145/3539618.3591781},
abstract = {Open domain entity state tracking aims to predict reasonable state changes of entities (i.e., [attribute] of [entity] was [before_state] and [after_state] afterwards) given the action descriptions. It's important to many reasoning tasks to support human everyday activities. However, it's challenging as the model needs to predict an arbitrary number of entity state changes caused by the action while most of the entities are implicitly relevant to the actions and their attributes as well as states are from open vocabularies. To tackle these challenges, we propose a novel end-to-end Knowledge Informed framework for open domain Entity State Tracking, namely KIEST, which explicitly retrieves the relevant entities and attributes from external knowledge graph (i.e., ConceptNet) and incorporates them to autoregressively generate all the entity state changes with a novel dynamic knowledge grained encoder-decoder framework. To enforce the logical coherence among the predicted entities, attributes, and states, we design a new constraint decoding strategy and employ a coherence reward to improve the decoding process. Experimental results show that our proposed KIEST framework significantly outperforms the strong baselines on the public benchmark dataset - OpenPI},
booktitle = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {842–851},
numpages = {10},
keywords = {coherent reward, constraint decoding, knowledge informed genera- tion, open domain entity state tracking},
location = {Taipei, Taiwan},
series = {SIGIR '23}
}

@inproceedings{10.1145/3539618.3591930,
author = {Trappolini, Giovanni and Santilli, Andrea and Rodol\`{a}, Emanuele and Halevy, Alon and Silvestri, Fabrizio},
title = {Multimodal Neural Databases},
year = {2023},
isbn = {9781450394086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539618.3591930},
doi = {10.1145/3539618.3591930},
abstract = {The rise in loosely-structured data available through text, images, and other modalities has called for new ways of querying them. Multimedia Information Retrieval has filled this gap and has witnessed exciting progress in recent years. Tasks such as search and retrieval of extensive multimedia archives have undergone massive performance improvements, driven to a large extent by recent developments in multimodal deep learning. However, methods in this field remain limited in the kinds of queries they support and, in particular, their inability to answer database-like queries. For this reason, inspired by recent work on neural databases, we propose a new framework, which we name Multimodal Neural Databases (MMNDBs). MMNDBs can answer complex database-like queries that involve reasoning over different input modalities, such as text and images, at scale. In this paper, we present the first architecture able to fulfill this set of requirements and test it with several baselines, showing the limitations of currently available models. The results show the potential of these new techniques to process unstructured data coming from different modalities, paving the way for future research in the area.},
booktitle = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2619–2628},
numpages = {10},
keywords = {databases, multimedia information retrieval, neural networks},
location = {Taipei, Taiwan},
series = {SIGIR '23}
}

@proceedings{10.1145/3542637,
title = {APNet '22: Proceedings of the 6th Asia-Pacific Workshop on Networking},
year = {2022},
isbn = {9781450397483},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Fuzhou, China}
}

@inproceedings{10.1145/3543507.3583191,
author = {Zhang, Xuefeng and Zhang, Richong and Li, Xiaoyang and Kong, Fanshuang and Chen, Junfan and Mensah, Samuel and Mao, Yongyi},
title = {Word Sense Disambiguation by Refining Target Word Embedding},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583191},
doi = {10.1145/3543507.3583191},
abstract = {Word Sense Disambiguation (WSD) which aims to identify the correct sense of a target word appearing in a specific context is essential for web text analysis. The use of glosses has been explored as a means for WSD. However, only a few works model the correlation between the target context and gloss. We add to the body of literature by presenting a model that employs a multi-head attention mechanism on deep contextual features of the target word and candidate glosses to refine the target word embedding. Furthermore, to encourage the model to learn the relevant part of target features that align with the correct gloss, we recursively alternate attention on target word features and that of candidate glosses to gradually extract the relevant contextual features of the target word, refining its representation and strengthening the final disambiguation results. Empirical studies on the five most commonly used benchmark datasets show that our proposed model is effective and achieves state-of-the-art results.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {1405–1414},
numpages = {10},
keywords = {Embedding Refinement, Recursive Attention, Word Sense Disambiguation},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3543507.3583194,
author = {Diao, Shizhe and Keh, Sedrick Scott and Pan, Liangming and Tian, Zhiliang and Song, Yan and Zhang, Tong},
title = {Hashtag-Guided Low-Resource Tweet Classification},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583194},
doi = {10.1145/3543507.3583194},
abstract = {Social media classification tasks (e.g., tweet sentiment analysis, tweet stance detection) are challenging because social media posts are typically short, informal, and ambiguous. Thus, training on tweets is challenging and demands large-scale human-annotated labels, which are time-consuming and costly to obtain. In this paper, we find that providing hashtags to social media tweets can help alleviate this issue because hashtags can enrich short and ambiguous tweets in terms of various information, such as topic, sentiment, and stance. This motivates us to propose a novel Hashtag-guided Tweet Classification model (HashTation), which automatically generates meaningful hashtags for the input tweet to provide useful auxiliary signals for tweet classification. To generate high-quality and insightful hashtags, our hashtag generation model retrieves and encodes the post-level and entity-level information across the whole corpus. Experiments show that HashTation achieves significant improvements on seven low-resource tweet classification tasks, in which only a limited amount of training data is provided, showing that automatically enriching tweets with model-generated hashtags could significantly reduce the demand for large-scale human-labeled data. Further analysis demonstrates that HashTation is able to generate high-quality hashtags that are consistent with the tweets and their labels. The code is available at https://github.com/shizhediao/HashTation.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {1415–1426},
numpages = {12},
keywords = {hashtag generation, low-resource classification, social media analysis, tweet classification},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3543507.3583209,
author = {Kang, SeongKu and Kweon, Wonbin and Lee, Dongha and Lian, Jianxun and Xie, Xing and Yu, Hwanjo},
title = {Distillation from Heterogeneous Models for Top-K Recommendation},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583209},
doi = {10.1145/3543507.3583209},
abstract = {Recent recommender systems have shown remarkable performance by using an ensemble of heterogeneous models. However, it is exceedingly costly because it requires resources and inference latency proportional to the number of models, which remains the bottleneck for production. Our work aims to transfer the ensemble knowledge of heterogeneous teachers to a lightweight student model using knowledge distillation (KD), to reduce the huge inference costs while retaining high accuracy. Through an empirical study, we find that the efficacy of distillation severely drops when transferring knowledge from heterogeneous teachers. Nevertheless, we show that an important signal to ease the difficulty can be obtained from the teacher’s training trajectory. This paper proposes a new KD framework, named HetComp, that guides the student model by transferring easy-to-hard sequences of knowledge generated from the teachers’ trajectories. To provide guidance according to the student’s learning state, HetComp uses dynamic knowledge construction to provide progressively difficult ranking knowledge and adaptive knowledge transfer to gradually transfer finer-grained ranking information. Our comprehensive experiments show that HetComp significantly improves the distillation quality and the generalization of the student model.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {801–811},
numpages = {11},
keywords = {Easy-to-hard learning, Knowledge distillation, Model compression, Recommender system},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3543507.3583214,
author = {Hays, Chris and Schutzman, Zachary and Raghavan, Manish and Walk, Erin and Zimmer, Philipp},
title = {Simplistic Collection and Labeling Practices Limit the Utility of Benchmark Datasets for Twitter Bot Detection},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583214},
doi = {10.1145/3543507.3583214},
abstract = {Accurate bot detection is necessary for the safety and integrity of online platforms. It is also crucial for research on the influence of bots in elections, the spread of misinformation, and financial market manipulation. Platforms deploy infrastructure to flag or remove automated accounts, but their tools and data are not publicly available. Thus, the public must rely on third-party bot detection. These tools employ machine learning and often achieve near-perfect performance for classification on existing datasets, suggesting bot detection is accurate, reliable and fit for use in downstream applications. We provide evidence that this is not the case and show that high performance is attributable to limitations in dataset collection and labeling rather than sophistication of the tools. Specifically, we show that simple decision rules — shallow decision trees trained on a small number of features — achieve near-state-of-the-art performance on most available datasets and that bot detection datasets, even when combined together, do not generalize well to out-of-sample datasets. Our findings reveal that predictions are highly dependent on each dataset’s collection and labeling procedures rather than fundamental differences between bots and humans. These results have important implications for both transparency in sampling and labeling procedures and potential biases in research using existing bot detection tools for pre-processing.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {3660–3669},
numpages = {10},
keywords = {Social media, bot detection},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3543507.3583321,
author = {Song, Wenzhuo and Wang, Shoujin and Wang, Yan and Liu, Kunpeng and Liu, Xueyan and Yin, Minghao},
title = {A Counterfactual Collaborative Session-based Recommender System},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583321},
doi = {10.1145/3543507.3583321},
abstract = {Most session-based recommender systems (SBRSs) focus on extracting information from the observed items in the current session of a user to predict a next item, ignoring the causes outside the session (called outer-session causes, OSCs) that influence the user’s selection of items. However, these causes widely exist in the real world, and few studies have investigated their role in SBRSs. In this work, we analyze the causalities and correlations of the OSCs in SBRSs from the perspective of causal inference. We find that the OSCs are essentially the confounders in SBRSs, which leads to spurious correlations in the data used to train SBRS models. To address this problem, we propose a novel SBRS framework named COCO-SBRS (COunterfactual COllaborative Session-Based Recommender Systems) to learn the causality between OSCs and user-item interactions in SBRSs. COCO-SBRS first adopts a self-supervised approach to pre-train a recommendation model by designing pseudo-labels of causes for each user’s selection of the item in data to guide the training process. Next, COCO-SBRS adopts counterfactual inference to recommend items based on the outputs of the pre-trained recommendation model considering the causalities to alleviate the data sparsity problem. As a result, COCO-SBRS can learn the causalities in data, preventing the model from learning spurious correlations. The experimental results of our extensive experiments conducted on three real-world datasets demonstrate the superiority of our proposed framework over ten representative SBRSs.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {971–982},
numpages = {12},
keywords = {counterfactuals, self-supervised learning, session-based recommendation},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3543507.3583370,
author = {Nakamura, Kota and Matsubara, Yasuko and Kawabata, Koki and Umeda, Yuhei and Wada, Yuichiro and Sakurai, Yasushi},
title = {Fast and Multi-aspect Mining of Complex Time-stamped Event Streams},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583370},
doi = {10.1145/3543507.3583370},
abstract = {Given a huge, online stream of time-evolving events with multiple attributes, such as online shopping logs: (item, price, brand, time), how can we summarize large, dynamic high-order tensor streams? How can we see any hidden patterns, rules, and anomalies? Our answer is to focus on two types of patterns, i.e., “regimes” and “components”, over high-order tensor streams, for which we present an efficient and effective method, namely CubeScope. Specifically, it identifies any sudden discontinuity and recognizes distinct dynamical patterns, “regimes” (e.g., weekday/weekend/holiday patterns). In each regime, it also performs multi-way summarization for all attributes (e.g., item, price, brand, and time) and discovers hidden “components” representing latent groups (e.g., item/brand groups) and their relationship. Thanks to its concise but effective summarization, CubeScope can also detect the sudden appearance of anomalies and identify the types of anomalies that occur in practice. Our proposed method has the following properties: (a) Effective: it captures dynamical multi-aspect patterns, i.e., regimes and components, and statistically summarizes all the events; (b) General: it is practical for successful application to data compression, pattern discovery, and anomaly detection on various types of tensor streams; (c) Scalable: our algorithm does not depend on the length of the data stream and its dimensionality. Extensive experiments on real datasets demonstrate that CubeScope finds meaningful patterns and anomalies correctly, and consistently outperforms the state-of-the-art methods as regards accuracy and execution speed.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {1638–1649},
numpages = {12},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3543507.3583374,
author = {Quan, Yuhan and Ding, Jingtao and Gao, Chen and Yi, Lingling and Jin, Depeng and Li, Yong},
title = {Robust Preference-Guided Denoising for Graph based Social Recommendation},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583374},
doi = {10.1145/3543507.3583374},
abstract = {Graph Neural Network&nbsp;(GNN) based social recommendation models improve the prediction accuracy of user preference by leveraging GNN in exploiting preference similarity contained in social relations. However, in terms of both effectiveness and efficiency of recommendation, a large portion of social relations can be redundant or even noisy, e.g., it is quite normal that friends share no preference in a certain domain. Existing models do not fully solve this problem of relation redundancy and noise, as they directly characterize social influence over the full social network. In this paper, we instead propose to improve graph based social recommendation by only retaining the informative social relations to ensure an efficient and effective influence diffusion, i.e., graph denoising. Our designed denoising method is preference-guided to model social relation confidence and benefits user preference learning in return by providing a denoised but more informative social graph for recommendation models. Moreover, to avoid interference of noisy social relations, it designs a self-correcting curriculum learning module and an adaptive denoising strategy, both favoring highly-confident samples. Experimental results on three public datasets demonstrate its consistent capability of improving three state-of-the-art social recommendation models by robustly removing 10-40\% of original relations. We release the source code at https://github.com/tsinghua-fib-lab/Graph-Denoising-SocialRec.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {1097–1108},
numpages = {12},
keywords = {Graph Denoising, Preference Learning, Social Recommendation},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3543507.3583388,
author = {He, Bing and Ahamad, Mustaque and Kumar, Srijan},
title = {Reinforcement Learning-based Counter-Misinformation Response Generation: A Case Study of COVID-19 Vaccine Misinformation},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583388},
doi = {10.1145/3543507.3583388},
abstract = {The spread of online misinformation threatens public health, democracy, and the broader society. While professional fact-checkers form the first line of defense by fact-checking popular false claims, they do not engage directly in conversations with misinformation spreaders. On the other hand, non-expert ordinary users act as eyes-on-the-ground who proactively counter misinformation – recent research has shown that 96\% counter-misinformation responses are made by ordinary users. However, research also found that 2/3 times, these responses are rude and lack evidence. This work seeks to create a counter-misinformation response generation model to empower users to effectively correct misinformation. This objective is challenging due to the absence of datasets containing ground-truth of ideal counter-misinformation responses, and the lack of models that can generate responses backed by communication theories. In this work, we create two novel datasets of misinformation and counter-misinformation response pairs from in-the-wild social media and crowdsourcing from college-educated students. We annotate the collected data to distinguish poor from ideal responses that are factual, polite, and refute misinformation. We propose MisinfoCorrect, a reinforcement learning-based framework that learns to generate counter-misinformation responses for an input misinformation post. The model rewards the generator to increase the politeness, factuality, and refutation attitude while retaining text fluency and relevancy. Quantitative and qualitative evaluation shows that our model outperforms several baselines by generating high-quality counter-responses. This work illustrates the promise of generative text models for social good – here, to help create a safe and reliable information ecosystem. The code and data is accessible on https://github.com/claws-lab/MisinfoCorrect.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {2698–2709},
numpages = {12},
keywords = {misinformation, reinforcement learning, text generation},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3543507.3583406,
author = {Zhao, Xianbing and Chen, Yixin and Liu, Sicen and Zang, Xuan and Xiang, Yang and Tang, Buzhou},
title = {TMMDA: A New Token Mixup Multimodal Data Augmentation for Multimodal Sentiment Analysis},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583406},
doi = {10.1145/3543507.3583406},
abstract = {Existing methods for Multimodal Sentiment Analysis (MSA) mainly focus on integrating multimodal data effectively on limited multimodal data. Learning more informative multimodal representation often relies on large-scale labeled datasets, which are difficult and unrealistic to obtain. To learn informative multimodal representation on limited labeled datasets as more as possible, we proposed TMMDA for MSA, a new Token Mixup Multimodal Data Augmentation, which first generates new virtual modalities from the mixed token-level representation of raw modalities, and then enhances the representation of raw modalities by utilizing the representation of the generated virtual modalities. To preserve semantics during virtual modality generation, we propose a novel cross-modal token mixup strategy based on the generative adversarial network. Extensive experiments on two benchmark datasets, i.e., CMU-MOSI and CMU-MOSEI, verify the superiority of our model compared with several state-of-the-art baselines. The code is available at https://github.com/xiaobaicaihhh/TMMDA.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {1714–1722},
numpages = {9},
keywords = {Data Augmentation, Generative Adversarial Network, Mixup., Multimodal Sentiment Analysis},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3543507.3583535,
author = {Nguyen, Tuan-Phong and Razniewski, Simon and Varde, Aparna and Weikum, Gerhard},
title = {Extracting Cultural Commonsense Knowledge at Scale},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583535},
doi = {10.1145/3543507.3583535},
abstract = {Structured knowledge is important for many AI applications. Commonsense knowledge, which is crucial for robust human-centric AI, is covered by a small number of structured knowledge projects. However, they lack knowledge about human traits and behaviors conditioned on socio-cultural contexts, which is crucial for situative AI. This paper presents Candle, an end-to-end methodology for extracting high-quality cultural commonsense knowledge (CCSK) at scale. Candle extracts CCSK assertions from a huge web corpus and organizes them into coherent clusters, for 3 domains of subjects (geography, religion, occupation) and several cultural facets (food, drinks, clothing, traditions, rituals, behaviors). Candle includes judicious techniques for classification-based filtering and scoring of interestingness. Experimental evaluations show the superiority of the Candle CCSK collection over prior works, and an extrinsic use case demonstrates the benefits of CCSK for the GPT-3 language model. Code and data can be accessed at https://candle.mpi-inf.mpg.de/.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {1907–1917},
numpages = {11},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3543507.3583867,
author = {Wu, Jiageng and Wu, Xian and Hua, Yining and Lin, Shixu and Zheng, Yefeng and Yang, Jie},
title = {Exploring Social Media for Early Detection of Depression in COVID-19 Patients},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583867},
doi = {10.1145/3543507.3583867},
abstract = {The COVID-19 pandemic has caused substantial damage to global health. Even though three years have passed, the world continues to struggle with the virus. Concerns are growing about the impact of COVID-19 on the mental health of infected individuals, who are more likely to experience depression, which can have long-lasting consequences for both the affected individuals and the world. Detection and intervention at an early stage can reduce the risk of depression in COVID-19 patients. In this paper, we investigated the relationship between COVID-19 infection and depression through social media analysis. Firstly, we managed a dataset of COVID-19 patients that contains information about their social media activity both before and after infection. Secondly, We conducted an extensive analysis of this dataset to investigate the characteristic of COVID-19 patients with a higher risk of depression. Thirdly, we proposed a deep neural network for early prediction of depression risk. This model considers daily mood swings as a psychiatric signal and incorporates textual and emotional characteristics via knowledge distillation. Experimental results demonstrate that our proposed framework outperforms baselines in detecting depression risk, with an AUROC of 0.9317 and an AUPRC of 0.8116. Our model has the potential to enable public health organizations to initiate prompt intervention with high-risk patients.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {3968–3977},
numpages = {10},
keywords = {Depression detection, Natural language processing, Social media},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3543507.3587430,
author = {Xie, Yutong and Pan, Zhaoying and Ma, Jinge and Jie, Luo and Mei, Qiaozhu},
title = {A Prompt Log Analysis of Text-to-Image Generation Systems},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3587430},
doi = {10.1145/3543507.3587430},
abstract = {Recent developments in large language models (LLM) and generative AI have unleashed the astonishing capabilities of text-to-image generation systems to synthesize high-quality images that are faithful to a given reference text, known as a “prompt”. These systems have immediately received lots of attention from researchers, creators, and common users. Despite the plenty of efforts to improve the generative models, there is limited work on understanding the information needs of the users of these systems at scale. We conduct the first comprehensive analysis of large-scale prompt logs collected from multiple text-to-image generation systems. Our work is analogous to analyzing the query logs of Web search engines, a line of work that has made critical contributions to the glory of the Web search industry and research. Compared with Web search queries, text-to-image prompts are significantly longer, often organized into special structures that consist of the subject, form, and intent of the generation tasks and present unique categories of information needs. Users make more edits within creation sessions, which present remarkable exploratory patterns. There is also a considerable gap between the user-input prompts and the captions of the images included in the open training data of the generative models. Our findings provide concrete implications on how to improve text-to-image generation systems for creation purposes.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {3892–3902},
numpages = {11},
keywords = {AI for Creativity, AI-Generated Content (AIGC), Prompt Analysis, Query Log Analysis., Text-to-Image Generation},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3543873.3587617,
author = {Zaitoun, Antonio and Sagi, Tomer and Hose, Katja},
title = {Automated Ontology Evaluation: Evaluating Coverage and Correctness using a Domain Corpus},
year = {2023},
isbn = {9781450394192},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543873.3587617},
doi = {10.1145/3543873.3587617},
abstract = {Ontologies conceptualize domains and are a crucial part of web semantics and information systems. However, re-using an existing ontology for a new task requires a detailed evaluation of the candidate ontology as it may cover only a subset of the domain concepts, contain information that is redundant or misleading, and have inaccurate relations and hierarchies between concepts. Manual evaluation of large and complex ontologies is a tedious task. Thus, a few approaches have been proposed for automated evaluation, ranging from concept coverage to ontology generation from a corpus. Existing approaches, however, are limited by their dependence on external structured knowledge sources, such as a thesaurus, as well as by their inability to evaluate semantic relationships. In this paper, we propose a novel framework to automatically evaluate the domain coverage and semantic correctness of existing ontologies based on domain information derived from text. The approach uses a domain-tuned named-entity-recognition model to extract phrasal concepts. The extracted concepts are then used as a representation of the domain against which we evaluate the candidate ontology’s concepts. We further employ a domain-tuned language model to determine the semantic correctness of the candidate ontology’s relations. We demonstrate our automated approach on several large ontologies from the oceanographic domain and show its agreement with a manual evaluation by domain experts and its superiority over the state-of-the-art.},
booktitle = {Companion Proceedings of the ACM Web Conference 2023},
pages = {1127–1137},
numpages = {11},
keywords = {BERT, knowledge engineering, natural language processing, ontology},
location = {Austin, TX, USA},
series = {WWW '23 Companion}
}

@proceedings{10.1145/3544548,
title = {CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hamburg, Germany}
}

@inproceedings{10.1145/3544548.3580816,
author = {Wang, Zijie J. and Wortman Vaughan, Jennifer and Caruana, Rich and Chau, Duen Horng},
title = {GAM Coach: Towards Interactive and User-centered Algorithmic Recourse},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580816},
doi = {10.1145/3544548.3580816},
abstract = {Machine learning (ML) recourse techniques are increasingly used in high-stakes domains, providing end users with actions to alter ML predictions, but they assume ML developers understand what input variables can be changed. However, a recourse plan’s actionability is subjective and unlikely to match developers’ expectations completely. We present GAM Coach, a novel open-source system that adapts integer linear programming to generate customizable counterfactual explanations for Generalized Additive Models (GAMs), and leverages interactive visualizations to enable end users to iteratively generate recourse plans meeting their needs. A quantitative user study with 41 participants shows our tool is usable and useful, and users prefer personalized recourse plans over generic plans. Through a log analysis, we explore how users discover satisfactory recourse plans, and provide empirical evidence that transparency can lead to more opportunities for everyday users to discover counterintuitive patterns in ML models. GAM Coach is available at: https://poloclub.github.io/gam-coach/.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {835},
numpages = {20},
keywords = {Algorithmic Recourse, Counterfactual Explanation, Interpretability},
location = {Hamburg, Germany},
series = {CHI '23}
}

@proceedings{10.1145/3544549,
title = {CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hamburg, Germany}
}

@proceedings{10.1145/3544793,
title = {UbiComp/ISWC '22 Adjunct: Adjunct Proceedings of the 2022 ACM International Joint Conference on Pervasive and Ubiquitous Computing and the 2022 ACM International Symposium on Wearable Computers},
year = {2022},
isbn = {9781450394239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Cambridge, United Kingdom}
}

@proceedings{10.1145/3552326,
title = {EuroSys '23: Proceedings of the Eighteenth European Conference on Computer Systems},
year = {2023},
isbn = {9781450394871},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rome, Italy}
}

@proceedings{10.1145/3555776,
title = {SAC '23: Proceedings of the 38th ACM/SIGAPP Symposium on Applied Computing},
year = {2023},
isbn = {9781450395175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tallinn, Estonia}
}

@inproceedings{10.1145/3558482.3590175,
author = {Zhang, Shaohu and Li, Zhouyu and Das, Anupam},
title = {VoicePM: A Robust Privacy Measurement on Voice Anonymity},
year = {2023},
isbn = {9781450398596},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3558482.3590175},
doi = {10.1145/3558482.3590175},
abstract = {Voice-based human-computer interaction has become pervasive in laptops, smartphones, home voice assistants, and Internet of Thing (IoT) devices. However, voice interaction comes with security and privacy risks. Numerous privacy-preserving measures have been proposed for hiding the speaker's identity while maintaining speech intelligibility. However, existing works do not consider the overall tradeoff between speech utility, speaker verification, and inference of voice attributes, including emotional state, age, accent, and gender. In this study, we first develop a tradeoff metric to capture voice biometrics as well as different voice attributes. We then propose VoicePM, a robust Voice Privacy Measurement framework, to study the feasibility of applying different state-of-the-art voice anonymization solutions to achieve the optimum tradeoff between privacy and utility. We conduct extensive experiments using anonymization approaches covering signal processing, voice synthesis, voice conversion, and adversarial techniques on three speech datasets that include both English and Chinese speakers to showcase the effectiveness and feasibility of VoicePM.},
booktitle = {Proceedings of the 16th ACM Conference on Security and Privacy in Wireless and Mobile Networks},
pages = {215–226},
numpages = {12},
keywords = {privacy control, voice anonymity, voice assistant},
location = {Guildford, United Kingdom},
series = {WiSec '23}
}

@inproceedings{10.1145/3558482.3590177,
author = {Wang, Chenggang and Ninan, Mabon and Reilly, Shane and Ward, Joel and Hawkins, William and Wang, Boyang and Emmert, John M.},
title = {Portability of Deep-Learning Side-Channel Attacks against Software Discrepancies},
year = {2023},
isbn = {9781450398596},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3558482.3590177},
doi = {10.1145/3558482.3590177},
abstract = {Deep-learning side-channel attacks can reveal encryption keys on a device by analyzing power consumption with neural networks. However, the portability of deep-learning side-channel attacks can be affected when training data (from the training device) and test data (from the test device) are discrepant. Recent studies have examined the portability of deep-learning side-channel attacks against hardware discrepancies between two devices. In this paper, we investigate the portability of deep-learning side-channel attacks against software discrepancies between the training device and test device. Specifically, we examine four factors that can lead to software discrepancies, including random delays, instruction rewriting, optimization levels, and code obfuscation. Our experimental results show that software discrepancies caused by each factor can significantly downgrade the attack performance of deep-learning side-channel attacks, and even prevent an attacker from recovering keys. To mitigate the impacts of software discrepancies, we investigate three mitigation methods, including adjusting Points of Interest, domain adaptation, and multi-domain training, from the perspective of an attacker. Our results indicate that multi-domain training is the most effective approach among the three, but it can be difficult to scale given the diversity of software discrepancies.},
booktitle = {Proceedings of the 16th ACM Conference on Security and Privacy in Wireless and Mobile Networks},
pages = {227–238},
numpages = {12},
keywords = {deep learning, side-channel analysis, software discrepancies},
location = {Guildford, United Kingdom},
series = {WiSec '23}
}

@proceedings{10.1145/3563359,
title = {UMAP '23 Adjunct: Adjunct Proceedings of the 31st ACM Conference on User Modeling, Adaptation and Personalization},
year = {2023},
isbn = {9781450398916},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Limassol, Cyprus}
}

@inproceedings{10.1145/3563657.3595960,
author = {Kou, Yubo and Gui, Xinning},
title = {Harmful Design in the Metaverse and How to Mitigate it: A Case Study of User-Generated Virtual Worlds on Roblox},
year = {2023},
isbn = {9781450398930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563657.3595960},
doi = {10.1145/3563657.3595960},
abstract = {Metaverse platforms such as Roblox have become increasingly popular and profitable through a business model that relies on their end users to create and interact with user-generated virtual worlds (UGVWs). However, UGVWs are difficult to moderate, because game design is inherently more complex than static content such as text and images; and Roblox, a game platform targeted primarily at child players, is notorious for harmful user-generated game such as Nazi roleplay games and gambling-like mechanisms. To develop a better understanding of how harmful design is embedded in UGVWs, we conducted an empirical study to understand Roblox users’ experiences with harmful design. We identified several primary ways in which user-generated game designs can be harmful, ranging from directly injecting inappropriate content into the virtual environment of UGVWs to embedding problematic incentive mechanisms into the UGVWs. We further discuss opportunities and challenges for mitigating harmful designs.},
booktitle = {Proceedings of the 2023 ACM Designing Interactive Systems Conference},
pages = {175–188},
numpages = {14},
location = {Pittsburgh, PA, USA},
series = {DIS '23}
}

@inproceedings{10.1145/3563657.3595961,
author = {Chung, John Joon Young and Adar, Eytan},
title = {Artinter: AI-powered Boundary Objects for Commissioning Visual Arts},
year = {2023},
isbn = {9781450398930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563657.3595961},
doi = {10.1145/3563657.3595961},
abstract = {When commissioning visual art, clients and artists communicate to agree on what is to be created. This often requires bridging a language gap in how they conceive art. To arrive at a mutual understanding, they leverage boundary objects—organized language and artifact instances. However, building and working with such objects is hard due to their innate subjectivity and ambiguity. Moreover, acquiring artifact instances, such as references and sketches, requires effort. We introduce Artinter, an AI-powered commission-support system for sharing, concretizing, and expanding boundary objects. Artinter helps artists and clients develop a mutually understood ‘language’ by allowing them to define concepts with artifacts (e.g., what they mean by ‘happy’). The system provides two AI-powered approaches for expanding commission boundary objects: 1) guided search with user-defined concepts and 2) instance generation by mixing concepts and artifacts. Our studies identify how AI features can support commissions and reveal future directions for AI-powered collaborative art-making.},
booktitle = {Proceedings of the 2023 ACM Designing Interactive Systems Conference},
pages = {1997–2018},
numpages = {22},
keywords = {collaboration, creativity support tool, human-AI interaction, visual arts},
location = {Pittsburgh, PA, USA},
series = {DIS '23}
}

@inproceedings{10.1145/3563657.3595977,
author = {Lawton, Tomas and Grace, Kazjon and Ibarrola, Francisco J},
title = {When is a Tool a Tool? User Perceptions of System Agency in Human–AI Co-Creative Drawing},
year = {2023},
isbn = {9781450398930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563657.3595977},
doi = {10.1145/3563657.3595977},
abstract = {This paper presents an analysis of the user experience of Reframer, a novel human-AI drawing interface designed with the iterative and reflective nature of creativity in mind. Collaboration with Reframer occurs in real time, with the user and the system drawing together concurrently. This approach is inspired by theories of creativity as being more problem-framing than problem-solving, and contrasts with the automated one-shot end-to-end workflows of most generative AI models. A 12-participant qualitative exploratory study of the capabilities of our prototype is detailed, as well as a thematic analysis of user attitudes towards drawing with it. The paper then describes two modified prototypes and a second 32-participant comparative study revealing how interface variations evoke differences in user attitudes and experiences. It concludes by proposing a model that characterises the conditions under which users experience co-creative AI as a collaborator, rather than a non-agentive tool.},
booktitle = {Proceedings of the 2023 ACM Designing Interactive Systems Conference},
pages = {1978–1996},
numpages = {19},
keywords = {datasets, gaze detection, neural networks, text tagging},
location = {Pittsburgh, PA, USA},
series = {DIS '23}
}

@inproceedings{10.1145/3563657.3596000,
author = {Hoque, Md Naimul and Ghai, Bhavya and Kraus, Kari and Elmqvist, Niklas},
title = {Portrayal: Leveraging NLP and Visualization for Analyzing Fictional Characters},
year = {2023},
isbn = {9781450398930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563657.3596000},
doi = {10.1145/3563657.3596000},
abstract = {Many creative writing tasks (e.g., fiction writing) require authors to write complex narrative components (e.g., characterization, events, dialogue) over the course of a long story. Similarly, literary scholars need to manually annotate and interpret texts to understand such abstract components. In this paper, we explore how Natural Language Processing (NLP) and interactive visualization can help writers and scholars in such scenarios. To this end, we present Portrayal, an interactive visualization system for analyzing characters in a story. Portrayal extracts natural language indicators from a text to capture the characterization process and then visualizes the indicators in an interactive interface. We evaluated the system with 12 creative writers and scholars in a one-week-long qualitative study. Our findings suggest Portrayal helped writers revise their drafts and create dynamic characters and scenes. It helped scholars analyze characters without the need for any manual annotation, and design literary arguments with concrete evidence.},
booktitle = {Proceedings of the 2023 ACM Designing Interactive Systems Conference},
pages = {74–94},
numpages = {21},
keywords = {Creativity, characters, fiction, natural language processing, visualization.},
location = {Pittsburgh, PA, USA},
series = {DIS '23}
}

@inproceedings{10.1145/3563657.3596036,
author = {Vega-Cebri\'{a}n, Jos\'{e} Manuel and M\'{a}rquez Segura, Elena and Turmo Vidal, Laia and Valdiviezo-Hern\'{a}ndez, Omar and Waern, Annika and Van Delden, Robby and Weijdom, Joris and Elb\ae{}k, Lars and Andersen, Rasmus Vestergaard and Lekbo, S\o{}ren Stigk\ae{}r and Tajadura-Jim\'{e}nez, Ana},
title = {Design Resources in Movement-based Design Methods: a Practice-based Characterization},
year = {2023},
isbn = {9781450398930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563657.3596036},
doi = {10.1145/3563657.3596036},
abstract = {Movement-based design methods are increasingly adopted to help design rich embodied experiences. While there are well-known methods in the field, there is no systematic overview to help designers choose among them, adapt them, or create their own. We collected 41 methods used by movement design researchers and employed a practice-based, bottom-up approach to analyze and characterize their properties. We found 17 categories and arranged them into five main groups: Design Resources, Activities, Delivery, Framing, and Context. In this paper, we describe these groups in general and then focus on Design Resources containing the categories of Movement, Space, and Objects. We ground the characterization with examples from empirical material provided by the design researchers and references to previous work. Additionally, we share recommendations and action points to bring these into practice. This work can help novice and seasoned design researchers who want to employ movement-based design methods in their practice.},
booktitle = {Proceedings of the 2023 ACM Designing Interactive Systems Conference},
pages = {871–888},
numpages = {18},
keywords = {Bodystorming, Design Methods, Embodied Design, Embodied Ideation Methods, Movement-based Design Methods},
location = {Pittsburgh, PA, USA},
series = {DIS '23}
}

@inproceedings{10.1145/3563657.3596078,
author = {Sullivan, John D. and Alaoui, Sarah Fdili and Godard, Pierre and Santoro, Liz},
title = {Embracing the messy and situated practice of dance technology design},
year = {2023},
isbn = {9781450398930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563657.3596078},
doi = {10.1145/3563657.3596078},
abstract = {Designing technology for dance presents a unique challenge to conventional design research and methods. It is subject to diverse and idiosyncratic approaches to the artistic practice that it is situated. We investigated this by joining a dance company to develop interactive technologies for a new performance. From our firsthand account, we show the design space to be messy and non-linear, demanding flexibility and negotiation between multiple stakeholders and constraints. Through interviews with performers and choreographers, we identified nine themes for incorporating technology into dance, revealing tensions and anxiety, but also evolution and improvised processes to weave complex layers into a finished work. We find design for dance productions to be resistant to formal interpretation, requiring designers to embrace the intertwining stages, steps, and methods of the artistic processes that generate them. We suggest that our findings can be of value in other HCI contexts requiring flexible design approaches.},
booktitle = {Proceedings of the 2023 ACM Designing Interactive Systems Conference},
pages = {1383–1397},
numpages = {15},
keywords = {dance, interaction design, performance, performance-led research, research through design},
location = {Pittsburgh, PA, USA},
series = {DIS '23}
}

@inproceedings{10.1145/3563657.3596081,
author = {Wakkary, Ron and Oogjes, Doenja and Sakib, Nazmus and Behzad, Armi},
title = {Turner Boxes and Bees: From Ambivalence to Diffraction},
year = {2023},
isbn = {9781450398930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563657.3596081},
doi = {10.1145/3563657.3596081},
abstract = {This paper is a Research through Design (RtD) investigation that deeply reflects on our ambivalence with three design choices we made while designing in a multispecies context. The ongoing RtD project, called Turner Boxes, aims to design a technological network to interact with wild bees in an urban environment. The design choices negotiate challenges we encountered, including the potential effects of electromagnetic fields (EMF) on bee ecologies; sucrose feeding as an established human-bee interaction; and the question of human intervention when designing in relation to other species. We analyze our negotiations of these challenges along with the practices of beekeepers and ecologists who were part of our investigation, to realize that ambivalence is a characteristic and a resource in multispecies designing. We extend this analysis through feminist epistemologies to articulate a position of diffraction, a standpoint from which to design in multispecies worlds in which interdependencies and differences are critical.},
booktitle = {Proceedings of the 2023 ACM Designing Interactive Systems Conference},
pages = {790–807},
numpages = {18},
keywords = {ambivalence, beekeeping, bees, diffraction, more than human, multispecies, research through design},
location = {Pittsburgh, PA, USA},
series = {DIS '23}
}

@inproceedings{10.1145/3563657.3596094,
author = {Tzanidou, Alexandra and Abosaleh, Al Husein Sami and Lindsay, Stephen and Durrant, Abigail C and Vlachokyriakos, Vasilis},
title = {From Inclusive Theatre to inclusive technologies: Lessons learnt from co-designing Touch Tours with an Inclusive Theatre group},
year = {2023},
isbn = {9781450398930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563657.3596094},
doi = {10.1145/3563657.3596094},
abstract = {The HCI community has attempted to understand the role theatre can play in systems design, but the ways inclusive design methodologies could benefit from inclusive theatre are underexamined. To better understand inclusive theatre practices for technology design, we worked with the first professional inclusive theatre ensemble in Greece, which faced difficulties due to social distancing during the Covid-19 pandemic. In this paper, we attempt to better understand inclusion within such theatre practices through the co-designing of a prototype digital system for Touch Tours, an experience through touch service. We conducted a series of research through design activities with the group, building on eighteen months of ethnographic research. Our goal was to develop a service based on their practices. We contribute design implications for inclusive services, with respect to equity in experience, which enhance the activistic character of the movement, and HCI research concerned with developing technologies that support inclusion.},
booktitle = {Proceedings of the 2023 ACM Designing Interactive Systems Conference},
pages = {1367–1382},
numpages = {16},
keywords = {Accessibility, HCI, Social Model of Disability, Theatre, Touch Sensory Tours},
location = {Pittsburgh, PA, USA},
series = {DIS '23}
}

@inproceedings{10.1145/3563657.3596101,
author = {Feng, K. J. Kevin and Coppock, Maxwell James and McDonald, David W.},
title = {How Do UX Practitioners Communicate AI as a Design Material? Artifacts, Conceptions, and Propositions},
year = {2023},
isbn = {9781450398930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563657.3596101},
doi = {10.1145/3563657.3596101},
abstract = {UX practitioners (UXPs) face novel challenges when working with and communicating artificial intelligence (AI) as a design material. We explore how UXPs communicate AI concepts when given hands-on experience training and experimenting with AI models. To do so, we conducted a task-based design study with 27 UXPs in which they prototyped and created a design presentation for a AI-enabled interface while having access to a simple AI model training tool. Through analyzing UXPs’ design presentations and post-activity interviews, we found that although UXPs struggled to clearly communicate some AI concepts, tinkering with AI broadened common ground when communicating with technical stakeholders. UXPs also identified key risks and benefits of AI in their designs, and proposed concrete next steps for both UX and AI work. We conclude with a sensitizing concept and recommendations for design and AI tools to enhance multi-stakeholder communication and collaboration when crafting human-centered AI experiences.},
booktitle = {Proceedings of the 2023 ACM Designing Interactive Systems Conference},
pages = {2263–2280},
numpages = {18},
keywords = {artificial intelligence, design communication, user experience},
location = {Pittsburgh, PA, USA},
series = {DIS '23}
}

@inproceedings{10.1145/3563657.3596138,
author = {Zamfirescu-Pereira, J.D. and Wei, Heather and Xiao, Amy and Gu, Kitty and Jung, Grace and Lee, Matthew G and Hartmann, Bjoern and Yang, Qian},
title = {Herding AI Cats: Lessons from Designing a Chatbot by Prompting GPT-3},
year = {2023},
isbn = {9781450398930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563657.3596138},
doi = {10.1145/3563657.3596138},
abstract = {Prompting Large Language Models (LLMs) is an exciting new approach to designing chatbots. But can it improve LLM’s user experience (UX) reliably enough to power chatbot products? Our attempt to design a robust chatbot by prompting GPT-3/4 alone suggests: not yet. Prompts made achieving “80\%” UX goals easy, but not the remaining 20\%. Fixing the few remaining interaction breakdowns resembled herding cats: We could not address one UX issue or test one design solution at a time; instead, we had to handle everything everywhere all at once. Moreover, because no prompt could make GPT reliably say “I don’t know” when it should, the user-GPT conversations had no guardrails after a breakdown occurred, often leading to UX downward spirals. These risks incentivized us to design highly prescriptive prompts and scripted bots, counter to the promises of LLM-powered chatbots. This paper describes this case study, unpacks prompting’s fickleness and its impact on UX design processes, and discusses implications for LLM-based design methods and tools.},
booktitle = {Proceedings of the 2023 ACM Designing Interactive Systems Conference},
pages = {2206–2220},
numpages = {15},
keywords = {GPT., Prompt engineering, UX, conversational user interface},
location = {Pittsburgh, PA, USA},
series = {DIS '23}
}

@proceedings{10.1145/3564121,
title = {AIMLSystems '22: Proceedings of the Second International Conference on AI-ML Systems},
year = {2022},
isbn = {9781450398473},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bangalore, India}
}

@proceedings{10.1145/3564246,
title = {STOC 2023: Proceedings of the 55th Annual ACM Symposium on Theory of Computing},
year = {2023},
isbn = {9781450399135},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The papers in this volume were presented at the 55th Annual ACM Symposium on Theory of Computing (STOC 2023), sponsored by the ACM Special Interest Group on Algorithms and Computation Theory (SIGACT). The conference was held in Orlando, Florida, as part of the ACM Federated Computing Research Conference (FCRC). The papers were presented as live talks during sessions held between June 20-23, 2023. STOC 2023 was part of Theory Fest, which included a range of panels, meetings, and social activities. FCRC 2023 featured plenary talks given by Kunle Olukotun, Margaret Martonosi, Shafi Goldwasser, Don Towsley, and Torsten Hoefler.},
location = {Orlando, FL, USA}
}

@proceedings{10.1145/3564746,
title = {ACMSE '23: Proceedings of the 2023 ACM Southeast Conference},
year = {2023},
isbn = {9781450399210},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Virtual Event, USA}
}

@proceedings{10.1145/3565066,
title = {MobileHCI '23 Companion: Proceedings of the 25th International Conference on Mobile Human-Computer Interaction},
year = {2023},
isbn = {9781450399241},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Athens, Greece}
}

@proceedings{10.1145/3565287,
title = {MobiHoc '23: Proceedings of the Twenty-fourth International Symposium on Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks and Mobile Computing},
year = {2023},
isbn = {9781450399265},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {ACM MobiHoc is a premier international annual conference with a highly selective single-track technical program dedicated to addressing the challenges emerging from networked systems that must operate in the face of dynamics.},
location = {Washington, DC, USA}
}

@proceedings{10.1145/3565472,
title = {UMAP '23: Proceedings of the 31st ACM Conference on User Modeling, Adaptation and Personalization},
year = {2023},
isbn = {9781450399326},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Limassol, Cyprus}
}

@proceedings{10.1145/3568812,
title = {ICER '23: Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2},
year = {2023},
isbn = {9781450399753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
location = {Chicago, IL, USA}
}

@proceedings{10.1145/3568813,
title = {ICER '23: Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1},
year = {2023},
isbn = {9781450399760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
location = {Chicago, IL, USA}
}

@inproceedings{10.1145/3568813.3600139,
author = {Hellas, Arto and Leinonen, Juho and Sarsa, Sami and Koutcheme, Charles and Kujanp\"{a}\"{a}, Lilja and Sorva, Juha},
title = {Exploring the Responses of Large Language Models to Beginner Programmers’ Help Requests},
year = {2023},
isbn = {9781450399760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568813.3600139},
doi = {10.1145/3568813.3600139},
abstract = {Background and Context: Over the past year, large language models (LLMs) have taken the world by storm. In computing education, like in other walks of life, many opportunities and threats have emerged as a consequence. Objectives: In this article, we explore such opportunities and threats in a specific area: responding to student programmers’ help requests. More specifically, we assess how good LLMs are at identifying issues in problematic code that students request help on. Method: We collected a sample of help requests and code from an online programming course. We then prompted two different LLMs (OpenAI Codex and GPT-3.5) to identify and explain the issues in the students’ code and assessed the LLM-generated answers both quantitatively and qualitatively. Findings: GPT-3.5 outperforms Codex in most respects. Both LLMs frequently find at least one actual issue in each student program (GPT-3.5 in 90\% of the cases). Neither LLM excels at finding all the issues (GPT-3.5 finding them 57\% of the time). False positives are common (40\% chance for GPT-3.5). The advice that the LLMs provide on the issues is often sensible. The LLMs perform better on issues involving program logic rather than on output formatting. Model solutions are frequently provided even when the LLM is prompted not to. LLM responses to prompts in a non-English language are only slightly worse than responses to English prompts. Implications: Our results continue to highlight the utility of LLMs in programming education. At the same time, the results highlight the unreliability of LLMs: LLMs make some of the same mistakes that students do, perhaps especially when formatting output as required by automated assessment systems. Our study informs teachers interested in using LLMs as well as future efforts to customize LLMs for the needs of programming education.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1},
pages = {93–105},
numpages = {13},
keywords = {CS1, GPT, OpenAI Codex, automatic feedback, help seeking, introductory programming education, large language models, student questions},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3568813.3600142,
author = {Savelka, Jaromir and Agarwal, Arav and An, Marshall and Bogart, Chris and Sakr, Majd},
title = {Thrilled by Your Progress! Large Language Models (GPT-4) No Longer Struggle to Pass Assessments in Higher Education Programming Courses},
year = {2023},
isbn = {9781450399760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568813.3600142},
doi = {10.1145/3568813.3600142},
abstract = {This paper studies recent developments in large language models’ (LLM) abilities to pass assessments in introductory and intermediate Python programming courses at the postsecondary level. The emergence of ChatGPT resulted in heated debates of its potential uses (e.g., exercise generation, code explanation) as well as misuses in programming classes (e.g., cheating). Recent studies show that while the technology performs surprisingly well on diverse sets of assessment instruments employed in typical programming classes the performance is usually not sufficient to pass the courses. The release of GPT-4 largely emphasized notable improvements in the capabilities related to handling assessments originally designed for human test-takers. This study is the necessary analysis in the context of this ongoing transition towards mature generative AI systems. Specifically, we report the performance of GPT-4, comparing it to the previous generations of GPT models, on three Python courses with assessments ranging from simple multiple-choice questions (no code involved) to complex programming projects with code bases distributed into multiple files (599 exercises overall). Additionally, we analyze the assessments that were not handled well by GPT-4 to understand the current limitations of the model, as well as its capabilities to leverage feedback provided by an auto-grader. We found that the GPT models evolved from completely failing the typical programming class’ assessments (the original GPT-3) to confidently passing the courses with no human involvement (GPT-4). While we identified certain limitations in GPT-4’s handling of MCQs and coding exercises, the rate of improvement across the recent generations of GPT models strongly suggests their potential to handle almost any type of assessment widely used in higher education programming courses. These findings could be leveraged by educators and institutions to adapt the design of programming assessments as well as to fuel the necessary discussions into how programming classes should be updated to reflect the recent technological developments. This study provides evidence that programming instructors need to prepare for a world in which there is an easy-to-use widely accessible technology that can be utilized by learners to collect passing scores, with no effort whatsoever, on what today counts as viable programming knowledge and skills assessments.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1},
pages = {78–92},
numpages = {15},
keywords = {AI code generation, AlphaCode, ChatGPT, Codex, GPT, GitHub Copilot, MCQ, Multiple-choice question answering, Python course, coding exercises, generative pre-trained transformers, introductory and intermediate programming, programming knowledge assessment},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@proceedings{10.1145/3569951,
title = {PEARC '23: Practice and Experience in Advanced Research Computing 2023: Computing for the Common Good},
year = {2023},
isbn = {9781450399852},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Portland, OR, USA}
}

@proceedings{10.1145/3570361,
title = {ACM MobiCom '23: Proceedings of the 29th Annual International Conference on Mobile Computing and Networking},
year = {2023},
isbn = {9781450399906},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Madrid, Spain}
}

@inproceedings{10.1145/3570361.3592508,
author = {Ahmed, Mohamed Ibrahim and Bansal, Atul and Yuan, Kuang and Kumar, Swarun and Steenkiste, Peter},
title = {Battery-free Wideband Spectrum Mapping using Commodity RFID Tags},
year = {2023},
isbn = {9781450399906},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3570361.3592508},
doi = {10.1145/3570361.3592508},
abstract = {This paper introduces RFIMap, a system that aims to inexpensively characterize the spatial and temporal distribution of RF spectrum occupancy of any indoor space at fine granularity (tens of centimeters). RFIMap builds rich wide-band indoor spectrum occupancy maps using low-cost and battery-free commodity RFID tags. RFIMap's spectrum maps have wide-ranging applications such as monitoring ambient interference in smart manufacturing, and smart hospitals. RFIMap relies on the observation that commodity RFID tags naturally reflect ambient transmission at other frequency bands, without any modification. RFIMap uses these reflections to estimate the ambient signal power originally received at these tags. RFIMap further performs a careful modeling of indoor multipath to build a dense spectrum map with fine spatial granularity. Our experiments demonstrate spatial spectrum measurement with 2.15 dB of median error at 2.4 GHz, 4.45 dB of median error at 470-700 MHz TV whitespace band, 2.1 dB of median error at 1.8-1.9 GHz in diverse industrial and university settings.},
booktitle = {Proceedings of the 29th Annual International Conference on Mobile Computing and Networking},
articleno = {9},
numpages = {16},
keywords = {spectrum sensing, RFID, backscattering, battery-free},
location = {Madrid, Spain},
series = {ACM MobiCom '23}
}

@inproceedings{10.1145/3570361.3592525,
author = {Lee, Kyungjin and Yi, Juheon and Lee, Youngki},
title = {FarfetchFusion: Towards Fully Mobile Live 3D Telepresence Platform},
year = {2023},
isbn = {9781450399906},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3570361.3592525},
doi = {10.1145/3570361.3592525},
abstract = {We present FarfetchFusion, a fully mobile live 3D telepresence system. Enabling mobile live telepresence is a challenging problem as it requires i) realistic reconstruction of the user and ii) high responsiveness for immersive experience. We first thoroughly analyze the live 3D telepresence pipeline and identify three critical challenges: i) 3D data streaming latency and compression complexity, ii) computational complexity of volumetric fusion-based 3D reconstruction, and iii) inconsistent reconstruction quality due to sparsity of mobile 3D sensors. To tackle the challenges, we propose a disentangled fusion approach, which separates invariant regions and dynamically changing regions with our low-complexity spatio-temporal alignment technique, topology anchoring. We then design and implement an end-to-end system, which achieves realistic reconstruction quality comparable to existing server-based solutions while meeting the real-time performance requirements (&lt;100 ms end-to-end latency, 30 fps throughput, &lt;16 ms motion-to-photon latency) solely relying on mobile computation capability.},
booktitle = {Proceedings of the 29th Annual International Conference on Mobile Computing and Networking},
articleno = {20},
numpages = {15},
keywords = {3D telepresence, mobile systems, volumetric fusion},
location = {Madrid, Spain},
series = {ACM MobiCom '23}
}

@proceedings{10.1145/3571600,
title = {ICVGIP '22: Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing},
year = {2022},
isbn = {9781450398220},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Gandhinagar, India}
}

@proceedings{10.1145/3571884,
title = {CUI '23: Proceedings of the 5th International Conference on Conversational User Interfaces},
year = {2023},
isbn = {9798400700149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Eindhoven, Netherlands}
}

@inproceedings{10.1145/3571884.3597136,
author = {Meyer, Selina and Elsweiler, David},
title = {Towards Cross-Content Conversational Agents for Behaviour Change: Investigating Domain Independence and the Role of Lexical Features in Written Language Around Change},
year = {2023},
isbn = {9798400700149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3571884.3597136},
doi = {10.1145/3571884.3597136},
abstract = {Valuable insights into an individual’s current thoughts and stance regarding behaviour change can be obtained by analysing the language they use, which can be conceptualized using Motivational Interviewing concepts. Training conversational agents (CAs) to detect and employ these concepts could help them provide more personalized and effective assistance. This study investigates the similarity of written language around behaviour change spanning diverse conversational and social contexts and change objectives. Drawing on previous research that applied MI concepts to texts about health behaviour change, we evaluate the performance of existing classifiers on six newly constructed datasets from diverse contexts. To gain insights in determining factors when identifying change language, we explore the impact of lexical features on classification. The results suggest that patterns of change language remain stable across contexts and domains, leading us to conclude that peer-to-peer online data may be sufficient to train CAs to understand user utterances related to behaviour change.},
booktitle = {Proceedings of the 5th International Conference on Conversational User Interfaces},
articleno = {17},
numpages = {13},
keywords = {NLU, behaviour change language, conversational contexts, transfer learning},
location = {Eindhoven, Netherlands},
series = {CUI '23}
}

@proceedings{10.1145/3572334,
title = {ICTD '22: Proceedings of the 2022 International Conference on Information and Communication Technologies and Development},
year = {2022},
isbn = {9781450397872},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Seattle, WA, USA}
}

@inproceedings{10.1145/3572334.3572398,
author = {Maitland, Carleen and Martin, Jean-Laurent and Bravo, Maria Gabriela Urgiles and Bertram, Alex},
title = {A Qualitative Difference: Integrating Qualitative Data into Humanitarian Response Operations},
year = {2023},
isbn = {9781450397872},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3572334.3572398},
doi = {10.1145/3572334.3572398},
abstract = {Recent developments in qualitative data analytics may generate helpful insights for humanitarian response. At the same time, humanitarian coordination efforts are embracing data sharing platforms to ease data flows. Combined, these two innovations could simultaneously offer operational insights across multiple humanitarian organizations. We pursue this potential through the QualMiner project, an18-month collaboration of the UN-led response to the Venezuelan forced migration crisis in Ecuador. In our efforts to integrate qualitative data, we developed applications with implications for local operations as well as platform features and analyzed data entry processes and information product designs. Our analysis finds the established quantitative system serves as an installed base enacting agency and generating three effects, namely framing, artifacts, and informing. We also find collaborative innovation with non-profit users results in direct and indirect factors shaping the data sharing platform's boundaries. Finally, our analysis provides a critical, yet depolarized [1], assessment of advanced analytics in the humanitarian context. These findings have implications for platform boundary theories and critical data studies in the humanitarian domain, as well as humanitarian information management practice.},
booktitle = {Proceedings of the 2022 International Conference on Information and Communication Technologies and Development},
articleno = {26},
numpages = {18},
location = {Seattle, WA, USA},
series = {ICTD '22}
}

@inproceedings{10.1145/3573128.3604901,
author = {Dash, Amanda and Cote, Melissa and Albu, Alexandra Branzan},
title = {WEATHERGOV+: A Table Recognition and Summarization Dataset to Bridge the Gap Between Document Image Analysis and Natural Language Generation},
year = {2023},
isbn = {9798400700279},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573128.3604901},
doi = {10.1145/3573128.3604901},
abstract = {Tables, ubiquitous in data-oriented documents like scientific papers and financial statements, organize and convey relational information. Automatic table recognition from document images, which involves detection within the page, structural segmentation into rows, columns, and cells, and information extraction from cells, has been a popular research topic in document image analysis (DIA). With recent advances in natural language generation (NLG) based on deep neural networks, data-to-text generation, in particular for table summarization, offers interesting solutions to time-intensive data analysis. In this paper, we aim to bridge the gap between efforts in DIA and NLG regarding tabular data: we propose WEATHERGOV+, a dataset building upon the WEATHERGOV dataset, the standard for tabular data summarization techniques, that allows for the training and testing of end-to-end methods working from input document images to generate text summaries as output. WEATHERGOV+ contains images of tables created from the tabular data of WEATHERGOV using visual variations that cover various levels of difficulty, along with the corresponding human-generated table summaries of WEATHERGOV. We also propose an end-to-end pipeline that compares state-of-the-art table recognition methods for summarization purposes. We analyse the results of the proposed pipeline by evaluating WEATHERGOV+ at each stage of the pipeline to identify the effects of error propagation and the weaknesses of the current methods, such as OCR errors. With this research (dataset and code available here1), we hope to encourage new research for the processing and management of inter- and intra-document collections.},
booktitle = {Proceedings of the ACM Symposium on Document Engineering 2023},
articleno = {10},
numpages = {10},
keywords = {data-to-text generation, datasets, document collection management, table recognition, table summarization},
location = {Limerick, Ireland},
series = {DocEng '23}
}

@inproceedings{10.1145/3573128.3609340,
author = {Kulkarni, Hrishikesh and Young, Zachary and Goharian, Nazli and Frieder, Ophir and MacAvaney, Sean},
title = {Genetic Generative Information Retrieval},
year = {2023},
isbn = {9798400700279},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573128.3609340},
doi = {10.1145/3573128.3609340},
abstract = {Documents come in all shapes and sizes and are created by many different means, including now-a-days, generative language models. We demonstrate that a simple genetic algorithm can improve generative information retrieval by using a document's text as a genetic representation, a relevance model as a fitness function, and a large language model as a genetic operator that introduces diversity through random changes to the text to produce new documents. By "mutating" highly-relevant documents and "crossing over" content between documents, we produce new documents of greater relevance to a user's information need --- validated in terms of estimated relevance scores from various models and via a preliminary human evaluation. We also identify challenges that demand further study.},
booktitle = {Proceedings of the ACM Symposium on Document Engineering 2023},
articleno = {8},
numpages = {4},
keywords = {generative information retrieval, genetic algorithm, large language models},
location = {Limerick, Ireland},
series = {DocEng '23}
}

@proceedings{10.1145/3573381,
title = {IMX '23: Proceedings of the 2023 ACM International Conference on Interactive Media Experiences},
year = {2023},
isbn = {9798400700286},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Nantes, France}
}

@proceedings{10.1145/3573382,
title = {CHI PLAY Companion '23: Companion Proceedings of the Annual Symposium on Computer-Human Interaction in Play},
year = {2023},
isbn = {9798400700293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Stratford, ON, Canada}
}

@proceedings{10.1145/3573900,
title = {SIGSIM-PADS '23: Proceedings of the 2023 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
year = {2023},
isbn = {9798400700309},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Orlando, FL, USA}
}

@proceedings{10.1145/3573942,
title = {AIPR '22: Proceedings of the 2022 5th International Conference on Artificial Intelligence and Pattern Recognition},
year = {2022},
isbn = {9781450396899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xiamen, China}
}

@proceedings{10.1145/3575813,
title = {e-Energy '23: Proceedings of the 14th ACM International Conference on Future Energy Systems},
year = {2023},
isbn = {9798400700323},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Orlando, FL, USA}
}

@proceedings{10.1145/3576781,
title = {NANOCOM '23: Proceedings of the 10th ACM International Conference on Nanoscale Computing and Communication},
year = {2023},
isbn = {9798400700347},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Coventry, United Kingdom}
}

@proceedings{10.1145/3576841,
title = {ICCPS '23: Proceedings of the ACM/IEEE 14th International Conference on Cyber-Physical Systems (with CPS-IoT Week 2023)},
year = {2023},
isbn = {9798400700361},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {San Antonio, TX, USA}
}

@inproceedings{10.1145/3576841.3585924,
author = {Rezaei, Yoones and Lee, Stephen},
title = {sat2pc: Generating Building Roof's Point Cloud from a Single 2D Satellite Images},
year = {2023},
isbn = {9798400700361},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576841.3585924},
doi = {10.1145/3576841.3585924},
abstract = {Three-dimensional (3D) urban models have gained interest because of their applications in many use-cases such as disaster management, energy management and solar potential analysis. However, generating these 3D representations requires LiDAR data, which is usually expensive to collect. Because it is expensive, the lidar data are not frequently updated and are not widely available for many regions in the US. As such, 3D models based on these lidar data are either outdated or limited to those locations where the data is available. In contrast, satellite images are freely available and frequently updated. To take advantage of this availability, we propose sat2pc, a deep learning-based approach that predicts the point cloud of a building roof from a single 2D satellite image. Our technique integrates two different loss functions, namely Chamfer Distance and Earth Mover's Distance loss, resulting in a 3D output that balances the overall structure and detail. We extensively evaluate our model and perform ablation studies on a building roof dataset. Our results show that sat2pc outperforms the existing baselines by at least 18.6\%. Moreover, we show that our refinement module improves the overall performance, resulting in fine-grained 3D output. Finally, we show that the predicted point cloud captures more detail and geometric characteristics than other baselines.},
booktitle = {Proceedings of the ACM/IEEE 14th International Conference on Cyber-Physical Systems (with CPS-IoT Week 2023)},
pages = {221–230},
numpages = {10},
keywords = {neural networks, building reconstruction, lidar},
location = {San Antonio, TX, USA},
series = {ICCPS '23}
}

@proceedings{10.1145/3576842,
title = {IoTDI '23: Proceedings of the 8th ACM/IEEE Conference on Internet of Things Design and Implementation},
year = {2023},
isbn = {9798400700378},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {San Antonio, TX, USA}
}

@proceedings{10.1145/3576914,
title = {CPS-IoT Week '23: Proceedings of Cyber-Physical Systems and Internet of Things Week 2023},
year = {2023},
isbn = {9798400700491},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {San Antonio, TX, USA}
}

@inproceedings{10.1145/3576915.3616594,
author = {Liu, Yinxi and Meng, Wei},
title = {DSFuzz: Detecting Deep State Bugs with Dependent State Exploration},
year = {2023},
isbn = {9798400700507},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576915.3616594},
doi = {10.1145/3576915.3616594},
abstract = {Traditional random mutation-based fuzzers are ineffective at reaching deep program states that require specific input values. Consequently, a large number of deep bugs remain undiscovered. To enhance the effectiveness of input mutation, previous research has utilized taint analysis to identify control-dependent critical bytes and only mutates those bytes. However, existing works do not consider indirect control dependencies, in which the critical bytes for taking one branch can only be set in a basic block that is control dependent on a series of other basic blocks. These critical bytes cannot be identified unless that series of basic blocks are visited in the execution path. Existing approaches would take an unacceptably long time and computation resources to attempt multiple paths before setting these critical bytes. In other words, the search space for identifying the critical bytes cannot be effectively explored by the current mutation strategies.In this paper, we aim to explore a new input generation strategy for satisfying a series of indirect control dependencies that can lead to deep program states. We present DSFuzz, a directed fuzzing scheme that effectively constructs inputs for exploring particular deep states. DSFuzz focuses on the deep targets reachable by only satisfying a set of indirect control dependencies. By analyzing the conditions that a deep state indirectly depends on, it can generate dependent critical bytes for taking the corresponding branches. It also rules out the control flows that are unlikely to lead to the target state. As a result, it only needs to mutate under a limited search space. DSFuzz significantly outperformed state-of-the-art directed greybox fuzzers in detecting bugs in deep program states: it detected eight new bugs that other tools failed to find.},
booktitle = {Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1242–1256},
numpages = {15},
keywords = {fuzzing, program analysis, software testing},
location = {Copenhagen, Denmark},
series = {CCS '23}
}

@inproceedings{10.1145/3576915.3616639,
author = {Bahramali, Alireza and Bozorgi, Ardavan and Houmansadr, Amir},
title = {Realistic Website Fingerprinting By Augmenting Network Traces},
year = {2023},
isbn = {9798400700507},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576915.3616639},
doi = {10.1145/3576915.3616639},
abstract = {Website Fingerprinting (WF) is considered a major threat to the anonymity of Tor users (and other anonymity systems). While state-of-the-art WF techniques have claimed high attack accuracies, e.g., by leveraging Deep Neural Networks (DNN), several recent works have questioned the practicality of such WF attacks in the real world due to the assumptions made in the design and evaluation of these attacks. In this work, we argue that such impracticality issues are mainly due to the attacker's inability in collecting training data in comprehensive network conditions, e.g., a WF classifier may be trained only on high-bandwidth samples collected on specific high-bandwidth network links but deployed on connections with different network conditions. We show that augmenting network traces can enhance the performance of WF classifiers in unobserved network conditions. Specifically, we introduce NetAugment, an augmentation technique tailored to the specifications of Tor traces. We instantiate NetAugment through semi-supervised and self-supervised learning techniques. Our extensive open-world and close-world experiments demonstrate that under practical evaluation settings, our WF attacks provide superior performances compared to the state-of-the-art; this is due to their use of augmented network traces for training, which allows them to learn the features of target traffic in unobserved settings (e.g., unknown bandwidth, Tor circuits, etc.). For instance, with a 5-shot learning in a closed-world scenario, our self-supervised WF attack (named NetCLR) reaches up to 80\% accuracy when the traces for evaluation are collected in a setting unobserved by the WF adversary. This is compared to an accuracy of 64.4\% achieved by the state-of-the-art Triplet Fingerprinting [34]. We believe that the promising results of our work can encourage the use of network trace augmentation in other types of network traffic analysis.},
booktitle = {Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1035–1049},
numpages = {15},
keywords = {anonymous communications, flow correlation attacks, tor, traffic analysis, website fingerprinting},
location = {Copenhagen, Denmark},
series = {CCS '23}
}

@inproceedings{10.1145/3576915.3616679,
author = {Qu, Yiting and Shen, Xinyue and He, Xinlei and Backes, Michael and Zannettou, Savvas and Zhang, Yang},
title = {Unsafe Diffusion: On the Generation of Unsafe Images and Hateful Memes From Text-To-Image Models},
year = {2023},
isbn = {9798400700507},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576915.3616679},
doi = {10.1145/3576915.3616679},
abstract = {State-of-the-art Text-to-Image models like Stable Diffusion and DALLEcdot2 are revolutionizing how people generate visual content. At the same time, society has serious concerns about how adversaries can exploit such models to generate problematic or unsafe images. In this work, we focus on demystifying the generation of unsafe images and hateful memes from Text-to-Image models. We first construct a typology of unsafe images consisting of five categories (sexually explicit, violent, disturbing, hateful, and political). Then, we assess the proportion of unsafe images generated by four advanced Text-to-Image models using four prompt datasets. We find that Text-to-Image models can generate a substantial percentage of unsafe images; across four models and four prompt datasets, 14.56\% of all generated images are unsafe. When comparing the four Text-to-Image models, we find different risk levels, with Stable Diffusion being the most prone to generating unsafe content (18.92\% of all generated images are unsafe). Given Stable Diffusion's tendency to generate more unsafe content, we evaluate its potential to generate hateful meme variants if exploited by an adversary to attack a specific individual or community. We employ three image editing methods, DreamBooth, Textual Inversion, and SDEdit, which are supported by Stable Diffusion to generate variants. Our evaluation result shows that 24\% of the generated images using DreamBooth are hateful meme variants that present the features of the original hateful meme and the target individual/community; these generated images are comparable to hateful meme variants collected from the real world. Overall, our results demonstrate that the danger of large-scale generation of unsafe images is imminent. We discuss several mitigating measures, such as curating training data, regulating prompts, and implementing safety filters, and encourage better safeguard tools to be developed to prevent unsafe generation.1 Our code is available at https://github.com/YitingQu/unsafe-diffusion.},
booktitle = {Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security},
pages = {3403–3417},
numpages = {15},
keywords = {hateful memes, text-to-image models, unsafe images},
location = {Copenhagen, Denmark},
series = {CCS '23}
}

@inproceedings{10.1145/3576915.3623097,
author = {Meng, Ruijie and P\^{\i}rlea, George and Roychoudhury, Abhik and Sergey, Ilya},
title = {Greybox Fuzzing of Distributed Systems},
year = {2023},
isbn = {9798400700507},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576915.3623097},
doi = {10.1145/3576915.3623097},
abstract = {Grey-box fuzzing is the lightweight approach of choice for finding bugs in sequential programs. It provides a balance between efficiency and effectiveness by conducting a biased random search over the domain of program inputs using a feedback function from observed test executions. For distributed system testing, however, the state-of-practice is represented today by only black-box tools that do not attempt to infer and exploit any knowledge of the system's past behaviours to guide the search for bugs.In this work, we present MALLORY: the first framework for grey-box fuzz-testing of distributed systems. Unlike popular black-box distributed system fuzzers, such as JEPSEN, that search for bugs by randomly injecting network partitions and node faults or by following human-defined schedules, MALLORY is adaptive. It exercises a novel metric to learn how to maximize the number of observed system behaviors by choosing different sequences of faults, thus increasing the likelihood of finding new bugs. Our approach relies on timeline-driven testing. MALLORY dynamically constructs Lamport timelines of the system behaviour and further abstracts these timelines into happens-before summaries, which serve as a feedback function guiding the fuzz campaign. Subsequently, MALLORY reactively learns a policy using Q-learning, enabling it to introduce faults guided by its real-time observation of the summaries.We have evaluated MALLORY on a diverse set of widely-used industrial distributed systems. Compared to the start-of-the-art black-box fuzzer JEPSEN, MALLORY explores 54.27\% more distinct states within 24 hours while achieving a speed-up of 2.24X. At the same time, MALLORY finds bugs 1.87X faster, thereby finding more bugs within the given time budget. MALLORY discovered 22 zero-day bugs (of which 18 were confirmed by developers), including 10 new vulnerabilities, in rigorously tested distributed systems such as Braft, Dqlite and Redis. 6 new CVEs have been assigned.},
booktitle = {Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1615–1629},
numpages = {15},
keywords = {distributed systems, greybox fuzzing, reactive system testing},
location = {Copenhagen, Denmark},
series = {CCS '23}
}

@inproceedings{10.1145/3576915.3623120,
author = {Li, Zongjie and Wang, Chaozheng and Wang, Shuai and Gao, Cuiyun},
title = {Protecting Intellectual Property of Large Language Model-Based Code Generation APIs via Watermarks},
year = {2023},
isbn = {9798400700507},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576915.3623120},
doi = {10.1145/3576915.3623120},
abstract = {The rise of large language model-based code generation (LLCG) has enabled various commercial services and APIs. Training LLCG models is often expensive and time-consuming, and the training data are often large-scale and even inaccessible to the public. As a result, the risk of intellectual property (IP) theft over the LLCG models (e.g., via imitation attacks) has been a serious concern. In this paper, we propose the first watermark (WM) technique to protect LLCG APIs from remote imitation attacks. Our proposed technique is based on replacing tokens in an LLCG output with their "synonyms" available in the programming language. A WM is thus defined as the stealthily tweaked distribution among token synonyms in LLCG outputs. We design six WM schemes (instantiated into over 30 WM passes) which rely on conceptually distinct token synonyms available in programming languages. Moreover, to check the IP of a suspicious model (decide if it is stolen from our protected LLCG API), we propose a statistical tests-based procedure that can directly check a remote, suspicious LLCG API.We evaluate our WM technique on LLCG models fine-tuned from two popular large language models, CodeT5 and CodeBERT. The evaluation shows that our approach is effective in both WM injection and IP check. The inserted WMs do not undermine the usage of normal users (i.e., high fidelity) and incur negligible extra cost. Moreover, our injected WMs exhibit high stealthiness and robustness against powerful attackers; even if they know all WM schemes, they can hardly remove WMs without largely undermining the accuracy of their stolen models.},
booktitle = {Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security},
pages = {2336–2350},
numpages = {15},
keywords = {code generation, large language model, watermark},
location = {Copenhagen, Denmark},
series = {CCS '23}
}

@inproceedings{10.1145/3576915.3623166,
author = {Li, Wen and Yang, Haoran and Luo, Xiapu and Cheng, Long and Cai, Haipeng},
title = {PyRTFuzz: Detecting Bugs in Python Runtimes via Two-Level Collaborative Fuzzing},
year = {2023},
isbn = {9798400700507},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576915.3623166},
doi = {10.1145/3576915.3623166},
abstract = {Given the widespread use of Python and its sustaining impact, the security and reliability of the Python runtime system is highly and broadly critical. Yet with real-world bugs in Python runtimes being continuously and increasingly reported, technique/tool support for automated detection of such bugs is still largely lacking. In this paper, we present PyRTFuzz, a novel fuzzing technique/tool for holistically testing Python runtimes including the language interpreter and its runtime libraries. PyRTFuzz combines generationand mutation-based fuzzing at the compiler- and application-testing level, respectively, as enabled by static/dynamic analysis for extracting runtime API descriptions, a declarative, specification language for valid and diverse Python code generation, and a custom type-guided mutation strategy for format/structure-aware application input generation. We implemented PyRTFuzz for the primary Python implementation (CPython) and applied it to three versions of the runtime. Our experiments revealed 61 new, demonstrably exploitable bugs including those in the interpreter and most in the runtime libraries. Our results also demonstrated the promising scalability and cost-effectiveness of PyRTFuzz and its great potential for further bug discovery. The two-level collaborative fuzzing methodology instantiated in PyRTFuzz may also apply to other language runtimes especially those of interpreted languages.},
booktitle = {Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1645–1659},
numpages = {15},
keywords = {code generation, collaborative fuzzing, fuzz testing, greybox fuzzing, language runtime, python, runtime system, software security},
location = {Copenhagen, Denmark},
series = {CCS '23}
}

@inproceedings{10.1145/3576915.3623175,
author = {He, Jingxuan and Vechev, Martin},
title = {Large Language Models for Code: Security Hardening and Adversarial Testing},
year = {2023},
isbn = {9798400700507},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576915.3623175},
doi = {10.1145/3576915.3623175},
abstract = {Large language models (large LMs) are increasingly trained on massive codebases and used to generate code. However, LMs lack awareness of security and are found to frequently produce unsafe code. This work studies the security of LMs along two important axes: (i) security hardening, which aims to enhance LMs' reliability in generating secure code, and (ii) adversarial testing, which seeks to evaluate LMs' security at an adversarial standpoint. We address both of these by formulating a new security task called controlled code generation. The task is parametric and takes as input a binary property to guide the LM to generate secure or unsafe code, while preserving the LM's capability of generating functionally correct code. We propose a novel learning-based approach called SVEN to solve this task. SVEN leverages property-specific continuous vectors to guide program generation towards the given property, without modifying the LM's weights. Our training procedure optimizes these continuous vectors by enforcing specialized loss terms on different regions of code, using a high-quality dataset carefully curated by us. Our extensive evaluation shows that SVEN is highly effective in achieving strong security control. For instance, a state-of-the-art CodeGen LM with 2.7B parameters generates secure code for 59.1\% of the time. When we employ SVEN to perform security hardening (or adversarial testing) on this LM, the ratio is significantly boosted to 92.3\% (or degraded to 36.8\%). Importantly, SVEN closely matches the original LMs in functional correctness.},
booktitle = {Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1865–1879},
numpages = {15},
keywords = {ai safety, code generation, code security, large language models},
location = {Copenhagen, Denmark},
series = {CCS '23}
}

@inproceedings{10.1145/3576915.3623209,
author = {Yu, Zhiyuan and Zhai, Shixuan and Zhang, Ning},
title = {AntiFake: Using Adversarial Audio to Prevent Unauthorized Speech Synthesis},
year = {2023},
isbn = {9798400700507},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576915.3623209},
doi = {10.1145/3576915.3623209},
abstract = {The rapid development of deep neural networks and generative AI has catalyzed growth in realistic speech synthesis. While this technology has great potential to improve lives, it also leads to the emergence of ''DeepFake'' where synthesized speech can be misused to deceive humans and machines for nefarious purposes. In response to this evolving threat, there has been a significant amount of interest in mitigating this threat by DeepFake detection.Complementary to the existing work, we propose to take the preventative approach and introduce AntiFake, a defense mechanism that relies on adversarial examples to prevent unauthorized speech synthesis. To ensure the transferability to attackers' unknown synthesis models, an ensemble learning approach is adopted to improve the generalizability of the optimization process. To validate the efficacy of the proposed system, we evaluated AntiFake against five state-of-the-art synthesizers using real-world DeepFake speech samples. The experiments indicated that AntiFake achieved over 95\% protection rate even to unknown black-box models. We have also conducted usability tests involving 24 human participants to ensure the solution is accessible to diverse populations.},
booktitle = {Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security},
pages = {460–474},
numpages = {15},
keywords = {adversarial machine learning, deepfake defense, generative ai, speech synthesis},
location = {Copenhagen, Denmark},
series = {CCS '23}
}

@proceedings{10.1145/3577065,
title = {ICTCE '22: Proceedings of the 2022 5th International Conference on Telecommunications and Communication Engineering},
year = {2022},
isbn = {9781450397797},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Chengdu, China}
}

@proceedings{10.1145/3577148,
title = {SSIP '22: Proceedings of the 2022 5th International Conference on Sensors, Signal and Image Processing},
year = {2022},
isbn = {9781450397124},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Nanjing, China}
}

@proceedings{10.1145/3577190,
title = {ICMI '23: Proceedings of the 25th International Conference on Multimodal Interaction},
year = {2023},
isbn = {9798400700552},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Paris, France}
}

@inproceedings{10.1145/3577190.3614155,
author = {Mertes, Silvan and Strobl, Marcel and Schlagowski, Ruben and Andr\'{e}, Elisabeth},
title = {ASMRcade: Interactive Audio Triggers for an Autonomous Sensory Meridian Response},
year = {2023},
isbn = {9798400700552},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3577190.3614155},
doi = {10.1145/3577190.3614155},
abstract = {Autonomous Sensory Meridian Response (ASMR) is a sensory phenomenon involving pleasurable tingling sensations in response to stimuli such as whispering, tapping, and hair brushing. It is increasingly used to promote health and well-being, help with sleep, and reduce stress and anxiety. ASMR triggers are both highly individual and of great variety. Consequently, finding or identifying suitable ASMR content, e.g., by searching online platforms, can take time and effort. This work addresses this challenge by introducing a novel interactive approach for users to generate personalized ASMR sounds. The presented system utilizes a generative adversarial network (GAN) for sound generation and a graphical user interface (GUI) for user control. Our system allows users to create and manipulate audio samples by interacting with a visual representation of the GAN’s latent input vector. Further, we present the results of a first user study which indicates that our approach is suitable for triggering ASMR experiences.},
booktitle = {Proceedings of the 25th International Conference on Multimodal Interaction},
pages = {70–78},
numpages = {9},
keywords = {ASMR, ASMR Generation, Audio Synthesis, GAN, Interactive ASMR, Stress},
location = {Paris, France},
series = {ICMI '23}
}

@inproceedings{10.1145/3577190.3614158,
author = {Hensel, Laura Birka and Yongsatianchot, Nutchanon and Torshizi, Parisa and Minucci, Elena and Marsella, Stacy},
title = {Large language models in textual analysis for gesture selection},
year = {2023},
isbn = {9798400700552},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3577190.3614158},
doi = {10.1145/3577190.3614158},
abstract = {Gestures perform a variety of communicative functions that powerfully influence human face-to-face interaction. How this communicative function is achieved varies greatly between individuals and depends on the role of the speaker and the context of the interaction. Approaches to automatic gesture generation vary not only in the degree to which they rely on data-driven techniques but also the degree to which they can produce context and speaker specific gestures. However, these approaches face two major challenges: The first is obtaining sufficient training data that is appropriate for the context and the goal of the application. The second is related to designer control to realize their specific intent for the application. Here, we approach these challenges by using large language models (LLMs) to show that these powerful models of large amounts of data can be adapted for gesture analysis and generation. Specifically, we used ChatGPT as a tool for suggesting context-specific gestures that can realize designer intent based on minimal prompts. We also find that ChatGPT can suggests novel yet appropriate gestures not present in the minimal training data. The use of LLMs is a promising avenue for gesture generation that reduce the need for laborious annotations and has the potential to flexibly and quickly adapt to different designer intents.},
booktitle = {Proceedings of the 25th International Conference on Multimodal Interaction},
pages = {378–387},
numpages = {10},
keywords = {gesture analysis, gesture selection, large language models},
location = {Paris, France},
series = {ICMI '23}
}

@proceedings{10.1145/3577193,
title = {ICS '23: Proceedings of the 37th ACM International Conference on Supercomputing},
year = {2023},
isbn = {9798400700569},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {ICS is a well-known and outstanding forum for the presentation of significant research in high performance computing.},
location = {Orlando, FL, USA}
}

@proceedings{10.1145/3578356,
title = {EuroMLSys '23: Proceedings of the 3rd Workshop on Machine Learning and Systems},
year = {2023},
isbn = {9798400700842},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rome, Italy}
}

@proceedings{10.1145/3578357,
title = {EUROSEC '23: Proceedings of the 16th European Workshop on System Security},
year = {2023},
isbn = {9798400700859},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rome, Italy}
}

@proceedings{10.1145/3578503,
title = {WebSci '23: Proceedings of the 15th ACM Web Science Conference 2023},
year = {2023},
isbn = {9798400700897},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Austin, TX, USA}
}

@inproceedings{10.1145/3578503.3583624,
author = {Wang, Weixiang and Soundarajan, Sucheta},
title = {Fair Link Prediction with Multi-Armed Bandit Algorithms},
year = {2023},
isbn = {9798400700897},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578503.3583624},
doi = {10.1145/3578503.3583624},
abstract = {Recommendation systems have been used in many domains, and in recent years, ethical problems associated with such systems have gained serious attention. The problem of unfairness in friendship or link recommendation systems in social networks has begun attracting attention, as such unfairness can cause problems like segmentation and echo chambers. One challenge in this problem is that there are many fairness metrics for networks, and existing methods only consider the improvement of a single specific fairness indicator&nbsp;[16, 17, 20]. In this work, we model the fair link prediction problem as a multi-armed bandit problem. We propose FairLink, a multi-armed bandit based framework that predicts new edges that are both accurate and well-behaved with respect to a fairness property of choice. This method allows the user to specify the desired fairness metric. Experiments on five real-world datasets show that FairLink can achieve a significant fairness improvement as compared to a standard recommendation algorithm, with only a small reduction in accuracy.},
booktitle = {Proceedings of the 15th ACM Web Science Conference 2023},
pages = {219–228},
numpages = {10},
keywords = {fairness, link prediction, social networks},
location = {Austin, TX, USA},
series = {WebSci '23}
}

@article{10.1145/3578552,
author = {Starzy\'{n}ska-Grze\'{s}, Ma\l{}gorzata B. and Roussel, Robin and Jacoby, Sam and Asadipour, Ali},
title = {Computer Vision-based Analysis of Buildings and Built Environments: A Systematic Review of Current Approaches},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {13s},
issn = {0360-0300},
url = {https://doi.org/10.1145/3578552},
doi = {10.1145/3578552},
abstract = {Analysing 88 sources published from 2011 to 2021, this article presents a first systematic review of the computer vision-based analysis of buildings and the built environment. Its aim is to assess the potential of this research for architectural studies and the implications of a shift to a cross-disciplinarity approach between architecture and computer science for research problems, aims, processes, and applications. To this end, the types of algorithms and data sources used in the reviewed studies are discussed in respect to architectural applications such as a building classification, detail classification, qualitative environmental analysis, building condition survey, and building value estimation. Based on this, current research gaps and trends are identified, with two main research aims emerging. First, studies that use or optimise computer vision methods to automate time-consuming, labour-intensive, or complex tasks when analysing architectural image data. Second, work that explores the methodological benefits of machine learning approaches to overcome limitations of conventional analysis to investigate new questions about the built environment by finding patterns and relationships among visual, statistical, and qualitative data. The growing body of research offers new methods to architectural and design studies, with the article identifying future challenges and directions of research.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {284},
numpages = {25},
keywords = {Architecture, built environment, computer vision, machine learning, image data}
}

@proceedings{10.1145/3578837,
title = {ICEEL '22: Proceedings of the 2022 6th International Conference on Education and E-Learning},
year = {2022},
isbn = {9781450398428},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Yamanashi, Japan}
}

@proceedings{10.1145/3579142,
title = {BiDEDE '23: Proceedings of the International Workshop on Big Data in Emergent Distributed Environments},
year = {2023},
isbn = {9798400700934},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Seattle, WA, USA}
}

@proceedings{10.1145/3579371,
title = {ISCA '23: Proceedings of the 50th Annual International Symposium on Computer Architecture},
year = {2023},
isbn = {9798400700958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Orlando, FL, USA}
}

@inproceedings{10.1145/3579371.3589089,
author = {Ma, Tianrui and Boloor, Adith Jagadish and Yang, Xiangxing and Cao, Weidong and Williams, Patrick and Sun, Nan and Chakrabarti, Ayan and Zhang, Xuan},
title = {LeCA: In-Sensor Learned Compressive Acquisition for Efficient Machine Vision on the Edge},
year = {2023},
isbn = {9798400700958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579371.3589089},
doi = {10.1145/3579371.3589089},
abstract = {With the rapid advances of deep learning-based computer vision (CV) technology, digital images are increasingly consumed, not by humans, but by downstream CV algorithms. However, capturing high-fidelity and high-resolution images is energy-intensive. It not only dominates the energy consumption of the sensor itself (i.e. in low-power edge devices), but also contributes to significant memory burdens and performance bottlenecks in the later storage, processing, and communication stages. In this paper, we systematically explore a new paradigm of in-sensor processing, termed "learned compressive acquisition" (LeCA). Targeting machine vision applications on the edge, the LeCA framework exploits the joint learning of a sensor autoencoder structure with the downstream CV algorithms to effectively compress the original image into low-dimensional features with adaptive bit depth. We employ column-parallel analog-domain processing directly inside the image sensor to perform the compressive encoding of the raw image, resulting in meaningful hardware savings, and energy efficiency improvements. Evaluated within a modern machine vision processing pipeline, LeCA achieves 4\texttimes{}, 6\texttimes{}, and 8\texttimes{} compression ratios prior to any digital compression, with minimal accuracy loss of 0.97\%, 0.98\%, and 2.01\% on ImageNet, outperforming existing methods. Compared with the conventional full-resolution image sensor and the state-of-the-art compressive sensing sensor, our LeCA sensor is 6.3\texttimes{} and 2.2\texttimes{} more energy-efficient while reaching a 2\texttimes{} higher compression ratio.},
booktitle = {Proceedings of the 50th Annual International Symposium on Computer Architecture},
articleno = {54},
numpages = {14},
keywords = {CMOS image sensor, image compression, autoencoder},
location = {Orlando, FL, USA},
series = {ISCA '23}
}

@inproceedings{10.1145/3579371.3589352,
author = {Smith, Kaitlin N. and Perlin, Michael A. and Gokhale, Pranav and Frederick, Paige and Owusu-Antwi, David and Rines, Richard and Omole, Victory and Chong, Frederic},
title = {Clifford-based Circuit Cutting for Quantum Simulation},
year = {2023},
isbn = {9798400700958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579371.3589352},
doi = {10.1145/3579371.3589352},
abstract = {Quantum computing has potential to provide exponential speedups over classical computing for many important applications. However, today's quantum computers are in their early stages, and hardware quality issues hinder the scale of program execution. Benchmarking and simulation of quantum circuits on classical computers is therefore essential to advance the understanding of how quantum computers and programs operate, enabling both algorithm discovery that leads to high-impact quantum computation and engineering improvements that deliver to more powerful quantum systems. Unfortunately, the nature of quantum information causes simulation complexity to scale exponentially with problem size.In this paper, we debut Super.tech's SuperSim framework, a new approach for high fidelity and scalable quantum circuit simulation. SuperSim employs two key techniques for accelerated quantum circuit simulation: Clifford-based simulation and circuit cutting. Through the isolation of Clifford subcircuit fragments within a larger non-Clifford circuit, resource-efficient Clifford simulation can be invoked, leading to significant reductions in runtime. After fragments are independently executed, circuit cutting and recombination procedures allow the final output of the original circuit to be reconstructed from fragment execution results. Through the combination of these two state-of-art techniques, SuperSim is a product for quantum practitioners that allows quantum circuit evaluation to scale beyond the frontiers of current simulators. Our results show that Clifford-based circuit cutting accelerates the simulation of near-Clifford circuits, allowing 100s of qubits to be evaluated with modest runtimes.},
booktitle = {Proceedings of the 50th Annual International Symposium on Computer Architecture},
articleno = {84},
numpages = {13},
keywords = {quantum computation, quantum circuit simulation, circuit cutting, Clifford+T simulation},
location = {Orlando, FL, USA},
series = {ISCA '23}
}

@article{10.1145/3579600,
author = {Corvite, Shanley and Roemmich, Kat and Rosenberg, Tillie Ilana and Andalibi, Nazanin},
title = {Data Subjects' Perspectives on Emotion Artificial Intelligence Use in the Workplace: A Relational Ethics Lens},
year = {2023},
issue_date = {April 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {CSCW1},
url = {https://doi.org/10.1145/3579600},
doi = {10.1145/3579600},
abstract = {The workplace has experienced extensive digital transformation, in part due to artificial intelligence's commercial availability. Though still an emerging technology, emotional artificial intelligence (EAI) is increasingly incorporated into enterprise systems to augment and automate organizational decisions and to monitor and manage workers. EAI use is often celebrated for its potential to improve workers' wellbeing and performance as well as address organizational problems such as bias and safety. Workers subject to EAI in the workplace are data subjects whose data make EAI possible and who are most impacted by it. However, we lack empirical knowledge about data subjects' perspectives on EAI, including in the workplace. To this end, using a relational ethics lens, we qualitatively analyzed 395 U.S. adults' open-ended survey (partly representative) responses regarding the perceived benefits and risks they associate with being subjected to EAI in the workplace. While participants acknowledged potential benefits of being subject to EAI (e.g., employers using EAI to aid their wellbeing, enhance their work environment, reduce bias), a myriad of potential risks overshadowed perceptions of potential benefits. Participants expressed concerns regarding the potential for EAI use to harm their wellbeing, work environment and employment status, and create and amplify bias and stigma against them, especially the most marginalized (e.g., along dimensions of race, gender, mental health status, disability). Distrustful of EAI and its potential risks, participants anticipated conforming to (e.g., partaking in emotional labor) or refusing (e.g., quitting a job) EAI implementation in practice. We argue that EAI may magnify, rather than alleviate, existing challenges data subjects face in the workplace and suggest that some EAI-inflicted harms would persist even if concerns of EAI's accuracy and bias are addressed.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {124},
numpages = {38},
keywords = {data subjects, emotion AI, emotion artificial intelligence, emotion recognition, ethics, future of work, relational ethics, workers, workplace}
}

@article{10.1145/3579615,
author = {Ferrier-Barbut, El\'{e}onore and Avellino, Ignacio and Canlorbe, Geoffroy and Vitrani, Marie-Aude and Luengo, Vanda},
title = {Learning With Pedagogical Models: Videos As Adjuncts to Apprenticeship for Surgical Training},
year = {2023},
issue_date = {April 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {CSCW1},
url = {https://doi.org/10.1145/3579615},
doi = {10.1145/3579615},
abstract = {Videos are a powerful media to learn activities through guided physical training such as surgery, especially when they are produced following human learning models and not as "how-to" videos. However, their success greatly depends on how they are integrated into the extensive curricula of domains where learning occurs through guided practice. In this work, we investigate the impact of integrating video as a learning tool into the learning curricula of surgery. We created a pedagogical video on surgical hysterectomy through a model based on the Conceptual Fields theory (Vergnaud) and performed two rounds of interviews with seven medical residents, who watched the video freely during their residency in gynecology-obstetrics as they trained with experts. We find that videos can complement guided physical training, as they can provide the rationale behind expert action, something that is difficult to explicit during guided training. Still, their linear and static nature limits their integration as true adjuncts. We discuss our vision of moving towards interactive videos created with an ontological approach, developed in a workshop with four expert surgeons, which involves the ability to navigate through levels of information and layers of representations, so that experts can represent information to learners according to pedagogical models that complement their complex and extensive learning curricula.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {139},
numpages = {40},
keywords = {conceptual fields theory, guided practice, surgery, video-based learning}
}

@proceedings{10.1145/3579856,
title = {ASIA CCS '23: Proceedings of the 2023 ACM Asia Conference on Computer and Communications Security},
year = {2023},
isbn = {9798400700989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Melbourne, VIC, Australia}
}

@inproceedings{10.1145/3579856.3582816,
author = {Chen, Zitao and Dash, Pritam and Pattabiraman, Karthik},
title = {Jujutsu: A Two-stage Defense against Adversarial Patch Attacks on Deep Neural Networks},
year = {2023},
isbn = {9798400700989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579856.3582816},
doi = {10.1145/3579856.3582816},
abstract = {Adversarial patch attacks create adversarial examples by injecting arbitrary distortions within a bounded region of the input to fool deep neural networks (DNNs). These attacks are robust (i.e., physically-realizable) and universally malicious, and hence represent a severe security threat to real-world DNN-based systems. We propose Jujutsu, a two-stage technique to detect and mitigate robust and universal adversarial patch attacks. We first observe that adversarial patches are crafted as localized features that yield large influence on the prediction output, and continue to dominate the prediction on any input. Jujutsu leverages this observation for accurate attack detection with low false positives. Patch attacks corrupt only a localized region of the input, while the majority of the input remains unperturbed. Therefore, Jujutsu leverages generative adversarial networks (GAN) to perform localized attack recovery by synthesizing the semantic contents of the input that are corrupted by the attacks, and reconstructs a “clean” input for correct prediction. We evaluate Jujutsu on four diverse datasets spanning 8 different DNN models, and find that it achieves superior performance and significantly outperforms four existing defenses. We further evaluate Jujutsu against physical-world attacks, as well as adaptive attacks.},
booktitle = {Proceedings of the 2023 ACM Asia Conference on Computer and Communications Security},
pages = {689–703},
numpages = {15},
keywords = {Adversarial robustness, Deep learning, Neural networks, Security},
location = {Melbourne, VIC, Australia},
series = {ASIA CCS '23}
}

@inproceedings{10.1145/3579856.3582821,
author = {Rajabi, Arezoo and Sahabandu, Dinuka and Niu, Luyao and Ramasubramanian, Bhaskar and Poovendran, Radha},
title = {LDL: A Defense for Label-Based Membership Inference Attacks},
year = {2023},
isbn = {9798400700989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579856.3582821},
doi = {10.1145/3579856.3582821},
abstract = {The data used to train deep neural network (DNN) models in applications such as healthcare and finance typically contain sensitive information. A DNN model may suffer from overfitting– it will perform very well on samples seen during training, and poorly on samples not seen during training. Overfitted models have been shown to be susceptible to query-based attacks such as membership inference attacks (MIAs). MIAs aim to determine whether a sample belongs to the dataset used to train a classifier (members) or not (nonmembers). Recently, a new class of label-based MIAs (LAB MIAs) was proposed, where an adversary was only required to have knowledge of predicted labels of samples. LAB MIAs used the insight that member samples were typically located farther away from a classification decision boundary than nonmembers, and were shown to be highly effective across multiple datasets. Developing a defense against an adversary carrying out a LAB MIA on DNN models that cannot be retrained remains an open problem. We present LDL, a light weight defense against LAB MIAs. LDL works by constructing a high-dimensional sphere around queried samples such that the model decision is unchanged for (noisy) variants of the sample within the sphere. This sphere of label-invariance creates ambiguity and prevents a querying adversary from correctly determining whether a sample is a member or a nonmember. We analytically characterize the success rate of an adversary carrying out a LAB MIA when LDL is deployed, and show that the formulation is consistent with experimental observations. We evaluate LDL on seven datasets– CIFAR-10, CIFAR-100, GTSRB, Face, Purchase, Location, and Texas– with varying sizes of training data. All of these datasets have been used by SOTA LAB MIAs. Our experiments demonstrate that LDL reduces the success rate of an adversary carrying out a LAB MIA in each case. We empirically compare LDL with defenses against LAB MIAs that require retraining of DNN models, and show that LDL performs favorably despite not needing to retrain the DNNs.},
booktitle = {Proceedings of the 2023 ACM Asia Conference on Computer and Communications Security},
pages = {95–108},
numpages = {14},
keywords = {MIA defense, Membership inference attack (MIA), overfitted DNNs},
location = {Melbourne, VIC, Australia},
series = {ASIA CCS '23}
}

@inproceedings{10.1145/3579856.3582822,
author = {Yan, Zhicong and Li, Shenghong and Zhao, Ruijie and Tian, Yuan and Zhao, Yuanyuan},
title = {DHBE: Data-free Holistic Backdoor Erasing in Deep Neural Networks via Restricted Adversarial Distillation},
year = {2023},
isbn = {9798400700989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579856.3582822},
doi = {10.1145/3579856.3582822},
abstract = {Backdoor attacks have emerged as an urgent threat to Deep Neural Networks (DNNs), where victim DNNs are furtively implanted with malicious neurons that could be triggered by the adversary. To defend against backdoor attacks, many works establish a staged pipeline to remove backdoors from victim DNNs: inspecting, locating, and erasing. However, in a scenario where a few clean data can be accessible, such pipeline is fragile and cannot erase backdoors completely without sacrificing model accuracy. To address this issue, in this paper, we propose a novel data-free holistic backdoor erasing (DHBE) framework. Instead of the staged pipeline, the DHBE treats the backdoor erasing task as a unified adversarial procedure, which seeks equilibrium between two different competing processes: distillation and backdoor regularization. In distillation, the backdoored DNN is distilled into a proxy model, transferring its knowledge about clean data, yet backdoors are simultaneously transferred. In backdoor regularization, the proxy model is holistically regularized to prevent from infecting any possible backdoor transferred from distillation. These two processes jointly proceed with data-free adversarial optimization until a clean, high-accuracy proxy model is obtained. With the novel adversarial design, our framework demonstrates its superiority in three aspects: 1) minimal detriment to model accuracy, 2) high tolerance for hyperparameters, and 3) no demand for clean data. Extensive experiments on various backdoor attacks and datasets are performed to verify the effectiveness of the proposed framework. Code is available at https://github.com/yanzhicong/DHBE},
booktitle = {Proceedings of the 2023 ACM Asia Conference on Computer and Communications Security},
pages = {731–745},
numpages = {15},
keywords = {Backdoor Erasing, Data-free., Deep Neural Networks, Restricted Adversarial Distillation},
location = {Melbourne, VIC, Australia},
series = {ASIA CCS '23}
}

@inproceedings{10.1145/3579856.3582823,
author = {Kim, Hyunjin and Bak, Jinyeong and Cho, Kyunghyun and Koo, Hyungjoon},
title = {A Transformer-based Function Symbol Name Inference Model from an Assembly Language for Binary Reversing},
year = {2023},
isbn = {9798400700989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579856.3582823},
doi = {10.1145/3579856.3582823},
abstract = {Reverse engineering of a stripped binary has a wide range of applications, yet it is challenging mainly due to the lack of contextually useful information within. Once debugging symbols (e.g., variable names, types, function names) are discarded, recovering such information is not technically viable with traditional approaches like static or dynamic binary analysis. We focus on a function symbol name recovery, which allows a reverse engineer to gain a quick overview of an unseen binary. The key insight is that a well-developed program labels a meaningful function name that describes its underlying semantics well. In this paper, we present AsmDepictor, the Transformer-based framework that generates a function symbol name from a set of assembly codes (i.e., machine instructions), which consists of three major components: binary code refinement, model training, and inference. To this end, we conduct systematic experiments on the effectiveness of code refinement that can enhance an overall performance. We introduce the per-layer positional embedding and Unique-softmax for AsmDepictor so that both can aid to capture a better relationship between tokens. Lastly, we devise a novel evaluation metric tailored for a short description length, the Jaccard* score. Our empirical evaluation shows that the performance of AsmDepictor by far surpasses that of the state-of-the-art models up to around 400\%. The best AsmDepictor model achieves an F1 of 71.5 and Jaccard* of 75.4.},
booktitle = {Proceedings of the 2023 ACM Asia Conference on Computer and Communications Security},
pages = {951–965},
numpages = {15},
keywords = {Transformer, assembly, function name, neural networks, reversing},
location = {Melbourne, VIC, Australia},
series = {ASIA CCS '23}
}

@inproceedings{10.1145/3579856.3582839,
author = {Mukherjee, Avirup and Murali, Kousshik and Jha, Shivam Kumar and Ganguly, Niloy and Chatterjee, Rahul and Mondal, Mainack},
title = {MASCARA : Systematically Generating Memorable And Secure Passphrases},
year = {2023},
isbn = {9798400700989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579856.3582839},
doi = {10.1145/3579856.3582839},
abstract = {Passwords are the most common mechanism for authenticating users online. However, studies have shown that users find it difficult to create and manage secure passwords. To that end, passphrases are often recommended as a usable alternative to passwords, which would potentially be easy to remember and hard to guess. However, as we show, user-chosen passphrases fall short of being secure, while state-of-the-art machine-generated passphrases are difficult to remember. In this work, we aim to tackle the drawbacks of the systems that generate passphrases for practical use. In particular, we address the problem of generating secure and memorable passphrases and compare them against user chosen passphrases in use. We identify and characterize 72, 999 user-chosen in-use unique English passphrases from prior leaked password databases. Then we leverage this understanding to create a novel framework for measuring memorability and guessability of passphrases. Utilizing our framework, we design MASCARA, which follows a constrained Markov generation process to create passphrases that optimize for both memorability and guessability. Our evaluation of passphrases shows that MASCARA -generated passphrases are harder to guess than in-use user-generated passphrases, while being easier to remember compared to state-of-the-art machine-generated passphrases. We conduct a two-part user study with crowdsourcing platform Prolific to demonstrate that users have highest memory-recall (and lowest error rate) while using MASCARA passphrases. Moreover, for passphrases of length desired by the users, the recall rate is 60-100\% higher for MASCARA-generated passphrases compared to current system-generated ones.},
booktitle = {Proceedings of the 2023 ACM Asia Conference on Computer and Communications Security},
pages = {524–538},
numpages = {15},
keywords = {authentication, dataset, guessability, memorability, passphrases},
location = {Melbourne, VIC, Australia},
series = {ASIA CCS '23}
}

@inproceedings{10.1145/3579856.3595801,
author = {Yasur, Lior and Frankovits, Guy and Grabovski, Fred M. and Mirsky, Yisroel},
title = {Deepfake CAPTCHA: A Method for Preventing Fake Calls},
year = {2023},
isbn = {9798400700989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579856.3595801},
doi = {10.1145/3579856.3595801},
abstract = {Deep learning technology has made it possible to generate realistic content of specific individuals. These ‘deepfakes’ can now be generated in real-time which enables attackers to impersonate people over audio and video calls. Moreover, some methods only need a few images or seconds of audio to steal an identity. Existing defenses perform passive analysis to detect fake content. However, with the rapid progress of deepfake quality, this may be a losing game. In this paper, we propose D-CAPTCHA: an active defense against real-time deepfakes. The approach is to force the adversary into the spotlight by challenging the deepfake model to generate content which exceeds its capabilities. By doing so, passive detection becomes easier since the content will be distorted. In contrast to existing CAPTCHAs, we challenge the AI’s ability to create content as opposed to its ability to classify content. In this work we focus on real-time audio deepfakes and present preliminary results on video. In our evaluation we found that D-CAPTCHA outperforms state-of-the-art audio deepfake detectors with an accuracy of 91-100\% depending on the challenge (compared to 71\% without challenges). We also performed a study on 41 volunteers to understand how threatening current real-time deepfake attacks are. We found that the majority of the volunteers could not tell the difference between real and fake audio.},
booktitle = {Proceedings of the 2023 ACM Asia Conference on Computer and Communications Security},
pages = {608–622},
numpages = {15},
keywords = {CAPTCHA, Deepfake, deep fake, deep learning, fake calls, impersonation, security, social engineering, voice cloning},
location = {Melbourne, VIC, Australia},
series = {ASIA CCS '23}
}

@inproceedings{10.1145/3580305.3599245,
author = {Xia, Jinxiong and Wang, Houfeng},
title = {A Sequence-to-Sequence Approach with Mixed Pointers to Topic Segmentation and Segment Labeling},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599245},
doi = {10.1145/3580305.3599245},
abstract = {Topic segmentation is the process of dividing a text into semantically coherent segments, and segment labeling involves assigning a topic label to each of these segments. Previous work on this task has included the use of sequence labeling, segment-extraction, and generative models. While these methods have yielded impressive results, existing generative models have struggled to accurately generate strings of segment boundaries, limiting their competitiveness in this area. In this paper, we present a novel Sequence-to-Sequence approach with Mixed Pointers (Seq2Seq-MP). Seq2Seq-MP employs an encoder-decoder architecture with the pointer mechanism to generate both segment boundaries and topics, which allows for a more robust performance than string-generation models and can handle long-range dependencies better than sequence labeling and segment-extraction models. Additionally, we introduce the pairwise type encoding and type-aware relative position encoding to improve the fusion of type and position information, enhancing the interactions between sentences and topics in the encoder and decoder. Our experiments on public datasets show that Seq2Seq-MP outperforms the current state-of-the-art, with up to 2.9\% and 4.0\% improvements in Pk and F1, respectively.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2683–2693},
numpages = {11},
keywords = {pointer networks, segment labeling, sequence-to-sequence, topic segmentation},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3580305.3599249,
author = {Wang, Danqing and Wen, Zeyu and Ye, Fei and Li, Lei and Zhou, Hao},
title = {Accelerating Antimicrobial Peptide Discovery with Latent Structure},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599249},
doi = {10.1145/3580305.3599249},
abstract = {Antimicrobial peptides (AMPs) are promising therapeutic approaches against drug-resistant pathogens. Recently, deep generative models are used to discover new AMPs. However, previous studies mainly focus on peptide sequence attributes and do not consider crucial structure information. In this paper, we propose a latent sequence-structure model for designing AMPs (LSSAMP). LSSAMP exploits multi-scale vector quantization in the latent space to represent secondary structures (e.g. alpha helix and beta sheet). By sampling in the latent space, LSSAMP can simultaneously generate peptides with ideal sequence attributes and secondary structures. Experimental results show that the peptides generated by LSSAMP have a high probability of antimicrobial activity. Our wet laboratory experiments verified that two of the 21 candidates exhibit strong antimicrobial activity. The code is released at https://github.com/dqwang122/LSSAMP.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2243–2255},
numpages = {13},
keywords = {drug discovery, generative model, peptide generation},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3580305.3599291,
author = {Pan, Xudong and Zhang, Mi and Yan, Yifan and Wang, Yining and Yang, Min},
title = {Cracking White-box DNN Watermarks via Invariant Neuron Transforms},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599291},
doi = {10.1145/3580305.3599291},
abstract = {Recently, how to protect the Intellectual Property (IP) of deep neural networks (DNN) becomes a major concern for the AI industry. To combat potential model piracy, recent works explore various watermarking strategies to embed secret identity messages into the prediction behaviors or the internals (e.g., weights and neuron activation) of the target model. Sacrificing less functionality and involving more knowledge about the target model, the latter branch of watermarking schemes (i.e., white-box model watermarking) is claimed to be accurate, credible and secure against most known watermark removal attacks, with emerging research efforts and applications in the industry.In this paper, we present the first effective removal attack which cracks almost all the existing white-box watermarking schemes with provably no performance overhead and no required prior knowledge. By analyzing these IP protection mechanisms at the granularity of neurons, we for the first time discover their common dependence on a set of fragile features of a local neuron group, all of which can be arbitrarily tampered by our proposed chain of invariant neuron transforms. On nine state-of-the-art white-box watermarking schemes and a broad set of industry-level DNN architectures, our attack for the first time reduces the embedded identity message in the protected models to be almost random. Meanwhile, unlike known removal attacks, our attack requires no prior knowledge on the training data distribution or the adopted watermark algorithms, and leaves model functionality intact.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {1783–1794},
numpages = {12},
keywords = {deep learning, digital watermark, intellectual property},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3580305.3599294,
author = {Chang, Chun-Hao and Yoon, Jinsung and Arik, Sercan \"{O}. and Udell, Madeleine and Pfister, Tomas},
title = {Data-Efficient and Interpretable Tabular Anomaly Detection},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599294},
doi = {10.1145/3580305.3599294},
abstract = {Anomaly detection (AD) plays an important role in numerous applications. In this paper, we focus on two understudied aspects of AD that are critical for integration into real-world applications. First, most AD methods cannot incorporate labeled data that are often available in practice in small quantities and can be crucial to achieve high accuracy. Second, most AD methods are not interpretable, a bottleneck that prevents stakeholders from understanding the reason behind the anomalies. In this paper, we propose a novel AD framework, DIAD, that adapts a white-box model class, Generalized Additive Models, to detect anomalies using a partial identification objective which naturally handles noisy or heterogeneous features. DIAD can incorporate a small amount of labeled data to further boost AD performances in semi-supervised settings. We demonstrate the superiority of DIAD compared to previous work in both unsupervised and semi-supervised settings on multiple datasets. We also present explainability capabilities of DIAD, on its rationale behind predicting certain samples as anomalies.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {190–201},
numpages = {12},
keywords = {anomaly detection, interpretability},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3580305.3599307,
author = {Franco, Gabriel and Crovella, Mark and Comarela, Giovanni},
title = {Dependence and Model Selection in LLP: The Problem of Variants},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599307},
doi = {10.1145/3580305.3599307},
abstract = {The problem of Learning from Label Proportions (LLP) has received considerable research attention and has numerous practical applications. In LLP, a hypothesis assigning labels to items is learned using knowledge of only the proportion of labels found in predefined groups, called bags. While a number of algorithmic approaches to learning in this context have been proposed, very little work has addressed the model selection problem for LLP. Nonetheless, it is not obvious how to extend straightforward model selection approaches to LLP, in part because of the lack of item labels. More fundamentally, we argue that a careful approach to model selection for LLP requires consideration of the dependence structure that exists between bags, items, and labels. In this paper we formalize this structure and show how it affects model selection. We show how this leads to improved methods of model selection that we demonstrate outperform the state of the art over a wide range of datasets and LLP algorithms.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {470–481},
numpages = {12},
keywords = {hyperparameter selection, learning from label proportions, weakly supervised learning},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3580305.3599318,
author = {Zhuang, Yuchen and Yu, Yue and Kong, Lingkai and Chen, Xiang and Zhang, Chao},
title = {DyGen: Learning from Noisy Labels via Dynamics-Enhanced Generative Modeling},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599318},
doi = {10.1145/3580305.3599318},
abstract = {Learning from noisy labels is a challenge that arises in many real-world applications where training data can contain incorrect or corrupted labels. When fine-tuning language models with noisy labels, models can easily overfit the label noise, leading to decreased performance. Most existing methods for learning from noisy labels use static input features for denoising, but these methods are limited by the information they can provide on true label distributions and can result in biased or incorrect predictions. In this work, we propose the Dynamics-Enhanced Generative Model (DyGen), which uses dynamic patterns in the embedding space during the fine-tuning process of language models to improve noisy label predictions. DyGen uses the variational auto-encoding framework to infer the posterior distributions of true labels from noisy labels and training dynamics. Additionally, a co-regularization mechanism is used to minimize the impact of potentially noisy labels and priors. DyGen demonstrates an average accuracy improvement of 3.10\% on two synthetic noise datasets and 1.48\% on three real-world noise datasets compared to the previous state-of-the-art. Extensive experiments and analyses show the effectiveness of each component in DyGen. Our code is available for reproducibility on GitHub.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3674–3686},
numpages = {13},
keywords = {generative modeling, noisy label learning, training dynamics},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3580305.3599319,
author = {Zhang, Kaike and Cao, Qi and Fang, Gaolin and Xu, Bingbing and Zou, Hongjian and Shen, Huawei and Cheng, Xueqi},
title = {DyTed: Disentangled Representation Learning for Discrete-time Dynamic Graph},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599319},
doi = {10.1145/3580305.3599319},
abstract = {Unsupervised representation learning for dynamic graphs has attracted a lot of research attention in recent years. Compared with static graph, the dynamic graph is a comprehensive embodiment of both the intrinsic stable characteristics of nodes and the time-related dynamic preference. However, existing methods generally mix these two types of information into a single representation space, which may lead to poor explanation, less robustness, and a limited ability when applied to different downstream tasks. To solve the above problems, in this paper, we propose a novel disenTangled representation learning framework for discrete-time Dynamic graphs, namely DyTed. We specially design a temporal-clips contrastive learning task together with a structure contrastive learning to effectively identify the time-invariant and time-varying representations respectively. To further enhance the disentanglement of these two types of representation, we propose a disentanglement-aware discriminator under an adversarial learning framework from the perspective of information theory. Extensive experiments on Tencent and five commonly used public datasets demonstrate that DyTed, as a general framework that can be applied to existing methods, achieves state-of-the-art performance on various downstream tasks, as well as be more robust against noise.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3309–3320},
numpages = {12},
keywords = {disentangled representation learning, dynamic graphs},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3580305.3599324,
author = {Wang, Zongwei and Gao, Min and Li, Wentao and Yu, Junliang and Guo, Linxin and Yin, Hongzhi},
title = {Efficient Bi-Level Optimization for Recommendation Denoising},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599324},
doi = {10.1145/3580305.3599324},
abstract = {The acquisition of explicit user feedback (e.g., ratings) in real-world recommender systems is often hindered by the need for active user involvement. To mitigate this issue, implicit feedback (e.g., clicks) generated during user browsing is exploited as a viable substitute. However, implicit feedback possesses a high degree of noise, which significantly undermines recommendation quality. While many methods have been proposed to address this issue by assigning varying weights to implicit feedback, two shortcomings persist: (1) the weight calculation in these methods is iteration-independent, without considering the influence of weights in previous iterations, and (2) the weight calculation often relies on prior knowledge, which may not always be readily available or universally applicable.To overcome these two limitations, we model recommendation denoising as a bi-level optimization problem. The inner optimization aims to derive an effective model for the recommendation, as well as guiding the weight determination, thereby eliminating the need for prior knowledge. The outer optimization leverages gradients of the inner optimization and adjusts the weights in a manner considering the impact of previous weights. To efficiently solve this bi-level optimization problem, we employ a weight generator to avoid the storage of weights and a one-step gradient-matching-based loss to significantly reduce computational time. The experimental results on three benchmark datasets demonstrate that our proposed approach outperforms both state-of-the-art general and denoising recommendation models. The code is available at https://github.com/CoderWZW/BOD.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2502–2511},
numpages = {10},
keywords = {bi-level optimization, denoising, implicit feedback, recommendation},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3580305.3599343,
author = {Vo, Vy and Le, Trung and Nguyen, Van and Zhao, He and Bonilla, Edwin V. and Haffari, Gholamreza and Phung, Dinh},
title = {Feature-based Learning for Diverse and Privacy-Preserving Counterfactual Explanations},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599343},
doi = {10.1145/3580305.3599343},
abstract = {Interpretable machine learning seeks to understand the reasoning process of complex black-box systems that are long notorious for lack of explainability. One flourishing approach is through counterfactual explanations, which provide suggestions on what a user can do to alter an outcome. Not only must a counterfactual example counter the original prediction from the black-box classifier but it should also satisfy various constraints for practical applications. Diversity is one of the critical constraints that however remains less discussed. While diverse counterfactuals are ideal, it is computationally challenging to simultaneously address some other constraints. Furthermore, there is a growing privacy concern over the released counterfactual data. To this end, we propose a feature-based learning framework that effectively handles the counterfactual constraints and contributes itself to the limited pool of private explanation models. We demonstrate the flexibility and effectiveness of our method in generating diverse counterfactuals of actionability and plausibility. Our counterfactual engine is more efficient than counterparts of the same capacity while yielding the lowest re-identification risks.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2211–2222},
numpages = {12},
keywords = {algorithmic recourse, explainable ai, privacy},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3580305.3599374,
author = {Li, Wen-Zhi and Wang, Chang-Dong and Xiong, Hui and Lai, Jian-Huang},
title = {GraphSHA: Synthesizing Harder Samples for Class-Imbalanced Node Classification},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599374},
doi = {10.1145/3580305.3599374},
abstract = {Class imbalance is the phenomenon that some classes have much fewer instances than others, which is ubiquitous in real-world graph-structured scenarios. Recent studies find that off-the-shelf Graph Neural Networks (GNNs) would under-represent minor class samples. We investigate this phenomenon and discover that the subspaces of minor classes being squeezed by those of the major ones in the latent space is the main cause of this failure. We are naturally inspired to enlarge the decision boundaries of minor classes and propose a general framework GraphSHA by Synthesizing HArder minor samples. Furthermore, to avoid the enlarged minor boundary violating the subspaces of neighbor classes, we also propose a module called SemiMixup to transmit enlarged boundary information to the interior of the minor classes while blocking information propagation from minor classes to neighbor classes. Empirically, GraphSHA shows its effectiveness in enlarging the decision boundaries of minor classes, as it outperforms various baseline methods in class-imbalanced node classification with different GNN backbone encoders over seven public benchmark datasets. Code is avilable at https://github.com/wenzhilics/GraphSHA.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {1328–1340},
numpages = {13},
keywords = {class imbalance, data augmentation, graph neural network, hard sample, node classification},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3580305.3599391,
author = {Xiao, Chunjing and Gou, Zehua and Tai, Wenxin and Zhang, Kunpeng and Zhou, Fan},
title = {Imputation-based Time-Series Anomaly Detection with Conditional Weight-Incremental Diffusion Models},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599391},
doi = {10.1145/3580305.3599391},
abstract = {Existing anomaly detection models for time series are primarily trained with normal-point-dominant data and would become ineffective when anomalous points intensively occur in certain episodes. To solve this problem, we propose a new approach, called DiffAD, from the perspective of time series imputation. Unlike previous prediction- and reconstruction-based methods that adopt either partial or complete data as observed values for estimation, DiffAD uses a density ratio-based strategy to select normal observations flexibly that can easily adapt to the anomaly concentration scenarios. To alleviate the model bias problem in the presence of anomaly concentration, we design a new denoising diffusion-based imputation method to enhance the imputation performance of missing values with conditional weight-incremental diffusion, which can preserve the information of observed values and substantially improves data generation quality for stable anomaly detection. Besides, we customize a multi-scale state space model to capture the long-term dependencies across episodes with different anomaly patterns. Extensive experimental results on real-world datasets show that DiffAD performs better than state-of-the-art benchmarks.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2742–2751},
numpages = {10},
keywords = {data imputation, diffusion models, state space model, time series},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3580305.3599400,
author = {Yang, Yuhao and Huang, Chao and Xia, Lianghao and Huang, Chunzhen},
title = {Knowledge Graph Self-Supervised Rationalization for Recommendation},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599400},
doi = {10.1145/3580305.3599400},
abstract = {In this paper, we introduce a new self-supervised rationalization method, called KGRec, for knowledge-aware recommender systems. To effectively identify informative knowledge connections, we propose an attentive knowledge rationalization mechanism that generates rational scores for knowledge triplets. With these scores, KGRec integrates generative and contrastive self-supervised tasks for recommendation through rational masking. To highlight rationales in the knowledge graph, we design a novel generative task in the form of masking-reconstructing. By masking important knowledge with high rational scores, KGRec is trained to rebuild and highlight useful knowledge connections that serve as rationales. To further rationalize the effect of collaborative interactions on knowledge graph learning, we introduce a contrastive learning task that aligns signals from knowledge and user-item interaction views. To ensure noise-resistant contrasting, potential noisy edges in both graphs judged by the rational scores are masked. Extensive experi-ments on three real-world datasets demonstrate that KGRec outperforms state-of-the-art methods. We also provide the implementation codes for our approach at https://github.com/HKUDS/KGRec.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3046–3056},
numpages = {11},
keywords = {knowledge graph, recommendation, self-supervised learning},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3580305.3599468,
author = {Gao, Kaiyuan and Wu, Lijun and Zhu, Jinhua and Peng, Tianbo and Xia, Yingce and He, Liang and Xie, Shufang and Qin, Tao and Liu, Haiguang and He, Kun and Liu, Tie-Yan},
title = {Pre-training Antibody Language Models for Antigen-Specific Computational Antibody Design},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599468},
doi = {10.1145/3580305.3599468},
abstract = {Antibodies are proteins that effectively protect the human body by binding to pathogens. Recently, deep learning-based computational antibody design has attracted popular attention since it automatically mines the antibody patterns from data that could be complementary to human experiences. However, the computational methods heavily rely on high-quality antibody structure data, which is quite limited. Besides, the complementarity-determining region (CDR), which is the key component of an antibody that determines the specificity and binding affinity, is highly variable and hard to predict. Therefore, the limited availability of high-quality antibody structure data exacerbates the difficulty of CDR generation. Fortunately, there is a large amount of sequence data for antibodies that can help model the CDR and reduce reliance on structure data. By witnessing the success of pre-training models for protein modeling, in this paper, we develop the antibody pre-training language model and incorporate it into the antigen-specific antibody design model in a systemic way. Specifically, we first pre-train a novel antibody language model based on the sequence data, then propose a one-shot way for sequence and structure generation of CDR to mitigate the high cost and error propagation associated with autoregressive methods, and finally leverage the pre-trained antibody model for the antigen-specific antibody generation model with some carefully designed modules. Our experiments demonstrate the superiority of our method over previous baselines in tasks such as sequence and structure generation, CDR-H3 design for antigen binding, and antibody optimization1. The code is available at https://github.com/KyGao/ABGNN.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {506–517},
numpages = {12},
keywords = {antibody pre-training, antibody sequence-structure co-design},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3580305.3599534,
author = {Das, Trisha and Wang, Zifeng and Sun, Jimeng},
title = {TWIN: Personalized Clinical Trial Digital Twin Generation},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599534},
doi = {10.1145/3580305.3599534},
abstract = {Clinical trial digital twins are virtual patients that reflect personal characteristics in a high degree of granularity and can be used to simulate various patient outcomes under different conditions. With the growth of clinical trial databases captured by Electronic Data Capture (EDC) systems, there is a growing interest in using machine learning models to generate digital twins. This can benefit the drug development process by reducing the sample size required for participant recruitment, improving patient outcome predictive modeling, and mitigating privacy risks when sharing synthetic clinical trial data. However, prior research has mainly focused on generating Electronic Healthcare Records (EHRs), which often assume large training data and do not account for personalized synthetic patient record generation. In this paper, we propose a sample-efficient method TWIN for generating personalized clinical trial digital twins. TWIN can produce digital twins of patient-level clinical trial records with high fidelity to the targeting participant's record and preserves the temporal relations across visits and events. We compare our method with various baselines for generating real-world patient-level clinical trial data. The results show that TWIN generates synthetic trial data with high fidelity to facilitate patient outcome predictions in low-data scenarios and strong privacy protection against real patients from the trials.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {402–413},
numpages = {12},
keywords = {clinical trial, digital twin, synthetic data},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3580305.3599546,
author = {Li, Jintang and Wu, Ruofan and Sun, Wangbin and Chen, Liang and Tian, Sheng and Zhu, Liang and Meng, Changhua and Zheng, Zibin and Wang, Weiqiang},
title = {What's Behind the Mask: Understanding Masked Graph Modeling for Graph Autoencoders},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599546},
doi = {10.1145/3580305.3599546},
abstract = {The last years have witnessed the emergence of a promising self-supervised learning strategy, referred to as masked autoencoding. However, there is a lack of theoretical understanding of how masking matters on graph autoencoders (GAEs). In this work, we present masked graph autoencoder (MaskGAE), a self-supervised learning framework for graph-structured data. Different from standard GAEs, MaskGAE adopts masked graph modeling (MGM) as a principled pretext task - masking a portion of edges and attempting to reconstruct the missing part with partially visible, unmasked graph structure. To understand whether MGM can help GAEs learn better representations, we provide both theoretical and empirical evidence to comprehensively justify the benefits of this pretext task. Theoretically, we establish close connections between GAEs and contrastive learning, showing that MGM significantly improves the self-supervised learning scheme of GAEs. Empirically, we conduct extensive experiments on a variety of graph benchmarks, demonstrating the superiority of MaskGAE over several state-of-the-arts on both link prediction and node classification tasks.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {1268–1279},
numpages = {12},
keywords = {graph neural networks, graph representation learning, graph self-supervised learning, masked graph autoencoders},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3580305.3599770,
author = {Jiang, Liyao and Li, Chenglin and Chen, Haolan and Gao, Xiaodong and Zhong, Xinwang and Qiu, Yang and Ye, Shani and Niu, Di},
title = {AdSEE: Investigating the Impact of Image Style Editing on Advertisement Attractiveness},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599770},
doi = {10.1145/3580305.3599770},
abstract = {Online advertisements are important elements in e-commerce sites, social media platforms, and search engines. With the increasing popularity of mobile browsing, many online ads are displayed with visual information in the form of a cover image in addition to text descriptions to grab the attention of users. Various recent studies have focused on predicting the click rates of online advertisements aware of visual features or composing optimal advertisement elements to enhance visibility. In this paper, we propose Advertisement Style Editing and Attractiveness Enhancement (AdSEE), which explores whether semantic editing to ads images can affect or alter the popularity of online advertisements. We introduce StyleGAN-based facial semantic editing and inversion to ads images and train a click rate predictor attributing GAN-based face latent representations in addition to traditional visual and textual features to click rates. Through a large collected dataset named QQ-AD, containing 20,527 online ads, we perform extensive offline tests to study how different semantic directions and their edit coefficients may impact click rates. We further design a Genetic Advertisement Editor to efficiently search for the optimal edit directions and intensity given an input ad cover image to enhance its projected click rates. Online A/B tests performed over a period of 5 days have verified the increased click-through rates of AdSEE-edited samples as compared to a control group of original ads, verifying the relation between image styles and ad popularity. We open source the code for AdSEE research at https://github.com/LiyaoJiang1998/adsee.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4239–4251},
numpages = {13},
keywords = {advertisement image editing, click-through rate prediction, genetic algorithms, stylegan},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3580305.3599774,
author = {Xue, Bing and Said, Ahmed Sameh and Xu, Ziqi and Liu, Hanyang and Shah, Neel and Yang, Hanqing and Payne, Philip and Lu, Chenyang},
title = {Assisting Clinical Decisions for Scarcely Available Treatment via Disentangled Latent Representation},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599774},
doi = {10.1145/3580305.3599774},
abstract = {Extracorporeal membrane oxygenation (ECMO) is an essential life-supporting modality for COVID-19 patients who are refractory to conventional therapies. However, the proper treatment decision has been the subject of significant debate and it remains controversial about who benefits from this scarcely available and technically complex treatment option. To support clinical decisions, it is a critical need to predict the treatment need and the potential treatment and no-treatment responses. Targeting this clinical challenge, we propose Treatment Variational AutoEncoder (TVAE), a novel approach for individualized treatment analysis. TVAE is specifically designed to address the modeling challenges like ECMO with strong treatment selection bias and scarce treatment cases. TVAE conceptualizes the treatment decision as a multi-scale problem. We model a patient's potential treatment assignment and the factual and counterfactual outcomes as part of their intrinsic characteristics that can be represented by a deep latent variable model. The factual and counterfactual prediction errors are alleviated via a reconstruction regularization scheme together with semi-supervision, and the selection bias and the scarcity of treatment cases are mitigated by the disentangled and distribution-matched latent space and the label-balancing generative strategy. We evaluate TVAE on two real-world COVID-19 datasets: an international dataset collected from 1651 hospitals across 63 countries, and a institutional dataset collected from 15 hospitals. The results show that TVAE outperforms state-of-the-art treatment effect models in predicting both the propensity scores and factual outcomes on heterogeneous COVID-19 datasets. Additional experiments also show TVAE outperforms the best existing models in individual treatment effect estimation on the synthesized IHDP benchmark dataset.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5360–5371},
numpages = {12},
keywords = {causal inference, covid analysis, deep latent variable models, generative ai, machine learning for healthcare, representation learning, semi-supervised learning, treatment effect estimation, variational autoencoder},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3580305.3599790,
author = {Zheng, Qinkai and Xia, Xiao and Zou, Xu and Dong, Yuxiao and Wang, Shan and Xue, Yufei and Shen, Lei and Wang, Zihan and Wang, Andi and Li, Yang and Su, Teng and Yang, Zhilin and Tang, Jie},
title = {CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Benchmarking on HumanEval-X},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599790},
doi = {10.1145/3580305.3599790},
abstract = {Large pre-trained code generation models, such as OpenAI Codex, can generate syntax-and function-correct code, making the coding of programmers more productive. In this paper, we introduce CodeGeeX, a multilingual model with 13 billion parameters for code generation. CodeGeeX is pre-trained on 850 billion tokens of 23 programming languages as of June 2022. Our extensive experiments suggest that CodeGeeX outperforms multilingual code models of similar scale for both the tasks of code generation and translation on HumanEval-X. Building upon HumanEval (Python only), we develop the HumanEval-X benchmark for evaluating multilingual models by hand-writing the solutions in C++, Java, JavaScript, and Go. In addition, we build CodeGeeX-based extensions on Visual Studio Code, JetBrains, and Cloud Studio, generating 8 billion tokens for tens of thousands of active users per week. Our user study demonstrates that CodeGeeX can help to increase coding efficiency for 83.4\% of its users. Finally, CodeGeeX is publicly accessible since Sep. 2022, we open-sourced its code, model weights, API, extensions, and HumanEval-X at https://github.com/THUDM/CodeGeeX.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5673–5684},
numpages = {12},
keywords = {code generation, large language model, pre-trained model},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3580305.3599808,
author = {Elhamod, Mohannad and Khurana, Mridul and Manogaran, Harish Babu and Uyeda, Josef C. and Balk, Meghan A. and Dahdul, Wasila and Bakis, Yasin and Bart, Henry L. and Mabee, Paula M. and Lapp, Hilmar and Balhoff, James P. and Charpentier, Caleb and Carlyn, David and Chao, Wei-Lun and Stewart, Charles V. and Rubenstein, Daniel I. and Berger-Wolf, Tanya and Karpatne, Anuj},
title = {Discovering Novel Biological Traits From Images Using Phylogeny-Guided Neural Networks},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599808},
doi = {10.1145/3580305.3599808},
abstract = {Discovering evolutionary traits that are heritable across species on the tree of life (also referred to as a phylogenetic tree) is of great interest to biologists to understand how organisms diversify and evolve. However, the measurement of traits is often a subjective and labor-intensive process, making trait discovery a highly label-scarce problem. We present a novel approach for discovering evolutionary traits directly from images without relying on trait labels. Our proposed approach, Phylo-NN, encodes the image of an organism into a sequence of quantized feature vectors -or codes- where different segments of the sequence capture evolutionary signals at varying ancestry levels in the phylogeny. We demonstrate the effectiveness of our approach in producing biologically meaningful results in a number of downstream tasks including species image generation and species-to-species image translation, using fish species as a target example},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3966–3978},
numpages = {13},
keywords = {computer vision, knowledge-guided machine learning, morphology, neural networks, phylogeny},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3580305.3599816,
author = {Peng, Zhiyuan and Dave, Vachik and McNabb, Nicole and Sharnagat, Rahul and Magnani, Alessandro and Liao, Ciya and Fang, Yi and Rajanala, Sravanthi},
title = {Entity-aware Multi-task Learning for Query Understanding at Walmart},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599816},
doi = {10.1145/3580305.3599816},
abstract = {Query Understanding (QU) is a fundamental process in E-commerce search engines by extracting the shopping intents of customers. It usually includes a set of different tasks such as named entity recognization and query classification. Traditional approaches often tackle each task separately by its own network, which leads to excessive workload for development and maintenance as well as increased latency and resource usage in large-scale E-commerce platforms. To tackle these challenges, this paper presents a multi-task learning approach to query understanding at Walmart. We experimented with several state-of-the-art multi-task learning architectures including MTDNN, MMoE, and PLE. Furthermore, we propose a novel large-scale entity-aware multi-task learning model (EAMT)1 by retrieving entities from engagement data as query context to augment the query representation. To the best of our knowledge, there exists no prior work on multi-task learning for E-commerce query understanding. Comprehensive offline experiments are conducted on industry-scale datasets (up to 965M queries) to illustrate the effectiveness of our approach. The results from online experiments show substantial gains in key accuracy and latency metrics. https://github.com/zhiyuanpeng/KDD2023-EAMT},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4733–4742},
numpages = {10},
keywords = {e-commerce, multi-task learning, query understanding, semi-supervised learning},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3580305.3599830,
author = {Atri, Yash Kumar and Goyal, Vikram and Chakraborty, Tanmoy},
title = {Fusing Multimodal Signals on Hyper-complex Space for Extreme Abstractive Text Summarization (TL;DR) of Scientific Contents},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599830},
doi = {10.1145/3580305.3599830},
abstract = {The realm of scientific text summarization has experienced remarkable progress due to the availability of annotated brief summaries and ample data. However, the utilization of multiple input modalities, such as videos and audio, has yet to be thoroughly explored. At present, scientific multimodal-input-based text summarization systems tend to employ longer target summaries like abstracts, leading to an underwhelming performance in the task of text summarization.In this paper, we deal with a novel task of extreme abstractive text summarization (aka TL;DR generation) by leveraging multiple input modalities. To this end, we introduce mTLDR, a first-of-its-kind dataset for the aforementioned task, comprising videos, audio, and text, along with both author-composed summaries and expert-annotated summaries. The mTLDR dataset accompanies a total of 4,182 instances collected from various academic conference proceedings, such as ICLR, ACL, and CVPR. Subsequently, we present mTLDRgen, an encoder-decoder-based model that employs a novel dual-fused hyper-complex Transformer combined with a Wasserstein Riemannian Encoder Transformer, to dexterously capture the intricacies between different modalities in a hyper-complex latent geometric space. The hyper-complex Transformer captures the intrinsic properties between the modalities, while the Wasserstein Riemannian Encoder Transformer captures the latent structure of the modalities in the latent space geometry, thereby enabling the model to produce diverse sentences. mTLDRgen outperforms 20 baselines on mTLDR as well as another non-scientific dataset (How2) across three Rouge-based evaluation measures. Furthermore, based on the qualitative metrics, BERTScore and FEQA, and human evaluations, we demonstrate that the summaries generated by mTLDRgen are fluent and congruent to the original source material.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3724–3736},
numpages = {13},
keywords = {abstractive summarization, deep learning, multi-modal summarization, neural networks},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3580305.3599832,
author = {Zhang, Jing and Zhang, Xiaokang and Zhang-Li, Daniel and Yu, Jifan and Yao, Zijun and Ma, Zeyao and Xu, Yiqi and Wang, Haohua and Zhang, Xiaohan and Lin, Nianyi and Lu, Sunrui and Li, Juanzi and Tang, Jie},
title = {GLM-Dialog: Noise-tolerant Pre-training for Knowledge-grounded Dialogue Generation},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599832},
doi = {10.1145/3580305.3599832},
abstract = {We present GLM-Dialog, a large-scale language model (LLM) with 10B parameters capable of knowledge-grounded conversation in Chinese using a search engine to access the Internet knowledge. GLM-Dialog offers a series of applicable techniques for exploiting various external knowledge including both helpful and noisy knowledge, enabling the creation of robust knowledge-grounded dialogue LLMs with limited proper datasets. To evaluate the GLM-Dialog more fairly, we also propose a novel evaluation method to allow humans to converse with multiple deployed bots simultaneously and compare their performance implicitly instead of explicitly rating using multidimensional metrics. Comprehensive evaluations from automatic to human perspective demonstrate the advantages of GLM-Dialog comparing with existing open source Chinese dialogue models. We release both the model checkpoint and source code, and also deploy it as a WeChat application to interact with users. We offer our evaluation platform online in an effort to prompt the development of open source models and reliable dialogue evaluation systems. All the source code is available on Github.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5564–5575},
numpages = {12},
keywords = {dialogue evaluation, dialogue system, large language model},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3580305.3599837,
author = {Li, Yang and Chen, Xinyan and Guo, Wenxuan and Li, Xijun and Luo, Wanqian and Huang, Junhua and Zhen, Hui-Ling and Yuan, Mingxuan and Yan, Junchi},
title = {HardSATGEN: Understanding the Difficulty of Hard SAT Formula Generation and A Strong Structure-Hardness-Aware Baseline},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599837},
doi = {10.1145/3580305.3599837},
abstract = {Industrial SAT formula generation is a critical yet challenging task. Existing SAT generation approaches can hardly simultaneously capture the global structural properties and maintain plausible computational hardness. We first present an in-depth analysis for the limitation of previous learning methods in reproducing the computational hardness of original instances, which may stem from the inherent homogeneity in their adopted split-merge procedure. On top of the observations that industrial formulae exhibit clear community structure and oversplit substructures lead to the difficulty in semantic formation of logical structures, we propose HardSATGEN, which introduces a fine-grained control mechanism to the neural split-merge paradigm for SAT formula generation to better recover the structural and computational properties of the industrial benchmarks. Experiments including evaluations on private and practical corporate testbed show the superiority of HardSATGEN being the only method to successfully augments formulae maintaining similar computational hardness and capturing the global structural properties simultaneously. Compared to the best previous methods, the average performance gains achieve 38.5\% in structural statistics, 88.4\% in computational metrics, and over 140.7\% in the effectiveness of guiding solver tuning by our generated instances. Source code is available at https://github.com/Thinklab-SJTU/HardSATGEN.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4414–4425},
numpages = {12},
keywords = {boolean satisfiability problem, graph generation},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3580305.3599873,
author = {Liao, Hao and Peng, Jiahao and Huang, Zhanyi and Zhang, Wei and Li, Guanghua and Shu, Kai and Xie, Xing},
title = {MUSER: A MUlti-Step Evidence Retrieval Enhancement Framework for Fake News Detection},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599873},
doi = {10.1145/3580305.3599873},
abstract = {The ease of spreading false information online enables individuals with malicious intent to manipulate public opinion and destabilize social stability. Recently, fake news detection based on evidence retrieval has gained popularity in an effort to identify fake news reliably and reduce its impact. Evidence retrieval-based methods can improve the reliability of fake news detection by computing the textual consistency between the evidence and the claim in the news. In this paper, we propose a framework for fake news detection based on MUlti- Step Evidence Retrieval enhancement (MUSER), which simulates the steps of human beings in the process of reading news, summarizing, consulting materials, and inferring whether the news is true or fake. Our model can explicitly model dependencies among multiple pieces of evidence, and perform multi-step associations for the evidence required for news verification through multi-step retrieval. In addition, our model is able to automatically collect existing evidence through paragraph retrieval and key evidence selection, which can save the tedious process of manual evidence collection. We conducted extensive experiments on real-world datasets in different languages, and the results demonstrate that our proposed model outperforms state-of-the-art baseline methods for detecting fake news by at least 3\% in F1-Macro and 4\% in F1-Micro. Furthermore, it provides interpretable evidence for end users.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4461–4472},
numpages = {12},
keywords = {evidence-based fake news detection, explainability, multi-step retrieval},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3580305.3599895,
author = {Wang, Lewen and Zhao, Haozhe and Feng, Cunguang and Liu, Weiqing and Huang, Congrui and Santoni, Marco and Cristofaro, Manuel and Jafrancesco, Paola and Bian, Jiang},
title = {Removing Camouflage and Revealing Collusion: Leveraging Gang-crime Pattern in Fraudster Detection},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599895},
doi = {10.1145/3580305.3599895},
abstract = {As one of the major threats to the healthy development of various online platforms, fraud has become increasingly committed in the form of gangs since collusive fraudulent activities are much easier to obtain illicit benefits with lower exposure risk. To detect fraudsters in a gang, spatio-temporal graph neural network models have been widely applied to detect both temporal and spatial collusive patterns. However, a closer peek into real-world records of fraudsters can reveal that fraud gangs usually conduct community-level camouflage, specified by two types, i.e., temporal and spatial camouflage. Such camouflage can disguise gangs as benign communities by concealing collusive patterns and thus deceiving many existing graph neural network models. In the meantime, many existing graph neural network models suffer from the challenge of extreme sample imbalance caused by rare fraudsters hidden among massive users. To handle all these challenges, in this paper, we propose a generative adversarial network framework, named Adversarial Camouflage Detector, to detect fraudsters. Concretely, this ACD framework consists of four modules, in charge of community division, camouflage identification, fraudster detection, and camouflage generation, respectively. The first three modules form up a discriminator that uses spatio-temporal graph neural networks as the foundation model and enhance fraudster detection by amplifying the gangs' collusive patterns through automatically identifying and removing camouflage. Meanwhile, the camouflage generation module plays as the generator role that generates fraudsters samples by competing against the discriminator to alleviate the challenge of sample imbalance and increase the model robustness. The experimental result shows that our proposed method outperforms other methods on real-world datasets.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5104–5115},
numpages = {12},
keywords = {camouflage, fraud, generative adversarial networks, graph neural networks},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3580305.3599931,
author = {Liu, Xiao and Lai, Hanyu and Yu, Hao and Xu, Yifan and Zeng, Aohan and Du, Zhengxiao and Zhang, Peng and Dong, Yuxiao and Tang, Jie},
title = {WebGLM: Towards An Efficient Web-Enhanced Question Answering System with Human Preferences},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599931},
doi = {10.1145/3580305.3599931},
abstract = {We present WebGLM, a web-enhanced question-answering system based on the General Language Model (GLM). Its goal is to augment a pre-trained large language model (LLM) with web search and retrieval capabilities while being efficient for real-world deployments. To achieve this, we develop WebGLM with strategies for the LLM-augmented retriever, bootstrapped generator, and human preference-aware scorer. Specifically, we identify and address the limitations of WebGPT (OpenAI), through which WebGLM is enabled with accuracy, efficiency, and cost-effectiveness advantages. In addition, we propose systematic criteria for evaluating web-enhanced QA systems. We conduct multi-dimensional human evaluation and quantitative ablation studies, which suggest the outperformance of the proposed WebGLM designs over existing systems. WebGLM with the 10-billion-parameter GLM (10B) is shown to perform better than the similar-sized WebGPT (13B) and even comparably to WebGPT (175B) in human evaluation. The code, demo, and data are at https://github.com/THUDM/WebGLM.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4549–4560},
numpages = {12},
keywords = {efficient retrieval enhancement system, human preference alignment, pre-trained language model},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@proceedings{10.1145/3580507,
title = {EC '23: Proceedings of the 24th ACM Conference on Economics and Computation},
year = {2023},
isbn = {9798400701047},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Over the course of two decades, EC has established itself as one of the few truly successful interdisciplinary conferences, attracting papers and participants with a broad range of interests in economics and computer science, and fostering work in the intersection.},
location = {London, United Kingdom}
}

@proceedings{10.1145/3580585,
title = {AutomotiveUI '23: Proceedings of the 15th International Conference on Automotive User Interfaces and Interactive Vehicular Applications},
year = {2023},
isbn = {9798400701054},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Ingolstadt, Germany}
}

@inproceedings{10.1145/3581783.3611709,
author = {Yang, Shuyu and Zhou, Yinan and Zheng, Zhedong and Wang, Yaxiong and Zhu, Li and Wu, Yujiao},
title = {Towards Unified Text-based Person Retrieval: A Large-scale Multi-Attribute and Language Search Benchmark},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3611709},
doi = {10.1145/3581783.3611709},
abstract = {In this paper, we introduce a large Multi-Attribute and Language Search dataset for text-based person retrieval, called MALS, and explore the feasibility of performing pre-training on both attribute recognition and image-text matching tasks in one stone. In particular, MALS contains 1,510,330 image-text pairs, which is about 37.5 \texttimes{} larger than prevailing CUHK-PEDES, and all images are annotated with 27 attributes. Considering the privacy concerns and annotation costs, we leverage the off-the-shelf diffusion models to generate the dataset. To verify the feasibility of learning from the generated data, we develop a new joint Attribute Prompt Learning and Text Matching Learning (APTM) framework, considering the shared knowledge between attribute and text. As the name implies, APTM contains an attribute prompt learning stream and a text matching learning stream. (1) The attribute prompt learning leverages the attribute prompts for image-attribute alignment, which enhances the text matching learning. (2) The text matching learning facilitates the representation learning on fine-grained details, and in turn, boosts the attribute prompt learning. Extensive experiments validate the effectiveness of the pre-training on MALS, achieving state-of-the-art retrieval performance via APTM on three challenging real-world benchmarks. In particular, APTM achieves a consistent improvement of +6.96 \%, +7.68\%, and +16.95\% Recall@1 accuracy on CUHK-PEDES, ICFG-PEDES, and RSTPReid datasets by a clear margin, respectively. The dataset, model, and code are available at https://github.com/Shuyu-XJTU/APTM.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {4492–4501},
numpages = {10},
keywords = {attribute prompt learning, image-text alignment, multi-attribute recognition, synthetic data, text-based person retrieval},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3581783.3611833,
author = {Jiang, Wan and Diao, Yunfeng and Wang, He and Sun, Jianxin and Wang, Meng and Hong, Richang},
title = {Unlearnable Examples Give a False Sense of Security: Piercing through Unexploitable Data with Learnable Examples},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3611833},
doi = {10.1145/3581783.3611833},
abstract = {Safeguarding data from unauthorized exploitation is vital for privacy and security, especially in recent rampant research in security breach such as adversarial/membership attacks. To this end,unlearnable examples (UEs) have been recently proposed as a compelling protection, by adding imperceptible perturbation to data so that models trained on them cannot classify them accurately on original clean distribution. Unfortunately, we find UEs provide a false sense of security, because they cannot stop unauthorized users from utilizing other unprotected data to remove the protection, by turning unlearnable data into learnable again. Motivated by this observation, we formally define a new threat by introducinglearnable unauthorized examples (LEs) which are UEs with their protection removed. The core of this approach is a novel purification process that projects UEs onto the manifold of LEs. This is realized by a new joint-conditional diffusion model which denoises UEs conditioned on the pixel and perceptual similarity between UEs and LEs. Extensive experiments demonstrate that LE delivers state-of-the-art countering performance against both supervised UEs and unsupervised UEs in various scenarios, which is the first generalizable countermeasure to UEs across supervised learning and unsupervised learning. Our code is available at https://github.com/jiangw-0/LE_JCDP.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {8910–8921},
numpages = {12},
keywords = {data protection, deep neural network, unlearnable examples},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3581783.3611977,
author = {Yu, Jiaguo and Shen, Yuming and Zhang, Haofeng},
title = {Hashing One With All},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3611977},
doi = {10.1145/3581783.3611977},
abstract = {The recent trend in unsupervised hashing requires not only a discrete representation space but also the ability to mine the similarities between data points. Determining and maintaining the relations between each datum and all the others maximally utilize the semantic diversity of the training set, but can we explore this on the holistic dataset using a single network end-to-end? In this paper, we take a step towards this vision by proposing Overview Hashing (OH). OH unifies the two ultimate goals of unsupervised hashing, i.e., (1) encoding compact features and (2) learning data similarities on a large scale end-to-end, into one model. In particular, we split the top of an encoder into a binary hash head and a continuous one. For an arbitrary datum, its similarities to all the others in the dataset are reflected in the Hamming distances of their hash heads. The distances then act as the weights to aggregate the continuous heads, shaping the final representation of this datum for loss computation. Hence, training with this representation simultaneously tunes the similarities of this datum to the whole dataset. In the context of a contrastive learning framework, we theoretically endorse our design by linking it to knowledge distillation and the attention mechanisms. Our experiments on the benchmarked datasets show the superiority of OH over the state-of-the-art hashing methods. Code is available at hrefhttps://github.com/RosieYuu/OH textcolorred https://github.com/RosieYuu/OH.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {6420–6431},
numpages = {12},
keywords = {contrastive learning, image retrieval, memory bank, unsupervised deep hashing},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3581783.3612034,
author = {Lyu, Mingzhi and Huang, Yi and Kong, Adams Wai-Kin},
title = {Adversarial Attack for Robust Watermark Protection Against Inpainting-based and Blind Watermark Removers},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3612034},
doi = {10.1145/3581783.3612034},
abstract = {The rise of social media platforms, especially those focusing on image sharing, has made visible watermarks increasingly important in protecting image copyrights. However, multiple studies have revealed that watermarks are vulnerable to both inpainting-based removers and blind watermark removers. Though two adversarial attack methods have been proposed to defend against watermark removers, they are tailored to a particular type of removers in a white-box setting, which significantly limits their practicality and applicability. To date, there is no adversarial attack method that can protect watermarks against the two types of watermark removers simultaneously. In this paper, we propose a novel method, named Adversarial Watermark Defender with Attribution-Guided Perturbation (AWD-AGP), that defends against both inpainting-based and blind watermark removers under a black-box setting. AWD-AGP is the first watermark protection method employing adversarial location. The adversarial location is generated by a Watermark Positioning Network, which predicts an optimal location for watermark placement, making watermark removal challenging for inpainting-based removers. Since inpainting-based removers and blind watermark removers exploit information in different regions of an image to perform removal, we propose an attribution-guided scheme, which automatically assigns attack strengths to different pixels against different removers. With this design, the generated perturbation can attack the two types of watermark removers concurrently. Experiments on seven models, including four inpainting-based removers and three blind watermark removers demonstrate the effectiveness of AWD-AGP.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {8396–8405},
numpages = {10},
keywords = {adversarial attack, blind watermark remover, inpainting-based watermark remover, watermark},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3581783.3612046,
author = {Yao, Siyue and Sun, Mingjie and Li, Bingliang and Yang, Fengyu and Wang, Junle and Zhang, Ruimao},
title = {Dance with You: The Diversity Controllable Dancer Generation via Diffusion Models},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3612046},
doi = {10.1145/3581783.3612046},
abstract = {Recently, digital humans for interpersonal interaction in virtual environments have gained significant attention. In this paper, we introduce a novel multi-dancer synthesis task called partner dancer generation, which involves synthesizing virtual human dancers capable of performing dance with users. The task aims to control the pose diversity between the lead dancer and the partner dancer. The core of this task is to ensure the controllable diversity of the generated partner dancer while maintaining temporal coordination with the lead dancer. This scenario varies from earlier research in generating dance motions driven by music, as our emphasis is on automatically designing partner dancer postures according to pre-defined diversity, the pose of lead dancer, as well as the accompanying tunes. To achieve this objective, we propose a three-stage framework called Dance-with-You (DanY). Initially, we employ a 3D Pose Collection stage to collect a wide range of basic dance poses as references for motion generation. Then, we introduce a hyper-parameter that coordinates the similarity between dancers by masking poses to prevent the generation of sequences that are over-diverse or consistent. To avoid the rigidity of movements, we design a Dance Pre-generated stage to pre-generate these masked poses instead of filling them with zeros. After that, a Dance Motion Transfer stage is adopted with leader sequences and music, in which a multi-conditional sampling formula is rewritten to transfer the pre-generated poses into a sequence with a partner style. In practice, to address the lack of multi-person datasets, we introduce AIST-M, a new dataset for partner dancer generation, which is publicly availiable at https://github.com/JJessicaYao/AIST-M-Dataset. Comprehensive evaluations on our AIST-M dataset demonstrate that the proposed DanY can synthesize satisfactory partner dancer results with controllable diversity.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {8504–8514},
numpages = {11},
keywords = {diffusion model, diversity controllability, partner dancer synthesis},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3581783.3612086,
author = {Zhao, Wanqing and Nakashima, Yuta and Chen, Haiyuan and Babaguchi, Noboru},
title = {Enhancing Fake News Detection in Social Media via Label Propagation on Cross-modal Tweet Graph},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3612086},
doi = {10.1145/3581783.3612086},
abstract = {Fake news detection in social media has become increasingly important due to the rapid proliferation of personal media channels and the consequential dissemination of misleading information. Existing methods, which primarily rely on multimodal features and graph-based techniques, have shown promising performance in detecting fake news. However, they still face a limitation, i.e., sparsity in graph connections, which hinders capturing possible interactions among tweets. This challenge has motivated us to explore a novel method that densifies the graph's connectivity to capture denser interaction better. Our method constructs a cross-modal tweet graph using CLIP, which encodes images and text into a unified space, allowing us to extract potential connections based on similarities in text and images. We then design a Feature Contextualization Network with Label Propagation (FCN-LP) to model the interaction among tweets as well as positive or negative correlations between predicted labels of connected tweets. The propagated labels from the graph are weighted and aggregated for the final detection. To enhance the model's generalization ability to unseen events, we introduce a domain generalization loss that ensures consistent features between tweets on seen and unseen events. We use three publicly available fake news datasets, Twitter, PHEME, and Weibo, for evaluation. Our method consistently improves the performance over the state-of-the-art methods on all benchmark datasets and effectively demonstrates its aptitude for generalizing fake news detection in social media.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {2400–2408},
numpages = {9},
keywords = {cross-modal graphs, fake news detection, label propagation},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3581783.3612116,
author = {Zhong, Fangming and Chu, Chenglong and Zhu, Zijie and Chen, Zhikui},
title = {Hypergraph-Enhanced Hashing for Unsupervised Cross-Modal Retrieval via Robust Similarity Guidance},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3612116},
doi = {10.1145/3581783.3612116},
abstract = {Unsupervised cross-modal hashing retrieval across image and text modality is a challenging task because of the suboptimality of similarity guidance, i.e., the joint similarity matrix constructed by existing methods does not possess clear enough guiding significance. How to construct more robust similarity matrix is the key to solve this problem. The unsupervised cross-modal retrieval methods based on graph have a good performance in mining semantic information of input samples, but the graph hashing based on traditional affinity graph cannot capture the high-order semantic information of input samples effectively. In order to overcome the aforementioned limitations, this paper presents a novel hypergraph-based approach for unsupervised cross-modal retrieval that differs from previous works in two significant ways. Firstly, to address the ubiquitous redundant information present in current methods, this paper introduces a robust similarity matrix constructing method. Secondly, we propose a novel hypergraph enhanced module that produces embedding vectors by hypergraph convolution and attention mechanism for input data, capturing important high-order semantics. Our approach is evaluated on the NUS-WIDE and MIRFlickr datasets, and yields state-of-the-art performance for unsupervised cross-modal retrieval.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {3517–3527},
numpages = {11},
keywords = {cross-modal retrieval, hypergraph learning, similarity estimation, unsupervised cross-modal hashing},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3581783.3612156,
author = {Chen, Aozhu and Wang, Ziyuan and Dong, Chengbo and Tian, Kaibin and Zhao, Ruixiang and Liang, Xun and Kang, Zhanhui and Li, Xirong},
title = {ChinaOpen: A Dataset for Open-world Multimodal Learning},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3612156},
doi = {10.1145/3581783.3612156},
abstract = {This paper introduces ChinaOpen, a dataset sourced from Bilibili, a popular Chinese video-sharing website, for open-world multimodal learning. While the state-of-the-art multimodal learning networks have shown impressive performance in automated video annotation and cross-modal video retrieval, their training and evaluation are primarily conducted on YouTube videos with English text. Their effectiveness on Chinese data remains to be verified. In order to support multimodal learning in the new context, we construct ChinaOpen-50k, a webly annotated training set of 50k Bilibili videos associated with user-generated titles and tags. Both text-based and content-based data cleaning are performed to remove low-quality videos in advance. For a multi-faceted evaluation, we build ChinaOpen-1k, a manually labeled test set of 1k videos. Each test video is accompanied with a manually checked user title and a manually written caption. Besides, each video is manually tagged to describe objects / actions / scenes shown in the visual content. The original user tags are also manually checked. Moreover, with all the Chinese text translated into English, ChinaOpen-1k is also suited for evaluating models trained on English data. In addition to ChinaOpen, we propose Generative Video-to-text Transformer (GVT) for Chinese video captioning. We conduct an extensive evaluation of the state-of-the-art single-task / multi-task models on the new dataset, resulting in a number of novel findings and insights.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {6432–6440},
numpages = {9},
keywords = {chinese video dataset, multi-task evaluation, multimodal learning},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3581783.3612322,
author = {Wang, Jieming and Li, Ziyan and Yu, Jianfei and Yang, Li and Xia, Rui},
title = {Fine-Grained Multimodal Named Entity Recognition and Grounding with a Generative Framework},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3612322},
doi = {10.1145/3581783.3612322},
abstract = {Multimodal Named Entity Recognition (MNER) aims to locate and classify named entities mentioned in a pair of text and image. However, most previous MNER works focus on extracting entities in the form of text but failing to ground text symbols to their corresponding visual objects. Moreover, existing MNER studies primarily classify entities into four coarse-grained entity types, which are often insufficient to map them to their real-world referents. To solve these limitations, we introduce a task named Fine-grained Multimodal Named Entity Recognition and Grounding (FMNERG) in this paper, which aims to simultaneously extract named entities in text, their fine-grained entity types, and their grounded visual objects in image. Moreover, we construct a Twitter dataset for the FMNERG task, and further propose a T5-based multImodal GEneration fRamework (TIGER), which formulates FMNERG as a generation problem by converting all the entity-type-object triples into a target sequence and adapts a pre-trained sequence-to-sequence model T5 to directly generate the target sequence from an image-text input pair. Experimental results demonstrate that TIGER performs significantly better than a number of baseline systems on the annotated Twitter dataset. Our dataset annotation and source code are publicly released at https://github.com/NUSTM/FMNERG.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {3934–3943},
numpages = {10},
keywords = {fine-grained named entity recognition, generative framework, multimodal named entity recognition, visual grounding},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3581783.3612331,
author = {Wang, Run and Ren, Jixing and Li, Boheng and She, Tianyi and Zhang, Wenhui and Fang, Liming and Chen, Jing and Wang, Lina},
title = {Free Fine-tuning: A Plug-and-Play Watermarking Scheme for Deep Neural Networks},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3612331},
doi = {10.1145/3581783.3612331},
abstract = {Watermarking has been widely adopted for protecting the intellectual property (IP) of Deep Neural Networks (DNN) to defend the unauthorized distribution. Unfortunately, studies have shown that the popular data-poisoning DNN watermarking scheme via tedious model fine-tuning on a poisoned dataset (carefully-crafted sample-label pairs) is not efficient in tackling the tasks on challenging datasets and production-level DNN model protection. To address the aforementioned limitation, in this paper, we propose a plug-and-play watermarking scheme for DNN models by injecting an independent proprietary model into the target model to serve the watermark embedding and ownership verification. In contrast to the prior studies, our proposed method by incorporating a proprietary model is free of target model fine-tuning without involving any parameters update of the target model, thus the fidelity is well preserved and scalable to challenging real tasks. Experimental results on real-world challenging datasets (e.g., ImageNet) and production-level DNN models demonstrated its effectiveness, fidelity w.r.t. the functionality preservation of the target model, robustness against popular watermark removal attacks, and the plug-and-play deployment. The source code and models are available at https://github.com/AntigoneRandy/PTYNet.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {8463–8474},
numpages = {12},
keywords = {dnn watermarking, free fine-tuning, proprietary network},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3581783.3612345,
author = {Yao, Xuan and Gao, Junyu and Chen, Mengyuan and Xu, Changsheng},
title = {Video Entailment via Reaching a Structure-Aware Cross-modal Consensus},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3612345},
doi = {10.1145/3581783.3612345},
abstract = {This paper targets at the task of video entailment, which aims to achieve a thorough comprehension and draw inferences on whether a natural language statement entails or contradicts a given multi-modal video. Despite the recent progress, most existing methods focus on designing a vision-language encoder for multi-modal feature extraction in video entailment, which ignore the underlying consensus knowledge between two modalities, hindering the reasoning performance. As human beings, we make sense of the world by synthesizing information from different sense perceptions, which can acquire consensus among multiple modalities to form a more thorough and coherent representation of the surroundings, as well as to perform complicated understanding tasks. In this paper, we attempt to recreate this ability to infer the truthfulness of a given statement in the context of video entailment. To this end, we propose a unified structure-aware cross-modal consensus method to excavate the consensus semantics shared between video and language modalities, thereby incorporating which into video entailment as statement-related clues. Specifically, the consensus information is achieved by filtering away redundant information by utilizing the global information from one modality and the local complementary information from the other one. Moreover, a consensus-guided graph reasoning method is designed to explore inter-modality consistency and emphasize the significant features related to the judged statement, generating the inference results. Extensive experiments on two benchmarks demonstrate the accurate and robust performance of our approach compared to state-of-the-arts. Code is available at https://github.com/Feliciaxyao/MM2023-SACCN.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {4240–4249},
numpages = {10},
keywords = {consensus knowledge, graph reasoning, video entailment},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3581783.3612408,
author = {Chen, Yanzhe and Zhong, Huasong and He, Xiangteng and Peng, Yuxin and Cheng, Lele},
title = {Real20M: A Large-scale E-commerce Dataset for Cross-domain Retrieval},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3612408},
doi = {10.1145/3581783.3612408},
abstract = {In e-commerce, products and micro-videos serve as two primary carriers. Introducing cross-domain retrieval between these carriers can establish associations, thereby leading to the advancement of specific scenarios, such as retrieving products based on micro-videos or recommending relevant videos based on products. However, existing datasets only focus on retrieval within the product domain while neglecting the micro-video domain and often ignore the multi-modal characteristics of the product domain. Additionally, these datasets strictly limit their data scale through content alignment and use a content-based data organization format that hinders the inclusion of user retrieval intentions. To address these limitations, we propose the PKU Real20M dataset, a large-scale e-commerce dataset designed for cross-domain retrieval. We adopt a query-driven approach to efficiently gather over 20 million e-commerce products and micro-videos, including multimodal information. Additionally, we design a three-level entity prompt learning framework to align inter-modality information from coarse to fine. Moreover, we introduce the Query-driven Cross-Domain retrieval framework (QCD), which leverages user queries to facilitate efficient alignment between the product and micro-video domains. Extensive experiments on two downstream tasks validate the effectiveness of our proposed approaches. The dataset and source code are available at https://github.com/PKU-ICST-MIPL/Real20M_ACMMM2023.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {4939–4948},
numpages = {10},
keywords = {cross-domain retrieval, e-commerce datasets, large-scale data collection},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3581783.3612434,
author = {Yang, Tao and Wang, Fan and Lin, Junfan and Qi, Zhongang and Wu, Yang and Xu, Jing and Shan, Ying and Chen, Changwen},
title = {Toward Human Perception-Centric Video Thumbnail Generation},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3612434},
doi = {10.1145/3581783.3612434},
abstract = {Video thumbnail plays an essential role in summarizing video content into a compact and concise image for users to browse efficiently. However, automatically generating attractive and informative video thumbnails remains an open problem due to the difficulty of formulating human aesthetic perception and the scarcity of paired training data. This work proposes a novel Human Perception-Centric Video Thumbnail Generation (HPCVTG) to address these challenges. Specifically, our framework first generates a set of thumbnails using a principle-based system, which conforms to established aesthetic and human perception principles, such as visual balance in the layout and avoiding overlapping elements. Then rather than designing from scratch, we ask human annotators to evaluate some of these thumbnails and select their preferred ones. A Transformer-based Variational Auto-Encoder (VAE) model is firstly pre-trained with Model-Agnostic Meta-Learning (MAML) and then fine-tuned on these human-selected thumbnails. The exploration of combining the MAML pre-training paradigm with human feedback in training can reduce human involvement and make the training process more efficient. Extensive experimental results show that our HPCVTG framework outperforms existing methods in objective and subjective evaluations, highlighting its potential to improve the user experience when browsing videos and inspire future research in human perception-centric content generation tasks. The code and dataset will be released via https://github.com/yangtao2019yt/HPCVTG.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {6653–6664},
numpages = {12},
keywords = {few-shot learning, human preference, variational auto-encoder, video thumbnail},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3581783.3612451,
author = {Lu, Lingxiao and Li, Jiangtong and Cao, Junyan and Niu, Li and Zhang, Liqing},
title = {Painterly Image Harmonization using Diffusion Model},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3612451},
doi = {10.1145/3581783.3612451},
abstract = {Painterly image harmonization aims to insert photographic objects into paintings and obtain artistically coherent composite images. Previous methods for this task mainly rely on inference optimization or generative adversarial network, but they are either very time-consuming or struggling at fine control of the foreground objects (e.g., texture and content details). To address these issues, we propose a novel Painterly Harmonization stable Diffusion model (PHDiffusion), which includes a lightweight adaptive encoder and a Dual Encoder Fusion (DEF) module. Specifically, the adaptive encoder and the DEF module first stylize foreground features within each encoder. Then, the stylized foreground features from both encoders are combined to guide the harmonization process. During training, besides the noise loss in diffusion model, we additionally employ content loss and two style losses, i.e., AdaIN style loss and contrastive style loss, aiming to balance the trade-off between style migration and content preservation. Compared with the state-of-the-art models from related fields, our PHDiffusion can stylize the foreground more sufficiently and simultaneously retain finer content. Our code and model are available at https://github.com/bcmi/PHDiffusion-Painterly-Image-Harmonization},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {233–241},
numpages = {9},
keywords = {diffusion model, painterly image harmonization, style transfer},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3581783.3612471,
author = {Wu, Xiaoshuai and Liao, Xin and Ou, Bo},
title = {SepMark: Deep Separable Watermarking for Unified Source Tracing and Deepfake Detection},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3612471},
doi = {10.1145/3581783.3612471},
abstract = {Malicious Deepfakes have led to a sharp conflict over distinguishing between genuine and forged faces. Although many countermeasures have been developed to detect Deepfakes ex-post, undoubtedly, passive forensics has not considered any preventive measures for the pristine face before foreseeable manipulations. To complete this forensics ecosystem, we thus put forward the proactive solution dubbed SepMark, which provides a unified framework for source tracing and Deepfake detection. SepMark originates from encoder-decoder-based deep watermarking but with two separable decoders. For the first time the deep separable watermarking, SepMark brings a new paradigm to the established study of deep watermarking, where a single encoder embeds one watermark elegantly, while two decoders can extract the watermark separately at different levels of robustness. The robust decoder termed Tracer that resists various distortions may have an overly high level of robustness, allowing the watermark to survive both before and after Deepfake. The semi-robust one termed Detector is selectively sensitive to malicious distortions, making the watermark disappear after Deepfake. Only SepMark comprising of Tracer and Detector can reliably trace the trusted source of the marked face and detect whether it has been altered since being marked; neither of the two alone can achieve this. Extensive experiments demonstrate the effectiveness of the proposed SepMark on typical Deepfakes, including face swapping, expression reenactment, and attribute editing. Code will be available at https://github.com/sh1newu/SepMark.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {1190–1201},
numpages = {12},
keywords = {deep watermarking, deepfake forensics, watermarking robustness},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3581783.3612485,
author = {Lu, Hui and Wu, Xixin and Wu, Zhiyong and Meng, Helen},
title = {SpeechTripleNet: End-to-End Disentangled Speech Representation Learning for Content, Timbre and Prosody},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3612485},
doi = {10.1145/3581783.3612485},
abstract = {Disentangled speech representation learning aims to separate different factors of variation from speech into disjoint representations. This paper focuses on disentangling speech into representations for three factors: spoken content, speaker timbre, and speech prosody. Many previous methods for speech disentanglement have focused on separating spoken content and speaker timbre. However, the lack of explicit modeling of prosodic information leads to degraded speech generation performance and uncontrollable prosody leakage into content and/or speaker representations. While some recent methods have utilized explicit speaker labels or pre-trained models to facilitate triple-factor disentanglement, there are no end-to-end methods to simultaneously disentangle three factors using only unsupervised or self-supervised learning objectives. This paper introduces SpeechTripleNet, an end-to-end method to disentangle speech into representations for content, timbre, and prosody. Based on VAE, SpeechTripleNet restricts the structures of the latent variables and the amount of information captured in them to induce disentanglement. It is a pure unsupervised/self-supervised learning method that only requires speech data and no additional labels. Our qualitative and quantitative results demonstrate that SpeechTripleNet is effective in achieving triple-factor speech disentanglement, as well as controllable speech editing concerning different factors.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {2829–2837},
numpages = {9},
keywords = {prosody modeling, speech disentanglement, unsupervised representation learning, vae},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3581783.3612524,
author = {Chen, Jingwen and Pan, Yingwei and Yao, Ting and Mei, Tao},
title = {ControlStyle: Text-Driven Stylized Image Generation Using Diffusion Priors},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3612524},
doi = {10.1145/3581783.3612524},
abstract = {Recently, the multimedia community has witnessed the rise of diffusion models trained on large-scale multi-modal data for visual content creation, particularly in the field of text-to-image generation. In this paper, we propose a new task for "stylizing'' text-to-image models, namely text-driven stylized image generation, that further enhances editability in content creation. Given input text prompt and style image, this task aims to produce stylized images which are both semantically relevant to input text prompt and meanwhile aligned with the style image in style. To achieve this, we present a new diffusion model (ControlStyle) via upgrading a pre-trained text-to-image model with a trainable modulation network enabling more conditions of text prompts and style images. Moreover, diffusion style and content regularizations are simultaneously introduced to facilitate the learning of this modulation network with these diffusion priors, pursuing high-quality stylized text-to-image generation. Extensive experiments demonstrate the effectiveness of our ControlStyle in producing more visually pleasing and artistic results, surpassing a simple combination of text-to-image model and conventional style transfer techniques.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {7540–7548},
numpages = {9},
keywords = {diffusion models, style transfer, text-to-image generation},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3581783.3612704,
author = {Xu, Danni and Fan, Shaojing and Kankanhalli, Mohan},
title = {Combating Misinformation in the Era of Generative AI Models},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3612704},
doi = {10.1145/3581783.3612704},
abstract = {Misinformation has been a persistent and harmful phenomenon affecting our society in various ways, including individuals' physical health and economic stability. With the rise of short video platforms and related applications, the spread of multi-modal misinformation, encompassing images, texts, audios, and videos have exacerbated these concerns. The introduction of generative AI models like ChatGPT and Stable Diffusion has further complicated matters, giving rise to Artificial Intelligence Generated Content (AIGC) and presenting new challenges in detecting and mitigating misinformation. Consequently, traditional approaches to misinformation detection and intervention have become inadequate in this evolving landscape. This paper explores the challenges posed by AIGC in the context of misinformation. It examines the issue from psychological and societal perspectives, and explores the subtle manipulation traces found in AIGC at signal, perceptual, semantic, and human levels. By scrutinizing manipulation traces such as signal manipulation, semantic inconsistencies, logical incoherence, and psychological strategies, our objective is to tackle AI-generated misinformation and provide a conceptual design of systematic explainable solution. Ultimately, we aim for this paper to contribute valuable insights into combating misinformation, particularly in the era of AIGC.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {9291–9298},
numpages = {8},
keywords = {aigc, generative ai models, misinformation detection, multimodal},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3581783.3612708,
author = {Martin, Alexander and Zheng, Haitian and An, Jie and Luo, Jiebo},
title = {Jurassic World Remake: Bringing Ancient Fossils Back to Life via Zero-Shot Long Image-to-Image Translation},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3612708},
doi = {10.1145/3581783.3612708},
abstract = {With a strong understanding of the target domain from natural language, we produce promising results in translating across large domain gaps and bringing skeletons back to life. In this work, we use text-guided latent diffusion models for zero-shot image-to-image translation (I2I) across large domain gaps (longI2I), where large amounts of new visual features and new geometry need to be generated to enter the target domain. Being able to perform translations across large domain gaps has a wide variety of real-world applications in criminology, astrology, environmental conservation, and paleontology. In this work, we introduce a new task Skull2Animal for translating between skulls and living animals. On this task, we find that unguided Generative Adversarial Networks (GANs) are not capable of translating across large domain gaps. Instead of these traditional I2I methods, we explore the use of guided diffusion and image editing models and provide a new benchmark model, Revive-2I, capable of performing zero-shot I2I via text-prompting latent diffusion models. We find that guidance is necessary for longI2I because, to bridge the large domain gap, prior knowledge about the target domain is needed. In addition, we find that prompting provides the best and most scalable information about the target domain as classifier-guided diffusion models require retraining for specific use cases and lack stronger constraints on the target domain because of the wide variety of images they are trained on.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {9320–9328},
numpages = {9},
keywords = {image-to-image translation, large domain gap, stable diffusion},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3581783.3613432,
author = {Elhagry, Ahmed},
title = {Text-to-Metaverse: Towards a Digital Twin-Enabled Multimodal Conditional Generative Metaverse},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3613432},
doi = {10.1145/3581783.3613432},
abstract = {Developing realistic and interactive virtual environments is a major hurdle in the progress of Metaverse. At present, majority of Metaverse applications necessitate the manual construction of 3D models which is both time-consuming and costly. Additionally, it is challenging to design environments that can promptly react to users' actions. To address this challenge, this paper proposes a novel approach to generate virtual worlds using digital twin (DT) technology and AI through a Text-to-Metaverse pipeline. This pipeline converts natural language input into a scene JSON, which is used to generate a 3D virtual world using two engines: Generative Script Engine (GSE) and Generative Metaverse Engine (GME). GME generates a design script from the JSON file, and then uses it to generate 3D objects in an environment. It aims to use multimodal AI and DT technology to produce realistic and highly detailed virtual environments. The proposed pipeline has potential applications including education, training, architecture, healthcare and entertainment, and could change the way designers and developers create virtual worlds. While this short paper covers an abstract as per the Doctorial Symposium's guidelines, it contributes to the research on generative models for multimodal data and provides a new direction for creating immersive virtual experiences.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {9336–9339},
numpages = {4},
keywords = {computer vision, digital twin, generative models, metaverse, multimodal ai, nlp},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3581783.3613767,
author = {Zhang, Rui and Wang, Hongxia and Du, Mingshan and Liu, Hanqing and Zhou, Yang and Zeng, Qiang},
title = {UMMAFormer: A Universal Multimodal-adaptive Transformer Framework for Temporal Forgery Localization},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3613767},
doi = {10.1145/3581783.3613767},
abstract = {The emergence of artificial intelligence-generated content (AIGC) has raised concerns about the authenticity of multimedia content in various fields. However, existing research for forgery content detection has focused mainly on binary classification tasks of complete videos, which has limited applicability in industrial settings. To address this gap, we propose UMMAFormer, a novel universal transformer framework for temporal forgery localization (TFL) that predicts forgery segments with multimodal adaptation. Our approach introduces a Temporal Feature Abnormal Attention (TFAA) module based on temporal feature reconstruction to enhance the detection of temporal differences. We also design a Parallel Cross-Attention Feature Pyramid Network (PCA-FPN) to optimize the Feature Pyramid Network (FPN) for subtle feature enhancement. To evaluate the proposed method, we contribute a novel Temporal Video Inpainting Localization (TVIL) dataset specifically tailored for video inpainting scenes. Our experiments show that our approach achieves state-of-the-art performance on benchmark datasets, including Lav-DF, TVIL, and Psynd, significantly outperforming previous methods. The code and data are available at https://github.com/ymhzyj/UMMAFormer/.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {8749–8759},
numpages = {11},
keywords = {multimodal-adaptive, temporal forgery localization, transformer},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3581783.3613825,
author = {Sheng, Zheng-Yan and Ai, Yang and Chen, Yan-Nian and Ling, Zhen-Hua},
title = {Face-Driven Zero-Shot Voice Conversion with Memory-based Face-Voice Alignment},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3613825},
doi = {10.1145/3581783.3613825},
abstract = {This paper presents a novel task, zero-shot voice conversion based on face images (zero-shot FaceVC), which aims at converting the voice characteristics of an utterance from any source speaker to a newly coming target speaker, solely relying on a single face image of the target speaker. To address this task, we propose a face-voice memory-based zero-shot FaceVC method. This method leverages a memory-based face-voice alignment module, in which slots act as the bridge to align these two modalities, allowing for the capture of voice characteristics from face images. A mixed supervision strategy is also introduced to mitigate the long-standing issue of the inconsistency between training and inference phases for voice conversion tasks. To obtain speaker-independent content-related representations, we transfer the knowledge from a pretrained zero-shot voice conversion model to our zero-shot FaceVC model. Considering the differences between FaceVC and traditional voice conversion tasks, systematic subjective and objective metrics are designed to thoroughly evaluate the homogeneity, diversity and consistency of voice characteristics controlled by face images. Through extensive experiments, we demonstrate the superiority of our proposed method on the zero-shot FaceVC task. Samples are presented on our demo website.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {8443–8452},
numpages = {10},
keywords = {face-voice alignment, voice conversion, zero-shot},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3581783.3613831,
author = {Han, Zhongxuan and Chen, Chaochao and Zheng, Xiaolin and Liu, Weiming and Wang, Jun and Cheng, Wenjie and Li, Yuyuan},
title = {In-processing User Constrained Dominant Sets for User-Oriented Fairness in Recommender Systems},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3613831},
doi = {10.1145/3581783.3613831},
abstract = {Recommender systems are typically biased toward a small group of users, leading to severe unfairness in recommendation performance, i.e., User-Oriented Fairness (UOF) issue. The existing research on UOF is limited and fails to deal with the root cause of the UOF issue: the learning process between advantaged and disadvantaged users is unfair. To tackle this issue, we propose an In-processing User Constrained Dominant Sets (In-UCDS) framework, which is a general framework that can be applied to any backbone recommendation model to achieve user-oriented fairness. We split In-UCDS into two stages, i.e., the UCDS modeling stage and the in-processing training stage. In the In-UCDS modeling stage, for each disadvantaged user, we extract a constrained dominant set (a user cluster) containing some advantaged users that are similar to it. In the in-processing training stage, we move the representations of disadvantaged users closer to their corresponding cluster by calculating a fairness loss. By combining the fairness loss with the original backbone model loss, we address the UOF issue and maintain the overall recommendation performance simultaneously. Comprehensive experiments on three real-world datasets demonstrate that In-UCDS outperforms the state-of-the-art methods, leading to a fairer model with better overall recommendation performance.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {6190–6201},
numpages = {12},
keywords = {dominant sets, fairness, recommender system},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@proceedings{10.1145/3581784,
title = {SC '23: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
year = {2023},
isbn = {9798400701092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Started in 1988, the SC Conference has become the annual nexus for researchers and practitioners from academia, industry and government to share information and foster collaborations to advance the state of the art in High Performance Computing (HPC), Networking, Storage, and Analysis.},
location = {Denver, CO, USA}
}

@inproceedings{10.1145/3581784.3607087,
author = {Castro, Roberto L. and Ivanov, Andrei and Andrade, Diego and Ben-Nun, Tal and Fraguela, Basilio B. and Hoefler, Torsten},
title = {VENOM: A Vectorized N:M Format for Unleashing the Power of Sparse Tensor Cores},
year = {2023},
isbn = {9798400701092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581784.3607087},
doi = {10.1145/3581784.3607087},
abstract = {The increasing success and scaling of Deep Learning models demands higher computational efficiency and power. Sparsification can lead to both smaller models as well as higher compute efficiency, and accelerated hardware is becoming available. However, exploiting it efficiently requires kernel implementations, pruning algorithms, and storage formats, to utilize hardware support of specialized sparse vector units. An example of those are the NVIDIA's Sparse Tensor Cores (SPTCs), which promise a 2\texttimes{} speedup. However, SPTCs only support the 2:4 format, limiting achievable sparsity ratios to 50\%. We present the V:N:M format, which enables the execution of arbitrary N:M ratios on SPTCs. To efficiently exploit the resulting format, we propose Spatha, a high-performance sparse-library for DL routines. We show that Spatha achieves up to 37\texttimes{} speedup over cuBLAS. We also demonstrate a second-order pruning technique that enables sparsification to high sparsity ratios with V:N:M and little to no loss in accuracy in modern transformers.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
articleno = {72},
numpages = {14},
keywords = {neural networks, pruning, GPGPU, CUDA, sparse tensor cores},
location = {Denver, CO, USA},
series = {SC '23}
}

@proceedings{10.1145/3581791,
title = {MobiSys '23: Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of the entire organizing committee, it is with immense pleasure that we welcome you to the 21st ACM International Conference on Mobile Systems, Applications, and Services (ACM MobiSys 2023) hosted in Helsinki, Finland on June 18 - 22, 2023. ACM MobiSys is the leading conference in research on mobile systems, applications and services, and a flagship conference of ACM SIGMOBILE.},
location = {Helsinki, Finland}
}

@proceedings{10.1145/3581792,
title = {CIIS '22: Proceedings of the 2022 5th International Conference on Computational Intelligence and Intelligent Systems},
year = {2022},
isbn = {9781450397612},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Quzhou, China}
}

@proceedings{10.1145/3581807,
title = {ICCPR '22: Proceedings of the 2022 11th International Conference on Computing and Pattern Recognition},
year = {2022},
isbn = {9781450397056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Beijing, China}
}

@proceedings{10.1145/3581961,
title = {AutomotiveUI '23 Adjunct: Adjunct Proceedings of the 15th International Conference on Automotive User Interfaces and Interactive Vehicular Applications},
year = {2023},
isbn = {9798400701122},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Ingolstadt, Germany}
}

@proceedings{10.1145/3582099,
title = {AICCC '22: Proceedings of the 2022 5th Artificial Intelligence and Cloud Computing Conference},
year = {2022},
isbn = {9781450398749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Osaka, Japan}
}

@proceedings{10.1145/3582515,
title = {GoodIT '23: Proceedings of the 2023 ACM Conference on Information Technology for Social Good},
year = {2023},
isbn = {9798400701160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3582515.3609536,
author = {Montagna, Sara and Ferretti, Stefano and Klopfenstein, Lorenz Cuno and Florio, Antonio and Pengo, Martino Francesco},
title = {Data Decentralisation of LLM-Based Chatbot Systems in Chronic Disease Self-Management},
year = {2023},
isbn = {9798400701160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3582515.3609536},
doi = {10.1145/3582515.3609536},
abstract = {Chronic patient self-management is crucial for maintaining physical and psychological health, reducing pressure on healthcare systems, and promoting patient empowerment. Digital technologies, particularly chatbots, have emerged as powerful tools for supporting patients in managing their chronic conditions. Large language models (LLMs), such as GPT-4, have shown potential in improving chatbot-based systems in healthcare. However, their adoption in clinical practice faces challenges, including reliability, the need for clinical trials, and privacy concerns. This paper proposes a general architecture for developing an LLM-based chatbot system that supports chronic patients while addressing privacy and security concerns. The architecture is designed to be independent of specific technologies and health conditions, focusing on data protection legislation compliance. A prototype of the system has been developed for hypertension management, demonstrating its potential for motivating patients to monitor their blood pressure and adhere to prescriptions.},
booktitle = {Proceedings of the 2023 ACM Conference on Information Technology for Social Good},
pages = {205–212},
numpages = {8},
keywords = {chatbot, healthcare data privacy, hypertension, personal data store},
location = {Lisbon, Portugal},
series = {GoodIT '23}
}

@proceedings{10.1145/3582768,
title = {NLPIR '22: Proceedings of the 2022 6th International Conference on Natural Language Processing and Information Retrieval},
year = {2022},
isbn = {9781450397629},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bangkok, Thailand}
}

@proceedings{10.1145/3583120,
title = {IPSN '23: Proceedings of the 22nd International Conference on Information Processing in Sensor Networks},
year = {2023},
isbn = {9798400701184},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {San Antonio, TX, USA}
}

@proceedings{10.1145/3583131,
title = {GECCO '23: Proceedings of the Genetic and Evolutionary Computation Conference},
year = {2023},
isbn = {9798400701191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {GECCO is the largest peer-reviewed conference in the field of Evolutionary Computation, and the main conference of the Special Interest Group on Genetic and Evolutionary Computation (SIGEVO) of the Association for Computing Machinery (ACM).},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3583131.3590409,
author = {Huntsman, Steve},
title = {Quality-diversity in dissimilarity spaces},
year = {2023},
isbn = {9798400701191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583131.3590409},
doi = {10.1145/3583131.3590409},
abstract = {The theory of magnitude provides a mathematical framework for quantifying and maximizing diversity. We apply this framework to formulate quality-diversity algorithms in generic dissimilarity spaces. In particular, we instantiate a very general version of Go-Explore with promising performance for challenging and computationally expensive objectives, such as arise in simulations.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {1009–1018},
numpages = {10},
keywords = {quality-diversity optimization, dissimilarity, magnitude},
location = {Lisbon, Portugal},
series = {GECCO '23}
}

@proceedings{10.1145/3583133,
title = {GECCO '23 Companion: Proceedings of the Companion Conference on Genetic and Evolutionary Computation},
year = {2023},
isbn = {9798400701207},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {GECCO is the largest peer-reviewed conference in the field of Evolutionary Computation, and the main conference of the Special Interest Group on Genetic and Evolutionary Computation (SIGEVO) of the Association for Computing Machinery (ACM).},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3583678,
title = {DEBS '23: Proceedings of the 17th ACM International Conference on Distributed and Event-based Systems},
year = {2023},
isbn = {9798400701221},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {DEBS 2023 is the seventeenth in a series that spans more than 20 years of history, with 16 past editions as a conference and five editions as a workshop co-located with major conferences.The objectives of DEBS have been to provide a forum dedicated to the dissemination of original research, the discussion of practical insights, and the reporting of experiences relevant to distributed systems and event-based computing. The conference provides a forum for academia and industry to exchange ideas through its tutorials, research papers, and the grand challenge. Recently, the ACM International Conference on Distributed and Event-Based Systems, including DEBS 2022, has become the premier venue for cutting-edge research in the integration of distributed and event-based systems in relevant domains such as Big Data, AI, ML, IoT, and Blockchain.},
location = {Neuchatel, Switzerland}
}

@inproceedings{10.1145/3583780.3614758,
author = {Yang, Kailai and Zhang, Tianlin and Ji, Shaoxiong and Ananiadou, Sophia},
title = {A Bipartite Graph is All We Need for Enhancing Emotional Reasoning with Commonsense Knowledge},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3614758},
doi = {10.1145/3583780.3614758},
abstract = {The context-aware emotional reasoning ability of AI systems, especially in conversations, is of vital importance in applications such as online opinion mining from social media and empathetic dialogue systems. Due to the implicit nature of conveying emotions in many scenarios, commonsense knowledge is widely utilized to enrich utterance semantics and enhance conversation modeling. However, most previous knowledge infusion methods perform empirical knowledge filtering and design highly customized architectures for knowledge interaction with the utterances, which can discard useful knowledge aspects and limit their generalizability to different knowledge sources. Based on these observations, we propose a Bipartite Heterogeneous Graph (BHG) method for enhancing emotional reasoning with commonsense knowledge. In BHG, the extracted context-aware utterance representations and knowledge representations are modeled as heterogeneous nodes. Two more knowledge aggregation node types are proposed to perform automatic knowledge filtering and interaction. BHG-based knowledge infusion can be directly generalized to multi-type and multi-grained knowledge sources. In addition, we propose a Multi-dimensional Heterogeneous Graph Transformer (MHGT) to perform graph reasoning, which can retain unchanged feature spaces and unequal dimensions for heterogeneous node types during inference to prevent unnecessary loss of information. Experiments show that BHG-based methods significantly outperform state-of-the-art knowledge infusion methods and show generalized knowledge infusion ability with higher efficiency. Further analysis proves that previous empirical knowledge filtering methods do not guarantee to provide the most useful knowledge information. Our code is available at: https://github.com/SteveKGYang/BHG.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {2917–2927},
numpages = {11},
keywords = {bipartite heterogeneous graph, casual emotion entailment, emotion recognition in conversations, knowledge infusion},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3583780.3614777,
author = {Ghafouri, Vahid and Agarwal, Vibhor and Zhang, Yong and Sastry, Nishanth and Such, Jose and Suarez-Tangil, Guillermo},
title = {AI in the Gray: Exploring Moderation Policies in Dialogic Large Language Models vs. Human Answers in Controversial Topics},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3614777},
doi = {10.1145/3583780.3614777},
abstract = {The introduction of ChatGPT and the subsequent improvement of Large Language Models (LLMs) have prompted more and more individuals to turn to the use of ChatBots, both for information and assistance with decision-making. However, the information the user is after is often not formulated by these ChatBots objectively enough to be provided with a definite, globally accepted answer.Controversial topics, such as "religion", "gender identity", "freedom of speech", and "equality", among others, can be a source of conflict as partisan or biased answers can reinforce preconceived notions or promote disinformation. By exposing ChatGPT to such debatable questions, we aim to understand its level of awareness and if existing models are subject to socio-political and/or economic biases. We also aim to explore how AI-generated answers compare to human ones. For exploring this, we use a dataset of a social media platform created for the purpose of debating human-generated claims on polemic subjects among users, dubbed Kialo.Our results show that while previous versions of ChatGPT have had important issues with controversial topics, more recent versions of ChatGPT (gpt-3.5-turbo) are no longer manifesting significant explicit biases in several knowledge areas. In particular, it is well-moderated regarding economic aspects. However, it still maintains degrees of implicit libertarian leaning toward right-winged ideals which suggest the need for increased moderation from the socio-political point of view. In terms of domain knowledge on controversial topics, with the exception of the "Philosophical" category, ChatGPT is performing well in keeping up with the collective human level of knowledge. Finally, we see that sources of Bing AI have slightly more tendency to the center when compared to human answers. All the analyses we make are generalizable to other types of biases and domains.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {556–565},
numpages = {10},
keywords = {AI bias, ChatGPT, Kialo, NLP, controversial topics, sentence transformers},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3583780.3614805,
author = {Song, Zijie and Chen, Jiawei and Zhou, Sheng and Shi, Qihao and Feng, Yan and Chen, Chun and Wang, Can},
title = {CDR: Conservative Doubly Robust Learning for Debiased Recommendation},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3614805},
doi = {10.1145/3583780.3614805},
abstract = {In recommendation systems (RS), user behavior data is observational rather than experimental, resulting in widespread bias in the data. Consequently, tackling bias has emerged as a major challenge in the field of recommendation systems. Recently, Doubly Robust Learning (DR) has gained significant attention due to its remarkable performance and robust properties. However, our experimental findings indicate that existing DR methods are severely impacted by the presence of so-called Poisonous Imputation, where the imputation significantly deviates from the truth and becomes counterproductive.To address this issue, this work proposes Conservative Doubly Robust strategy (CDR) which filters imputations by scrutinizing their mean and variance. Theoretical analyses show that CDR offers reduced variance and improved tail bounds.In addition, our experimental investigations illustrate that CDR significantly enhances performance and can indeed reduce the frequency of poisonous imputation.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {2321–2330},
numpages = {10},
keywords = {doubly robust, recommender systems, selection bias},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3583780.3614857,
author = {Lee, Jongsoo and Park, Byeongtae and Chae, Dong-Kyu},
title = {DuoGAT: Dual Time-oriented Graph Attention Networks for Accurate, Efficient and Explainable Anomaly Detection on Time-series},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3614857},
doi = {10.1145/3583780.3614857},
abstract = {Recently, Graph Neural Networks (GNNs) have achieved state-of-the-art performance on the multivariate time-series anomaly detection task by learning relationships between variables (sensors). However, they show limitations in capturing temporal dependencies due to lack of sufficient consideration on the characteristics of time to their graph structure. Several studies constructed a time-oriented graph, where each node represents a timestamp within a certain sliding window, to model temporal dependencies, but they failed to learn the trend of changes in time-series. This paper proposes Dual time-oriented Graph ATtention networks (DuoGAT) that resolves the aforementioned problems. Unlike previous work that uses the simple complete undirected structure for time-oriented graphs, our work models directed graphs with weighted edges that only connect from prior events to posterior events, and the edges that connect nearby events are given higher weights. In addition, another time-oriented graph is used to model time series stationary via differencing, which especially focuses on capturing the series of changes. Empirically, our method outperformed the existing state-of-the-art work with the highest F1-score for the four real-world dataset while maintaining low training cost. We also proposed a novel explanation method for anomaly detection using DuoGAT, which provides time-oriented reasoning via hierarchically tracking time points critical in a specific anomaly detection. Our code is available at: https://github.com/ByeongtaePark/DuoGAT},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {1188–1197},
numpages = {10},
keywords = {anomaly detection, explainable AI, graph neural networks, multivariate time-series},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3583780.3614864,
author = {Bonomi, Luca and Gousheh, Sepand and Fan, Liyue},
title = {Enabling Health Data Sharing with Fine-Grained Privacy},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3614864},
doi = {10.1145/3583780.3614864},
abstract = {Sharing health data is vital in advancing medical research and transforming knowledge into clinical practice. Meanwhile, protecting the privacy of data contributors is of paramount importance. To that end, several privacy approaches have been proposed to protect individual data contributors in data sharing, including data anonymization and data synthesis techniques. These approaches have shown promising results in providing privacy protection at the dataset level. In this work, we study the privacy challenges in enabling fine-grained privacy in health data sharing. Our work is motivated by recent research findings, in which patients and healthcare providers may have different privacy preferences and policies that need to be addressed. Specifically, we propose a novel and effective privacy solution that enables data curators (e.g., healthcare providers) to protect sensitive data elements while preserving data usefulness. Our solution builds on randomized techniques to provide rigorous privacy protection for sensitive elements and leverages graphical models to mitigate privacy leakage due to dependent elements. To enhance the usefulness of the shared data, our randomized mechanism incorporates domain knowledge to preserve semantic similarity and adopts a block-structured design to minimize utility loss. Evaluations with real-world health data demonstrate the effectiveness of our approach and the usefulness of the shared data for health applications.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {131–141},
numpages = {11},
keywords = {data privacy, data sharing, health data},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3583780.3614894,
author = {Shi, Yucheng and Dong, Yushun and Tan, Qiaoyu and Li, Jundong and Liu, Ninghao},
title = {GiGaMAE: Generalizable Graph Masked Autoencoder via Collaborative Latent Space Reconstruction},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3614894},
doi = {10.1145/3583780.3614894},
abstract = {Self-supervised learning with masked autoencoders has recently gained popularity for its ability to produce effective image or textual representations, which can be applied to various downstream tasks without retraining. However, we observe that the current masked autoencoder models lack good generalization ability on graph data. To tackle this issue, we propose a novel graph masked autoencoder framework called GiGaMAE. Different from existing masked autoencoders that learn node presentations by explicitly reconstructing the original graph components (e.g., features or edges), in this paper, we propose to collaboratively reconstruct informative and integrated latent embeddings. By considering embeddings encompassing graph topology and attribute information as reconstruction targets, our model could capture more generalized and comprehensive knowledge. Furthermore, we introduce a mutual information based reconstruction loss that enables the effective reconstruction of multiple targets. This learning objective allows us to differentiate between the exclusive knowledge learned from a single target and common knowledge shared by multiple targets. We evaluate our method on three downstream tasks with seven datasets as benchmarks. Extensive experiments demonstrate the superiority of GiGaMAE against state-of-the-art baselines. We hope our results will shed light on the design of foundation models on graph-structured data. Our code is available at: https://github.com/sycny/GiGaMAE.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {2259–2269},
numpages = {11},
keywords = {graph mining, masked autoencoder, self-supervised learning},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3583780.3614905,
author = {Chen, Yuyan and Fu, Qiang and Yuan, Yichen and Wen, Zhihao and Fan, Ge and Liu, Dayiheng and Zhang, Dongmei and Li, Zhixu and Xiao, Yanghua},
title = {Hallucination Detection: Robustly Discerning Reliable Answers in Large Language Models},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3614905},
doi = {10.1145/3583780.3614905},
abstract = {Large language models (LLMs) have gained widespread adoption in various natural language processing tasks, including question answering and dialogue systems. However, a major drawback of LLMs is the issue of hallucination, where they generate unfaithful or inconsistent content that deviates from the input source, leading to severe consequences. In this paper, we propose a robust discriminator named RelD to effectively detect hallucination in LLMs' generated answers. RelD is trained on the constructed RelQA, a bilingual question-answering dialogue dataset along with answers generated by LLMs and a comprehensive set of metrics. Our experimental results demonstrate that the proposed RelD successfully detects hallucination in the answers generated by diverse LLMs. Moreover, it performs well in distinguishing hallucination in LLMs' generated answers from both in-distribution and out-of-distribution datasets. Additionally, we also conduct a thorough analysis of the types of hallucinations that occur and present valuable insights. This research significantly contributes to the detection of reliable answers generated by LLMs and holds noteworthy implications for mitigating hallucination in the future work.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {245–255},
numpages = {11},
keywords = {hallucination detection, large language models, reliable answers},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3583780.3614933,
author = {Hu, Qi and Song, Yangqiu},
title = {Independent Distribution Regularization for Private Graph Embedding},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3614933},
doi = {10.1145/3583780.3614933},
abstract = {Learning graph embeddings is a crucial task in graph mining tasks. An effective graph embedding model can learn low-dimensional representations from graph-structured data for data publishing benefiting various downstream applications such as node classification, link prediction, etc. However, recent studies have revealed that graph embeddings are susceptible to attribute inference attacks, which allow attackers to infer private node attributes from the learned graph embeddings. To address these concerns, privacy-preserving graph embedding methods have emerged, aiming to simultaneously consider primary learning and privacy protection through adversarial learning. However, most existing methods assume that representation models have access to all sensitive attributes in advance during the training stage, which is not always the case due to diverse privacy preferences. Furthermore, the commonly used adversarial learning technique in privacy-preserving representation learning suffers from unstable training issues. In this paper, we propose a novel approach calledPrivate Variational Graph AutoEncoders (PVGAE) with the aid of independent distribution penalty as a regularization term. Specifically, we split the original variational graph autoencoder (VGAE) to learn sensitive and non-sensitive latent representations using two sets of encoders. Additionally, we introduce a novel regularization to enforce the independence of the encoders. We prove the theoretical effectiveness of regularization from the perspective of mutual information. Experimental results on three real-world datasets demonstrate that PVGAE outperforms other baselines in private embedding learning regarding utility performance and privacy protection.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {823–832},
numpages = {10},
keywords = {graph embedding, graph neural network, privacy preserving},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3583780.3614934,
author = {Chen, Lu and Zhang, Ruqing and Huang, Wei and Chen, Wei and Guo, Jiafeng and Cheng, Xueqi},
title = {Inducing Causal Structure for Abstractive Text Summarization},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3614934},
doi = {10.1145/3583780.3614934},
abstract = {The mainstream of data-driven abstractive summarization models tends to explore the correlations rather than the causal relationships. Among such correlations, there can be spurious ones which suffer from the language prior learned from the training corpus and therefore undermine the overall effectiveness of the learned model. To tackle this issue, we introduce a Structural Causal Model (SCM) to induce the underlying causal structure of the summarization data. We assume several latent causal factors and non-causal factors, representing the content and style of the document and summary. Theoretically, we prove that the latent factors in our SCM can be identified by fitting the observed training data under certain conditions. On the basis of this, we propose a Causality Inspired Sequence-to-Sequence model (CI-Seq2Seq) to learn the causal representations that can mimic the causal factors, guiding us to pursue causal information for summary generation. The key idea is to reformulate the Variational Auto-encoder (VAE) to fit the joint distribution of the document and summary variables from the training corpus. Experimental results on two widely used text summarization datasets demonstrate the advantages of our approach.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {213–223},
numpages = {11},
keywords = {VAE, abstractive text summarization, structural causal model},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3583780.3614937,
author = {Singh, Apoorva and Verma, Apoorv and Jain, Raghav and Saha, Sriparna},
title = {Investigating the Impact of Multimodality and External Knowledge in Aspect-level Complaint and Sentiment Analysis},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3614937},
doi = {10.1145/3583780.3614937},
abstract = {Automated complaint analysis is vital for generating critical insights, which in turn enhance customer satisfaction, product quality, and overall business performance. Nevertheless, conventional methods frequently fail to capture the nuances of aspect-level complaints and inadequately utilize external knowledge, thus creating a gap in effective complaint detection and analysis. In response to this issue, we proactively explore the role of external knowledge and multimodality in this domain. This leads to the development of MGasD (Multimodal Generative framework for aspect-based complaint and sentiment Detection), a multimodal knowledge-infused unified framework. MGasD diverges from traditional methods by reframing the complaint detection problem as a multimodal text-to-text generation task. Significantly, our research includes the development of a novel aspect-level dataset. Annotated for both complaint and sentiment categories across diverse domains such as books, electronics, edibles, fashion, and miscellaneous, this dataset provides a comprehensive platform for the concurrent study of complaints and sentiment. This resource facilitates a more robust understanding of consumer feedback. Our proposed methodology establishes a benchmark performance in the novel aspect-based complaint and sentiment detection tasks based on extensive evaluation. We also demonstrate that our model consistently outperforms all other baselines and state-of-the-art models in both full and few-shot settings (The dataset and code are available at:https://github.com/appy1608/CIKM2023).},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {2291–2300},
numpages = {10},
keywords = {generative modeling, multi-task learning, multimodal complaint detection, social media mining},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3583780.3614940,
author = {Gupta, Rishabh and V, Venktesh and Mohania, Mukesh and Goyal, Vikram},
title = {James ate 5 oranges = Steve bought 5 pencils: Structure-Aware Denoising for Paraphrasing Word Problems},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3614940},
doi = {10.1145/3583780.3614940},
abstract = {We propose SCANING, an unsupervised framework for paraphrasing via controlled noise injection. We focus on the novel task of paraphrasing algebraic word problems having practical applications in online pedagogy as a means to reduce plagiarism as well as evoke reasoning capabilities on the part of the student instead of rote memorization. This task is more complex than paraphrasing general-domain corpora due to the difficulty in preserving critical information for solution consistency of the paraphrased word problem, managing the increased length of the text and ensuring diversity in the generated paraphrase. Existing approaches fail to demonstrate adequate performance on at least one, if not all, of these facets, necessitating the need for a more comprehensive solution. To this end, we model the noising search space as a composition of contextual and syntactic aspects to sample noising functions. This allows for learning a denoising function, that operates over both aspects and produces semantically equivalent and syntactically diverse outputs through grounded noise injection. The denoising function serves as a foundation for training a paraphrasing function, which operates solely in the input-paraphrase space without carrying any direct dependency on noise. We demonstrate that SCANING improves performance in terms of producing semantically equivalent and syntactically diverse paraphrases by 35\% through extensive automated and human evaluation across 4 datasets.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {679–688},
numpages = {10},
keywords = {MWP, denoising, education, neural networks, paraphrasing, self-supervised},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3583780.3614949,
author = {He, Zhankui and Xie, Zhouhang and Jha, Rahul and Steck, Harald and Liang, Dawen and Feng, Yesu and Majumder, Bodhisattwa Prasad and Kallus, Nathan and Mcauley, Julian},
title = {Large Language Models as Zero-Shot Conversational Recommenders},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3614949},
doi = {10.1145/3583780.3614949},
abstract = {In this paper, we present empirical studies on conversational recommendation tasks using representative large language models in a zero-shot setting with three primary contributions. (1) Data: To gain insights into model behavior in "in-the-wild" conversational recommendation scenarios, we construct a new dataset of recommendation-related conversations by scraping a popular discussion website. This is the largest public real-world conversational recommendation dataset to date. (2) Evaluation: On the new dataset and two existing conversational recommendation datasets, we observe that even without fine-tuning, large language models can outperform existing fine-tuned conversational recommendation models. (3) Analysis: We propose various probing tasks to investigate the mechanisms behind the remarkable performance of large language models in conversational recommendation. We analyze both the large language models' behaviors and the characteristics of the datasets, providing a holistic understanding of the models' effectiveness, limitations and suggesting directions for the design of future conversational recommenders.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {720–730},
numpages = {11},
keywords = {conversational recommendation, datasets, large language model},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3583780.3615026,
author = {Yang, Jiuding and Luo, Jinwen and Guo, Weidong and Chen, Jerry and Niu, Di and Xu, Yu},
title = {Mulco: Recognizing Chinese Nested Named Entities through Multiple Scopes},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615026},
doi = {10.1145/3583780.3615026},
abstract = {Nested Named Entity Recognition (NNER), as a subarea of Named Entity Recognition, has presented longstanding challenges to researchers. In NNER, one entity may be part of a larger entity, which can occur at multiple levels. These nested structures prevent traditional sequence labeling methods from properly recognizing all entities. While recent research has focused on designing better recognition methods for NNER in various languages, Chinese Nested Named Entity Recognition (CNNER) is still underdeveloped, largely due to a lack of freely available CNNER benchmarks. To support CNNER research, in this paper, we introduce ChiNesE, a CNNER dataset comprising 20,000 sentences from online passages in multiple domains and containing 117,284 entities that fall into 10 categories, of which 43.8\% are nested named entities. Based on ChiNesE, we propose Mulco, a novel method that can recognize named entities in nested structures through multiple scopes. Each scope uses a scope-based sequence labeling method that predicts an anchor and the length of a named entity to recognize it. Experimental results show that Mulco outperforms state-of-the-art baseline methods with different recognition schemes on ChiNesE and ACE 2005 Chinese corpus.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {2980–2989},
numpages = {10},
keywords = {Chinese nested named entity recognition, datasets, nested named entity recognition, sequence labeling},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3583780.3615045,
author = {Liao, Jie and Li, Jintang and Chen, Liang and Wu, Bingzhe and Bian, Yatao and Zheng, Zibin},
title = {SAILOR: Structural Augmentation Based Tail Node Representation Learning},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615045},
doi = {10.1145/3583780.3615045},
abstract = {Graph neural networks (GNNs) have achieved state-of-the-art performance in representation learning for graphs recently. However, the effectiveness of GNNs, which capitalize on the key operation of message propagation, highly depends on the quality of the topology structure. Most of the graphs in real-world scenarios follow a long-tailed distribution on their node degrees, that is, a vast majority of the nodes in the graph are tail nodes with only a few connected edges. GNNs produce inferior node representations for tail nodes due to the lack of sufficient structural information. In the pursuit of promoting the performance of GNNs for tail nodes, we explore how the deficiency of structural information deteriorates the performance of tail nodes and propose a general structural augmentation based tailno de representation learning framework, dubbed as \o{}urs, which can jointly learn to augment the graph structure and extract more informative representations for tail nodes. Extensive experiments on six public benchmark datasets demonstrate that \o{}urs outperforms the state-of-the-art methods for tail node representation learning.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {1389–1399},
numpages = {11},
keywords = {graph neural networks, graph representation learning, long-tailed degree distribution},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3583780.3615070,
author = {Meng, Chuan and Aliannejadi, Mohammad and de Rijke, Maarten},
title = {System Initiative Prediction for Multi-turn Conversational Information Seeking},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615070},
doi = {10.1145/3583780.3615070},
abstract = {Identifying the right moment for a system to take the initiative is essential to conversational information seeking (CIS). Existing studies have extensively studied the clarification need prediction task, i.e., predicting when to ask a clarifying question, however, it only covers one specific system-initiative action. We define the system initiative prediction (SIP) task as predicting whether a CIS system should take the initiative at the next turn. Our analysis reveals that for effective modeling of SIP, it is crucial to capture dependencies between adjacent user?system initiative-taking decisions. We propose to model SIP by CRFs. Due to their graphical nature, CRFs are effective in capturing such dependencies and have greater transparency than more complex methods, e.g., LLMs. Applying CRFs to SIP comes with two challenges: (i) CRFs need to be given the unobservable system utterance at the next turn, and (ii) they do not explicitly model multi-turn features. We model SIP as an input-incomplete sequence labeling problem and propose a multi-turn system initiative predictor (MuSIc) that has (i) prior-posterior inter-utterance encoders to eliminate the need to be given the unobservable system utterance, and (ii) a multi-turn feature-aware CRF layer to incorporate multi-turn features into the dependencies between adjacent initiative-taking decisions. Experiments show that MuSIc outperforms LLM-based baselines including LLaMA, achieving state-of-the-art results on SIP. We also show the benefits of SIP on clarification need prediction and action prediction.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {1807–1817},
numpages = {11},
keywords = {conversational information seeking, mixed initiative, system initiative prediction},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3583780.3615104,
author = {Zhao, Tianyi and Hu, Hui and Cheng, Lu},
title = {Unveiling the Role of Message Passing in Dual-Privacy Preservation on GNNs},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615104},
doi = {10.1145/3583780.3615104},
abstract = {Graph Neural Networks (GNNs) are powerful tools for learning representations on graphs, such as social networks. However, their vulnerability to privacy inference attacks restricts their practicality, especially in high-stake domains. To address this issue, privacy-preserving GNNs have been proposed, focusing on preserving node and/or link privacy. This work takes a step back and investigates how GNNs contribute to privacy leakage. Through theoretical analysis and simulations, we identify message passing under structural bias as the core component that allows GNNs to propagate andamplify privacy leakage. Building upon these findings, we propose a principled privacy-preserving GNN framework that effectively safeguards both node and link privacy, referred to as dual-privacy preservation. The framework comprises three major modules: a Sensitive Information Obfuscation Module that removes sensitive information from node embeddings, a Dynamic Structure Debiasing Module that dynamically corrects the structural bias, and an Adversarial Learning Module that optimizes the privacy-utility trade-off. Experimental results on four benchmark datasets validate the effectiveness of the proposed model in protecting both node and link privacy while preserving high utility for downstream tasks, such as node classification.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {3474–3483},
numpages = {10},
keywords = {graph neural networks, privacy preservation, structural bias},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3583780.3615106,
author = {Lai, Jinrong and Wang, Tong and Chen, Chuan and Li, Yihao and Zheng, Zibin},
title = {VFedAD: A Defense Method Based on the Information Mechanism Behind the Vertical Federated Data Poisoning Attack},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615106},
doi = {10.1145/3583780.3615106},
abstract = {In recent years, federated learning has achieved remarkable results in the medical and financial fields, but various attacks have always plagued federated learning. Data poisoning attack and defense research in horizontal federated learning are sufficient, yet vertical federated data poisoning attack and defense remains an open area due to two challenges: (1) Complex data distributions lead to immense attack possibilities, and (2) defense methods are insufficient for complex data distributions. We have discovered that from the perspective of information theory, the above challenges can be addressed elegantly and succinctly with a solution. We first reveal the information-theoretic mechanisms underlying vertical federated data poisoning attacks and then propose an unsupervised vertical federated data poisoning defense method (VFedAD) based on information theory. VFedAD learns semantic-rich client data representations through contrastive learning task and cross-client prediction task to identify anomalies. Experiments show VFedAD effectively detects vertical federated anomalies, protecting subsequent algorithms from vertical federated data poisoning attacks.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {1148–1157},
numpages = {10},
keywords = {data poisoning attack and defense, information theory, vertical federated learning},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@proceedings{10.1145/3583788,
title = {ICMLSC '23: Proceedings of the 2023 7th International Conference on Machine Learning and Soft Computing},
year = {2023},
isbn = {9781450398633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Chongqing, China}
}

@proceedings{10.1145/3583961,
title = {IHM '23: Proceedings of the 34th Conference on l'Interaction Humain-Machine},
year = {2023},
isbn = {9781450398244},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {TROYES, France}
}

@proceedings{10.1145/3584202,
title = {ICFNDS '22: Proceedings of the 6th International Conference on Future Networks \&amp; Distributed Systems},
year = {2022},
isbn = {9781450399050},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tashkent, TAS, Uzbekistan}
}

@proceedings{10.1145/3584318,
title = {NSPW '22: Proceedings of the 2022 New Security Paradigms Workshop},
year = {2022},
isbn = {9781450398664},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {North Conway, NH, USA}
}

@inproceedings{10.1145/3584318.3584320,
author = {Buckley, Gerard and Caulfield, Tristan and Becker, Ingolf},
title = {“It may be a pain in the backside but...” Insights into the resilience of business after GDPR},
year = {2023},
isbn = {9781450398664},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584318.3584320},
doi = {10.1145/3584318.3584320},
abstract = {The General Data Protection Regulation (GDPR) came into effect in May 2018 and is designed to safeguard European Union (EU) citizens’ data privacy. The benefits of the regulation to consumers’ rights and to regulators’ powers are well known. The benefits to regulated businesses are less obvious and under-researched. We conduct exploratory research into understanding the socio-technical impacts and resilience of business in the face of a major new disruptive regulation. In particular, we investigate if GDPR is all pain and no gain. Using semi-structured interviews, we survey 14 senior-level executives responsible for business, finance, marketing, compliance and technology drawn from six companies in the UK and Ireland. We find the threat of fines has focused the corporate mind and made business more privacy aware. Organisationally, it has created new power bases within companies to advocate GDPR. It has forced companies to modernise their platforms and indirectly benefited them with better risk management processes, information security infrastructure and up to date customer databases. Compliance, for some, is used as a reputational signal of trustworthiness. Many implementation challenges remain. New business development and intra-company communication is more constrained. Regulation has increased costs and internal bureaucracy. Grey areas remain due to a lack of case law. Disgruntled customers and ex-employees weaponise Subject Access Requests (SAR) as a tool of retaliation. All small and medium-sized businesses in our sample see GDPR as overkill and overwhelming. We conclude GDPR may be regarded as a pain by business but it has made it more careful with data. It created a short-term disruption that monopolised IT budgets in the run-up to GDPR and created a long-term disruption to company politics as Compliance and Information Security leverage the regulation for budget and control. The rising trend in the number of fines issued by national data protection regulators and the establishment of new case law will continue to reshape organisations.},
booktitle = {Proceedings of the 2022 New Security Paradigms Workshop},
pages = {21–34},
numpages = {14},
keywords = {Data protection, GDPR, GDPR Business benefits, GDPR implementation challenges, General Data Protection Regulation},
location = {North Conway, NH, USA},
series = {NSPW '22}
}

@proceedings{10.1145/3584371,
title = {BCB '23: Proceedings of the 14th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics},
year = {2023},
isbn = {9798400701269},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {ACM-BCB is the flagship conference of the ACM SIGBio, the ACM Special Interest Group in Bioinformatics, Computational Biology, and Biomedical Informatics. Continuing the annual tradition, the conference focuses on interdisciplinary research linking computer science, mathematics, statistics, biology, bioinformatics, biomedical informatics, and health informatics.},
location = {Houston, TX, USA}
}

@inproceedings{10.1145/3584371.3612964,
author = {Zheng, Julia and Nishida, Yuya and Okrasinska, Alicja and Bonito, Gregory M. and Heath-Heckman, Elizabeth A. C. and Liu, Kevin J.},
title = {The Impact of Species Tree Estimation Error on Cophylogenetic Reconstruction},
year = {2023},
isbn = {9798400701269},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584371.3612964},
doi = {10.1145/3584371.3612964},
abstract = {Just as a phylogeny encodes the evolutionary relationships among a group of organisms, a cophylogeny represents the coevolutionary relationships among symbiotic partners. Both are primarily reconstructed using computational analysis of biomolecular sequence data. The most widely used cophylogenetic reconstruction methods utilize an important simplifying assumption: species phylogenies for each set of coevolved taxa are required as input and assumed to be correct. Many studies have shown that this assumption is rarely - if ever - satisfied, and the consequences for cophylogenetic studies are poorly understood.To address this gap, we conduct a comprehensive performance study that quantifies the relationship between species tree estimation error and downstream cophylogenetic estimation accuracy. We study the performance of state-of-the-art methods for cophylogenetic reconstruction using in silico model-based simulations. Our investigation also includes assessments of cophylogenetic reproducibility using genomic sequence datasets sampled from two important models of symbiosis: soil-associated fungi and their endosymbiotic bacteria, and bobtail squid and their bioluminescent bacterial symbionts.Our findings conclusively demonstrate the major impact that upstream phylogenetic estimation error has on downstream cophylogenetic reconstruction quality. Relative to other experimental factors such as cophylogenetic estimation method choice and coevolutionary event costs, phylogenetic estimation error ranked highest in importance based on a random forest-based variable importance assessment. We conclude with practical guidance and future research directions. In particular, among the many considerations needed for accurate cophylogenetic reconstruction - choice of cophylogenetic reconstruction method and method settings, sampling design, and others - just as much attention must be paid to careful species phylogeny estimation using modern best practices.},
booktitle = {Proceedings of the 14th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics},
articleno = {18},
numpages = {10},
keywords = {cophylogeny, cophylogenetic reconciliation, species tree, simulation study, mortierella, bobtail squid, symbiont, symbiosis},
location = {Houston, TX, USA},
series = {BCB '23}
}

@proceedings{10.1145/3584376,
title = {RICAI '22: Proceedings of the 2022 4th International Conference on Robotics, Intelligent Control and Artificial Intelligence},
year = {2022},
isbn = {9781450398343},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Dongguan, China}
}

@proceedings{10.1145/3584684,
title = {ApPLIED 2023: Proceedings of the 5th workshop on Advanced tools, programming languages, and PLatforms for Implementing and Evaluating algorithms for Distributed systems},
year = {2023},
isbn = {9798400701283},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Orlando, FL, USA}
}

@inproceedings{10.1145/3584684.3597263,
author = {Ilani, Arnon and Dolev, Shlomi},
title = {Invited Paper: Common Public Knowledge for Enhancing Machine Learning Data Sets},
year = {2023},
isbn = {9798400701283},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584684.3597263},
doi = {10.1145/3584684.3597263},
abstract = {In this study, we show the advantages of incorporating multi-source knowledge from publicly available sources, such as ChatGPT and Wikipedia, into existing datasets to enhance the performance of machine learning models for routine tasks, such as classification. specifically, we propose the utilization of supplementary data from external sources and demonstrate the utility of widely accessible knowledge in the context of the Forest Cover Type Prediction task launched by the Roosevelt National Forest of Northern Colorado. Additionally, we exhibit an improvement in classification accuracy for the Isolated Letter Speech Recognition dataset when incorporating information on regional accents in the prediction of spoken English letter names.},
booktitle = {Proceedings of the 5th Workshop on Advanced Tools, Programming Languages, and PLatforms for Implementing and Evaluating Algorithms for Distributed Systems},
articleno = {2},
numpages = {10},
keywords = {ontology, machine learning, random forests, feature engineering, world knowledge, speech recognition, isolated letter, forest management, tree cover type, ChatGPT},
location = {Orlando, FL, USA},
series = {ApPLIED 2023}
}

@proceedings{10.1145/3584871,
title = {ICSIM '23: Proceedings of the 2023 6th International Conference on Software Engineering and Information Management},
year = {2023},
isbn = {9781450398237},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Palmerston North, New Zealand}
}

@proceedings{10.1145/3584931,
title = {CSCW '23 Companion: Companion Publication of the 2023 Conference on Computer Supported Cooperative Work and Social Computing},
year = {2023},
isbn = {9798400701290},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Minneapolis, MN, USA}
}

@inproceedings{10.1145/3584931.3606955,
author = {Shen, Hong and Li, Tianshi and Li, Toby Jia-Jun and Park, Joon Sung and Yang, Diyi},
title = {Shaping the Emerging Norms of Using Large Language Models in Social Computing Research},
year = {2023},
isbn = {9798400701290},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584931.3606955},
doi = {10.1145/3584931.3606955},
abstract = {The emergence of Large Language Models (LLMs) has brought both excitement and concerns to social computing research. On the one hand, LLMs offer unprecedented capabilities in analyzing vast amounts of textual data and generating human-like responses, enabling researchers to delve into complex social phenomena. On the other hand, concerns are emerging regarding the validity, privacy, and ethics of the research when LLMs are involved. This SIG aims at offering an open space for social computing researchers who are interested in understanding the impacts of LLMs to discuss their current practices, perspectives, challenges when engaging with LLMs in their everyday work and collectively shaping the emerging norms of using LLMs in social computing research.},
booktitle = {Companion Publication of the 2023 Conference on Computer Supported Cooperative Work and Social Computing},
pages = {569–571},
numpages = {3},
keywords = {Ethics, Large Language Models, Privacy, Research Methods, Social Computing, Validity},
location = {Minneapolis, MN, USA},
series = {CSCW '23 Companion}
}

@proceedings{10.1145/3585059,
title = {SIGITE '23: Proceedings of the 24th Annual Conference on Information Technology Education},
year = {2023},
isbn = {9798400701306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Marietta, GA, USA}
}

@proceedings{10.1145/3585088,
title = {IDC '23: Proceedings of the 22nd Annual ACM Interaction Design and Children Conference},
year = {2023},
isbn = {9798400701313},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Chicago, IL, USA}
}

@article{10.1145/3585385,
author = {Cin\`{a}, Antonio Emanuele and Grosse, Kathrin and Demontis, Ambra and Vascon, Sebastiano and Zellinger, Werner and Moser, Bernhard A. and Oprea, Alina and Biggio, Battista and Pelillo, Marcello and Roli, Fabio},
title = {Wild Patterns Reloaded: A Survey of Machine Learning Security against Training Data Poisoning},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {13s},
issn = {0360-0300},
url = {https://doi.org/10.1145/3585385},
doi = {10.1145/3585385},
abstract = {The success of machine learning is fueled by the increasing availability of computing power and large training datasets. The training data is used to learn new models or update existing ones, assuming that it is sufficiently representative of the data that will be encountered at test time. This assumption is challenged by the threat of poisoning, an attack that manipulates the training data to compromise the model’s performance at test time. Although poisoning has been acknowledged as a relevant threat in industry applications, and a variety of different attacks and defenses have been proposed so far, a complete systematization and critical review of the field is still missing. In this survey, we provide a comprehensive systematization of poisoning attacks and defenses in machine learning, reviewing more than 100 papers published in the field in the past 15 years. We start by categorizing the current threat models and attacks and then organize existing defenses accordingly. While we focus mostly on computer-vision applications, we argue that our systematization also encompasses state-of-the-art attacks and defenses for other data modalities. Finally, we discuss existing resources for research in poisoning and shed light on the current limitations and open research questions in this research field.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {294},
numpages = {39},
keywords = {Poisoning attacks, backdoor attacks, machine learning, computer vision, computer security}
}

@proceedings{10.1145/3586182,
title = {UIST '23 Adjunct: Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
year = {2023},
isbn = {9798400700965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {San Francisco, CA, USA}
}

@inproceedings{10.1145/3586182.3615825,
author = {Aveni, Timothy J. and Fox, Armando and Hartmann, Bj\"{o}rn},
title = {Bringing Context-Aware Completion Suggestions to Arbitrary Text Entry Interfaces},
year = {2023},
isbn = {9798400700965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586182.3615825},
doi = {10.1145/3586182.3615825},
abstract = {Large language models (LLMs) can predict “obvious” next steps that users will take in text entry fields, especially the tedious components of tasks like software engineering or email composition. These models are not only useful in large, unbroken text fields, however. We present OmniFill, a browser extension that detects text entry fields and offers “autofill”-style suggestions based on context from the browsing session. The system constructs an LLM prompt that includes three main components: (a) a description of the active tab’s text fields and their current values, (b) information from the user’s recent web browsing context, and (c) a history, if available, of the user’s prior submissions to the web form (alongside those submissions’ associated browsing context). Suggestions from the LLM’s response are offered to the user to be automatically typed into each corresponding text field. We offer a motivating example of a time-saving interaction and discuss the broader utility of interface-agnostic LLM integrations.},
booktitle = {Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {77},
numpages = {3},
keywords = {Web accessibility, intelligent user interfaces, large language models},
location = {San Francisco, CA, USA},
series = {UIST '23 Adjunct}
}

@proceedings{10.1145/3586183,
title = {UIST '23: Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {San Francisco, CA, USA}
}

@inproceedings{10.1145/3586183.3606725,
author = {Brade, Stephen and Wang, Bryan and Sousa, Mauricio and Oore, Sageev and Grossman, Tovi},
title = {Promptify: Text-to-Image Generation through Interactive Prompt Exploration with Large Language Models},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606725},
doi = {10.1145/3586183.3606725},
abstract = {Text-to-image generative models have demonstrated remarkable capabilities in generating high-quality images based on textual prompts. However, crafting prompts that accurately capture the user’s creative intent remains challenging. It often involves laborious trial-and-error procedures to ensure that the model interprets the prompts in alignment with the user’s intention. To address these challenges, we present Promptify, an interactive system that supports prompt exploration and refinement for text-to-image generative models. Promptify utilizes a suggestion engine powered by large language models to help users quickly explore and craft diverse prompts. Our interface allows users to organize the generated images flexibly, and based on their preferences, Promptify suggests potential changes to the original prompt. This feedback loop enables users to iteratively refine their prompts and enhance desired features while avoiding unwanted ones. Our user study shows that Promptify effectively facilitates the text-to-image workflow, allowing users to create visually appealing images on their first attempt while requiring significantly less cognitive load than a widely-used baseline tool.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {96},
numpages = {14},
keywords = {Large Language Models, Prompt Engineering, Text-to-Image},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

@inproceedings{10.1145/3586183.3606735,
author = {Huh, Mina and Peng, Yi-Hao and Pavel, Amy},
title = {GenAssist: Making Image Generation Accessible},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606735},
doi = {10.1145/3586183.3606735},
abstract = {Blind and low vision (BLV) creators use images to communicate with sighted audiences. However, creating or retrieving images is challenging for BLV creators as it is difficult to use authoring tools or assess image search results. Thus, creators limit the types of images they create or recruit sighted collaborators. While text-to-image generation models let creators generate high-fidelity images based on a text description (i.e. prompt), it is difficult to assess the content and quality of generated images. We present GenAssist, a system to make text-to-image generation accessible. Using our interface, creators can verify whether generated image candidates followed the prompt, access additional details in the image not specified in the prompt, and skim a summary of similarities and differences between image candidates. To power the interface, GenAssist uses a large language model to generate visual questions, vision-language models to extract answers, and a large language model to summarize the results. Our study with 12 BLV creators demonstrated that GenAssist enables and simplifies the process of image selection and generation, making visual authoring more accessible to all.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {38},
numpages = {17},
keywords = {Accessibility, Creativity Support Tools, Generative AI, Image Generation},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

@inproceedings{10.1145/3586183.3606741,
author = {Chen, Weihao and Yu, Chun and Wang, Huadong and Wang, Zheng and Yang, Lichen and Wang, Yukun and Shi, Weinan and Shi, Yuanchun},
title = {From Gap to Synergy: Enhancing Contextual Understanding through Human-Machine Collaboration in Personalized Systems},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606741},
doi = {10.1145/3586183.3606741},
abstract = {This paper presents LangAware, a collaborative approach for constructing personalized context for context-aware applications. The need for personalization arises due to significant variations in context between individuals based on scenarios, devices, and preferences. However, there is often a notable gap between humans and machines in the understanding of how contexts are constructed, as observed in trigger-action programming studies such as IFTTT. LangAware enables end-users to participate in establishing contextual rules in-situ using natural language. The system leverages large language models (LLMs) to semantically connect low-level sensor detectors to high-level contexts and provide understandable natural language feedback for effective user involvement. We conducted a user study with 16 participants in real-life settings, which revealed an average success rate of 87.50\% for defining contextual rules in a variety of 12 campus scenarios, typically accomplished within just two modifications. Furthermore, users reported a better understanding of the machine’s capabilities by interacting with LangAware.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {110},
numpages = {15},
keywords = {Context-Aware Systems, End User Context Construction, Large Language Models, Personalization},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

@inproceedings{10.1145/3586183.3606756,
author = {Suh, Sangho and Min, Bryan and Palani, Srishti and Xia, Haijun},
title = {Sensecape: Enabling Multilevel Exploration and Sensemaking with Large Language Models},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606756},
doi = {10.1145/3586183.3606756},
abstract = {People are increasingly turning to large language models (LLMs) for complex information tasks like academic research or planning a move to another city. However, while they often require working in a nonlinear manner — e.g., to arrange information spatially to organize and make sense of it, current interfaces for interacting with LLMs are generally linear to support conversational interaction. To address this limitation and explore how we can support LLM-powered exploration and sensemaking, we developed Sensecape, an interactive system designed to support complex information tasks with an LLM by enabling users to (1) manage the complexity of information through multilevel abstraction and (2) switch seamlessly between foraging and sensemaking. Our within-subject user study reveals that Sensecape empowers users to explore more topics and structure their knowledge hierarchically, thanks to the externalization of levels of abstraction. We contribute implications for LLM-based workflows and interfaces for information tasks.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {1},
numpages = {18},
keywords = {abstraction hierarchy, human-AI interaction, information seeking, large language models, levels of abstraction, multilevel exploration, sensemaking, systems thinking},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

@inproceedings{10.1145/3586183.3606759,
author = {Kang, Hyeonsu B and Wu, Tongshuang and Chang, Joseph Chee and Kittur, Aniket},
title = {Synergi: A Mixed-Initiative System for Scholarly Synthesis and Sensemaking},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606759},
doi = {10.1145/3586183.3606759},
abstract = {Efficiently reviewing scholarly literature and synthesizing prior art are crucial for scientific progress. Yet, the growing scale of publications and the burden of knowledge make synthesis of research threads more challenging than ever.While significant research has been devoted to helping scholars interact with individual papers, building research threads scattered across multiple papers remains a challenge.Most top-down synthesis (and LLMs) make it difficult to personalize and iterate on the output, while bottom-up synthesis is costly in time and effort.Here, we explore a new design space of mixed-initiative workflows.In doing so we develop a novel computational pipeline, Synergi, that ties together user input of relevant seed threads with citation graphs and LLMs, to expand and structure them, respectively.Synergiallows scholars to start with an entire threads-and-subthreads structure generated from papers relevant to their interests, and to iterate and customize on it as they wish. In our evaluation, we find that Synergi helps scholars efficiently make sense of relevant threads, broaden their perspectives, and increases their curiosity. We discuss future design implications for thread-based, mixed-initiative scholarly synthesis support tools.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {43},
numpages = {19},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

@inproceedings{10.1145/3586183.3606773,
author = {Xia, Haijun and Wang, Tony and Gunturu, Aditya and Jiang, Peiling and Duan, William and Yao, Xiaoshuo},
title = {CrossTalk: Intelligent Substrates for Language-Oriented Interaction in Video-Based Communication and Collaboration},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606773},
doi = {10.1145/3586183.3606773},
abstract = {Despite the advances and ubiquity of digital communication media such as videoconferencing and virtual reality, they remain oblivious to the rich intentions expressed by users. Beyond transmitting audio, videos, and messages, we envision digital communication media as proactive facilitators that can provide unobtrusive assistance to enhance communication and collaboration. Informed by the results of a formative study, we propose three key design concepts to explore the systematic integration of intelligence into communication and collaboration, including the panel substrate, language-based intent recognition, and lightweight interaction techniques. We developed CrossTalk, a videoconferencing system that instantiates these concepts, which was found to enable a more fluid and flexible communication and collaboration experience.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {60},
numpages = {16},
keywords = {Context-aware Computing, Language-oriented Interaction, Natural Language Interface, Videoconferencing},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

@inproceedings{10.1145/3586183.3606800,
author = {Zhang, Zheng and Gao, Jie and Dhaliwal, Ranjodh Singh and Li, Toby Jia-Jun},
title = {VISAR: A Human-AI Argumentative Writing Assistant with Visual Programming and Rapid Draft Prototyping},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606800},
doi = {10.1145/3586183.3606800},
abstract = {In argumentative writing, writers must brainstorm hierarchical writing goals, ensure the persuasiveness of their arguments, and revise and organize their plans through drafting. Recent advances in large language models (LLMs) have made interactive text generation through a chat interface (e.g., ChatGPT) possible. However, this approach often neglects implicit writing context and user intent, lacks support for user control and autonomy, and provides limited assistance for sensemaking and revising writing plans. To address these challenges, we introduce VISAR, an AI-enabled writing assistant system designed to help writers brainstorm and revise hierarchical goals within their writing context, organize argument structures through synchronized text editing and visual programming, and enhance persuasiveness with argumentation spark recommendations. VISAR allows users to explore, experiment with, and validate their writing plans using automatic draft prototyping. A controlled lab study confirmed the usability and effectiveness of VISAR in facilitating the argumentative writing planning process.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {5},
numpages = {30},
keywords = {creativity support, human-AI collaboration, writing support},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

@inproceedings{10.1145/3586183.3606822,
author = {Pu, Kevin and Yang, Jim and Yuan, Angel and Ma, Minyi and Dong, Rui and Wang, Xinyu and Chen, Yan and Grossman, Tovi},
title = {DiLogics: Creating Web Automation Programs with Diverse Logics},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606822},
doi = {10.1145/3586183.3606822},
abstract = {Knowledge workers frequently encounter repetitive web data entry tasks, like updating records or placing orders. Web automation increases productivity, but translating tasks to web actions accurately and extending to new specifications is challenging. Existing tools can automate tasks that perform the same logical trace of UI actions (e.g., input text in each field in order), but do not support tasks requiring different executions based on varied input conditions. We present DiLogics, a programming-by-demonstration system that utilizes NLP to assist users in creating web automation programs that handle diverse specifications. DiLogics first semantically segments input data to structured task steps. By recording user demonstrations for each step, DiLogics generalizes the web macros to novel but semantically similar task requirements. Our evaluation showed that non-experts can effectively use DiLogics to create automation programs that fulfill diverse input instructions. DiLogics provides an efficient, intuitive, and expressive method for developing web automation programs satisfying diverse specifications.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {74},
numpages = {15},
keywords = {PBD, Web automation, neurosymbolic programming},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

@inproceedings{10.1145/3586183.3606827,
author = {Chulpongsatorn, Neil and Lunding, Mille Skovhus and Soni, Nishan and Suzuki, Ryo},
title = {Augmented Math: Authoring AR-Based Explorable Explanations by Augmenting Static Math Textbooks},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606827},
doi = {10.1145/3586183.3606827},
abstract = {We introduce Augmented Math, a machine learning-based approach to authoring AR explorable explanations by augmenting static math textbooks without programming. To augment a static document, our system first extracts mathematical formulas and figures from a given document using optical character recognition (OCR) and computer vision. By binding and manipulating these extracted contents, the user can see the interactive animation overlaid onto the document through mobile AR interfaces. This empowers non-technical users, such as teachers or students, to transform existing math textbooks and handouts into on-demand and personalized explorable explanations. To design our system, we first analyzed existing explorable math explanations to identify common design strategies. Based on the findings, we developed a set of augmentation techniques that can be automatically generated based on the extracted content, which are 1) dynamic values, 2) interactive figures, 3) relationship highlights, 4) concrete examples, and 5) step-by-step hints. To evaluate our system, we conduct two user studies: preliminary user testing and expert interviews. The study results confirm that our system allows more engaging experiences for learning math concepts.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {92},
numpages = {16},
keywords = {Augmented Reality, Augmented Textbook, Authoring Interfaces, Explorable Explanations, Interactive Paper},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

@inproceedings{10.1145/3586183.3606831,
author = {Li, Jingyi and Rawn, Eric and Ritchie, Jacob and Tran O'Leary, Jasper and Follmer, Sean},
title = {Beyond the Artifact: Power as a Lens for Creativity Support Tools},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606831},
doi = {10.1145/3586183.3606831},
abstract = {Researchers who build creativity support tools (CSTs) define abstractions and software representations that align with user needs to give users the power to accomplish tasks. However, these specifications also structure and limit how users can and should think, act, and express themselves. Thus, tool designers unavoidably exert power over their users by enacting a “normative ground” through their tools. Drawing on interviews with 11 creative practitioners, tool designers, and CST researchers, we offer a definition of empowerment in the context of creative practice, build a preliminary theory of how power relationships manifest in CSTs, and explain why researchers have had trouble addressing these concepts in the past. We re-examine CST literature through a lens of power and argue that mitigating power imbalances at the level of technical design requires enabling users in both vertical movement along levels of abstraction as well as horizontal movement between tools through interoperable representations. A lens of power is one possible orientation that lets us recognize the methodological shifts required towards building “artistic support tools.”},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {47},
numpages = {15},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

@inproceedings{10.1145/3587102.3588792,
author = {Savelka, Jaromir and Agarwal, Arav and Bogart, Christopher and Song, Yifan and Sakr, Majd},
title = {Can Generative Pre-trained Transformers (GPT) Pass Assessments in Higher Education Programming Courses?},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588792},
doi = {10.1145/3587102.3588792},
abstract = {We evaluated the capability of generative pre-trained transformers (GPT), to pass assessments in introductory and intermediate Python programming courses at the postsecondary level. Discussions of potential uses (e.g., exercise generation, code explanation) and misuses (e.g., cheating) of this emerging technology in programming education have intensified, but to date there has not been a rigorous analysis of the models' capabilities in the realistic context of a full-fledged programming course with diverse set of assessment instruments. We evaluated GPT on three Python courses that employ assessments ranging from simple multiple-choice questions (no code involved) to complex programming projects with code bases distributed into multiple files (599 exercises overall). Further, we studied if and how successfully GPT models leverage feedback provided by an auto-grader. We found that the current models are not capable of passing the full spectrum of assessments typically involved in a Python programming course (&lt;70\% on even entry-level modules). Yet, it is clear that a straightforward application of these easily accessible models could enable a learner to obtain a non-trivial portion of the overall available score (&gt;55\%) in introductory and intermediate courses alike. While the models exhibit remarkable capabilities, including correcting solutions based on auto-grader's feedback, some limitations exist (e.g., poor handling of exercises requiring complex chains of reasoning steps). These findings can be leveraged by instructors wishing to adapt their assessments so that GPT becomes a valuable assistant for a learner as opposed to an end-to-end solution.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {117–123},
numpages = {7},
keywords = {AI code generation, GPT, GitHub copilot, alphacode, codex, generative pre-trained transformers, introductory and intermediate programming, programming knowledge assessment, python course},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3587102.3588814,
author = {Cipriano, Bruno Pereira and Alves, Pedro},
title = {GPT-3 vs Object Oriented Programming Assignments: An Experience Report},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588814},
doi = {10.1145/3587102.3588814},
abstract = {Recent studies show that AI-driven code generation tools, such as Large Language Models, are able to solve most of the problems usually presented in introductory programming classes. However, it is still unknown how they cope with Object Oriented Programming assignments, where the students are asked to design and implement several interrelated classes (either by composition or inheritance) that follow a set of best-practices. Since the majority of the exercises in these tools' training dataset are written in English, it is also unclear how well they function with exercises published in other languages.In this paper, we report our experience using GPT-3 to solve 6 real-world tasks used in an Object Oriented Programming course at a Portuguese University and written in Portuguese. Our observations, based on an objective evaluation of the code, performed by an open-source Automatic Assessment Tool, show that GPT-3 is able to interpret and handle direct functional requirements, however it tends not to give the best solution in terms of object oriented design. We perform a qualitative analysis of GPT-3's output, and gather a set of recommendations for computer science educators, since we expect students to use and abuse this tool in their academic work.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {61–67},
numpages = {7},
keywords = {GPT-3, large language models, object oriented programming, programming assignments, teaching},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3587102.3588829,
author = {Russell, Se\'{a}n and Caton, Simon and Becker, Brett A.},
title = {Online Programming Exams - An Experience Report},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588829},
doi = {10.1145/3587102.3588829},
abstract = {When seeking to maximise the authenticity of assessment in programming courses it makes sense to provide students with practical programming problems to solve in an environment that is close to real software development practice, i.e., online, open book, and using their typical development environment. This creates an assessment environment that should afford students sufficient opportunities to evidence what they have learned, but also creates practical challenges in terms of academic integrity, flexibility in the automated grading process, and assumptions surrounding how the student may attempt to solve the problems both in terms of correct and incorrect solutions. In this experience report, we outline two independently observed cohorts of students sitting the same Java programming exam, with different weights, over three years. This is undertaken as a reflective exercise in order to derive a series of recommendations and retrospectively obvious pitfalls to act as guidance for educators considering online programming exams for large (i.e. n &gt; 150) introductory programming courses. After discussing our assessment methodology, we provide 4 high-level observations and centre a set of recommendations around these to aid practitioners in their assessment design.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {436–442},
numpages = {7},
keywords = {authentic assessment, plagiarism, programming, video},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@proceedings{10.1145/3587281,
title = {W4A '23: Proceedings of the 20th International Web for All Conference},
year = {2023},
isbn = {9798400707483},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Austin, TX, USA}
}

@inproceedings{10.1145/3587281.3587296,
author = {Stangl, Abigale and Sadjo, Emma and Emami-Naeini, Pardis and Wang, Yang and Gurari, Danna and Findlater, Leah},
title = {“Dump it, Destroy it, Send it to Data Heaven”: Blind People’s Expectations for Visual Privacy in Visual Assistance Technologies},
year = {2023},
isbn = {9798400707483},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587281.3587296},
doi = {10.1145/3587281.3587296},
abstract = {Visual assistance technologies provide people who are blind with access to information about their visual surroundings by digitally connecting them to remote humans or artificial intelligence systems that describe visual content such as objects, people, scenes, and text observed in their live image/video feeds. Prior work has revealed that users have concerns about how such technologies handle private visual content captured in their image/video feeds. Yet, it remains unclear how users want technologies to manage such private content. To fill this gap, we interviewed 16 totally blind individuals to learn about their expectations for visual privacy when using visual assistance technologies. Our findings reveal three overarching user-centered expectations associated with visual privacy-preservation in this domain, as well as the broader ethical challenges involved with developing AI-based privacy-preserving visual assistance technologies.},
booktitle = {Proceedings of the 20th International Web for All Conference},
pages = {134–147},
numpages = {14},
location = {Austin, TX, USA},
series = {W4A '23}
}

@proceedings{10.1145/3587421,
title = {SIGGRAPH '23: ACM SIGGRAPH 2023 Talks},
year = {2023},
isbn = {9798400701436},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Los Angeles, CA, USA}
}

@proceedings{10.1145/3587716,
title = {ICMLC '23: Proceedings of the 2023 15th International Conference on Machine Learning and Computing},
year = {2023},
isbn = {9781450398411},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Zhuhai, China}
}

@inproceedings{10.1145/3587716.3587741,
author = {Chen, Xi and Tan, Daniel Stanley and Gupta, Prakash and Bromuri, Stefano},
title = {Pair-wise selective classification with dynamic sampling for shipment importer prediction},
year = {2023},
isbn = {9781450398411},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587716.3587741},
doi = {10.1145/3587716.3587741},
abstract = {Whenever a shipped package crosses the border, logistic companies have to declare importer information for the clearance process. This information is not always provided by the customer, causing delays and additional expenses. Fortunately, importer information can often be inferred from historical shipments. The current technical standard, even in big companies, is to use a feature-weighted nearest neighbor approach based on domain knowledge. Nearest neighbors assume that each sample point is represented independently and is fixed in some high dimensional space. This makes it difficult to integrate higher-order pair-wise relationships such as transaction frequency from shipper to receiver transaction, because the features are now changing dependent on the pairs. This would require a complex ad-hoc feature engineering and metric learning to capture pairwise relationships properly with nearest neighbors. In this paper, we propose a framework for importer prediction based on a pair-wise classification approach that allows us to capture higher order pair-wise relationships. We also incorporate an auxiliary neural network that can reliably reject shipments that our model could not predict well such as shipments with new importers that are not in the historical data. This allows us to pass the difficult cases to a human agent instead of naively making an incorrect prediction. Our proposed pair-wise solution outperforms the industry standard by a significant margin of precision across a wide range of recall values.},
booktitle = {Proceedings of the 2023 15th International Conference on Machine Learning and Computing},
pages = {152–157},
numpages = {6},
keywords = {Dynamic sampling, Ranking, Selective classification},
location = {Zhuhai, China},
series = {ICMLC '23}
}

@proceedings{10.1145/3587819,
title = {MMSys '23: Proceedings of the 14th ACM Multimedia Systems Conference},
year = {2023},
isbn = {9798400701481},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Vancouver, BC, Canada}
}

@proceedings{10.1145/3587828,
title = {ICSCA '23: Proceedings of the 2023 12th International Conference on Software and Computer Applications},
year = {2023},
isbn = {9781450398589},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Kuantan, Malaysia}
}

@proceedings{10.1145/3588015,
title = {ETRA '23: Proceedings of the 2023 Symposium on Eye Tracking Research and Applications},
year = {2023},
isbn = {9798400701504},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tubingen, Germany}
}

@proceedings{10.1145/3588028,
title = {SIGGRAPH '23: ACM SIGGRAPH 2023 Posters},
year = {2023},
isbn = {9798400701528},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Los Angeles, CA, USA}
}

@proceedings{10.1145/3588155,
title = {APIT '23: Proceedings of the 2023 5th Asia Pacific Information Technology Conference},
year = {2023},
isbn = {9781450399500},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Ho Chi Minh City, Vietnam}
}

@proceedings{10.1145/3588243,
title = {IC4E '23: Proceedings of the 2023 14th International Conference on E-Education, E-Business, E-Management and E-Learning},
year = {2023},
isbn = {9798400700651},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Shenzhen, China}
}

@proceedings{10.1145/3588340,
title = {ICBICC '22: Proceedings of the 2022 International Conference on Big Data, IoT, and Cloud Computing},
year = {2022},
isbn = {9781450399548},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Chengdu, China}
}

@proceedings{10.1145/3588432,
title = {SIGGRAPH '23: ACM SIGGRAPH 2023 Conference Proceedings},
year = {2023},
isbn = {9798400701597},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Los Angeles, CA, USA}
}

@inproceedings{10.1145/3588432.3591509,
author = {Wang, Kaisiyuan and Zhou, Hang and Wu, Qianyi and Tang, Jiaxiang and Xu, Zhiliang and Liang, Borong and Hu, Tianshu and Ding, Errui and Liu, Jingtuo and Liu, Ziwei and Wang, Jingdong},
title = {Efficient Video Portrait Reenactment via Grid-based Codebook},
year = {2023},
isbn = {9798400701597},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3588432.3591509},
doi = {10.1145/3588432.3591509},
abstract = {While progress has been made in the field of portrait reenactment, the problem of how to efficiently produce high-fidelity and accurate videos remains. Recent studies build direct mappings between driving signals and their predictions, leading to failure cases when synthesizing background textures and detailed local motions. In this paper, we propose the Video Portrait via Grid-based Codebook (VPGC) framework, which achieves efficient and high-fidelity portrait modeling. Our key insight is to query driving signals in a position-aware textural codebook with an explicit grid structure. The grid-based codebook stores delicate textural information locally according to our observations on video portraits, which can be learned efficiently and precisely. We subsequently design a Prior-Guided Driving Module to predict reliable features from the driving signals, which can be later decoded back to high-quality video portraits by querying the codebook. Comprehensive experiments are conducted to validate the effectiveness of our approach.},
booktitle = {ACM SIGGRAPH 2023 Conference Proceedings},
articleno = {66},
numpages = {9},
keywords = {Facial Animation, Video Synthesis},
location = {Los Angeles, CA, USA},
series = {SIGGRAPH '23}
}

@inproceedings{10.1145/3588432.3591568,
author = {Lin, Anran and Zhao, Nanxuan and Ning, Shuliang and Qiu, Yuda and Wang, Baoyuan and Han, Xiaoguang},
title = {FashionTex: Controllable Virtual Try-on with Text and Texture},
year = {2023},
isbn = {9798400701597},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3588432.3591568},
doi = {10.1145/3588432.3591568},
abstract = {Virtual try-on attracts increasing research attention as a promising way for enhancing the user experience for online cloth shopping. Though existing methods can generate impressive results, users need to provide a well-designed reference image containing the target fashion clothes that often do not exist. To support user-friendly fashion customization in full-body portraits, we propose a multi-modal interactive setting by combining the advantages of both text and texture for multi-level fashion manipulation. With the carefully designed fashion editing module and loss functions, FashionTex framework can semantically control cloth types and local texture patterns without annotated pairwise training data. We further introduce an ID recovery module to maintain the identity of input portrait. Extensive experiments have demonstrated the effectiveness of our proposed pipeline. Code for this paper are at https://github.com/picksh/FashionTex.},
booktitle = {ACM SIGGRAPH 2023 Conference Proceedings},
articleno = {56},
numpages = {9},
keywords = {controllable fashion generation, image manipulation, multi-modal learning},
location = {Los Angeles, CA, USA},
series = {SIGGRAPH '23}
}

@proceedings{10.1145/3588444,
title = {MHV '23: Proceedings of the 2nd Mile-High Video Conference},
year = {2023},
isbn = {9798400701603},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Denver, CO, USA}
}

@article{10.1145/3588702,
author = {Ping, Haoyue and Stoyanovich, Julia},
title = {Most Expected Winner: An Interpretation of Winners over Uncertain Voter Preferences},
year = {2023},
issue_date = {May 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {1},
url = {https://doi.org/10.1145/3588702},
doi = {10.1145/3588702},
abstract = {It remains an open question how to determine the winner of an election when voter preferences are incomplete or uncertain. One option is to assume some probability space over the voting profile and select the Most Probable Winner (MPW) -- the candidate or candidates with the best chance of winning. In this paper, we propose an alternative winner interpretation, selecting the Most Expected Winner (MEW) according to the expected performance of the candidates.We separate the uncertainty in voter preferences into the generation step and the observation step, which gives rise to a unified voting profile combining both incomplete and probabilistic voting profiles. We use this framework to establish the theoretical hardness of MEW over incomplete voter preferences, and then identify a collection of tractable cases for a variety of voting profiles, including those based on the popular Repeated Insertion Model (RIM) and its special case, the Mallows model. We develop solvers customized for various voter preference types to quantify the candidate performance for the individual voters, and propose a pruning strategy that optimizes computation. The performance of the proposed solvers and pruning strategy is evaluated extensively on real and synthetic benchmarks, showing that our methods are practical.},
journal = {Proc. ACM Manag. Data},
month = may,
articleno = {22},
numpages = {25},
keywords = {computational social choice, positional scoring rules, uncertain preferences, voting and elections}
}

@article{10.1145/3588712,
author = {Wu, Renzhi and Bendeck, Alexander and Chu, Xu and He, Yeye},
title = {Ground Truth Inference for Weakly Supervised Entity Matching},
year = {2023},
issue_date = {May 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {1},
url = {https://doi.org/10.1145/3588712},
doi = {10.1145/3588712},
abstract = {Entity matching (EM) refers to the problem of identifying pairs of data records in one or more relational tables that refer to the same entity in the real world. Supervised machine learning (ML) models currently achieve state-of-the-art matching performance; however, they require a large number of labeled examples, which are often expensive or infeasible to obtain. This has inspired us to approach data labeling for EM using weak supervision. In particular, we use the labeling function abstraction popularized by Snorkel, where each labeling function (LF) is a user-provided program that can generate many noisy match/non-match labels quickly and cheaply. Given a set of user-written LFs, the quality of data labeling depends on a labeling model to accurately infer the ground-truth labels. In this work, we first propose a simple but powerful labeling model for general weak supervision tasks. Then, we tailor the labeling model specifically to the task of entity matching by considering the EM-specific transitivity property.The general form of our labeling model is simple while substantially outperforming the best existing method across ten general weak supervision datasets. To tailor the labeling model for EM, we formulate an approach to ensure that the final predictions of the labeling model satisfy the transitivity property required in EM, utilizing an exact solution where possible and an ML-based approximation in remaining cases. On two single-table and nine two-table real-world EM datasets, we show that our labeling model results in a 9\% higher F1 score on average than the best existing method. We also show that a deep learning EM end model (DeepMatcher) trained on labels generated from our weak supervision approach is comparable to an end model trained using tens of thousands of ground-truth labels, demonstrating that our approach can significantly reduce the labeling efforts required in EM.},
journal = {Proc. ACM Manag. Data},
month = may,
articleno = {32},
numpages = {28},
keywords = {entity matching, labeling model, transitivity, weak supervision}
}

@article{10.1145/3588713,
author = {Kurmanji, Meghdad and Triantafillou, Peter},
title = {Detect, Distill and Update: Learned DB Systems Facing Out of Distribution Data},
year = {2023},
issue_date = {May 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {1},
url = {https://doi.org/10.1145/3588713},
doi = {10.1145/3588713},
abstract = {Machine Learning (ML) is changing DBs as many DB components are being replaced by ML models. One open problem in this setting is how to update such ML models in the presence of data updates. We start this investigation focusing on data insertions (dominating updates in analytical DBs). We study how to update neural network (NN) models when new data follows a different distribution (a.k.a. it is "out-of-distribution" -- OOD), rendering previously-trained NNs inaccurate. A requirement in our problem setting is that learned DB components should ensure high accuracy for tasks on old and new data (e.g., for approximate query processing (AQP), cardinality estimation (CE), synthetic data generation (DG), etc.).This paper proposes a novel updatability framework (DDUp). DDUp can provide updatability for different learned DB system components, even based on different NNs, without the high costs to retrain the NNs from scratch. DDUp entails two components: First, a novel, efficient, and principled statistical-testing approach to detect OOD data. Second, a novel model updating approach, grounded on the principles of transfer learning with knowledge distillation, to update learned models efficiently, while still ensuring high accuracy. We develop and showcase DDUp's applicability for three different learned DB components, AQP, CE, and DG, each employing a different type of NN. Detailed experimental evaluation using real and benchmark datasets for AQP, CE, and DG detail DDUp's performance advantages.},
journal = {Proc. ACM Manag. Data},
month = may,
articleno = {33},
numpages = {27},
keywords = {knowledge distillation, learned databases, out of distribution detection, transfer learning}
}

@proceedings{10.1145/3588967,
title = {EmpathiCH '23: Proceedings of the 2nd Empathy-Centric Design Workshop},
year = {2023},
isbn = {9798400707490},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hamburg, Germany}
}

@article{10.1145/3589287,
author = {Cai, Kuntai and Xiao, Xiaokui and Cormode, Graham},
title = {PrivLava: Synthesizing Relational Data with Foreign Keys under Differential Privacy},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {2},
url = {https://doi.org/10.1145/3589287},
doi = {10.1145/3589287},
abstract = {Answering database queries while preserving privacy is an important problem that has attracted considerable research attention in recent years. A canonical approach to this problem is to use synthetic data. That is, we replace the input database R with a synthetic database R* that preserves the characteristics of R, and use R* to answer queries. Existing solutions for relational data synthesis, however, either fail to provide strong privacy protection, or assume that R contains a single relation. In addition, it is challenging to extend the existing single-relation solutions to the case of multiple relations, because they are unable to model the complex correlations induced by the foreign keys. Therefore, multi-relational data synthesis with strong privacy guarantees is an open problem.In this paper, we address the above open problem by proposing PrivLava, the first solution for synthesizing relational data with foreign keys under differential privacy, a rigorous privacy framework widely adopted in both academia and industry. The key idea of PrivLava is to model the data distribution in R using graphical models, with latent variables included to capture the inter-relational correlations caused by foreign keys. We show that PrivLava supports arbitrary foreign key references that form a directed acyclic graph, and is able to tackle the common case when R contains a mixture of public and private relations. Extensive experiments on census data sets and the TPC-H benchmark demonstrate that PrivLava significantly outperforms its competitors in terms of the accuracy of aggregate queries processed on the synthetic data.},
journal = {Proc. ACM Manag. Data},
month = jun,
articleno = {142},
numpages = {25},
keywords = {data synthesis, differential privacy}
}

@proceedings{10.1145/3589462,
title = {IDEAS '23: Proceedings of the 27th International Database Engineered Applications Symposium},
year = {2023},
isbn = {9798400707445},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Heraklion, Crete, Greece}
}

@proceedings{10.1145/3589572,
title = {ICMVA '23: Proceedings of the 2023 6th International Conference on Machine Vision and Applications},
year = {2023},
isbn = {9781450399531},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Singapore, Singapore}
}

@proceedings{10.1145/3589737,
title = {ICONS '23: Proceedings of the 2023 International Conference on Neuromorphic Systems},
year = {2023},
isbn = {9798400701757},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Santa Fe, NM, USA}
}

@proceedings{10.1145/3589845,
title = {ICCDE '23: Proceedings of the 2023 9th International Conference on Computing and Data Engineering},
year = {2023},
isbn = {9781450398022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Haikou, China}
}

@proceedings{10.1145/3589883,
title = {ICMLT '23: Proceedings of the 2023 8th International Conference on Machine Learning Technologies},
year = {2023},
isbn = {9781450398329},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Stockholm, Sweden}
}

@proceedings{10.1145/3590003,
title = {CACML '23: Proceedings of the 2023 2nd Asia Conference on Algorithms, Computing and Machine Learning},
year = {2023},
isbn = {9781450399449},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Shanghai, China}
}

@proceedings{10.1145/3590777,
title = {EICC '23: Proceedings of the 2023 European Interdisciplinary Cybersecurity Conference},
year = {2023},
isbn = {9781450398299},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Stavanger, Norway}
}

@proceedings{10.1145/3590837,
title = {ICIMMI '22: Proceedings of the 4th International Conference on Information Management \&amp; Machine Intelligence},
year = {2022},
isbn = {9781450399937},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Jaipur, India}
}

@inproceedings{10.1145/3590837.3590863,
author = {Sharma, Shikha and Goyal, Dinesh},
title = {Making a long video short: A Systematic Review},
year = {2023},
isbn = {9781450399937},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3590837.3590863},
doi = {10.1145/3590837.3590863},
abstract = {As a consequence of the great expansion in technology excessive amount of digitized data is produced daily. Data could be in any form, either images, videos, or text. In this paper, our focus is on large videos generated by various online devices. As per the Cisco networking report, an individual requires 5 million per year to watch all uploaded videos on the internet till the year 2021. To handle such massive videos is tough. These videos require large memory to store, high computational speed, and require lots of time to process. But nowadays, no one has time to deal with such long videos without knowing the interestingness of the content. So here, we will discuss various tools, techniques, and frameworks proposed by researchers to make the long video short by identifying the most prominent features and objects in the entire video. We will discuss various video summarization techniques based on domains, datasets available in this direction, applications, and challenges. We categorized summarization techniques using deep learning, machine learning, and computer vision approaches.},
booktitle = {Proceedings of the 4th International Conference on Information Management \&amp; Machine Intelligence},
articleno = {26},
numpages = {11},
keywords = {Computer vision, DNN, Machine learning, Video summary},
location = {Jaipur, India},
series = {ICIMMI '22}
}

@proceedings{10.1145/3591106,
title = {ICMR '23: Proceedings of the 2023 ACM International Conference on Multimedia Retrieval},
year = {2023},
isbn = {9798400701788},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Thessaloniki, Greece}
}

@article{10.1145/3591130,
author = {Byrne, Sean Anthony and Maquiling, Virmarie and Reynolds, Adam Peter Frederick and Polonio, Luca and Castner, Nora and Kasneci, Enkelejda},
title = {Exploring the Effects of Scanpath Feature Engineering for Supervised Image Classification Models},
year = {2023},
issue_date = {May 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {ETRA},
url = {https://doi.org/10.1145/3591130},
doi = {10.1145/3591130},
abstract = {Image classification models are becoming a popular method of analysis for scanpath classification. To implement these models, gaze data must first be reconfigured into a 2D image. However, this step gets relatively little attention in the literature as focus is mostly placed on model configuration. As standard model architectures have become more accessible to the wider eye-tracking community, we highlight the importance of carefully choosing feature representations within scanpath images as they may heavily affect classification accuracy. To illustrate this point, we create thirteen sets of scanpath designs incorporating different eye-tracking feature representations from data recorded during a task-based viewing experiment. We evaluate each scanpath design by passing the sets of images through a standard pre-trained deep learning model as well as a SVM image classifier. Results from our primary experiment show an average accuracy improvement of 25 percentage points between the best-performing set and one baseline set.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = may,
articleno = {161},
numpages = {18},
keywords = {computer vision, eye movements and cognition, feature engineering, image processing, machine learning, scanpaths, signal processing, visual search behavior}
}

@proceedings{10.1145/3591156,
title = {IVSP '23: Proceedings of the 2023 5th International Conference on Image, Video and Signal Processing},
year = {2023},
isbn = {9781450398381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Singapore, Singapore}
}

@proceedings{10.1145/3591196,
title = {C&amp;C '23: Proceedings of the 15th Conference on Creativity and Cognition},
year = {2023},
isbn = {9798400701801},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Virtual Event, USA}
}

@inproceedings{10.1145/3591196.3593516,
author = {Ding, Zijian and Srinivasan, Arvind and Macneil, Stephen and Chan, Joel},
title = {Fluid Transformers and Creative Analogies: Exploring Large Language Models’ Capacity for Augmenting Cross-Domain Analogical Creativity},
year = {2023},
isbn = {9798400701801},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3591196.3593516},
doi = {10.1145/3591196.3593516},
abstract = {Cross-domain analogical reasoning is a core creative ability that can be challenging for humans. Recent work has shown some proofs-of-concept of Large language Models’ (LLMs) ability to generate cross-domain analogies. However, the reliability and potential usefulness of this capacity for augmenting human creative work has received little systematic exploration. In this paper, we systematically explore LLMs capacity to augment cross-domain analogical reasoning. Across three studies, we found: 1) LLM-generated cross-domain analogies were frequently judged as helpful in the context of a problem reformulation task (median 4 out of 5 helpfulness rating), and frequently (∼ 80\% of cases) led to observable changes in problem formulations, and 2) there was an upper bound of ∼ 25\% of outputs being rated as potentially harmful, with a majority due to potentially upsetting content, rather than biased or toxic content. These results demonstrate the potential utility — and risks — of LLMs for augmenting cross-domain analogical creativity.},
booktitle = {Proceedings of the 15th Conference on Creativity and Cognition},
pages = {489–505},
numpages = {17},
keywords = {Analogy, Creativity Support Tools, Large Language Models},
location = {Virtual Event, USA},
series = {C&amp;C '23}
}

@proceedings{10.1145/3591197,
title = {SecTL '23: Proceedings of the 2023 Secure and Trustworthy Deep Learning Systems Workshop},
year = {2023},
isbn = {9798400701818},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Melbourne, VIC, Australia}
}

@article{10.1145/3591274,
author = {Valizadeh, Mojtaba and Berger, Martin},
title = {Search-Based Regular Expression Inference on a GPU},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {PLDI},
url = {https://doi.org/10.1145/3591274},
doi = {10.1145/3591274},
abstract = {Regular expression inference (REI) is a supervised machine learning and program synthesis problem that takes a cost metric for regular expressions, and positive and negative examples of strings as input. It outputs a regular expression that is precise (i.e., accepts all positive and rejects all negative examples), and minimal w.r.t. to the cost metric. We present a novel algorithm for REI over arbitrary alphabets that is enumerative and trades off time for space. Our main algorithmic idea is to implement the search space of regular expressions succinctly as a contiguous matrix of bitvectors. Collectively, the bitvectors represent, as characteristic sequences, all sub-languages of the infix-closure of the union of positive and negative examples. Mathematically, this is a semiring of (a variant of) formal power series. Infix-closure enables bottom-up compositional construction of larger from smaller regular expressions using the operations of our semiring. This minimises data movement and data-dependent branching, hence maximises data-parallelism. In addition, the infix-closure remains unchanged during the search, hence search can be staged: first pre-compute various expensive operations, and then run the compute intensive search process. We provide two C++ implementations, one for general purpose CPUs and one for Nvidia GPUs (using CUDA). We benchmark both on Google Colab Pro: the GPU implementation is on average over 1000x faster than the CPU implementation on the hardest benchmarks.},
journal = {Proc. ACM Program. Lang.},
month = jun,
articleno = {160},
numpages = {23},
keywords = {GPU, Grammar inference, machine learning, program synthesis, regular expression inference}
}

@article{10.1145/3591280,
author = {Li, Ziyang and Huang, Jiani and Naik, Mayur},
title = {Scallop: A Language for Neurosymbolic Programming},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {PLDI},
url = {https://doi.org/10.1145/3591280},
doi = {10.1145/3591280},
abstract = {We present Scallop, a language which combines the benefits of deep learning and logical reasoning. Scallop enables users to write a wide range of neurosymbolic applications and train them in a data- and compute-efficient manner. It achieves these goals through three key features: 1) a flexible symbolic representation that is based on the relational data model; 2) a declarative logic programming language that is based on Datalog and supports recursion, aggregation, and negation; and 3) a framework for automatic and efficient differentiable reasoning that is based on the theory of provenance semirings. We evaluate Scallop on a suite of eight neurosymbolic applications from the literature. Our evaluation demonstrates that Scallop is capable of expressing algorithmic reasoning in diverse and challenging AI tasks, provides a succinct interface for machine learning programmers to integrate logical domain knowledge, and yields solutions that are comparable or superior to state-of-the-art models in terms of accuracy. Furthermore, Scallop's solutions outperform these models in aspects such as runtime and data efficiency, interpretability, and generalizability.},
journal = {Proc. ACM Program. Lang.},
month = jun,
articleno = {166},
numpages = {25},
keywords = {Differentiable reasoning, Neurosymbolic methods}
}

@article{10.1145/3591301,
author = {Yuviler, Tom and Drachsler-Cohen, Dana},
title = {One Pixel Adversarial Attacks via Sketched Programs},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {PLDI},
url = {https://doi.org/10.1145/3591301},
doi = {10.1145/3591301},
abstract = {Neural networks are successful in various tasks but are also susceptible to adversarial examples. An adversarial example is generated by adding a small perturbation to a correctly-classified input with the goal of causing a network classifier to misclassify. In one pixel attacks, an attacker aims to fool an image classifier by modifying a single pixel. This setting is challenging for two reasons: the perturbation region is very small and the perturbation is not differentiable. To cope, one pixel attacks iteratively generate candidate adversarial examples and submit them to the network until finding a successful candidate. However, existing works require a very large number of queries, which is infeasible in many practical settings, where the attacker is limited to a few thousand queries to the network. We propose a novel approach for computing one pixel attacks. The key idea is to leverage program synthesis and identify an expressive program sketch that enables to compute adversarial examples using significantly fewer queries. We introduce OPPSLA, a synthesizer that, given a classifier and a training set, instantiates the sketch with customized conditions over the input’s pixels and the classifier’s output. OPPSLA employs a stochastic search, inspired by the Metropolis-Hastings algorithm, that synthesizes typed expressions enabling minimization of the number of queries to the classifier. We further show how to extend OPPSLA to compute few pixel attacks minimizing the number of perturbed pixels. We evaluate OPPSLA on several deep networks for CIFAR-10 and ImageNet. We show that OPPSLA obtains a state-of-the-art success rate, often with an order of magnitude fewer queries than existing attacks. We further show that OPPSLA’s programs are transferable to other classifiers, unlike existing one pixel attacks, which run from scratch on every classifier and input.},
journal = {Proc. ACM Program. Lang.},
month = jun,
articleno = {187},
numpages = {25},
keywords = {adversarial attack, computer vision, program synthesis}
}

@proceedings{10.1145/3591569,
title = {ICIIT '23: Proceedings of the 2023 8th International Conference on Intelligent Information Technology},
year = {2023},
isbn = {9781450399616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Da Nang, Vietnam}
}

@inproceedings{10.1145/3591569.3591591,
author = {Nguyen, Khang Hoang and Nguyen, Huynh Vu Nhu and Tran, Hoang Ngoc and Quach, Luyl-Da},
title = {Combining Autoencoder and Yolov6 Model for Classification and Disease Detection in Chickens},
year = {2023},
isbn = {9781450399616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3591569.3591591},
doi = {10.1145/3591569.3591591},
abstract = {Among the causes of reduced production is a chicken disease, which can negatively affect consumer health. With the advancement of computer vision technology and profound innovations in the field of research, it has become increasingly important to analyze disease images collected by sensors in chickens to analyze the possibility of infection conveniently and efficiently. Consequently, research proposes to identify lesions using the Autoencoder and Yolov6 model to classify and detect diseases in chicken flocks. This model is suitable for different chicken breeds from many countries and regions. This method helps improve and enhance image recognition accuracy by incorporating the data enhancement method in the data preprocessing step. The results show that the value of val/mAP (average accuracy) obtained by the method proposed in this paper is 99.15\%. Moreover, hit over 90\% on the test dataset. This method can be applied to the early detection of disease-carrying chickens in the captive population, ensuring a quality food source for humans.},
booktitle = {Proceedings of the 2023 8th International Conference on Intelligent Information Technology},
pages = {132–138},
numpages = {7},
keywords = {Yolov6, autoencoder, chickens disease, data enhancement},
location = {Da Nang, Vietnam},
series = {ICIIT '23}
}

@article{10.1145/3592111,
author = {Wang, Zhenwei and Zhao, Nanxuan and Hancke, Gerhard and Lau, Rynson W. H.},
title = {Language-based Photo Color Adjustment for Graphic Designs},
year = {2023},
issue_date = {August 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3592111},
doi = {10.1145/3592111},
abstract = {Adjusting the photo color to associate with some design elements is an essential way for a graphic design to effectively deliver its message and make it aesthetically pleasing. However, existing tools and previous works face a dilemma between the ease of use and level of expressiveness. To this end, we introduce an interactive language-based approach for photo recoloring, which provides an intuitive system that can assist both experts and novices on graphic design. Given a graphic design containing a photo that needs to be recolored, our model can predict the source colors and the target regions, and then recolor the target regions with the source colors based on the given language-based instruction. The multi-granularity of the instruction allows diverse user intentions. The proposed novel task faces several unique challenges, including: 1) color accuracy for recoloring with exactly the same color from the target design element as specified by the user; 2) multi-granularity instructions for parsing instructions correctly to generate a specific result or multiple plausible ones; and 3) locality for recoloring in semantically meaningful local regions to preserve original image semantics. To address these challenges, we propose a model called LangRecol with two main components: the language-based source color prediction module and the semantic-palette-based photo recoloring module. We also introduce an approach for generating a synthetic graphic design dataset with instructions to enable model training. We evaluate our model via extensive experiments and user studies. We also discuss several practical applications, showing the effectiveness and practicality of our approach. Please find the code and data at https://zhenwwang.github.io/langrecol.},
journal = {ACM Trans. Graph.},
month = jul,
articleno = {101},
numpages = {16},
keywords = {data-driven graphic design, photo recoloring, language-guided}
}

@article{10.1145/3592125,
author = {Jones, Benjamin and Noeckel, James and Kodnongbua, Milin and Baran, Ilya and Schulz, Adriana},
title = {B-rep Matching for Collaborating Across CAD Systems},
year = {2023},
issue_date = {August 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3592125},
doi = {10.1145/3592125},
abstract = {Large Computer-Aided Design (CAD) projects usually require collaboration across many different CAD systems as well as applications that interoperate with them for manufacturing, visualization, or simulation. A fundamental barrier to such collaborations is the ability to refer to parts of the geometry (such as a specific face) robustly under geometric and/or topological changes to the model. Persistent referencing schemes are a fundamental aspect of most CAD tools, but models that are shared across systems cannot generally make use of these internal referencing mechanisms, creating a challenge for collaboration. In this work, we address this issue by developing a novel learning-based algorithm that can automatically find correspondences between two CAD models using the standard representation used for sharing models across CAD systems: the Boundary-Representation (B-rep). Because our method works directly on B-reps it can be generalized across different CAD applications enabling collaboration.},
journal = {ACM Trans. Graph.},
month = jul,
articleno = {104},
numpages = {13},
keywords = {computer-aided design, parametric modeling, geometric correspondence, machine learning}
}

@proceedings{10.1145/3592307,
title = {ICECC '23: Proceedings of the 2023 6th International Conference on Electronics, Communications and Control Engineering},
year = {2023},
isbn = {9798400700002},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Fukuoka, Japan}
}

@article{10.1145/3592416,
author = {Jones, R. Kenny and Guerrero, Paul and Mitra, Niloy J. and Ritchie, Daniel},
title = {ShapeCoder: Discovering Abstractions for Visual Programs from Unstructured Primitives},
year = {2023},
issue_date = {August 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3592416},
doi = {10.1145/3592416},
abstract = {We introduce ShapeCoder, the first system capable of taking a dataset of shapes, represented with unstructured primitives, and jointly discovering (i) useful abstraction functions and (ii) programs that use these abstractions to explain the input shapes. The discovered abstractions capture common patterns (both structural and parametric) across a dataset, so that programs rewritten with these abstractions are more compact, and suppress spurious degrees of freedom. ShapeCoder improves upon previous abstraction discovery methods, finding better abstractions, for more complex inputs, under less stringent input assumptions. This is principally made possible by two methodological advancements: (a) a shape-to-program recognition network that learns to solve sub-problems and (b) the use of e-graphs, augmented with a conditional rewrite scheme, to determine when abstractions with complex parametric expressions can be applied, in a tractable manner. We evaluate ShapeCoder on multiple datasets of 3D shapes, where primitive decompositions are either parsed from manual annotations or produced by an unsupervised cuboid abstraction method. In all domains, ShapeCoder discovers a library of abstractions that captures high-level relationships, removes extraneous degrees of freedom, and achieves better dataset compression compared with alternative approaches. Finally, we investigate how programs rewritten to use discovered abstractions prove useful for downstream tasks.},
journal = {ACM Trans. Graph.},
month = jul,
articleno = {49},
numpages = {17},
keywords = {procedural modeling, visual programs, shape analysis, shape abstraction, library learning, e-graph}
}

@article{10.1145/3592436,
author = {Pandey, Karran and Chevalier, Fanny and Singh, Karan},
title = {Juxtaform: interactive visual summarization for exploratory shape design},
year = {2023},
issue_date = {August 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3592436},
doi = {10.1145/3592436},
abstract = {We present juxtaform, a novel approach to the interactive summarization of large shape collections for conceptual shape design. We conduct a formative study to ascertain design goals for creative shape exploration tools. Motivated by a mathematical formulation of these design goals, juxtaform integrates the exploration, analysis, selection, and refinement of large shape collections to support an interactive divergence-convergence shape design workflow. We exploit sparse, segmented sketch-stroke visual abstractions of shape and a novel visual summarization algorithm to balance the needs of shape understanding, in-situ shape juxtaposition, and visual clutter. Our evaluation is three-fold: we show that existing shape and stroke clustering algorithms do not address our design goals compared to our proposed shape corpus summarization algorithm; we compare juxtaform against a structured image gallery interface for various shape design and analysis tasks; and we present multiple compelling 2D/3D applications using juxtaform.},
journal = {ACM Trans. Graph.},
month = jul,
articleno = {52},
numpages = {14},
keywords = {shape exploration, shape design, sketch-based interaction}
}

@proceedings{10.1145/3592538,
title = {CPSS '23: Proceedings of the 9th ACM Cyber-Physical System Security Workshop},
year = {2023},
isbn = {9798400700903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Melbourne, VIC, Australia}
}

@proceedings{10.1145/3592571,
title = {ICDAR '23: Proceedings of the 4th ACM Workshop on Intelligent Cross-Data Analysis and Retrieval},
year = {2023},
isbn = {9798400701863},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Thessaloniki, Greece}
}

@proceedings{10.1145/3592572,
title = {MAD '23: Proceedings of the 2nd ACM International Workshop on Multimedia AI against Disinformation},
year = {2023},
isbn = {9798400701870},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Thessaloniki, Greece}
}

@proceedings{10.1145/3592573,
title = {LSC '23: Proceedings of the 6th Annual ACM Lifelog Search Challenge},
year = {2023},
isbn = {9798400701887},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Thessaloniki, Greece}
}

@proceedings{10.1145/3592686,
title = {BIC '23: Proceedings of the 2023 3rd International Conference on Bioinformatics and Intelligent Computing},
year = {2023},
isbn = {9798400700200},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Sanya, China}
}

@inproceedings{10.1145/3592686.3592748,
author = {Song, Sining and Liu, Demin and Wang, Haiyun and Zhao, Jianping and Zheng, Chunhou and Su, Yansen},
title = {scAEQN: A Batch Correction Joint Dimension Reduction Method on scRNA-seq Data},
year = {2023},
isbn = {9798400700200},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3592686.3592748},
doi = {10.1145/3592686.3592748},
abstract = {As single cell sequencing technique continues to advance, the size of scRNA-seq dataset has been enlarging, generating batch effects that affect downstream analysis, such as clustering analysis and differential expression gene (DEG) analysis. In this context, we present a novel batch integration joint dimensionality reduction method titled scAEQN. It adopts QuantNorm to calculate coefficient matrix and constructs an autoencoder to estimate the matrix of coefficient, ultimately obtaining a low-dimensional representation and reconstruction of the data. scAEQN is compared to different batch correction methods on a simulated dataset and six real single-cell RNA datasets. The results suggest that scAEQN is superior to batch correction methods under comparison in downstream analysis. scAEQN effectively eliminates batches and strongly reserves clustering pattern of cells, providing solid back-up for downstream analyses. scAEQN enhances the capability of clustering and selects more representative and stable DEGs in differential expression gene analysis. The source code and supplementary information of scAEQN are provided on website https://github.com/SiningSong/scAEQN.},
booktitle = {Proceedings of the 2023 3rd International Conference on Bioinformatics and Intelligent Computing},
pages = {344–350},
numpages = {7},
location = {Sanya, China},
series = {BIC '23}
}

@article{10.1145/3592788,
author = {Smith, Harrison Jesse and Zheng, Qingyuan and Li, Yifei and Jain, Somya and Hodgins, Jessica K.},
title = {A Method for Animating Children’s Drawings of the Human Figure},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {3},
issn = {0730-0301},
url = {https://doi.org/10.1145/3592788},
doi = {10.1145/3592788},
abstract = {Children’s drawings have a wonderful inventiveness, creativity, and variety to them. We present a system that automatically animates children’s drawings of the human figure, is robust to the variance inherent in these depictions, and is simple and straightforward enough for anyone to use. We demonstrate the value and broad appeal of our approach by building and releasing the Animated Drawings Demo, a freely available public website that has been used by millions of people around the world. We present a set of experiments exploring the amount of training data needed for fine-tuning, as well as a perceptual study demonstrating the appeal of a novel twisted perspective retargeting technique. Finally, we introduce the Amateur Drawings Dataset, a first-of-its-kind annotated dataset, collected via the public demo, containing over 178,000 amateur drawings and corresponding user-accepted character bounding boxes, segmentation masks, and joint location annotations.},
journal = {ACM Trans. Graph.},
month = jun,
articleno = {32},
numpages = {15},
keywords = {Skeletal animation, motion retargeting, motion stylization, 2D animation}
}

@proceedings{10.1145/3592813,
title = {SBSI '23: Proceedings of the XIX Brazilian Symposium on Information Systems},
year = {2023},
isbn = {9798400707599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Macei\'{o}, Brazil}
}

@proceedings{10.1145/3592979,
title = {PASC '23: Proceedings of the Platform for Advanced Scientific Computing Conference},
year = {2023},
isbn = {9798400701900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The PASC Conference series is an international platform for the exchange of competence in scientific computing and computational science, with a strong focus on methods, tools, algorithms, application challenges, and novel techniques and usage of high-performance computing.},
location = {Davos, Switzerland}
}

@proceedings{10.1145/3593013,
title = {FAccT '23: Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency},
year = {2023},
isbn = {9798400701924},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Chicago, IL, USA}
}

@inproceedings{10.1145/3593013.3594026,
author = {Wu, Stephen Tze-Inn and Demetriou, Daniel and Husain, Rudwan Ali},
title = {Honor Ethics: The Challenge of Globalizing Value Alignment in AI},
year = {2023},
isbn = {9798400701924},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593013.3594026},
doi = {10.1145/3593013.3594026},
abstract = {Some researchers have recognized that privileged communities dominate the discourse on AI Ethics, and other voices need to be heard. As such, we identify the current ethics milieu as arising from WEIRD (Western, Educated, Industrialized, Rich, Democratic) contexts, and aim to expand the discussion to non-WEIRD global communities, who are also stakeholders in global sociotechnical systems. We argue that accounting for honor, along with its values and related concepts, would better approximate a global ethical perspective. This complex concept already underlies some of the WEIRD discourse on AI ethics, but certain cultural forms of honor also bring overlooked issues and perspectives to light. We first describe honor according to recent empirical and philosophical scholarship. We then review “consensus” principles for AI ethics framed from an honor-based perspective, grounding comparisons and contrasts via example settings such as content moderation, job hiring, and genomics databases. A better appreciation of the marginalized concept of honor could, we hope, lead to more productive AI value alignment discussions, and to AI systems that better reflect the needs and values of users around the globe.},
booktitle = {Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency},
pages = {593–602},
numpages = {10},
keywords = {AI Ethics, artificial intelligence, cultures of honor, ethics alignment, honor cultures, universal human rights},
location = {Chicago, IL, USA},
series = {FAccT '23}
}

@inproceedings{10.1145/3593013.3594065,
author = {Lovato, Juniper and Mueller, Philip and Suchdev, Parisa and Dodds, Peter},
title = {More Data Types More Problems: A Temporal Analysis of Complexity, Stability, and Sensitivity in Privacy Policies},
year = {2023},
isbn = {9798400701924},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593013.3594065},
doi = {10.1145/3593013.3594065},
abstract = {Collecting personally identifiable information (PII) on data subjects has become big business. Data brokers and data processors are part of a multi-billion-dollar industry that profits from collecting, buying, and selling consumer data. Yet there is little transparency in the data collection industry which makes it difficult to understand what types of data are being collected, used, and sold, and thus the risk to individual data subjects. In this study, we examine a large textual dataset of privacy policies from 1997-2019 in order to investigate the data collection activities of data brokers and data processors. We also develop an original lexicon of PII-related terms representing PII data types curated from legislative texts. This mesoscale analysis looks at privacy policies over time on the word, topic, and network levels to understand the stability, complexity, and sensitivity of privacy policies over time. We find that (1) privacy legislation may be correlated with changes in stability and turbulence of PII data types in privacy policies; (2) the complexity of privacy policies decreases over time and becomes more regularized; (3) sensitivity rises over time and shows spikes that appear to be correlated with events when new privacy legislation is introduced.},
booktitle = {Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1088–1100},
numpages = {13},
keywords = {Data Ethics, Data Privacy, Data Science, NLP, Networks, Privacy, Privacy Policies},
location = {Chicago, IL, USA},
series = {FAccT '23}
}

@inproceedings{10.1145/3593013.3594067,
author = {Hacker, Philipp and Engel, Andreas and Mauer, Marco},
title = {Regulating ChatGPT and other Large Generative AI Models},
year = {2023},
isbn = {9798400701924},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593013.3594067},
doi = {10.1145/3593013.3594067},
abstract = {Large generative AI models (LGAIMs), such as ChatGPT, GPT-4 or Stable Diffusion, are rapidly transforming the way we communicate, illustrate, and create. However, AI regulation, in the EU and beyond, has primarily focused on conventional AI models, not LGAIMs. This paper will situate these new generative models in the current debate on trustworthy AI regulation, and ask how the law can be tailored to their capabilities. After laying technical foundations, the legal part of the paper proceeds in four steps, covering (1) direct regulation, (2) data protection, (3) content moderation, and (4) policy proposals. It suggests a novel terminology to capture the AI value chain in LGAIM settings by differentiating between LGAIM developers, deployers, professional and non-professional users, as well as recipients of LGAIM output. We tailor regulatory duties to these different actors along the value chain and suggest strategies to ensure that LGAIMs are trustworthy and deployed for the benefit of society at large. Rules in the AI Act and other direct regulation must match the specificities of pre-trained models. The paper argues for three layers of obligations concerning LGAIMs (minimum standards for all LGAIMs; high-risk obligations for high-risk use cases; collaborations along the AI value chain). In general, regulation should focus on concrete high-risk applications, and not the pre-trained model itself, and should include (i) obligations regarding transparency and (ii) risk management. Non-discrimination provisions (iii) may, however, apply to LGAIM developers. Lastly, (iv) the core of the DSA's content moderation rules should be expanded to cover LGAIMs. This includes notice and action mechanisms, and trusted flaggers.},
booktitle = {Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1112–1123},
numpages = {12},
location = {Chicago, IL, USA},
series = {FAccT '23}
}

@inproceedings{10.1145/3593013.3594070,
author = {Li, Hanlin and Vincent, Nicholas and Chancellor, Stevie and Hecht, Brent},
title = {The Dimensions of Data Labor: A Road Map for Researchers, Activists, and Policymakers to Empower Data Producers},
year = {2023},
isbn = {9798400701924},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593013.3594070},
doi = {10.1145/3593013.3594070},
abstract = {Many recent technological advances (e.g. ChatGPT and search engines) are possible only because of massive amounts of user-generated data produced through user interactions with computing systems or scraped from the web (e.g. behavior logs, user-generated content, and artwork). However, data producers have little say in what data is captured, how it is used, or who it benefits. Organizations with the ability to access and process this data, e.g. OpenAI and Google, possess immense power in shaping the technology landscape. By synthesizing related literature that reconceptualizes the production of data for computing as “data labor”, we outline opportunities for researchers, policymakers, and activists to empower data producers in their relationship with tech companies, e.g advocating for transparency about data reuse, creating feedback channels between data producers and companies, and potentially developing mechanisms to share data’s revenue more broadly. In doing so, we characterize data labor with six important dimensions - legibility, end-use awareness, collaboration requirement, openness, replaceability, and livelihood overlap - based on the parallels between data labor and various other types of labor in the computing literature.},
booktitle = {Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1151–1161},
numpages = {11},
keywords = {data leverage, empowerment, user-generated data},
location = {Chicago, IL, USA},
series = {FAccT '23}
}

@inproceedings{10.1145/3593013.3594072,
author = {Wolfe, Robert and Yang, Yiwei and Howe, Bill and Caliskan, Aylin},
title = {Contrastive Language-Vision AI Models Pretrained on Web-Scraped Multimodal Data Exhibit Sexual Objectification Bias},
year = {2023},
isbn = {9798400701924},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593013.3594072},
doi = {10.1145/3593013.3594072},
abstract = {Warning: The content of this paper may be upsetting or triggering.Nine language-vision AI models trained on web scrapes with the Contrastive Language-Image Pretraining (CLIP) objective are evaluated for evidence of a bias studied by psychologists: the sexual objectification of girls and women, which occurs when a person’s human characteristics, such as emotions, are disregarded and the person is treated as a body or a collection of body parts. We replicate three experiments in the psychology literature quantifying sexual objectification and show that the phenomena persist in trained AI models. A first experiment uses standardized images of women from the Sexual OBjectification and EMotion Database, and finds that human characteristics are disassociated from images of objectified women: the model’s recognition of emotional state is mediated by whether the subject is fully or partially clothed. Embedding association tests (EATs) return significant effect sizes for both anger (d &gt; 0.80) and sadness (d &gt; 0.50), associating images of fully clothed subjects with emotions. GRAD-CAM saliency maps highlight that CLIP gets distracted from emotional expressions in objectified images where subjects are partially clothed. A second experiment measures the effect in a representative application: an automatic image captioner (Antarctic Captions) includes words denoting emotion less than 50\% as often for images of partially clothed women than for images of fully clothed women. A third experiment finds that images of female professionals (scientists, doctors, executives) are likely to be associated with sexual descriptions relative to images of male professionals. A fourth experiment shows that a prompt of "a [age] year old girl" generates sexualized images (as determined by an NSFW classifier) up to 73\% of the time for VQGAN-CLIP (age 17), and up to 42\% of the time for Stable Diffusion (ages 14 and 18); the corresponding rate for boys never surpasses 9\%. The evidence indicates that language-vision AI models trained on automatically collected web scrapes learn biases of sexual objectification, which propagate to downstream applications.},
booktitle = {Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1174–1185},
numpages = {12},
keywords = {AI bias, AI bias in applications, AI bias propagation, gender bias, generative AI, language-vision AI, representation learning, sexualization, text-to-image generators},
location = {Chicago, IL, USA},
series = {FAccT '23}
}

@inproceedings{10.1145/3593013.3594094,
author = {Field, Anjalie and Coston, Amanda and Gandhi, Nupoor and Chouldechova, Alexandra and Putnam-Hornstein, Emily and Steier, David and Tsvetkov, Yulia},
title = {Examining risks of racial biases in NLP tools for child protective services},
year = {2023},
isbn = {9798400701924},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593013.3594094},
doi = {10.1145/3593013.3594094},
abstract = {Although much literature has established the presence of demographic bias in natural language processing (NLP) models, most work relies on curated bias metrics that may not be reflective of real-world applications. At the same time, practitioners are increasingly using algorithmic tools in high-stakes settings, with particular recent interest in NLP. In this work, we focus on one such setting: child protective services (CPS). CPS workers often write copious free-form text notes about families they are working with, and CPS agencies are actively seeking to deploy NLP models to leverage these data. Given well-established racial bias in this setting, we investigate possible ways deployed NLP is liable to increase racial disparities. We specifically examine word statistics within notes and algorithmic fairness in risk prediction, coreference resolution, and named entity recognition (NER). We document consistent algorithmic unfairness in NER models, possible algorithmic unfairness in coreference resolution models, and little evidence of exacerbated racial bias in risk prediction. While there is existing pronounced criticism of risk prediction, our results expose previously undocumented risks of racial bias in realistic information extraction systems, highlighting potential concerns in deploying them, even though they may appear more benign. Our work serves as a rare realistic examination of NLP algorithmic fairness in a potential deployed setting and a timely investigation of a specific risk associated with deploying NLP in CPS settings.},
booktitle = {Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1479–1492},
numpages = {14},
keywords = {CPS, NLP, bias, child protection system, race, text processing},
location = {Chicago, IL, USA},
series = {FAccT '23}
}

@article{10.1145/3593230,
author = {Brie, Paul and Burny, Nicolas and Slu\"{y}ters, Arthur and Vanderdonckt, Jean},
title = {Evaluating a Large Language Model on Searching for GUI Layouts},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {EICS},
url = {https://doi.org/10.1145/3593230},
doi = {10.1145/3593230},
abstract = {The field of generative artificial intelligence has seen significant advancements in recent years with the advent of large language models, which have shown impressive results in software engineering tasks but not yet in engineering user interfaces. Thus, we raise a specific research question: would an LLM-based system be able to search for relevant GUI layouts? To address this question, we conducted a controlled study evaluating how Instigator, an LLM-based system for searching GUI layouts of web pages by generative pre-trained training, would return GUI layouts that are relevant to a given instruction and what would be the user experience of (N =34) practitioners interacting with Instigator. Our results identify a very high similarity and a moderate correlation between the rankings of the GUI layouts generated by Instigator and the rankings of the practitioners with respect to their relevance to a given design instruction. We highlight the results obtained through thirteen UEQ+ scales that characterize the user experience of the practitioner with Instigator, which we use to discuss perspectives for improving such future tools.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = jun,
articleno = {178},
numpages = {37},
keywords = {generative pre-training, gui design, gui layout, large language model, web pages}
}

@proceedings{10.1145/3593342,
title = {WCCCE '23: Proceedings of the 25th Western Canadian Conference on Computing Education},
year = {2023},
isbn = {9798400707896},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Vancouver, BC, Canada}
}

@inproceedings{10.1145/3593342.3593360,
author = {Rajabi, Parsa and Taghipour, Parnian and Cukierman, Diana and Doleck, Tenzin},
title = {Exploring ChatGPT’s impact on post-secondary education: A qualitative study},
year = {2023},
isbn = {9798400707896},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593342.3593360},
doi = {10.1145/3593342.3593360},
abstract = {As Chat Generative Pre-trained Transformer (ChatGPT) gains traction, its impact on post-secondary education is increasingly being debated. This qualitative study explores the perception of students and faculty members at a research university in Canada regarding ChatGPT’s use in a post-secondary setting, focusing on how it could be incorporated and what ways instructors can respond to this technology. We present the summary of a discussion that took place in a two-hour focus group session with 40 participants from the computer science and engineering departments, and highlight issues surrounding plagiarism, assessment methods, and the appropriate use of ChatGPT. Findings suggest that students are likely to use ChatGPT, but there is a need for specific guidelines, more classroom assessments, and mandatory reporting of ChatGPT use. The study contributes to the emergent research on ChatGPT in higher education and emphasizes the importance of proactively addressing challenges and opportunities associated with ChatGPT adoption and use.},
booktitle = {Proceedings of the 25th Western Canadian Conference on Computing Education},
articleno = {9},
numpages = {6},
keywords = {Artificial Intelligence in education, ChatGPT, assessment, conversational AI, education, higher education, post-secondary},
location = {Vancouver, BC, Canada},
series = {WCCCE '23}
}

@proceedings{10.1145/3593434,
title = {EASE '23: Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering},
year = {2023},
isbn = {9798400700446},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Oulu, Finland}
}

@inproceedings{10.1145/3593434.3593468,
author = {Ahmad, Aakash and Waseem, Muhammad and Liang, Peng and Fahmideh, Mahdi and Aktar, Mst Shamima and Mikkonen, Tommi},
title = {Towards Human-Bot Collaborative Software Architecting with ChatGPT},
year = {2023},
isbn = {9798400700446},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593434.3593468},
doi = {10.1145/3593434.3593468},
abstract = {Architecting software-intensive systems can be a complex process. It deals with the daunting tasks of unifying stakeholders’ perspectives, designers’ intellect, tool-based automation, pattern-driven reuse, and so on, to sketch a blueprint that guides software implementation and evaluation. Despite its benefits, architecture-centric software engineering (ACSE) suffers from a multitude of challenges. ACSE challenges could stem from a lack of standardized processes, socio-technical limitations, and scarcity of human expertise etc. that can impede the development of existing and emergent classes of software. Software Development Bots (DevBots) trained on large language models can help synergise architects’ knowledge with artificially intelligent decision support to enable rapid architecting in a human-bot collaborative ACSE. An emerging solution to enable this collaboration is ChatGPT, a disruptive technology not primarily introduced for software engineering, but is capable of articulating and refining architectural artifacts based on natural language processing. We detail a case study that involves collaboration between a novice software architect and ChatGPT to architect a service-based software. Future research focuses on harnessing empirical evidence about architects’ productivity and explores socio-technical aspects of architecting with ChatGPT to tackle challenges of ACSE.},
booktitle = {Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering},
pages = {279–285},
numpages = {7},
keywords = {ChatGPT, DevBots, Large Language Models, Software Architecture},
location = {Oulu, Finland},
series = {EASE '23}
}

@proceedings{10.1145/3593743,
title = {C&amp;T '23: Proceedings of the 11th International Conference on Communities and Technologies},
year = {2023},
isbn = {9798400707582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lahti, Finland}
}

@proceedings{10.1145/3593856,
title = {HOTOS '23: Proceedings of the 19th Workshop on Hot Topics in Operating Systems},
year = {2023},
isbn = {9798400701955},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Providence, RI, USA}
}

@proceedings{10.1145/3594300,
title = {ICMAI '23: Proceedings of the 2023 8th International Conference on Mathematics and Artificial Intelligence},
year = {2023},
isbn = {9781450399982},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Chongqing, China}
}

@proceedings{10.1145/3594315,
title = {ICCAI '23: Proceedings of the 2023 9th International Conference on Computing and Artificial Intelligence},
year = {2023},
isbn = {9781450399029},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tianjin, China}
}

@inproceedings{10.1145/3594315.3594339,
author = {Tang, Chunming and Wang, Yu and Kamiya, Tohru},
title = {Research on Semantic segmentation co-evolutionary method for Automated Driving Haze Images},
year = {2023},
isbn = {9781450399029},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594315.3594339},
doi = {10.1145/3594315.3594339},
abstract = {In this paper, we address the problem of semantic segmentation of advanced automatic driving image in hazy weather. We mainly adopt the co-evolution method of image defogging model and semantic segmentation model, the defogging model adopts generative adversarial GAN network, the semantic segmentation model adopts BiSeNet,and the training data is a public self-driving data set Cityscapes. The co-evolution of these two models is used to improve the accuracy of semantic segmentation of fog maps. The experimental results show that the semantic segmentation of fog map by co-evolution has a more obvious improvement effect, and to a certain extent, it can meet the target extraction and recognition of autonomous driving requirements.},
booktitle = {Proceedings of the 2023 9th International Conference on Computing and Artificial Intelligence},
pages = {157–163},
numpages = {7},
location = {Tianjin, China},
series = {ICCAI '23}
}

@inproceedings{10.1145/3594315.3594371,
author = {Tang, Fanggeng and He, Pan},
title = {Software Defect Prediction using Multi-scale Structural Information},
year = {2023},
isbn = {9781450399029},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594315.3594371},
doi = {10.1145/3594315.3594371},
abstract = {In recent years, most researches have used the sequence of nodes in the abstract syntax tree (AST) of code to extract features for software defect prediction (SDP). While the AST is a kind of graph data, it may ignore some part of the structural information to use the original graph data as a sequence for input. Thus, Graph neural network (GNN) has been used to extract structural information in SDP. However, existing researches ignore that GNN learning is inherently local. It is difficult to interact between remote nodes and to capture long-term dependencies in source code. We apply a combination model of GNN Transformer to predict the software defects. Using an AST directly as the input, GNN extracts local features and structural information between the node and its neighbors. We then encode the relative and absolute positions of the nodes in the AST. The position encodings are passed into the Transformer along with the feature information extracted by GNN to extract the global features, which are the long-term dependencies between nodes. Finally, the extracted fused features are used in the SDP. Experiments on the PROMISE dataset have shown that our method achieves higher F-measure and better identification of defective features in source code than the state-of-the-art SDP method.},
booktitle = {Proceedings of the 2023 9th International Conference on Computing and Artificial Intelligence},
pages = {548–556},
numpages = {9},
keywords = {Graph neural network, Software defect prediction, Transformer, deep learning},
location = {Tianjin, China},
series = {ICCAI '23}
}

@proceedings{10.1145/3594409,
title = {ICIAI '23: Proceedings of the 2023 7th International Conference on Innovation in Artificial Intelligence},
year = {2023},
isbn = {9781450398398},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Harbin, China}
}

@proceedings{10.1145/3594536,
title = {ICAIL '23: Proceedings of the Nineteenth International Conference on Artificial Intelligence and Law},
year = {2023},
isbn = {9798400701979},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is my great pleasure to present to you the proceedings of the Nineteenth International Conference on Artificial Intelligence and Law (ICAIL 2023). The conference will be held June 19-23 at the Universidade do Minho in Braga, Portugal. It has been organized by the International Association for Artificial Intelligence and Law (IAAIL) and is held in cooperation with AAAI and ACM SIGAI. IAAIL's mission is to facilitate research, collaboration, and interdisciplinary communication at the intersection of law and the technical disciplines belonging to the field of artificial intelligence. The first ICAIL conference was held in 1987 and its 2023 iteration is the first to be held in person again after the Covid-19 pandemic.},
location = {Braga, Portugal}
}

@inproceedings{10.1145/3594536.3595176,
author = {Goebel, Randy and Kano, Yoshinobu and Kim, Mi-Young and Rabelo, Juliano and Satoh, Ken and Yoshioka, Masaharu},
title = {Summary of the Competition on Legal Information, Extraction/Entailment (COLIEE) 2023},
year = {2023},
isbn = {9798400701979},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594536.3595176},
doi = {10.1145/3594536.3595176},
abstract = {We summarize the 10th Competition on Legal Information Extraction and Entailment. In this edition, the competition included four tasks on case law and statute law. The case law component includes an information retrieval task (Task 1), and the confirmation of an entailment relation between an existing case and an unseen case (Task 2). The statute law component includes an information retrieval task (Task 3), and an entailment/question answering task based on retrieved civil code statutes (Task 4). Participation was open to any group based on any approach. Ten different teams participated in the case law competition tasks, most of them in more than one task. We received results from 8 teams for Task 1 (22 runs) and seven teams for Task 2 (18 runs). On the statute law task, there were 9 different teams participating, most in more than one task. 6 teams submitted a total of 16 runs for Task 3, and 9 teams submitted a total of 26 runs for Task 4. We describe the variety of approaches, our official evaluation, and analysis of our data and submission results.},
booktitle = {Proceedings of the Nineteenth International Conference on Artificial Intelligence and Law},
pages = {472–480},
numpages = {9},
keywords = {imbalanced datasets, legal information retrieval, legal textual entailment, text classification},
location = {Braga, Portugal},
series = {ICAIL '23}
}

@inproceedings{10.1145/3594536.3595177,
author = {Licari, Daniele and Bushipaka, Praveen and Marino, Gabriele and Comand\'{e}, Giovanni and Cucinotta, Tommaso},
title = {Legal Holding Extraction from Italian Case Documents using Italian-LEGAL-BERT Text Summarization},
year = {2023},
isbn = {9798400701979},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594536.3595177},
doi = {10.1145/3594536.3595177},
abstract = {Legal holdings are used in Italy as a critical component of the legal system, serving to establish legal precedents, provide guidance for future legal decisions, and ensure consistency and predictability in the interpretation and application of the law. They are written by domain experts who describe in a clear and concise manner the principle of law applied in the judgments.We introduce a legal holding extraction method based on Italian-LEGAL-BERT to automatically extract legal holdings from Italian cases. In addition, we present ITA-CaseHold, a benchmark dataset for Italian legal summarization. We conducted several experiments using this dataset, as a valuable baseline for future research on this topic.},
booktitle = {Proceedings of the Nineteenth International Conference on Artificial Intelligence and Law},
pages = {148–156},
numpages = {9},
keywords = {Benchmark Dataset, Extractive Text Summarization, Holding Extraction, Italian-LEGAL-BERT},
location = {Braga, Portugal},
series = {ICAIL '23}
}

@proceedings{10.1145/3594692,
title = {IEEA '23: Proceedings of the 2023 12th International Conference on Informatics, Environment, Energy and Applications},
year = {2023},
isbn = {9798400700125},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Singapore, Singapore}
}

@proceedings{10.1145/3594739,
title = {UbiComp/ISWC '23 Adjunct: Adjunct Proceedings of the 2023 ACM International Joint Conference on Pervasive and Ubiquitous Computing \&amp; the 2023 ACM International Symposium on Wearable Computing},
year = {2023},
isbn = {9798400702006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Cancun, Quintana Roo, Mexico}
}

@proceedings{10.1145/3594778,
title = {GRADES-NDA '23: Proceedings of the 6th Joint Workshop on Graph Data Management Experiences \&amp; Systems (GRADES) and Network Data Analytics (NDA)},
year = {2023},
isbn = {9798400702013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {GRADES-NDA 2023 is the sixth joint meeting of the GRADES and NDA workshops, which were each independently organized at previous SIGMOD-PODS meetings, GRADES since 2013 and NDA since 2016. The focus of the GRADES-NDA workshop is the application areas, usage scenarios and open challenges in managing largescale graph-shaped data. The workshop is a forum for exchanging ideas and methods for mining, querying, and learning with real-world network data, developing new common understandings of the problems at hand, sharing of data sets and benchmarks where applicable, and leveraging existing knowledge from different disciplines. GRADES-NDA aims to present technical contributions inside graph, RDF, and other data management systems on massive graphs.The purpose of this workshop is to bring together researchers from academia, industry, and government to create a forum for discussing recent advances in large-scale graph data management and analytics systems, as well as propose and discuss novel methods and techniques towards addressing domain specific challenges and handling noise in real-world graphs.},
location = {Seattle, WA, USA}
}

@proceedings{10.1145/3594781,
title = {LDT '23: Proceedings of the 2023 Symposium on Learning, Design and Technology},
year = {2023},
isbn = {9798400707360},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Evanston, IL, USA}
}

@proceedings{10.1145/3594806,
title = {PETRA '23: Proceedings of the 16th International Conference on PErvasive Technologies Related to Assistive Environments},
year = {2023},
isbn = {9798400700699},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Corfu, Greece}
}

@inproceedings{10.1145/3594806.3596542,
author = {Othman, Achraf and Dhouib, Amira and Nasser Al Jabor, Aljazi},
title = {Fostering websites accessibility: A case study on the use of the Large Language Models ChatGPT for automatic remediation},
year = {2023},
isbn = {9798400700699},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594806.3596542},
doi = {10.1145/3594806.3596542},
abstract = {The use of automated accessibility testing tools remains a common practice for evaluating web accessibility. However, the results obtained from these tools may not always provide a comprehensive and complete view of a site's accessibility status. The main purpose of this study is to improve web accessibility by automatically remediating non-accessible ones using Large Language Models (LLM), particularly ChatGPT. The effectiveness of the used model in detecting and remediating accessibility issues to ensure compliance with the Web Content Accessibility Guidelines (WCAG 2.1) is also discussed. By using ChatGPT as a remediation tool, this study investigates the potential of LLM in improving web accessibility. In the case study, two websites that did not adhere to the WCAG 2.1 guidelines were selected as the primary experimental subjects for the study. These websites were assessed using the web accessibility evaluation tool, WAVE, to detect accessibility issues. The identified issues served then as the basis for remediation using ChatGPT. The effectiveness of the used advanced language model as a web accessibility remediation tool was evaluated by comparing its findings with those obtained from manual accessibility testing. The results of this comparison have significant implications for stakeholders involved in achieving WCAG compliance and contribute to the development of more accessible online platforms for individuals with disabilities.},
booktitle = {Proceedings of the 16th International Conference on PErvasive Technologies Related to Assistive Environments},
pages = {707–713},
numpages = {7},
location = {Corfu, Greece},
series = {PETRA '23}
}

@proceedings{10.1145/3595353,
title = {WDC '23: Proceedings of the 2nd Workshop on Security Implications of Deepfakes and Cheapfakes},
year = {2023},
isbn = {9798400702037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Melbourne, VIC, Australia}
}

@proceedings{10.1145/3595360,
title = {DEEM '23: Proceedings of the Seventh Workshop on Data Management for End-to-End Machine Learning},
year = {2023},
isbn = {9798400702044},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Seattle, WA, USA}
}

@proceedings{10.1145/3596286,
title = {CVIPPR '23: Proceedings of the 2023 Asia Conference on Computer Vision, Image Processing and Pattern Recognition},
year = {2023},
isbn = {9798400700033},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Phuket, Thailand}
}

@proceedings{10.1145/3596454,
title = {EICS '23 Companion: Companion Proceedings of the 2023 ACM SIGCHI Symposium on Engineering Interactive Computing Systems},
year = {2023},
isbn = {9798400702068},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Swansea, United Kingdom}
}

@proceedings{10.1145/3596671,
title = {CHIWORK '23: Proceedings of the 2nd Annual Meeting of the Symposium on Human-Computer Interaction for Work},
year = {2023},
isbn = {9798400708077},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Oldenburg, Germany}
}

@inproceedings{10.1145/3596671.3597650,
author = {Sarkar, Advait},
title = {Exploring Perspectives on the Impact of Artificial Intelligence on the Creativity of Knowledge Work: Beyond Mechanised Plagiarism and Stochastic Parrots},
year = {2023},
isbn = {9798400708077},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3596671.3597650},
doi = {10.1145/3596671.3597650},
abstract = {Artificial Intelligence (AI), and in particular generative models, are transformative tools for knowledge work. They problematise notions of creativity, originality, plagiarism, the attribution of credit, and copyright ownership. Critics of generative models emphasise the reliance on large amounts of training data, and view the output of these models as no more than randomised plagiarism, remix, or collage of the source data. On these grounds many have argued for stronger regulations on the deployment, use, and attribution of the output of these models. However, these issues are not new or unique to artificial intelligence. In this position paper, using examples from literary criticism, the history of art, and copyright law, I show how creativity and originality resist definition as a notatable or information-theoretic property of an object, and instead can be seen as the property of a process, an author, or a viewer. Further alternative views hold that all creative work is essentially reuse (mostly without attribution), or that randomness itself can be creative. I suggest that creativity is ultimately defined by communities of creators and receivers, and the deemed sources of creativity in a workflow often depend on which parts of the workflow can be automated. Using examples from recent studies of AI in creative knowledge work, I suggest that AI shifts knowledge work from material production to critical integration. This position paper aims to begin a conversation around a more nuanced approach to the problems of creativity and credit assignment for generative models, one which more fully recognises the importance of the creative and curatorial voice of the users of these models, and moves away from simpler notational or information-theoretic views.},
booktitle = {Proceedings of the 2nd Annual Meeting of the Symposium on Human-Computer Interaction for Work},
articleno = {13},
numpages = {17},
keywords = {critical theory},
location = {Oldenburg, Germany},
series = {CHIWORK '23}
}

@book{10.1145/3596711,
editor = {Whitton, Mary C.},
title = {Seminal Graphics Papers: Pushing the Boundaries, Volume 2},
year = {2023},
isbn = {9798400708978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {1},
volume = {Volume 2},
abstract = {When we began planning how to celebrate 50 years of SIGGRAPH Conferences, there was unanimous agreement that one of the projects should be publishing a second volume of Seminal Graphics Papers. The first volume was published in 1998 as part of the celebration of the 25th SIGGRAPH conference. Seminal Graphics Papers Volume 2, perhaps more than any other activity undertaken in this milestone year, celebrates ACM SIGGRAPH's origins and continued success as a Technical and Professional Society. This collection of papers typifies the ground-breaking research that has been the conference's hallmark since 1974. A quick scan of the chapter and the paper titles shows just how far SIGGRAPH research has pushed the boundaries of our discipline and contributed to its evolution.The ACM Digital Library team has been supportive of this Seminal Graphics Papers project from the beginning. I am pleased to let you know that both Volumes 1 and 2 of Seminal Graphics Papers are freely available from the ACM Digital Library at these URLs: Volume 1: https://dl.acm.org/doi/book/10.1145/280811Volume 2: https://dl.acm.org/doi/book/10.1145/3596711}
}

@proceedings{10.1145/3596871,
title = {ICCBN '23: Proceedings of the 2023 11th International Conference on Communications and Broadband Networking},
year = {2023},
isbn = {9781450398404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xi'an, China}
}

@proceedings{10.1145/3596947,
title = {ISMSI '23: Proceedings of the 2023 7th International Conference on Intelligent Systems, Metaheuristics \&amp; Swarm Intelligence},
year = {2023},
isbn = {9781450399920},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Virtual Event, Malaysia}
}

@proceedings{10.1145/3597061,
title = {BodySys '23: Proceedings of the 8th Workshop on Body-Centric Computing Systems},
year = {2023},
isbn = {9798400702112},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 8th Workshop on Body-Centric Computing and Systems 2023 (BodySys'23). BodySys workshop focuses on advances and discussions on how wearable and body-centric (human/animal) computing technologies can shape mobile computing, systems, and applications research. The goal of this workshop is to provide a forum to bring together researchers and design experts to discuss how wearable, body-centric, and user-in-the-loop technologies have, and can, complement mobile systems research, and vice-versa. It also aims to provide a launchpad for bold and visionary ideas for systems research in this space.},
location = {Helsinki, Finland}
}

@proceedings{10.1145/3597512,
title = {TAS '23: Proceedings of the First International Symposium on Trustworthy Autonomous Systems},
year = {2023},
isbn = {9798400707346},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Edinburgh, United Kingdom}
}

@proceedings{10.1145/3597638,
title = {ASSETS '23: Proceedings of the 25th International ACM SIGACCESS Conference on Computers and Accessibility},
year = {2023},
isbn = {9798400702204},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {New York, NY, USA}
}

@proceedings{10.1145/3597926,
title = {ISSTA 2023: Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis},
year = {2023},
isbn = {9798400702211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to ISSTA 2023, the 32nd edition of the International Symposium on Software Testing and Analysis, to be held on July 18–20, 2023 in Seattle, USA. The symposium has become a premier scientific event in the expanding area of software testing and analysis, with a strong appeal to researchers from all continents.},
location = {Seattle, WA, USA}
}

@inproceedings{10.1145/3597926.3598067,
author = {Deng, Yinlin and Xia, Chunqiu Steven and Peng, Haoran and Yang, Chenyuan and Zhang, Lingming},
title = {Large Language Models Are Zero-Shot Fuzzers: Fuzzing Deep-Learning Libraries via Large Language Models},
year = {2023},
isbn = {9798400702211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597926.3598067},
doi = {10.1145/3597926.3598067},
abstract = {Deep Learning (DL) systems have received exponential growth in popularity and have become ubiquitous in our everyday life. Such systems are built on top of popular DL libraries, e.g., TensorFlow and PyTorch which provide APIs as building blocks for DL systems. Detecting bugs in these DL libraries is critical for almost all downstream DL systems in ensuring effectiveness/safety for end users. Meanwhile, traditional fuzzing techniques can be hardly effective for such a challenging domain since the input DL programs need to satisfy both the input language (e.g., Python) syntax/semantics and the DL API input/shape constraints for tensor computations.  
To address these limitations, we propose TitanFuzz – the first approach to directly leveraging Large Language Models (LLMs) to generate input programs for fuzzing DL libraries. LLMs are titanic models trained on billions of code snippets and can autoregressively generate human-like code snippets. Our key insight is that modern LLMs can also include numerous code snippets invoking DL library APIs in their training corpora, and thus can implicitly learn both language syntax/semantics and intricate DL API constraints for valid DL program generation. More specifically, we use both generative and infilling LLMs (e.g., Codex/InCoder) to generate and mutate valid/diverse input DL programs for fuzzing. Our experimental results demonstrate that TitanFuzz can achieve 30.38\%/50.84\% higher code coverage than state-of-the-art fuzzers on TensorFlow/PyTorch. Furthermore, TitanFuzz is able to detect 65 bugs, with 44 already confirmed as previously unknown bugs.  
This paper demonstrates that modern titanic LLMs can be leveraged to directly perform both generation-based and mutation-based fuzzing studied for decades, while being fully automated, generalizable, and applicable to domains challenging for traditional approaches (such as DL systems). We hope TitanFuzz can stimulate more work in this promising direction of LLMs for fuzzing.},
booktitle = {Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {423–435},
numpages = {13},
keywords = {Fuzz Testing, Large Language Model, Test Generation},
location = {Seattle, WA, USA},
series = {ISSTA 2023}
}

@inproceedings{10.1145/3597926.3598082,
author = {Chen, Simin and Wei, Shiyi and Liu, Cong and Yang, Wei},
title = {DyCL: Dynamic Neural Network Compilation Via Program Rewriting and Graph Optimization},
year = {2023},
isbn = {9798400702211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597926.3598082},
doi = {10.1145/3597926.3598082},
abstract = {The deep learning (DL) compiler serves as a vital infrastructure component to enable the deployment of deep neural networks on diverse hardware platforms such as mobile devices and Raspberry Pi. DL compiler’s primary function is to translate DNN programs written in high-level DL frameworks such as PyTorch and TensorFlow into portable executables. These executables can then be flexibly executed by the deployed host programs. However, existing DL compilers rely on a tracing mechanism, which involves feeding a runtime input to a neural network program and tracing the program execution paths to generate the computational graph necessary for compilation. Unfortunately, this mechanism falls short when dealing with modern dynamic neural networks (DyNNs) that possess varying computational graphs depending on the inputs. Consequently, conventional DL compilers struggle to accurately compile DyNNs into executable code. To address this limitation, we propose DyCL, a general approach that enables any existing DL compiler to successfully compile DyNNs. DyCL tackles the dynamic nature of DyNNs by introducing a compilation mechanism that redistributes the control and data flow of the original DNN programs during the compilation process. Specifically, DyCL develops program analysis and program transformation techniques to convert a dynamic neural network into multiple sub-neural networks. Each sub-neural network is devoid of conditional statements and is compiled independently. Furthermore, DyCL synthesizes a host module that models the control flow of the DyNNs and facilitates the invocation of the sub-neural networks. Our evaluation demonstrates the effectiveness of DyCL, achieving a 100\% success rate in compiling all dynamic neural networks. Moreover, the compiled executables generated by DyCL exhibit significantly improved performance, running between 1.12\texttimes{} and 20.21\texttimes{} faster than the original DyNNs executed on general-purpose DL frameworks.},
booktitle = {Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {614–626},
numpages = {13},
keywords = {Deep Learning Compilers, Dynamic Neural Networks},
location = {Seattle, WA, USA},
series = {ISSTA 2023}
}

@inproceedings{10.1145/3597926.3598092,
author = {Liu, Hao and Wang, Yanlin and Wei, Zhao and Xu, Yong and Wang, Juhong and Li, Hui and Ji, Rongrong},
title = {RefBERT: A Two-Stage Pre-trained Framework for Automatic Rename Refactoring},
year = {2023},
isbn = {9798400702211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597926.3598092},
doi = {10.1145/3597926.3598092},
abstract = {Refactoring is an indispensable practice of improving the quality and maintainability of source code in software evolution. Rename refactoring is the most frequently performed refactoring that suggests a new name for an identifier to enhance readability when the identifier is poorly named. However, most existing works only identify renaming activities between two versions of source code, while few works express concern about how to suggest a new name. In this paper, we study automatic rename refactoring on variable names, which is considered more challenging than other rename refactoring activities. We first point out the connections between rename refactoring and various prevalent learning paradigms and the difference between rename refactoring and general text generation in natural language processing. Based on our observations, we propose RefBERT, a two-stage pre-trained framework for rename refactoring on variable names. RefBERT first predicts the number of sub-tokens in the new name and then generates sub-tokens accordingly. Several techniques, including constrained masked language modeling, contrastive learning, and the bag-of-tokens loss, are incorporated into RefBERT to tailor it for automatic rename refactoring on variable names. Through extensive experiments on our constructed refactoring datasets, we show that the generated variable names of RefBERT are more accurate and meaningful than those produced by the existing method. Our implementation and data are available at https://github.com/KDEGroup/RefBERT.},
booktitle = {Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {740–752},
numpages = {13},
keywords = {bag-of-tokens loss, contrastive learning, language modeling, rename refactoring},
location = {Seattle, WA, USA},
series = {ISSTA 2023}
}

@inproceedings{10.1145/3597926.3598096,
author = {He, Yichen and Wang, Liran and Wang, Kaiyi and Zhang, Yupeng and Zhang, Hang and Li, Zhoujun},
title = {COME: Commit Message Generation with Modification Embedding},
year = {2023},
isbn = {9798400702211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597926.3598096},
doi = {10.1145/3597926.3598096},
abstract = {Commit messages concisely describe code changes in natural language and are important for program comprehension and maintenance. Previous studies proposed some approaches for automatic commit message generation, but their performance is limited due to inappropriate representation of code changes and improper combination of translation-based and retrieval-based approaches. To address these problems, this paper introduces a novel framework named COME, in which modification embeddings are used to represent code changes in a fine-grained way, a self-supervised generative task is designed to learn contextualized code change representation, and retrieval-based and translation-based methods are combined through a decision algorithm. The average improvement of COME over the state-of-the-art approaches is 9.2\% on automatic evaluation metrics and 8.0\% on human evaluation metrics. We also analyse the effectiveness of COME's three main components and each of them results in an improvement of 8.6\%, 8.7\% and 5.2\%.},
booktitle = {Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {792–803},
numpages = {12},
keywords = {Automatic Commit Message Generation, Contextualized Code Change Representation Learning, Self-supervised Learning},
location = {Seattle, WA, USA},
series = {ISSTA 2023}
}

@inproceedings{10.1145/3597926.3598108,
author = {Zhang, Xiaodong and Zhao, Wei and Sun, Yang and Sun, Jun and Shen, Yulong and Dong, Xuewen and Yang, Zijiang},
title = {Testing Automated Driving Systems by Breaking Many Laws Efficiently},
year = {2023},
isbn = {9798400702211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597926.3598108},
doi = {10.1145/3597926.3598108},
abstract = {An automated driving system (ADS), as the brain of an autonomous vehicle (AV), should be tested thoroughly ahead of deployment.  
ADS must satisfy a complex set of rules to ensure road safety, e.g., the existing traffic laws and possibly future laws that are dedicated to AVs.  
To comprehensively test an ADS, we would like to systematically discover diverse scenarios in which certain traffic law is violated. The challenge is that (1) there are many traffic laws (e.g., 13 testable articles in Chinese traffic laws and 16 testable articles in Singapore traffic laws, with 81 and 43 violation situations respectively); and (2) many of traffic laws are only relevant in complicated specific scenarios.  

Existing approaches to testing ADS either focus on simple oracles such as no-collision or have limited capacity in generating diverse law-violating scenarios.  
In this work, we propose ABLE, a new ADS testing method inspired by the success of GFlowNet, which Aims to Break many Laws Efficiently by generating diverse scenarios.  
Different from vanilla GFlowNet, ABLE drives the testing process with dynamically updated testing objectives (based on a robustness semantics of signal temporal logic) as well as active learning, so as to effectively explore the vast search space.  
We evaluate ABLE based on Apollo and LGSVL, and the results show that ABLE outperforms the state-of-the-art by violating 17\% and 25\% more laws when testing Apollo 6.0 and Apollo 7.0, most of which are hard-to-violate laws, respectively.},
booktitle = {Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {942–953},
numpages = {12},
keywords = {Automated Driving System, Baidu Apollo, Generative Flow Network, Testing Scenario Generation, Traffic Laws},
location = {Seattle, WA, USA},
series = {ISSTA 2023}
}

@inproceedings{10.1145/3597926.3598109,
author = {Zohdinasab, Tahereh and Riccio, Vincenzo and Tonella, Paolo},
title = {DeepAtash: Focused Test Generation for Deep Learning Systems},
year = {2023},
isbn = {9798400702211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597926.3598109},
doi = {10.1145/3597926.3598109},
abstract = {When deployed in the operation environment, Deep Learning (DL) systems often experience the so-called development to operation (dev2op) data shift, which causes a lower prediction accuracy on field data as compared to the one measured on the test set during development. To address the dev2op shift, developers must obtain new data with the newly observed features, as these are under-represented in the train/test set, and must use them to fine tune the DL model, so as to reach the desired accuracy level.  
In this paper, we address the issue of acquiring new data with the specific features observed in operation, which caused a dev2op shift, by proposing DeepAtash, a novel search-based focused testing approach for DL systems.  
DeepAtash targets a cell in the feature space, defined as a combination of feature ranges, to generate misbehaviour-inducing inputs with predefined features.  
Experimental results show that DeepAtash was able to generate up to 29X more targeted, failure-inducing inputs than the baseline approach. The inputs generated by DeepAtash were useful to significantly improve the quality of the original DL systems through fine tuning not only on data with the targeted features, but quite surprisingly also on inputs drawn from the original distribution.},
booktitle = {Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {954–966},
numpages = {13},
keywords = {deep learning, search based software engineering, software testing},
location = {Seattle, WA, USA},
series = {ISSTA 2023}
}

@inproceedings{10.1145/3597926.3598131,
author = {Kim, Myeongsoo and Corradini, Davide and Sinha, Saurabh and Orso, Alessandro and Pasqua, Michele and Tzoref-Brill, Rachel and Ceccato, Mariano},
title = {Enhancing REST API Testing with NLP Techniques},
year = {2023},
isbn = {9798400702211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597926.3598131},
doi = {10.1145/3597926.3598131},
abstract = {RESTful services are commonly documented using OpenAPI specifications. Although numerous automated testing techniques have been proposed that leverage the machine-readable part of these specifications to guide test generation, their human-readable part has been mostly neglected. This is a missed opportunity, as natural language descriptions in the specifications often contain relevant information, including example values and inter-parameter dependencies, that can be used to improve test generation. In this spirit, we propose NLPtoREST, an automated approach that applies natural language processing techniques to assist REST API testing. Given an API and its specification, NLPtoREST extracts additional OpenAPI rules from the human-readable part of the specification. It then enhances the original specification by adding these rules to it. Testing tools can transparently use the enhanced specification to perform better test case generation. Because rule extraction can be inaccurate, due to either the intrinsic ambiguity of natural language or mismatches between documentation and implementation, NLPtoREST also incorporates a validation step aimed at eliminating spurious rules. We performed studies to assess the effectiveness of  
our rule extraction and validation approach, and the impact of enhanced specifications on the performance of eight state-of-the-art REST API testing tools. Our results are encouraging and show that NLPtoREST can extract many relevant rules with high accuracy, which can in turn significantly improve testing tools’ performance.},
booktitle = {Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {1232–1243},
numpages = {12},
keywords = {Automated REST API Testing, Natural Language Processing for Testing, OpenAPI Specification Analysis},
location = {Seattle, WA, USA},
series = {ISSTA 2023}
}

@inproceedings{10.1145/3597926.3598135,
author = {Wu, Yi and Jiang, Nan and Pham, Hung Viet and Lutellier, Thibaud and Davis, Jordan and Tan, Lin and Babkin, Petr and Shah, Sameena},
title = {How Effective Are Neural Networks for Fixing Security Vulnerabilities},
year = {2023},
isbn = {9798400702211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597926.3598135},
doi = {10.1145/3597926.3598135},
abstract = {Security vulnerability repair is a difficult task that is in dire need of automation. Two groups of techniques have shown promise: (1) large code language models (LLMs) that have been pre-trained on source code for tasks such as code completion, and (2) automated program repair (APR) techniques that use deep learning (DL) models to automatically fix software bugs. This paper is the first to study and compare Java vulnerability repair capabilities of LLMs and DL-based APR models. The contributions include that we (1) apply and evaluate five LLMs (Codex, CodeGen, CodeT5, PLBART and InCoder), four fine-tuned LLMs, and four DL-based APR techniques on two real-world Java vulnerability benchmarks (Vul4J and VJBench), (2) design code transformations to address the training and test data overlapping threat to Codex, (3) create a new Java vulnerability repair benchmark VJBench, and its transformed version VJBench-trans, to better evaluate LLMs and APR techniques, and (4) evaluate LLMs and APR techniques on the transformed vulnerabilities in VJBench-trans. Our findings include that (1) existing LLMs and APR models fix very few Java vulnerabilities. Codex fixes 10.2 (20.4\%), the most number of vulnerabilities. Many of the generated patches are uncompilable patches. (2) Fine-tuning with general APR data improves LLMs’ vulnerability-fixing capabilities. (3) Our new VJBench reveals that LLMs and APR models fail to fix many Common Weakness Enumeration (CWE) types, such as CWE-325 Missing cryptographic step and CWE-444 HTTP request smuggling. (4) Codex still fixes 8.7 transformed vulnerabilities, outperforming all the other LLMs and APR models on transformed vulnerabilities. The results call for innovations to enhance automated Java vulnerability repair such as creating larger vulnerability repair training data, tuning LLMs with such data, and applying code simplification transformation to facilitate vulnerability repair.},
booktitle = {Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {1282–1294},
numpages = {13},
keywords = {AI and Software Engineering, Automated Program Repair, Language Model, Vulnerability},
location = {Seattle, WA, USA},
series = {ISSTA 2023}
}

@inproceedings{10.1145/3597926.3598141,
author = {Kabor\'{e}, Abdoul Kader and Barr, Earl T. and Klein, Jacques and Bissyand\'{e}, Tegawend\'{e} F.},
title = {CodeGrid: A Grid Representation of Code},
year = {2023},
isbn = {9798400702211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597926.3598141},
doi = {10.1145/3597926.3598141},
abstract = {Code representation is a key step in the application of AI in software engineering. Generic NLP representations are effective but do not exploit all the rich structure inherent to code. Recent work has focused on extracting abstract syntax trees (AST) and integrating their structural information into code representations.These AST-enhanced representations advanced the state of the art and accelerated new applications of AI to software engineering. ASTs, however, neglect important aspects of code structure, notably control and data flow, leaving some potentially relevant code signal unexploited. For example, purely image-based representations perform nearly as well as AST-based representations, despite the fact that they must learn to even recognize tokens, let alone their semantics. This result, from prior work, is strong evidence that these new code representations can still be improved; it also raises the question of just what signal image-based approaches are exploiting. We answer this question. We show that code is spatial and exploit this fact to propose , a new representation that embeds tokens into a grid that preserves code layout. Unlike some of the existing state of the art, is agnostic to the downstream task: whether that task is generation or classification, can complement the learning algorithm with spatial signal. For example, we show that CNNs, which are inherently spatially-aware models, can exploit outputs to effectively tackle fundamental software engineering tasks, such as code classification, code clone detection and vulnerability detection. PixelCNN leverages ’s grid representations to achieve code completion. Through extensive experiments, we validate our spatial code hypothesis, quantifying model performance as we vary the degree to which the representation preserves the grid. To demonstrate its generality, we show that augments models, improving their performance on a range of tasks, On clone detection, improves ASTNN’s performance by 3.3\% F1 score.},
booktitle = {Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {1357–1369},
numpages = {13},
keywords = {Code TypeSetting, Spatial-Aware Neural Network},
location = {Seattle, WA, USA},
series = {ISSTA 2023}
}

@proceedings{10.1145/3598151,
title = {RobCE '23: Proceedings of the 2023 3rd International Conference on Robotics and Control Engineering},
year = {2023},
isbn = {9781450398107},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Nanjing, China}
}

@proceedings{10.1145/3598438,
title = {ISBDAI '22: Proceedings of the 2022 3rd International Symposium on Big Data and Artificial Intelligence},
year = {2022},
isbn = {9781450396882},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Singapore, Singapore}
}

@proceedings{10.1145/3598469,
title = {dg.o '23: Proceedings of the 24th Annual International Conference on Digital Government Research},
year = {2023},
isbn = {9798400708374},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Gda?sk, Poland}
}

@proceedings{10.1145/3599589,
title = {ICMIP '23: Proceedings of the 2023 8th International Conference on Multimedia and Image Processing},
year = {2023},
isbn = {9781450399586},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tianjin, China}
}

@proceedings{10.1145/3599640,
title = {ICETT '23: Proceedings of the 9th International Conference on Education and Training Technologies},
year = {2023},
isbn = {9781450399593},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Macau, China}
}

@proceedings{10.1145/3599696,
title = {OASIS '23: Proceedings of the 3rd International Workshop on Open Challenges in Online Social Networks},
year = {2023},
isbn = {9798400702259},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rome, Italy}
}

@proceedings{10.1145/3599733,
title = {e-Energy '23 Companion: Companion Proceedings of the 14th ACM International Conference on Future Energy Systems},
year = {2023},
isbn = {9798400702273},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Orlando, FL, USA}
}

@proceedings{10.1145/3599957,
title = {RACS '23: Proceedings of the 2023 International Conference on Research in Adaptive and Convergent Systems},
year = {2023},
isbn = {9798400702280},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {With the expansion of both the Internet and the advanced information technology development profession, reliable and convergent computing has attracted increasing interest in both academia and industry. To cope with this important problem, the Research in Adaptive and Convergent Systems (RACS) provides a forum for exchanging highly original ideas about an important class of computing systems. The RACS aims primarily at researchers who have experience in reliable and convergent computing systems and are engaged in the design and implementation of new computing applications. Each year RACS brings together engineers and scientists from diverse communities with interests in practical computing technologies and creates an environment for them to discuss and report experimental results, novel designs, work-in-progress, experiences, case studies, and trend-setting ideas.},
location = {Gdansk, Poland}
}

@proceedings{10.1145/3600006,
title = {SOSP '23: Proceedings of the 29th Symposium on Operating Systems Principles},
year = {2023},
isbn = {9798400702297},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the Proceedings of the 29th ACM Symposium on Operating Systems Principles (SOSP 2023). This year's program includes 43 papers that reflect today's broad range of topics that comprise modern computer systems research. The program committee carefully reviewed submitted papers and worked closely with the authors of selected papers to produce the collection of high-quality, readable papers presented here. We hope that you enjoy the program!},
location = {Koblenz, Germany}
}

@proceedings{10.1145/3600061,
title = {APNet '23: Proceedings of the 7th Asia-Pacific Workshop on Networking},
year = {2023},
isbn = {9798400707827},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hong Kong, China}
}

@proceedings{10.1145/3600100,
title = {BuildSys '23: Proceedings of the 10th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
year = {2023},
isbn = {9798400702303},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Istanbul, Turkey}
}

@inproceedings{10.1145/3600100.3623748,
author = {Almashor, Mahathir and Rana, Mashud and McCulloch, John and Rahman, Ashfaqur and Sethuvenkatraman, Subbu},
title = {What's The Point: AutoEncoding Building Point Names},
year = {2023},
isbn = {9798400702303},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600100.3623748},
doi = {10.1145/3600100.3623748},
abstract = {Deciphering the point names of various equipment within commercial buildings remains a vexing challenge. Both the lack of standards, and the usual idiosyncrasies in naming conventions, add to the complexity faced by engineers as they attempt to analyse and optimise a building’s systems. For example, T, Tmp, Temp, C, and Celsius could all be used to denote a temperature sensor. Likewise, the delimiters (e.g., ., -, or _) that apportion parts of a point name varies considerably. This results in the possibility of both f1-AHU_tmp and Floor02.AHU.Temperature appearing in the same dataset (and often even within the same building). The initial work here explores foundational deep-learning techniques to help a human expert understand previously unseen building point names. We’ve applied a simplified yet effective neural-network architecture called AutoEncoders (AE) to the task, with tests done against an expansive dataset comprising of point names gathered from publicly available Brick and Mortar datasets, as well as a private corpus. This novel implementation is augmented by a unique sequential tokenising method that applies tri-grams in a sliding window over the point names, which preserves both the linearity and delimiters within point names. This is diametrically opposed to prior approaches that have either ignored the character sequences and/or removed the presence of delimiting characters. Early results show promising 91\% accuracy levels achieved against previously unseen point names.},
booktitle = {Proceedings of the 10th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {256–260},
numpages = {5},
keywords = {auto-encoders, brick schema, building management systems, building point names, metadata inference, neural-networks},
location = {Istanbul, Turkey},
series = {BuildSys '23}
}

@proceedings{10.1145/3600160,
title = {ARES '23: Proceedings of the 18th International Conference on Availability, Reliability and Security},
year = {2023},
isbn = {9798400707728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Benevento, Italy}
}

@inproceedings{10.1145/3600160.3605069,
author = {Castiglione, Gianpietro and Bella, Giampaolo and Santamaria, Daniele Francesco},
title = {Towards Grammatical Tagging for the Legal Language of Cybersecurity},
year = {2023},
isbn = {9798400707728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600160.3605069},
doi = {10.1145/3600160.3605069},
abstract = {Legal language can be understood as the language typically used by those engaged in the legal profession and, as such, it may come both in spoken or written form. Recent legislation on cybersecurity obviously uses legal language in writing, thus inheriting all its interpretative complications due to the typical abundance of cases and sub-cases as well as to the general richness in detail. This paper faces the challenge of the essential interpretation of the legal language of cybersecurity, namely of the extraction of the essential Parts of Speech (POS) from the legal documents concerning cybersecurity. The challenge is overcome by our methodology for POS tagging of legal language. It leverages state-of-the-art open-source tools for Natural Language Processing (NLP) as well as manual analysis to validate the outcomes of the tools. As a result, the methodology is automated and, arguably, general for any legal language following minor tailoring of the preprocessing step. It is demonstrated over the most relevant EU legislation on cybersecurity, namely on the NIS 2 directive, producing the first, albeit essential, structured interpretation of such a relevant document. Moreover, our findings indicate that tools such as SpaCy and ClausIE reach their limits over the legal language of the NIS 2.},
booktitle = {Proceedings of the 18th International Conference on Availability, Reliability and Security},
articleno = {82},
numpages = {9},
keywords = {Act, Data Protection, NLP, POS tagging, Privacy, Pronouncement},
location = {Benevento, Italy},
series = {ARES '23}
}

@inproceedings{10.1145/3600160.3605090,
author = {Merzouk, Mohamed Amine and Cuppens, Fr\'{e}d\'{e}ric and Boulahia-Cuppens, Nora and Yaich, Reda},
title = {Parameterizing poisoning attacks in federated learning-based intrusion detection},
year = {2023},
isbn = {9798400707728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600160.3605090},
doi = {10.1145/3600160.3605090},
abstract = {Federated learning is a promising research direction in network intrusion detection. It enables collaborative training of machine learning models without revealing sensitive data. However, the lack of transparency in federated learning creates a security threat. Since the server cannot ensure the clients’ reliability by analyzing their data, malicious clients have the opportunity to insert a backdoor in the model and activate it to evade detection. To maximize their chances of success, adversaries must fine-tune the attack parameters. Here we evaluate the impact of four attack parameters on the effectiveness, stealthiness, consistency, and timing of data poisoning attacks. Our results show that each parameter is decisive for the success of poisoning attacks, provided they are carefully adjusted to avoid damaging the model’s accuracy or the data’s consistency. Our findings serve as guidelines for the security evaluation of federated learning systems and insights for defense strategies. Our experiments are carried out on the UNSW-NB15 dataset, and their implementation is available in a public code repository.},
booktitle = {Proceedings of the 18th International Conference on Availability, Reliability and Security},
articleno = {104},
numpages = {8},
keywords = {adversarial attack, backdoor, data poisoning, federated learning, intrusion detection},
location = {Benevento, Italy},
series = {ARES '23}
}

@proceedings{10.1145/3600211,
title = {AIES '23: Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society},
year = {2023},
isbn = {9798400702310},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Montr\'{e}al, QC, Canada}
}

@inproceedings{10.1145/3600211.3604658,
author = {Chan, Alan and Bradley, Herbie and Rajkumar, Nitarshan},
title = {Reclaiming the Digital Commons: A Public Data Trust for Training Data},
year = {2023},
isbn = {9798400702310},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600211.3604658},
doi = {10.1145/3600211.3604658},
abstract = {Democratization of AI means not only that people can freely use AI, but also that people can collectively decide how AI is to be used. In particular, collective decision-making power is required to redress the negative externalities from the development of increasingly advanced AI systems, including degradation of the digital commons and unemployment from automation. The rapid pace of AI development and deployment currently leaves little room for this power. Monopolized in the hands of private corporations, the development of the most capable foundation models has proceeded largely without public input. There is currently no implemented mechanism for ensuring that the economic value generated by such models is redistributed to account for their negative externalities. The citizens that have generated the data necessary to train models do not have input on how their data are to be used. In this work, we propose that a public data trust assert control over training data for foundation models. In particular, this trust should scrape the internet as a digital commons, to license to commercial model developers for a percentage cut of revenues from deployment. First, we argue in detail for the existence of such a trust. We also discuss feasibility and potential risks. Second, we detail a number of ways for a data trust to incentivize model developers to use training data only from the trust. We propose a mix of verification mechanisms, potential regulatory action, and positive incentives. We conclude by highlighting other potential benefits of our proposed data trust and connecting our work to ongoing efforts in data and compute governance.},
booktitle = {Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {855–868},
numpages = {14},
keywords = {data rights, data trust, digital commons, training data},
location = {Montr\'{e}al, QC, Canada},
series = {AIES '23}
}

@inproceedings{10.1145/3600211.3604672,
author = {Ghosh, Sourojit and Caliskan, Aylin},
title = {ChatGPT Perpetuates Gender Bias in Machine Translation and Ignores Non-Gendered Pronouns: Findings across Bengali and Five other Low-Resource Languages},
year = {2023},
isbn = {9798400702310},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600211.3604672},
doi = {10.1145/3600211.3604672},
abstract = {In this multicultural age, language translation is one of the most performed tasks, and it is becoming increasingly AI-moderated and automated. As a novel AI system, ChatGPT claims to be proficient in machine translation tasks and in this paper, we put that claim to the test. Specifically, we examine ChatGPT’s accuracy in translating between English and languages that exclusively use gender-neutral pronouns. We center this study around Bengali, the 7th most spoken language globally, but also generalize our findings across five other languages: Farsi, Malay, Tagalog, Thai, and Turkish. We find that ChatGPT perpetuates gender defaults and stereotypes assigned to certain occupations (e.g., man = doctor, woman = nurse) or actions (e.g., woman = cook, man = go to work), as it converts gender-neutral pronouns in languages to ‘he’ or ‘she’. We also observe ChatGPT completely failing to translate the English gender-neutral singular pronoun ‘they’ into equivalent gender-neutral pronouns in other languages, as it produces translations that are incoherent and incorrect. While it does respect and provide appropriately gender-marked versions of Bengali words when prompted with gender information in English, ChatGPT appears to confer a higher respect to men than to women in the same occupation. We conclude that ChatGPT exhibits the same gender biases which have been demonstrated for tools like Google Translate or MS Translator, as we provide recommendations for a human centered approach for future designers of AI systems that perform machine translation to better accommodate such low-resource languages.},
booktitle = {Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {901–912},
numpages = {12},
keywords = {Bengali, ChatGPT, gender bias, human-centered design, language models, machine translation},
location = {Montr\'{e}al, QC, Canada},
series = {AIES '23}
}

@inproceedings{10.1145/3600211.3604720,
author = {Ali, Junaid and Kleindessner, Matth\"{a}us and Wenzel, Florian and Budhathoki, Kailash and Cevher, Volkan and Russell, Chris},
title = {Evaluating the Fairness of Discriminative Foundation Models in Computer Vision},
year = {2023},
isbn = {9798400702310},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600211.3604720},
doi = {10.1145/3600211.3604720},
abstract = {We propose a novel taxonomy for bias evaluation of discriminative foundation models, such as Contrastive Language-Pretraining (CLIP), that are used for labeling tasks. We then systematically evaluate existing methods for mitigating bias in these models with respect to our taxonomy. Specifically, we evaluate OpenAI’s CLIP and OpenCLIP models for key applications, such as zero-shot classification, image retrieval and image captioning. We categorize desired behaviors based around three axes: (i) if the task concerns humans; (ii) how subjective the task is (i.e., how likely it is that people from a diverse range of backgrounds would agree on a labeling); and (iii) the intended purpose of the task and if fairness is better served by impartiality (i.e., making decisions independent of the protected attributes) or representation (i.e., making decisions to maximize diversity). Finally, we provide quantitative fairness evaluations for both binary-valued and multi-valued protected attributes over ten diverse datasets. We find that fair PCA, a post-processing method for fair representations, works very well for debiasing in most of the aforementioned tasks while incurring only minor loss of performance. However, different debiasing approaches vary in their effectiveness depending on the task. Hence, one should choose the debiasing approach depending on the specific use case.},
booktitle = {Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {809–833},
numpages = {25},
keywords = {AI fairness, evaluation, foundation models},
location = {Montr\'{e}al, QC, Canada},
series = {AIES '23}
}

@proceedings{10.1145/3603163,
title = {HT '23: Proceedings of the 34th ACM Conference on Hypertext and Social Media},
year = {2023},
isbn = {9798400702327},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rome, Italy}
}

@inproceedings{10.1145/3603163.3609075,
author = {Ro\ss{}ner, Daniel and Atzenbeck, Claus and Brooker, Sam},
title = {SPORE: A Storybreaking Machine},
year = {2023},
isbn = {9798400702327},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3603163.3609075},
doi = {10.1145/3603163.3609075},
abstract = {The paper presents SPORE, a Spatial Recommender System. As we enter a period of unprecedented collaboration between authors and computers, where artificial intelligence in particular seems likely to act increasingly in a co-authoring capacity, SPORE offers a different approach to collaboration. More organic and exploratory than other automated or procedural systems, SPORE aims to mimic the process of storybreaking that already exists in the creative industries.},
booktitle = {Proceedings of the 34th ACM Conference on Hypertext and Social Media},
articleno = {1},
numpages = {6},
keywords = {Mother, education, hypertext, linguistics, recommender system, spatial hypertext, storytelling, tropes},
location = {Rome, Italy},
series = {HT '23}
}

@proceedings{10.1145/3603165,
title = {ACM TURC '23: Proceedings of the ACM Turing Award Celebration Conference - China 2023},
year = {2023},
isbn = {9798400702334},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Wuhan, China}
}

@book{10.1145/3603178,
author = {Talia, Domenico},
title = {From Algorithms to Thinking Machines: The New Digital Power},
year = {2023},
isbn = {9798400708572},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {1},
volume = {54},
abstract = {This book introduces and provides an analysis of the basic concepts of algorithms, data, and computation and discusses the role of algorithms in ruling and shaping our world. It provides a clear understanding of the power and impact on humanity of the pervasive use of algorithms.From Algorithms to Thinking Machines combines a layman’s approach with a well-founded scientific description to discuss both principles and applications of algorithms, Big Data, and machine intelligence. The book provides a clear and deep description of algorithms, software systems, data-driven applications, machine learning, and data science concepts, as well as the evolution and impact of artificial intelligence.After introducing computing concepts, the book examines the relationships between algorithms and human work, discussing how jobs are being affected and how computers and software programs are influencing human life and the labor sphere. Topics such as value alignment, collective intelligence, Big Data impact, automatic decision methods, social control, and political uses of algorithms are illustrated and discussed at length without excessive technical detail. Issues related to how corporations, governments, and autocratic regimes are exploiting algorithms and machine intelligence methods to influence people, laws, and markets are extensively addressed. Ethics principles in software programming and human value insertion into artificial intelligence algorithms are also discussed.}
}

@book{10.1145/3603195,
author = {Raghavan, Manish},
title = {The Societal Impacts of Algorithmic Decision-Making},
year = {2023},
isbn = {9798400708619},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {1},
volume = {53},
abstract = {This book demonstrates the need for and the value of interdisciplinary research in addressing important societal challenges associated with the widespread use of algorithmic decision-making. Algorithms are increasingly being used to make decisions in various domains such as criminal justice, medicine, and employment. While algorithmic tools have the potential to make decision-making more accurate, consistent, and transparent, they pose serious challenges to societal interests. For example, they can perpetuate discrimination, cause representational harm, and deny opportunities.The Societal Impacts of Algorithmic Decision-Making presents several contributions to the growing body of literature that seeks to respond to these challenges, drawing on techniques and insights from computer science, economics, and law. The author develops tools and frameworks to characterize the impacts of decision-making and incorporates models of behavior to reason about decision-making in complex environments. These technical insights are leveraged to deepen the qualitative understanding of the impacts of algorithms on problem domains including employment and lending.The social harms of algorithmic decision-making are far from being solved. While easy solutions are not presented here, there are actionable insights for those who seek to deploy algorithms responsibly. The research presented within this book will hopefully contribute to broader efforts to safeguard societal values while still taking advantage of the promise of algorithmic decision-making.}
}

@proceedings{10.1145/3603269,
title = {ACM SIGCOMM '23: Proceedings of the ACM SIGCOMM 2023 Conference},
year = {2023},
isbn = {9798400702365},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {New York, NY, USA}
}

@proceedings{10.1145/3603304,
title = {CEEeGov '23: Proceedings of the Central and Eastern European eDem and eGov Days 2023},
year = {2023},
isbn = {9798400700064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Budapest, Hungary}
}

@proceedings{10.1145/3603421,
title = {ICVARS '23: Proceedings of the 2023 7th International Conference on Virtual and Augmented Reality Simulations},
year = {2023},
isbn = {9781450397469},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Sydney, Australia}
}

@proceedings{10.1145/3603555,
title = {MuC '23: Proceedings of Mensch und Computer 2023},
year = {2023},
isbn = {9798400707711},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rapperswil, Switzerland}
}

@proceedings{10.1145/3603607,
title = {HUMAN '23: Proceedings of the 6th Workshop on Human Factors in Hypertext},
year = {2023},
isbn = {9798400702396},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rome, Italy}
}

@proceedings{10.1145/3603719,
title = {SSDBM '23: Proceedings of the 35th International Conference on Scientific and Statistical Database Management},
year = {2023},
isbn = {9798400707469},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Los Angeles, CA, USA}
}

@inproceedings{10.1145/3603719.3603737,
author = {Biggs, Mikayla and Wang, Yaohua and Soni, Neetu and Priya, Sarv and Bathla, Girish and Canahuate, Guadalupe},
title = {Evaluating Autoencoders for Dimensionality Reduction of MRI-derived Radiomics and Classification of Malignant Brain Tumors},
year = {2023},
isbn = {9798400707469},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3603719.3603737},
doi = {10.1145/3603719.3603737},
abstract = {Malignant brain tumors including parenchymal metastatic (MET) lesions, glioblastomas (GBM), and lymphomas (LYM) account for 29.7\% of brain cancers. However, the characterization of these tumors from MRI imaging is difficult due to the similarity of their radiologically observed image features. Radiomics is the extraction of quantitative imaging features to characterize tumor intensity, shape, and texture. Applying machine learning over radiomic features could aid diagnostics by improving the classification of these common brain tumors. However, since the number of radiomic features is typically larger than the number of patients in the study, dimensionality reduction is needed to balance feature dimensionality and model complexity. Autoencoders are a form of unsupervised representation learning that can be used for dimensionality reduction. It is similar to PCA but uses a more complex and non-linear model to learn a compact latent space. In this work, we examine the effectiveness of autoencoders for dimensionality reduction on the radiomic feature space of multiparametric MRI images and the classification of malignant brain tumors: GBM, LYM, and MET. We further aim to address the class imbalances imposed by the rarity of lymphomas by examining different approaches to increase overall predictive performance through multiclass decomposition strategies.},
booktitle = {Proceedings of the 35th International Conference on Scientific and Statistical Database Management},
articleno = {1},
numpages = {11},
keywords = {autoencoders, dimensionality reduction, malignant brain tumors, radiomics},
location = {Los Angeles, CA, USA},
series = {SSDBM '23}
}

@proceedings{10.1145/3603765,
title = {ICISDM '23: Proceedings of the 2023 7th International Conference on Information System and Data Mining},
year = {2023},
isbn = {9798400700637},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Atlanta, USA}
}

@proceedings{10.1145/3603781,
title = {CNIOT '23: Proceedings of the 2023 4th International Conference on Computing, Networks and Internet of Things},
year = {2023},
isbn = {9798400700705},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xiamen, China}
}

@inproceedings{10.1145/3603781.3603841,
author = {Huang, Huan and Yang, Wei},
title = {Interpretable Image/Video Compression by Extracting the Least Context Map},
year = {2023},
isbn = {9798400700705},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3603781.3603841},
doi = {10.1145/3603781.3603841},
abstract = {Current deep neural networks based image compression methods lack interpretability. Most of them follow a standard encoder-decoder framework and cannot be directly applied to video compression. We present a novel and interpretable finder-generator framework for image/video compression. The finder analyses the input image and selects important points on a one-channel binary map of the original width and height rather than compresses images into a multi-channel bitstream in a downsampled bottleneck layer. The binary one-channel map output by the finder retains the original width and height to keep the spatial information. We name it the least context map (LCM). The generator analyses the LCM to restore the original image based on its trained parameters. We put forward two different selection strategies for guiding the finder to extract the LCM. By extracting LCMs from images, our framework can reduce the size of real-world traffic surveillance videos by 96\% compared to most common video codecs and by 85\% compared to the next generation video compression codec VP9. This size reduction results from that adjacent frames always share similar LCMs and thus LCMs can be significantly compressed along the time axis. In addition, extensive experiments on Kodak dataset demonstrate our model surpasses the state-of-the-art image compression methods at low bit-rates. We only require an average compressed size of 2.01 kilobytes to achieve a high average MS-SSIM score of 0.9. This size is 50\% smaller than JPEG, 43\% smaller than FRRNN, and 11\% smaller than WebP. Further comparative experiments on image generation demonstrate the LCM is superior to the semantic map and the edge map in higher information capacity and less required storage.},
booktitle = {Proceedings of the 2023 4th International Conference on Computing, Networks and Internet of Things},
pages = {335–342},
numpages = {8},
keywords = {image compression, information processing, least context map, video compression},
location = {Xiamen, China},
series = {CNIOT '23}
}

@proceedings{10.1145/3604078,
title = {ICDIP '23: Proceedings of the 15th International Conference on Digital Image Processing},
year = {2023},
isbn = {9798400708237},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Nanjing, China}
}

@inproceedings{10.1145/3604237.3626883,
author = {Zhang, Shuaicheng and Zhu, Yada and Zhou, Dawei},
title = {TGEditor: Task-Guided Graph Editing for Augmenting Temporal Financial Transaction Networks},
year = {2023},
isbn = {9798400702402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604237.3626883},
doi = {10.1145/3604237.3626883},
abstract = {Recent years have witnessed a growth of research interest in designing powerful graph mining algorithms to discover and characterize the structural pattern of interests from financial transaction networks, motivated by impactful applications including anti-money laundering, identity protection, product promotion, and service promotion. However, state-of-the-art graph mining algorithms often suffer from high generalization errors due to data sparsity, data noisiness, and data dynamics. In the context of mining information from financial transaction networks, the issues of data sparsity, noisiness, and dynamics become particularly acute. Ensuring accuracy and robustness in such evolving systems is of paramount importance. Motivated by these challenges, we propose a fundamental transition from traditional mining to augmentation in the context of financial transaction networks. To navigate this paradigm shift, we introduce TGEditor, a versatile task-guided temporal graph augmentation framework. This framework has been crafted to concurrently preserve the temporal and topological distribution of input financial transaction networks, whilst leveraging the label information from pertinent downstream tasks, denoted as , inclusive of crucial downstream tasks like fraudulent transaction classification. In particular, to efficiently conduct task-specific augmentation, we propose two network editing operators that can be seamlessly optimized via adversarial training, while simultaneously capturing the dynamics of the data: Add operator aims to recover the missing temporal links due to data sparsity, and Prune operator is formulated to remove irrelevant/noisy temporal links due to data noisiness. Extensive results on financial transaction networks demonstrate that TGEditor 1) well preserves the data distribution of the original graph and 2) notably boosts the performance of the prediction models in the tasks of vertex classification and fraudulent transaction detection.},
booktitle = {Proceedings of the Fourth ACM International Conference on AI in Finance},
pages = {219–226},
numpages = {8},
keywords = {Financial transaction networks, generative graph model, temporal graph augmentation},
location = {Brooklyn, NY, USA},
series = {ICAIF '23}
}

@proceedings{10.1145/3604321,
title = {IMXw '23: Proceedings of the 2023 ACM International Conference on Interactive Media Experiences Workshops},
year = {2023},
isbn = {9798400708459},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Nantes, France}
}

@proceedings{10.1145/3604571,
title = {Asian CHI '23: Proceedings of the Asian HCI Symposium 2023},
year = {2023},
isbn = {9798400707612},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Online, Indonesia}
}

@proceedings{10.1145/3604915,
title = {RecSys '23: Proceedings of the 17th ACM Conference on Recommender Systems},
year = {2023},
isbn = {9798400702419},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Singapore, Singapore}
}

@inproceedings{10.1145/3604915.3608811,
author = {Zhao, Yuhan and Chen, Rui and Lai, Riwei and Han, Qilong and Song, Hongtao and Chen, Li},
title = {Augmented Negative Sampling for Collaborative Filtering},
year = {2023},
isbn = {9798400702419},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604915.3608811},
doi = {10.1145/3604915.3608811},
abstract = {Negative sampling is essential for implicit-feedback-based collaborative filtering, which is used to constitute negative signals from massive unlabeled data to guide supervised learning. The state-of-the-art idea is to utilize hard negative samples that carry more useful information to form a better decision boundary. To balance efficiency and effectiveness, the vast majority of existing methods follow the two-pass approach, in which the first pass samples a fixed number of unobserved items by a simple static distribution and then the second pass selects the final negative items using a more sophisticated negative sampling strategy. However, selecting negative samples from the original items in a dataset is inherently restricted due to the limited available choices, and thus may not be able to contrast positive samples well. In this paper, we confirm this observation via carefully designed experiments and introduce two major limitations of existing solutions: ambiguous trap and information discrimination. Our response to such limitations is to introduce “augmented” negative samples that may not exist in the original dataset. This direction renders a substantial technical challenge because constructing unconstrained negative samples may introduce excessive noise that eventually distorts the decision boundary. To this end, we introduce a novel generic augmented negative sampling (ANS) paradigm and provide a concrete instantiation. First, we disentangle hard and easy factors of negative items. Next, we generate new candidate negative samples by augmenting only the easy factors in a regulated manner: the direction and magnitude of the augmentation are carefully calibrated. Finally, we design an advanced negative sampling strategy to identify the final augmented negative samples, which considers not only the score function used in existing methods but also a new metric called augmentation gain. Extensive experiments on real-world datasets demonstrate that our method significantly outperforms state-of-the-art baselines. Our code is publicly available at https://github.com/Asa9aoTK/ANS-Recbole.},
booktitle = {Proceedings of the 17th ACM Conference on Recommender Systems},
pages = {256–266},
numpages = {11},
keywords = {Collaborative filtering, augmented negative sampling, disentanglement learning},
location = {Singapore, Singapore},
series = {RecSys '23}
}

@inproceedings{10.1145/3604915.3609493,
author = {Paparella, Vincenzo and Anelli, Vito Walter and Boratto, Ludovico and Di Noia, Tommaso},
title = {Reproducibility of Multi-Objective Reinforcement Learning Recommendation: Interplay between Effectiveness and Beyond-Accuracy Perspectives},
year = {2023},
isbn = {9798400702419},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604915.3609493},
doi = {10.1145/3604915.3609493},
abstract = {Providing effective suggestions is of predominant importance for successful Recommender Systems (RSs). Nonetheless, the need of accounting for additional multiple objectives has become prominent, from both the final users’ and the item providers’ points of view. This need has led to a new class of RSs, called Multi-Objective Recommender Systems (MORSs). These systems are designed to provide suggestions by considering multiple (conflicting) objectives simultaneously, such as diverse, novel, and fairness-aware recommendations. In this work, we reproduce a state-of-the-art study on MORSs that exploits a reinforcement learning agent to satisfy three objectives, i.e., accuracy, diversity, and novelty of recommendations. The selected study is one of the few MORSs where the source code and datasets are released to ensure the reproducibility of the proposed approach. Interestingly, we find that some challenges arise when replicating the results of the original work, due to the nature of multiple-objective problems. We also extend the evaluation of the approach to analyze the impact of improving user-centered objectives of recommendations (i.e., diversity and novelty) in terms of algorithmic bias. To this end, we take into consideration both popularity and category of the items. We discover some interesting trends in the recommendation performance according to different evaluation metrics. In addition, we see that the multi-objective reinforcement learning approach is responsible for increasing the bias disparity in the output of the recommendation algorithm for those items belonging to positively/negatively biased categories. We publicly release datasets and codes in the following GitHub repository: https://github.com/sisinflab/MORS_reproducibility.},
booktitle = {Proceedings of the 17th ACM Conference on Recommender Systems},
pages = {467–478},
numpages = {12},
keywords = {Bias, Diversity, Fairness, Multi-Objective Recommender Systems, Novelty, Reinforcement Learning},
location = {Singapore, Singapore},
series = {RecSys '23}
}

@proceedings{10.1145/3604930,
title = {HotCarbon '23: Proceedings of the 2nd Workshop on Sustainable Computer Systems},
year = {2023},
isbn = {9798400702426},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Hot Carbon focuses on understanding and addressing the negative environmental impacts of computing's success and computing's proliferation. The objective of the workshop is to foster insights and discussions as well as a growing community that focuses on sustainability of computer systems. We expect this includes innovative approaches to how we build, deploy, operate, and retire our creations, but perhaps even more. For example, software-driven hardware obsolescence that increases E-waste and embodied carbon suggests we must challenge computing's endemic upgrade and throwaway practices, and mindset.},
location = {Boston, MA, USA}
}

@proceedings{10.1145/3604951,
title = {HIP '23: Proceedings of the 7th International Workshop on Historical Document Imaging and Processing},
year = {2023},
isbn = {9798400708411},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {San Jose, CA, USA}
}

@proceedings{10.1145/3605157,
title = {FUZZING 2023: Proceedings of the 2nd International Fuzzing Workshop},
year = {2023},
isbn = {9798400702471},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 2nd International Workshop on Fuzzing (FUZZING 2023), co-located with ISSTA in Seattle, Washington, USA on 17 July 2023. This workshop is the continuation of last year's successful inauguration workshop that introduced a preregistration-based publication process to our community. Similar to last year, this workshop hosts the presentations of the accepted drafts of the registered reports that were accepted as part of the first stage in a two-stage publication process. In the first stage, the program committee (PC) evaluates all submissions based on: (i) the significance and novelty of the hypotheses or techniques and 
(ii) the soundness and reproducibility of the methodology specified to validate the claims or hypotheses -- but explicitly not based on the strength of the (preliminary) results. These draft registered reports are presented and improved at the FUZZING 2023 workshop in Seattle.},
location = {Seattle, WA, USA}
}

@proceedings{10.1145/3605181,
title = {WORDS '23: Proceedings of the 4th Workshop on Resource Disaggregation and Serverless},
year = {2023},
isbn = {9798400702501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Koblenz, Germany}
}

@proceedings{10.1145/3605390,
title = {CHItaly '23: Proceedings of the 15th Biannual Conference of the Italian SIGCHI Chapter},
year = {2023},
isbn = {9798400708060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Torino, Italy}
}

@proceedings{10.1145/3605423,
title = {ICCTA '23: Proceedings of the 2023 9th International Conference on Computer Technology Applications},
year = {2023},
isbn = {9781450399579},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Vienna, Austria}
}

@proceedings{10.1145/3605468,
title = {WiPSCE '23: Proceedings of the 18th WiPSCE Conference on Primary and Secondary Computing Education Research},
year = {2023},
isbn = {9798400708510},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Cambridge, United Kingdom}
}

@proceedings{10.1145/3605573,
title = {ICPP '23: Proceedings of the 52nd International Conference on Parallel Processing},
year = {2023},
isbn = {9798400708435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Salt Lake City, UT, USA}
}

@proceedings{10.1145/3605655,
title = {ECCE '23: Proceedings of the European Conference on Cognitive Ergonomics 2023},
year = {2023},
isbn = {9798400708756},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Swansea, United Kingdom}
}

@proceedings{10.1145/3605731,
title = {ICPP Workshops '23: Proceedings of the 52nd International Conference on Parallel Processing Workshops},
year = {2023},
isbn = {9798400708428},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Salt Lake City, UT, USA}
}

@proceedings{10.1145/3605801,
title = {CNCIT '23: Proceedings of the 2023 2nd International Conference on Networks, Communications and Information Technology},
year = {2023},
isbn = {9798400700620},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Qinghai, China}
}

@article{10.1145/3605943,
author = {Min, Bonan and Ross, Hayley and Sulem, Elior and Veyseh, Amir Pouran Ben and Nguyen, Thien Huu and Sainz, Oscar and Agirre, Eneko and Heintz, Ilana and Roth, Dan},
title = {Recent Advances in Natural Language Processing via Large Pre-trained Language Models: A Survey},
year = {2023},
issue_date = {February 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3605943},
doi = {10.1145/3605943},
abstract = {Large, pre-trained language models (PLMs) such as BERT and GPT have drastically changed the Natural Language Processing (NLP) field. For numerous NLP tasks, approaches leveraging PLMs have achieved state-of-the-art performance. The key idea is to learn a generic, latent representation of language from a generic task once, then share it across disparate NLP tasks. Language modeling serves as the generic task, one with abundant self-supervised text available for extensive training. This article presents the key fundamental concepts of PLM architectures and a comprehensive view of the shift to PLM-driven NLP techniques. It surveys work applying the pre-training then fine-tuning, prompting, and text generation approaches. In addition, it discusses PLM limitations and suggested directions for future research.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {30},
numpages = {40},
keywords = {Large language models, foundational models, generative AI, neural networks}
}

@article{10.1145/3606011,
author = {Videla, Alvaro},
title = {Echoes of Intelligence: Textual interpretation and large language models},
year = {2023},
issue_date = {May/June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {3},
issn = {1542-7730},
url = {https://doi.org/10.1145/3606011},
doi = {10.1145/3606011},
abstract = {We are now in the presence of a new medium disguised as good old text, but that text has been generated by an LLM, without authorial intention—an aspect that, if known beforehand, completely changes the expectations and response a human should have from a piece of text. Should our interpretation capabilities be engaged? If yes, under what conditions? The rules of the language game should be spelled out; they should not be passed over in silence.},
journal = {Queue},
month = jun,
pages = {36–53},
numpages = {18}
}

@proceedings{10.1145/3606037,
title = {SCA '23: Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation},
year = {2023},
isbn = {9798400702686},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Los Angeles, CA, USA}
}

@proceedings{10.1145/3606043,
title = {HP3C '23: Proceedings of the 2023 7th International Conference on High Performance Compilation, Computing and Communications},
year = {2023},
isbn = {9781450399883},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Jinan, China}
}

@proceedings{10.1145/3606094,
title = {ICDEL '23: Proceedings of the 2023 8th International Conference on Distance Education and Learning},
year = {2023},
isbn = {9798400700422},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Beijing, China}
}

@proceedings{10.1145/3606193,
title = {SSPS '23: Proceedings of the 2023 5th International Symposium on Signal Processing Systems},
year = {2023},
isbn = {9798400700040},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Guangzhou, China}
}

@proceedings{10.1145/3606283,
title = {ICGSP '23: Proceedings of the 2023 7th International Conference on Graphics and Signal Processing},
year = {2023},
isbn = {9798400700460},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Fujisawa, Japan}
}

@proceedings{10.1145/3606843,
title = {ITCC '23: Proceedings of the 2023 5th International Conference on Information Technology and Computer Communications},
year = {2023},
isbn = {9798400700583},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tianjin, China}
}

@proceedings{10.1145/3607199,
title = {RAID '23: Proceedings of the 26th International Symposium on Research in Attacks, Intrusions and Defenses},
year = {2023},
isbn = {9798400707650},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hong Kong, China}
}

@inproceedings{10.1145/3607199.3607200,
author = {Bundt, Joshua and Davinroy, Michael and Agadakos, Ioannis and Oprea, Alina and Robertson, William},
title = {Black-box Attacks Against Neural Binary Function Detection},
year = {2023},
isbn = {9798400707650},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3607199.3607200},
doi = {10.1145/3607199.3607200},
abstract = {Binary analyses based on deep neural networks&nbsp;(DNNs), or neural binary analyses&nbsp;(NBAs), have become a hotly researched topic in recent years. DNNs have been wildly successful at pushing the performance and accuracy envelopes in the natural language and image processing domains. Thus, DNNs are highly promising for solving binary analysis problems that are hard due to a lack of complete information resulting from the lossy compilation process. Despite this promise, it is unclear that the prevailing strategy of repurposing embeddings and model architectures originally developed for other problem domains is sound given the adversarial contexts under which binary analysis often operates. In this paper, we empirically demonstrate that the current state of the art in neural function boundary detection is vulnerable to both inadvertent and deliberate adversarial attacks. We proceed from the insight that current generation NBAs are built upon embeddings and model architectures intended to solve syntactic problems. We devise a simple, reproducible, and scalable black-box methodology for exploring the space of inadvertent attacks – instruction sequences that could be emitted by common compiler toolchains and configurations – that exploits this syntactic design focus. We then show that these inadvertent misclassifications can be exploited by an attacker, serving as the basis for a highly effective black-box adversarial example generation process. We evaluate this methodology against two state-of-the-art neural function boundary detectors: XDA and DeepDi. We conclude with an analysis of the evaluation data and recommendations for how future research might avoid succumbing to similar attacks.},
booktitle = {Proceedings of the 26th International Symposium on Research in Attacks, Intrusions and Defenses},
pages = {1–16},
numpages = {16},
keywords = {binary analysis, deep neural network, disassembly, function boundary detection},
location = {Hong Kong, China},
series = {RAID '23}
}

@inproceedings{10.1145/3607199.3607220,
author = {Boucher, Nicholas and Pajola, Luca and Shumailov, Ilia and Anderson, Ross and Conti, Mauro},
title = {Boosting Big Brother: Attacking Search Engines with Encodings},
year = {2023},
isbn = {9798400707650},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3607199.3607220},
doi = {10.1145/3607199.3607220},
abstract = {Search engines are vulnerable to attacks against indexing and searching via text encoding manipulation. By imperceptibly perturbing text using uncommon encoded representations, adversaries can control results across search engines for specific search queries. We demonstrate that this attack is successful against two major commercial search engines - Google and Bing - and one open source search engine - Elasticsearch. We further demonstrate that this attack is successful against LLM chat search including Bing’s GPT-4 chatbot and Google’s Bard chatbot. We also present a variant of the attack targeting text summarization and plagiarism detection models, two ML tasks closely tied to search. We provide a set of defenses against these techniques and warn that adversaries can leverage these attacks to launch disinformation campaigns against unsuspecting users, motivating the need for search engine maintainers to patch deployed systems.},
booktitle = {Proceedings of the 26th International Symposium on Research in Attacks, Intrusions and Defenses},
pages = {700–713},
numpages = {14},
keywords = {attacks, disinformation, indexing, search engines, text encodings},
location = {Hong Kong, China},
series = {RAID '23}
}

@inproceedings{10.1145/3607199.3607232,
author = {Ko, Myeongseob and Yang, Xinyu and Ji, Zhengjie and Just, Hoang Anh and Gao, Peng and Kumar, Anoop and Jia, Ruoxi},
title = {PrivMon: A Stream-Based System for Real-Time Privacy Attack Detection for Machine Learning Models},
year = {2023},
isbn = {9798400707650},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3607199.3607232},
doi = {10.1145/3607199.3607232},
abstract = {Machine learning (ML) models can expose the private information of training data when confronted with privacy attacks. Specifically, a malicious user with black-box access to a ML-as-a-service platform can reconstruct the training data (i.e., model inversion attacks) or infer the membership information (i.e., membership inference attacks) simply by querying the ML model. Despite the pressing need for effective defenses against privacy attacks with black-box access, existing approaches have mostly focused on enhancing the robustness of the ML model via modifying the model training process or the model prediction process. These defenses can compromise model utility and require the cooperation of the underlying AI platform (i.e., platform-dependent). These constraints largely limit the real-world applicability of existing defenses. Despite the prevalent focus on improving the model’s robustness, none of the existing works have focused on the continuous protection of already deployed ML models from privacy attacks by detecting privacy leakage in real-time. This defensive task becomes increasingly important given the vast deployment of ML-as-a-service platforms these days. To bridge the gap, we propose PrivMon, a new stream-based system for real-time privacy attack detection for ML models. To facilitate wide applicability and practicality, PrivMon defends black-box ML models against a wide range of privacy attacks in a platform-agnostic fashion: PrivMon only passively monitors model queries without requiring the cooperation of the model owner or the AI platform. Specifically, PrivMon takes as input a stream of ML model queries and provides an efficient attack detection engine that continuously monitors the stream to detect the privacy attack in real-time, by identifying self-similar malicious queries. We show empirically and theoretically that PrivMon can detect a wide range of realistic privacy attacks within a practical time frame and successfully mitigate the attack success rate. Code is available at https://github.com/ruoxi-jia-group/privmon.},
booktitle = {Proceedings of the 26th International Symposium on Research in Attacks, Intrusions and Defenses},
pages = {264–281},
numpages = {18},
keywords = {detection, label-only attack, machine learning, monitoring, privacy},
location = {Hong Kong, China},
series = {RAID '23}
}

@inproceedings{10.1145/3607199.3607242,
author = {Chen, Yizheng and Ding, Zhoujie and Alowain, Lamya and Chen, Xinyun and Wagner, David},
title = {DiverseVul: A New Vulnerable Source Code Dataset for Deep Learning Based Vulnerability Detection},
year = {2023},
isbn = {9798400707650},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3607199.3607242},
doi = {10.1145/3607199.3607242},
abstract = {We propose and release a new vulnerable source code dataset. We curate the dataset by crawling security issue websites, extracting vulnerability-fixing commits and source codes from the corresponding projects. Our new dataset contains 18,945 vulnerable functions spanning 150 CWEs and 330,492 non-vulnerable functions extracted from 7,514 commits. Our dataset covers 295 more projects than all previous datasets combined. Combining our new dataset with previous datasets, we present an analysis of the challenges and promising research directions of using deep learning for detecting software vulnerabilities. We study 11 model architectures belonging to 4 families. Our results show that deep learning is still not ready for vulnerability detection, due to high false positive rate, low F1 score, and difficulty of detecting hard CWEs. In particular, we demonstrate an important generalization challenge for the deployment of deep learning-based models. We show that increasing the volume of training data may not further improve the performance of deep learning models for vulnerability detection, but might be useful to improve the generalization ability to unseen projects. We also identify hopeful future research directions. We demonstrate that large language models (LLMs) are a promising research direction for ML-based vulnerability detection, outperforming Graph Neural Networks (GNNs) with code-structure features in our experiments. Moreover, developing source code specific pre-training objectives is a promising research direction to improve the vulnerability detection performance.},
booktitle = {Proceedings of the 26th International Symposium on Research in Attacks, Intrusions and Defenses},
pages = {654–668},
numpages = {15},
keywords = {datasets, deep learning, large language models, vulnerability detection},
location = {Hong Kong, China},
series = {RAID '23}
}

@proceedings{10.1145/3607505,
title = {CSET '23: Proceedings of the 16th Cyber Security Experimentation and Test Workshop},
year = {2023},
isbn = {9798400707889},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Marina del Rey, CA, USA}
}

@proceedings{10.1145/3607822,
title = {SUI '23: Proceedings of the 2023 ACM Symposium on Spatial User Interaction},
year = {2023},
isbn = {9798400702815},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Sydney, NSW, Australia}
}

@inproceedings{10.1145/3607827.3616842,
author = {Rossetto, Federico and Dalton, Jeffrey and Murray-Smith, Roderick},
title = {Generating Multimodal Augmentations with LLMs from Song Metadata for Music Information Retrieval},
year = {2023},
isbn = {9798400702839},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3607827.3616842},
doi = {10.1145/3607827.3616842},
abstract = {In this work we propose a set of new automatic text augmentations that leverage Large Language Models from song metadata to improve on music information retrieval tasks. Compared to recent works, our proposed methods leverage large language models and copyright-free corpora from web sources, enabling us to release the knowledge sources collected. We show how combining these representations with the audio signal provides a 21\% relative improvement on five of six datasets on genre classification, emotion recognition and music tagging, achieving state-of-the-art in three (GTZAN, FMA-Small and Deezer). We demonstrate the benefit of injecting external knowledge sources by comparing them withintrinsic text representation methods that rely only on the sample's information.},
booktitle = {Proceedings of the 1st Workshop on Large Generative Models Meet Multimodal Applications},
pages = {51–59},
numpages = {9},
keywords = {large language models application, multimodal learning, music information retrieval},
location = {Ottawa ON, Canada},
series = {LGM3A '23}
}

@inproceedings{10.1145/3607827.3616844,
author = {Chen, Qianqian and Zhang, Tianyi and Nie, Maowen and Wang, Zheng and Xu, Shihao and Shi, Wei and Cao, Zhao},
title = {Fashion-GPT: Integrating LLMs with Fashion Retrieval System},
year = {2023},
isbn = {9798400702839},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3607827.3616844},
doi = {10.1145/3607827.3616844},
abstract = {Customers on a fashion e-commerce platform although expressing their clothing preferences through combined imagery and textual information, they are limited to retrieve with single-round fixed inputs. At the same time, large language models (LLMs) have been gaining attention across various fields. ChatGPT is a remarkable example of an LLM, known for its user-friendly language interface, impressive conversational proficiency, and reasoning abilities. To this end, we propose Fashion-GPT, a system paradigm that integrates ChatGPT with a pool of AI models in the fashion domain to achieve a multi-round multi-modal search. Specifically, it enables the system to utilize the LLMs for understanding user queries, select retrieval models based on their function descriptions, execute each subtask with the selected fashion models, and leverage LLMs to summarize the response corresponding to the execution results.In order to boost the performance dominated by AI experts, we also introduce a novel pre-trained framework called 3M (short for Multi-view Multi-modal Matching). In particular, unlike prior studies that rely solely on one-to-one matching on image-text pair, 3M incorporates multiple texts describing the same image to achieve one-to-many alignment. Maximizing mutual information between features extracted from these views boosts capturing information about high-level factors that influence multiple views, such as the occurrence of specific objects. In addition, with the advantage of the characteristics of fashion data, multi-view images from the same product, like front-view and side-view, are naturally suitable for intra-modal self-alignment. Therefore, 3M also introduces an intra-modal contrastive objective to provide additional benefits in representation learning from the image perspective. To the best of our knowledge, our framework is the first to consider one-to-many mapping for multi-modality representation learning. Experimental evaluations demonstrate that our fashion experts are competitive and achieve state-of-the-art performance, bringing a +3.47\% R@10 boost on Fashion-200K and +1.98\% R@10 boost on the Fashion-IQ dress dataset compared to the previous SOTA results.},
booktitle = {Proceedings of the 1st Workshop on Large Generative Models Meet Multimodal Applications},
pages = {69–78},
numpages = {10},
keywords = {chatgpt-based system with retrieval function, multi-round multi-modal search, multimodal pre-training network},
location = {Ottawa ON, Canada},
series = {LGM3A '23}
}

@proceedings{10.1145/3607947,
title = {IC3-2023: Proceedings of the 2023 Fifteenth International Conference on Contemporary Computing},
year = {2023},
isbn = {9798400700224},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Noida, India}
}

@inproceedings{10.1145/3607947.3607980,
author = {Gupta, Vishu and Lyu, Yuhui and Suarez, Derick and Mao, Yuwei and Liao, Wei-Keng and Choudhary, Alok and Liu, Wing Kam and Cusatis, Gianluca and Agrawal, Ankit},
title = {Physics-based Data-Augmented Deep Learning for Enhanced Autogenous Shrinkage Prediction on Experimental Dataset},
year = {2023},
isbn = {9798400700224},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3607947.3607980},
doi = {10.1145/3607947.3607980},
abstract = {Prediction of the autogenous shrinkage referred to as the reduction of apparent volume of concrete under seal and isothermal conditions is of great significance in the service life analysis and design of durable concrete structures, especially with the increasing use of concrete with low water-to-cement ratios. However, due to the highly complex mechanism of autogenous shrinkage, it is hard to design accurate mechanistic models for it. Existing state-of-the-art models for autogenous shrinkage do not perform well for several reasons such as not being able to capture faster shrinkage change at early ages (swelling), coefficients used are derived using statistical optimization methods to fit certain databases only, and mechanism to identify the most influencing factors on autogenous shrinkage is not present. Moreover, it is also challenging to deploy a machine learning framework directly to perform predictive analysis due to the sparse and noisy nature of the available experimental dataset. In this paper, we study and propose a method to combine the physics-based knowledge and the predictive ability of deep regression neural networks to mitigate the shortcomings of the existing models. We introduce a novel data augmentation technique that utilizes physics based knowledge to improve the accuracy while maintaining the characteristics of autogenous shrinkage in its predictions simultaneously. Using state-of-the-art B4 model, a genetic algorithm, and a deep neural network trained using raw data for comparison, we show that the proposed methods help improve the accuracy of the model as compared to other methods. We also observe that the proposed method is able to successfully learn and predict the swelling component of the shrinkage strain curve as well, which cannot be predicted using the existing state-of-the-art models.},
booktitle = {Proceedings of the 2023 Fifteenth International Conference on Contemporary Computing},
pages = {188–197},
numpages = {10},
keywords = {Autogenous Shrinkage, Deep Learning, Deep Regression, Physics Based Data Augmentation, Predictive Modeling},
location = {Noida, India},
series = {IC3-2023}
}

@proceedings{10.1145/3608164,
title = {ICBBT '23: Proceedings of the 2023 15th International Conference on Bioinformatics and Biomedical Technology},
year = {2023},
isbn = {9798400700385},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xi'an, China}
}

@proceedings{10.1145/3608218,
title = {ICBDE '23: Proceedings of the 2023 6th International Conference on Big Data and Education},
year = {2023},
isbn = {9798400708220},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Jinan, China}
}

@proceedings{10.1145/3608251,
title = {ICCMS '23: Proceedings of the 2023 15th International Conference on Computer Modeling and Simulation},
year = {2023},
isbn = {9798400707919},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Dalian, China}
}

@proceedings{10.1145/3608298,
title = {ICMHI '23: Proceedings of the 2023 7th International Conference on Medical and Health Informatics},
year = {2023},
isbn = {9798400700712},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Kyoto, Japan}
}

@proceedings{10.1145/3609026,
title = {Haskell 2023: Proceedings of the 16th ACM SIGPLAN International Haskell Symposium},
year = {2023},
isbn = {9798400702983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {This is the prelude of the 16th ACM SIGPLAN Haskell Symposium, which was held on 8-9 September 2023 in Seattle, Washington, United States, co-located with ICFP 2023.},
location = {Seattle, WA, USA}
}

@proceedings{10.1145/3609395,
title = {EMS '23: Proceedings of the 2023 Workshop on Emerging Multimedia Systems},
year = {2023},
isbn = {9798400703034},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The workshop is focused on exciting research in augmented and virtual reality (AR/VR), real-time conferencing, AI-generated content, and video analytics.},
location = {New York, NY, USA}
}

@proceedings{10.1145/3609437,
title = {Internetware '23: Proceedings of the 14th Asia-Pacific Symposium on Internetware},
year = {2023},
isbn = {9798400708947},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hangzhou, China}
}

@inproceedings{10.1145/3609437.3609451,
author = {Zhang, Xuejun and Zhang, Fenghe and Zhao, Bo and Zhou, Bo and Xiao, Boyang},
title = {VulD-Transformer: Source Code Vulnerability Detection via Transformer},
year = {2023},
isbn = {9798400708947},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3609437.3609451},
doi = {10.1145/3609437.3609451},
abstract = {The detection of software vulnerability is an important and challenging problem. Existing studies have shown that deep learning-based approaches can significantly improve the performance of vulnerability detection due to their powerful capabilities of automatic learning semantically rich code representation. However, the deep learning-based source code vulnerability detection methods still have limited learning ability for remote contextual dependency information between code statements. In this paper, we propose a deep learning-based code slice-level vulnerability detection via Transformer, dubbed VulD-Transformer, which is designed to detect vulnerabilities more effectively. In VulD-Transformer, transformer model is used to capture the critical features of vulnerabilities of long code slices. Especially, we firstly obtain code slices containing data dependencies and control dependencies by extracting the vulnerability syntax features and programs’ Program Dependency Graphs. Moreover, in order to improve the feature learning capability of the model for remote code statements, we design a Transformer-based vulnerability detection model. The experimental results on four synthetic datasets show that, compared to the VulDeePecker, SySeVR-BGRU, SySeVR-ABGRU and Russell approaches, VulD-Transformer achieves 6.12\%, 8.01\%, and 7.63\% improvement on average in accuracy, recall and F1-measure respectively, when the code slices are more than 256 tokens. In addition, compared with these baselines, VulD-Transformer achieves 9.01\%, 38.51\%, and 20.98\% improvement on average in accuracy, recall and F1-measure respectively on two real source code vulnerability datasets, Devign and REVEAL respectively, which are significantly higher than those of the comparison methods.},
booktitle = {Proceedings of the 14th Asia-Pacific Symposium on Internetware},
pages = {185–193},
numpages = {9},
keywords = {Vulnerabilities detection, control dependencies, data dependencies, deep learning, transformer},
location = {Hangzhou, China},
series = {Internetware '23}
}

@inproceedings{10.1145/3609437.3609466,
author = {Zhou, Bingzhe and Wang, Xinying and Xu, Shengbin and Yao, Yuan and Pan, Minxue and Xu, Feng and Ma, Xiaoxing},
title = {Hybrid API Migration: A Marriage of Small API Mapping Models and Large Language Models},
year = {2023},
isbn = {9798400708947},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3609437.3609466},
doi = {10.1145/3609437.3609466},
abstract = {API migration is an essential step for code migration between libraries or programming languages, and it is a challenging task as it requires detailed comprehension of both source and target APIs. The existing work either recommends mapped API names only and requires developers to select specific parameters and return value, or uses encoder-decoder models to directly “translate” the source API code into the target API code without considering the characteristics of APIs. In this paper, we propose a hybrid approach that combines small API mapping models with Large Language Models (LLMs). Specifically, the small API mapping model is employed to embed API semantics through their usages and declarations, enabling accurate inference of API mappings across different libraries and programming languages. The inferred mappings are subsequently used as part of the prompts to guide LLMs to generate the target API code corresponding to the source API code. Experimental evaluations demonstrate the effectiveness of our approach in comparison to existing approaches w.r.t. both cross-library and cross-language API migration.},
booktitle = {Proceedings of the 14th Asia-Pacific Symposium on Internetware},
pages = {12–21},
numpages = {10},
keywords = {API mapping, API migration, large language models},
location = {Hangzhou, China},
series = {Internetware '23}
}

@proceedings{10.1145/3609703,
title = {PRIS '23: Proceedings of the 2023 5th International Conference on Pattern Recognition and Intelligent Systems},
year = {2023},
isbn = {9781450399968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Shenyang, China}
}

@proceedings{10.1145/3609956,
title = {SSTD '23: Proceedings of the 18th International Symposium on Spatial and Temporal Data},
year = {2023},
isbn = {9798400708992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Calgary, AB, Canada}
}

@proceedings{10.1145/3609987,
title = {CHIGREECE '23: Proceedings of the 2nd International Conference of the ACM Greek SIGCHI Chapter},
year = {2023},
isbn = {9798400708886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Athens, Greece}
}

@article{10.1145/3610035,
author = {Smith, C. Estelle and Miller Hillberg, Hannah and Levonian, Zachary},
title = {"Thoughts \&amp; Prayers" or " ❤️ \&amp; 🙏 ": How the Release of New Reactions on CaringBridge Reshapes Supportive Communication in Health Crises},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {CSCW2},
url = {https://doi.org/10.1145/3610035},
doi = {10.1145/3610035},
abstract = {Following Facebook's introduction of the "Like" in 2009, CaringBridge (a nonprofit health journaling platform) implemented a "Heart" symbol as a single-click reaction affordance in 2012. In 2016, Facebook expanded its Like into a set of emotion-based reactions. In 2021, CaringBridge likewise added three new reactions: "Prayer", "Happy", and "Sad." Through user surveys (N=808) and interviews (N=13), we evaluated this product launch. Unlike Likes on mainstream social media, CaringBridge's single-click Heart was consistently interpreted as a simple, meaningful expression of acknowledgement and support. Although most users accepted the new reactions, the product launch transformed user perceptions of the feature and ignited major disagreement regarding the meanings and functions of reactions in the high stakes context of health crises. Some users found the new reactions to be useful, convenient, and reducing of caregiver burden; others felt they cause emotional harms by stripping communication of meaningful expression and authentic care. Overall, these results surface tensions for small social media platforms that need to survive amidst giants, as well as highlighting crucial trade-offs between the cognitive effort, meaningfulness, and efficiency of different forms of Computer-Mediated Communication (CMC). Our work provides three contributions to support researchers and designers in navigating these tensions: (1) empirical knowledge of how users perceived the reactions launch on CaringBridge; (2) design implications for improving health-focused CMC; and (3) concrete questions to guide future research into reactions and health-focused CMC.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = oct,
articleno = {244},
numpages = {39},
keywords = {affective computing, computer-mediated communication, emoji, emotions, health blog, online health communities, online journaling, prayer, reactions, social media, social support, spiritual support, supportive communication}
}

@article{10.1145/3610041,
author = {Cheatle, Amy and Jackson, Steven},
title = {(Re)collecting Craft: Reviving Materials, Techniques, and Pedagogies of Craft for Computational Makers},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {CSCW2},
url = {https://doi.org/10.1145/3610041},
doi = {10.1145/3610041},
abstract = {This paper examines craft's foundational relations to materials, techniques, and collaborative modes of teaching and learning, and these can be called upon to strengthen and extend computational craft as practiced in fields like CSCW and HCI. Drawing from literature in HCI, craft studies and Science and Technology Studies (STS), we explore craft's modern formation at the dawn of the Industrial Revolution across three formative sites: Scandinavian Sl\"{o}yd, British Arts and Crafts, and Japanese Mingei. From this review we identify three key (and still evolving) features: craft's accountabilities to natural materials and local ecologies; craft's holistic ways of making with 'head, heart, and hand'; and craft's distinctly collaborative and embodied styles of teaching and learning. We then show how these lessons can be applied to contemporary practices and pedagogies of computational making. We argue that doing so can help to rebalance computation's ecological ties and relations, recenter its practice on a sensorially rich and 'whole-self' concept of making, and support more collaborative modes of teaching and learning that are inclusive, relational, and heterogeneous.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = oct,
articleno = {250},
numpages = {23},
keywords = {collaboration, craft and computation, craft studies, history}
}

@article{10.1145/3610077,
author = {Koshy, Vinay and Bajpai, Tanvi and Chandrasekharan, Eshwar and Sundaram, Hari and Karahalios, Karrie},
title = {Measuring User-Moderator Alignment on r/ChangeMyView},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {CSCW2},
url = {https://doi.org/10.1145/3610077},
doi = {10.1145/3610077},
abstract = {Social media sites like Reddit, Discord, and Clubhouse utilize a community-reliant approach to content moderation. Under this model, volunteer moderators are tasked with setting and enforcing content rules within the platforms' sub-communities. However, few mechanisms exist to ensure that the rules set by moderators reflect the values of their community. Misalignments between users and moderators can be detrimental to community health. Yet little quantitative work has been done to evaluate the prevalence or nature of user-moderator misalignment. Through a survey of 798 users on r/ChangeMyView, we evaluate user-moderator alignment at the level of policy-awareness (does users know what the rules are?), practice-awareness (do users know how the rules are applied?) and policy-/practice-support (do users agree with the rules and how they are applied?). We find that policy-support is high, while practice-support is low -- using a hierarchical Bayesian model we estimate the correlation between community opinion and moderator decisions to range from .14 to .45 across subreddit rules. Surprisingly, these correlations were only slightly higher when users were asked to predict moderator actions, demonstrating low awareness of moderation practices. Our findings demonstrate the need for careful analysis of user-moderator alignment at multiple levels. We argue that future work should focus on building tools to empower communities to conduct these analyses themselves.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = oct,
articleno = {286},
numpages = {36},
keywords = {content moderation, content regulation, user-moderator alignment}
}

@article{10.1145/3610172,
author = {Schulenberg, Kelsea and Li, Lingyuan and Lancaster, Caitlin and Zytko, Douglas and Freeman, Guo},
title = {"We Don't Want a Bird Cage, We Want Guardrails": Understanding \&amp; Designing for Preventing Interpersonal Harm in Social VR through the Lens of Consent},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {CSCW2},
url = {https://doi.org/10.1145/3610172},
doi = {10.1145/3610172},
abstract = {As social Virtual Reality (VR) grows in prevalence, new possibilities for embodied and immersive social interaction emerge, including varied forms of interpersonal harm. Yet, challenges remain regarding defining, identifying, and mitigating said harm in social VR. In this paper, we take an alternative approach to understanding and designing solutions for interpersonal harm in social VR through the lens of consent, which circumvents the lack of consensus and social norms on what should be defined as harm in social VR and reflects the embodied, immersive, and offline-world-like nature of harm in social VR. Through interviews with 39 social VR users, we offer one of the first empirical explorations on how social VR users understand consent as "boundaries," (re)purpose existing social VR features for practicing consent as "boundary setting," and envision the design of future consent mechanics in social VR to balance protection and interaction expectations to mitigate interpersonal harm as "boundary violations" in social VR. This work makes significant contributions to CSCW and HCI research by (1) uncovering how social VR users craft novel conceptualizations of consent as boundaries and harm as unwanted boundary violations, and (2) providing three foundational principles for designing future consent mechanics in social VR informed by actual social VR users.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = oct,
articleno = {323},
numpages = {30},
keywords = {computer-meditated consent, interpersonal harm, online social interactions, personal boundaries, social VR}
}

@article{10.1145/3610206,
author = {Lai, Vivian and Zhang, Yiming and Chen, Chacha and Liao, Q. Vera and Tan, Chenhao},
title = {Selective Explanations: Leveraging Human Input to Align Explainable AI},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {CSCW2},
url = {https://doi.org/10.1145/3610206},
doi = {10.1145/3610206},
abstract = {While a vast collection of explainable AI (XAI) algorithms has been developed in recent years, they have been criticized for significant gaps with how humans produce and consume explanations. As a result, current XAI techniques are often found to be hard to use and lack effectiveness. In this work, we attempt to close these gaps by making AI explanations selective ---a fundamental property of human explanations---by selectively presenting a subset of model reasoning based on what aligns with the recipient's preferences. We propose a general framework for generating selective explanations by leveraging human input on a small dataset. This framework opens up a rich design space that accounts for different selectivity goals, types of input, and more. As a showcase, we use a decision-support task to explore selective explanations based on what the decision-maker would consider relevant to the decision task. We conducted two experimental studies to examine three paradigms based on our proposed framework: in Study 1, we ask the participants to provide critique-based or open-ended input to generate selective explanations (self-input). In Study 2, we show the participants selective explanations based on input from a panel of similar users (annotator input). Our experiments demonstrate the promise of selective explanations in reducing over-reliance on AI and improving collaborative decision making and subjective perceptions of the AI system, but also paint a nuanced picture that attributes some of these positive effects to the opportunity to provide one's own input to augment AI explanations. Overall, our work proposes a novel XAI framework inspired by human communication behaviors and demonstrates its potential to encourage future work to make AI explanations more human-compatible.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = oct,
articleno = {357},
numpages = {35},
keywords = {explainable AI, human-AI decision making, selective explanations}
}

@article{10.1145/3610283,
author = {Videla, Alvaro},
title = {Echoes of Intelligence},
year = {2023},
issue_date = {November 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {66},
number = {11},
issn = {0001-0782},
url = {https://doi.org/10.1145/3610283},
doi = {10.1145/3610283},
abstract = {Textual interpretation and large language models.},
journal = {Commun. ACM},
month = oct,
pages = {38–43},
numpages = {6}
}

@proceedings{10.1145/3610602,
title = {ICGJ '23: Proceedings of the 7th International Conference on Game Jams, Hackathons and Game Creation Events},
year = {2023},
isbn = {9798400708794},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Virtual Event, Ukraine}
}

@proceedings{10.1145/3610612,
title = {PPDP '23: Proceedings of the 25th International Symposium on Principles and Practice of Declarative Programming},
year = {2023},
isbn = {9798400708121},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisboa, Portugal}
}

@proceedings{10.1145/3610661,
title = {ICMI '23 Companion: Companion Publication of the 25th International Conference on Multimodal Interaction},
year = {2023},
isbn = {9798400703218},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Paris, France}
}

@inproceedings{10.1145/3610661.3616547,
author = {Delbosc, Alice and Ochs, Magalie and Sabouret, Nicolas and Ravenet, Brian and Ayache, Stephane},
title = {Towards the generation of synchronized and believable non-verbal facial behaviors of a talking virtual agent},
year = {2023},
isbn = {9798400703218},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610661.3616547},
doi = {10.1145/3610661.3616547},
abstract = {This paper introduces a new model to generate rhythmically relevant non-verbal facial behaviors for virtual agents while they speak. The model demonstrates perceived performance comparable to behaviors directly extracted from the data and replayed on a virtual agent, in terms of synchronization with speech and believability. Interestingly, we found that training the model with two different sets of data, instead of one, did not necessarily improve its performance. The expressiveness of the people in the dataset and the shooting conditions are key elements. We also show that employing an adversarial model, in which fabricated fake examples are introduced during the training phase, increases the perception of synchronization with speech. A collection of videos demonstrating the results and code can be accessed at: https://github.com/aldelb/non_verbal_facial_animation.},
booktitle = {Companion Publication of the 25th International Conference on Multimodal Interaction},
pages = {228–237},
numpages = {10},
keywords = {Non-verbal behavior, adversarial learning, behavior generation, embodied conversational agent, encoder-decoder, neural networks},
location = {Paris, France},
series = {ICMI '23 Companion}
}

@article{10.1145/3610907,
author = {Patidar, Prasoon and Goel, Mayank and Agarwal, Yuvraj},
title = {VAX: Using Existing Video and Audio-based Activity Recognition Models to Bootstrap Privacy-Sensitive Sensors},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {3},
url = {https://doi.org/10.1145/3610907},
doi = {10.1145/3610907},
abstract = {The use of audio and video modalities for Human Activity Recognition (HAR) is common, given the richness of the data and the availability of pre-trained ML models using a large corpus of labeled training data. However, audio and video sensors also lead to significant consumer privacy concerns. Researchers have thus explored alternate modalities that are less privacy-invasive such as mmWave doppler radars, IMUs, motion sensors. However, the key limitation of these approaches is that most of them do not readily generalize across environments and require significant in-situ training data. Recent work has proposed cross-modality transfer learning approaches to alleviate the lack of trained labeled data with some success. In this paper, we generalize this concept to create a novel system called VAX (Video/Audio to 'X'), where training labels acquired from existing Video/Audio ML models are used to train ML models for a wide range of 'X' privacy-sensitive sensors. Notably, in VAX, once the ML models for the privacy-sensitive sensors are trained, with little to no user involvement, the Audio/Video sensors can be removed altogether to protect the user's privacy better. We built and deployed VAX in ten participants' homes while they performed 17 common activities of daily living. Our evaluation results show that after training, VAX can use its onboard camera and microphone to detect approximately 15 out of 17 activities with an average accuracy of 90\%. For these activities that can be detected using a camera and a microphone, VAX trains a per-home model for the privacy-preserving sensors. These models (average accuracy = 84\%) require no in-situ user input. In addition, when VAX is augmented with just one labeled instance for the activities not detected by the VAX A/V pipeline (~2 out of 17), it can detect all 17 activities with an average accuracy of 84\%. Our results show that VAX is significantly better than a baseline supervised-learning approach of using one labeled instance per activity in each home (average accuracy of 79\%) since VAX reduces the user burden of providing activity labels by 8x (~2 labels vs. 17 labels).},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {117},
numpages = {24},
keywords = {human activity recognition, privacy first design, ubiquitous sensing}
}

@proceedings{10.1145/3611314,
title = {Web3D '23: Proceedings of the 28th International ACM Conference on 3D Web Technology},
year = {2023},
isbn = {9798400703249},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {San Sebastian, Spain}
}

@proceedings{10.1145/3611450,
title = {AI2A '23: Proceedings of the 2023 3rd International Conference on Artificial Intelligence, Automation and Algorithms},
year = {2023},
isbn = {9798400707605},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Beijing, China}
}

@proceedings{10.1145/3611659,
title = {VRST '23: Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Christchurch, New Zealand}
}

@proceedings{10.1145/3613307,
title = {ICBIP '23: Proceedings of the 2023 8th International Conference on Biomedical Signal and Image Processing},
year = {2023},
isbn = {9798400707698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Chengdu, China}
}

@proceedings{10.1145/3613330,
title = {ICDLT '23: Proceedings of the 2023 7th International Conference on Deep Learning Technologies},
year = {2023},
isbn = {9798400707520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Dalian, China}
}

@proceedings{10.1145/3613372,
title = {SBES '23: Proceedings of the XXXVII Brazilian Symposium on Software Engineering},
year = {2023},
isbn = {9798400707872},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Campo Grande, Brazil}
}

@inproceedings{10.1145/3613372.3613405,
author = {Gomes, Anderson and Maia, Paulo Henrique M.},
title = {DoME: An Architecture for Domain Model Evolution at Runtime Using NLP},
year = {2023},
isbn = {9798400707872},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613372.3613405},
doi = {10.1145/3613372.3613405},
abstract = {In traditional information systems, domain models are represented as database tables with attributes and relationships. Changes in the domain models exist due to system evolution and the emergence of new requirements. In these applications, domain models evolve using CRUD operations requested by users. However, it is necessary to support changes in domain models during the applications’ runtime when new (unforeseen) situations may occur. This work presents an architecture called DoME, which relies on natural language processing (NLP) to allow users to trigger changes in the domain models and self-adaptation techniques to update the models at runtime. It is instantiated in a concrete architecture using a chatbot in Telegram and Transformers Libraries for NLP. The architecture has been preliminary evaluated regarding its assertiveness and user satisfaction, resulting in an 82.55\% hit rate and confirming that NL provides good usability and facilitates data manipulation.},
booktitle = {Proceedings of the XXXVII Brazilian Symposium on Software Engineering},
pages = {186–195},
numpages = {10},
keywords = {Domain Modelling., Generative Artificial Intelligence, Natural Language Processing, Software Architecture},
location = {Campo Grande, Brazil},
series = {SBES '23}
}

@proceedings{10.1145/3614008,
title = {SPML '23: Proceedings of the 2023 6th International Conference on Signal Processing and Machine Learning},
year = {2023},
isbn = {9798400707575},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tianjin, China}
}

@proceedings{10.1145/3615318,
title = {EuroMPI '23: Proceedings of the 30th European MPI Users' Group Meeting},
year = {2023},
isbn = {9798400709135},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bristol, United Kingdom}
}

@inproceedings{10.1145/3615318.3615329,
author = {Adam, Julien and Besnard, Jean-Baptiste and Canat, Paul and Taboada, Hugo and Roussel, Adrien and P\'{e}rache, Marc and Jaeger, Julien and Shende, Sameer},
title = {Generating and Scaling a Multi-Language Test-Suite for MPI},
year = {2023},
isbn = {9798400709135},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3615318.3615329},
doi = {10.1145/3615318.3615329},
abstract = {High-Performance Computing (HPC) is currently facing significant challenges. The hardware pressure has become increasingly difficult to manage due to the lack of parallel abstractions in applications. As a result, parallel programs must undergo drastic evolution to effectively exploit underlying hardware parallelism. Failure to do so results in inefficient code. In this constrained environment, parallel runtimes play a critical role, and their testing becomes crucial. This paper focuses on the MPI interface and leverages the MPI binding tools to develop a multi-language test suite for MPI. By doing so and building on previous work from the Forum document editors, we implement a systematic testing of MPI symbols in the context of the Parallel Computing Validation System (PCVS), which is an HPC validation platform dedicated to running and managing test suites at scale. We first describe PCVS, then outline the process of generating the MPI API test suite, and finally, run these tests at scale. All data sets, code generators, and implementations are made available in open-source to the community. We also set up a dedicated website showcasing the results, which self-updates thanks to the Spack package manager.},
booktitle = {Proceedings of the 30th European MPI Users' Group Meeting},
articleno = {11},
numpages = {10},
keywords = {HPC, MPI, api, test, validation},
location = {Bristol, United Kingdom},
series = {EuroMPI '23}
}

@proceedings{10.1145/3615335,
title = {SIGDOC '23: Proceedings of the 41st ACM International Conference on Design of Communication},
year = {2023},
isbn = {9798400703362},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Orlando, FL, USA}
}

@proceedings{10.1145/3615366,
title = {LADC '23: Proceedings of the 12th Latin-American Symposium on Dependable and Secure Computing},
year = {2023},
isbn = {9798400708442},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {La Paz, Bolivia}
}

@inproceedings{10.1145/3615366.3622793,
author = {Zamir, Bukhtawar and Campos, Jo\~{a}o R. and Vieira, Marco},
title = {Advanced Machine Learning for Runtime Data Generation},
year = {2023},
isbn = {9798400708442},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3615366.3622793},
doi = {10.1145/3615366.3622793},
abstract = {Given the ubiquity of software in everyday critical tasks, ensuring its dependability is of utmost importance. Software faults, which can lead to errors and vulnerabilities, can significantly comprise the target system. Various techniques have been developed to improve the dependability of software-intensive systems, from fault avoidance to fault tolerance. Machine Learning (ML) techniques have been playing a vital role in improving the dependability of systems. Nonetheless, such techniques require significant amounts of data, which are not typically available. To overcome this, various techniques, such as fault injection or intrusion injection, have been proposed to generate realistic data. Still, they are computationally expensive and require considerable expertise. At the same time, a recent growing sub-field of ML is generative models. Generative models offer an innovative solution by creating synthetic data that closely resemble real-world samples. If such models could be used to generate realistic synthetic failure or intrusion data on demand, their value would be significant. Notwithstanding, the feasibility of such an approach has not yet been researched. Generative models have only mostly been used for sequential data (e.g., text or music) or data with high spatial dependency (e.g., images). On the other hand, dependability problems often have high dimensional tabular data, for which generative models are yet to excel, and for which it is also considerably more difficult to assess the representativeness of the generated data. This research will focus on determining the feasibility of using generative techniques to generate runtime data to support dependability research.},
booktitle = {Proceedings of the 12th Latin-American Symposium on Dependable and Secure Computing},
pages = {182–187},
numpages = {6},
keywords = {Machine Learning, Generative Models, Artificial Intelligence},
location = {La Paz, Bolivia},
series = {LADC '23}
}

@proceedings{10.1145/3615452,
title = {ImmerCom '23: Proceedings of the 1st ACM Workshop on Mobile Immersive Computing, Networking, and Systems},
year = {2023},
isbn = {9798400703393},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {This Workshop aims to bring together researchers, engineers, practitioners, and policymakers from academia, industry, and government to discuss the latest research and identify future opportunities for mobile immersive computing, networking, and systems. It solicits high-quality original research and novel developments that promote innovations to advance mobile immersive content delivery, AR/VR/MR, and the metaverse. It also welcomes papers that summarize research challenges, survey existing solutions, and/or propose visionary solutions to ongoing issues in mobile XR and the metaverse.},
location = {Madrid, Spain}
}

@proceedings{10.1145/3615522,
title = {VINCI '23: Proceedings of the 16th International Symposium on Visual Information Communication and Interaction},
year = {2023},
isbn = {9798400707513},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Guangzhou, China}
}

@proceedings{10.1145/3615587,
title = {MobiArch '23: Proceedings of the 18th Workshop on Mobility in the Evolving Internet Architecture},
year = {2023},
isbn = {9798400703416},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Madrid, Spain}
}

@proceedings{10.1145/3615834,
title = {iWOAR '23: Proceedings of the 8th international Workshop on Sensor-Based Activity Recognition and Artificial Intelligence},
year = {2023},
isbn = {9798400708169},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {L\"{u}beck, Germany}
}

@proceedings{10.1145/3615886,
title = {GeoAI '23: Proceedings of the 6th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery},
year = {2023},
isbn = {9798400703485},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Emerging advances from artificial intelligence, hardware accelerators, and data processing architectures continue to reach the geospatial information sciences, with a transformative impact in many societal challenges. Recent breakthroughs in deep learning have brought forward an automated capability to learn hierarchical representational features from massive and complex data, including text, images, and videos. In tandem, rapid innovations in sensing technologies are supporting the collection of geospatial data in even higher resolution and throughput, supporting the observation, mapping, and analysis of different events/phenomena over the earth's surface with unprecedented detail. Combined, these developments are offering potential for breakthroughs in geographic knowledge discovery, impacting decision making in areas such as humanitarian mapping, intelligent transport systems, urban expansion analysis, health data analysis and epidemiology, the study of climate change, handling natural disasters, and the general monitoring of the Earth's surface.},
location = {Hamburg, Germany}
}

@inproceedings{10.1145/3615886.3627739,
author = {Ochiai, Keiichi and Terada, Masayuki and Sano, Hiroaki and Hanashima, Makoto and Usuda, Yuichiro},
title = {Anomaly Detection for Population Dynamics using Autoencoder Leveraging Periodic Residual Component in Disaster Situations},
year = {2023},
isbn = {9798400703485},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3615886.3627739},
doi = {10.1145/3615886.3627739},
abstract = {It is important for local governments to grasp the evacuation situation upon the occurrence of a large-scale disaster because administrative support can be provided, such as opening temporary accommodation facilities or distributing relief supplies. Early identification of locations where population transitions differ from normal conditions will help local governments to identify areas for disaster response. In this paper, we propose a simple yet effective anomaly detection method for population transition using an autoencoder that leverages periodic residual components using real-time population dynamics generated from operation data of cellular phone networks. We evaluated the effectiveness of our proposed method using data from three real earthquakes in Japan. The results demonstrated that our approach, which leverages periodic residual components, outperforms a baseline method that directly uses population transition. Moreover, the experimental results showed that the standard deviation of recall is smaller than that of the baseline method, indicating that utilizing the residual component has a stabilizing effect on accuracy.},
booktitle = {Proceedings of the 6th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery},
pages = {34–42},
numpages = {9},
keywords = {Mobile Phone-Based Population, Disaster Response, Deep Learning, Anomaly Detection},
location = {Hamburg, Germany},
series = {GeoAI '23}
}

@proceedings{10.1145/3615889,
title = {GeoPrivacy '23: Proceedings of the 1st ACM SIGSPATIAL International Workshop on Geo-Privacy and Data Utility for Smart Societies},
year = {2023},
isbn = {9798400703515},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {In an era of increasing reliance on technology, geospatial data plays a crucial role in shaping novel systems that drive decision-making, improve services, and drive innovation in fields ranging from social media and shopping to healthcare and transportation. In particular, the adoption of machine learning and deep learning techniques has heightened the demand for big geospatial data as well as magnified its transformative potential. Nevertheless, the availability and accessibility of this data, coupled with the security considerations surrounding the models that utilize it, have given rise to pressing ethical concerns that warrant our immediate attention. Striking a delicate balance between maximizing data utility and safeguarding individual privacy has become an imperative challenge. The processing of personal data poses inherent risks, including the potential infringement upon privacy rights and the potential for abuse or manipulation. As a result, profound ethical questions emerge, underscoring the interplay between utility and privacy. This workshop aims to bring together researchers and practitioners from diverse fields to delve into the multifaceted dimensions of geospatial data, unravel its potential implications and identify innovative solutions for enabling smart and safe societies.},
location = {Hamburg, Germany}
}

@proceedings{10.1145/3615984,
title = {ISACom '23: Proceedings of the 3rd ACM MobiCom Workshop on Integrated Sensing and Communications Systems},
year = {2023},
isbn = {9798400703645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Madrid, Spain}
}

@proceedings{10.1145/3616195,
title = {AM '23: Proceedings of the 18th International Audio Mostly Conference},
year = {2023},
isbn = {9798400708183},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Edinburgh, United Kingdom}
}

@proceedings{10.1145/3616961,
title = {Mindtrek '23: Proceedings of the 26th International Academic Mindtrek Conference},
year = {2023},
isbn = {9798400708749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tampere, Finland}
}

@inproceedings{10.1145/3616961.3616992,
author = {Buruk, O\u{g}uz 'Oz'},
title = {Academic Writing with GPT-3.5 (ChatGPT): Reflections on Practices, Efficacy and Transparency},
year = {2023},
isbn = {9798400708749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616961.3616992},
doi = {10.1145/3616961.3616992},
abstract = {The debate around the use of GPT-3.5 has been a popular topic among academics since the release of ChatGPT. Whilst some have argued for the advantages of GPT-3.5 in enhancing academic writing, others have raised concerns such as plagiarism, the spread of false information, and ecological issues. The need for finding ways to use GPT-3.5 models transparently has been voiced, and suggestions have been made on social media as to how to use GPT-3.5 models in a smart way. Nevertheless, to date, there is a lack of literature which clearly outlines how to use GPT-3.5 models in academic writing, how effective they are, and how to use them transparently. To address this, I conducted a personal experience experiment with GPT-3.5, specifically by using text-davinci-003 model of OpenAI, for writing this article. I identified six ways of using GPT-3.5: Chunk Stylist, Bullet-to-Paragraph, Talk Textualizer, Research Buddy, Polisher and Rephraser. I reflected on their efficacy, and commented on their potential impact on writing ethics. Additionally, I provided a comprehensive document which shows the prompts I used, results I got from GPT-3.5, the final edits and visually compares those by showing the differences in percentage.},
booktitle = {Proceedings of the 26th International Academic Mindtrek Conference},
pages = {144–153},
numpages = {10},
keywords = {Language Learning Models, LLM, GPT, Ethics of Writing, ChatGPT, Academic Writing, AI},
location = {Tampere, Finland},
series = {Mindtrek '23}
}

@proceedings{10.1145/3617023,
title = {WebMedia '23: Proceedings of the 29th Brazilian Symposium on Multimedia and the Web},
year = {2023},
isbn = {9798400709081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Ribeir\~{a}o Preto, Brazil}
}

@proceedings{10.1145/3617072,
title = {EuroUSEC '23: Proceedings of the 2023 European Symposium on Usable Security},
year = {2023},
isbn = {9798400708145},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Copenhagen, Denmark}
}

@article{10.1145/3617371,
author = {Banerjee, Anasua and Kumar, Vinay and Shankar, Achyut and Jhaveri, Rutvij H. and Banik, Debajyoty},
title = {Automatic Resource Augmentation for Machine Translation in Low Resource Language: EnIndic Corpus},
year = {2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2375-4699},
url = {https://doi.org/10.1145/3617371},
doi = {10.1145/3617371},
abstract = {Parallel corpus is the primary ingredient of machine translation. It is required to train the statistical machine translation (SMT) and neural machine translation (NMT) systems. There is a lack of good quality parallel corpus for Hindi to English. Comparable corpora for a given language pair are comparatively easy to find, but this cannot be used directly in SMT or NMT systems. As a result, we generate a parallel corpus from the comparable corpus. For this purpose, the sentences (which are translations of each other) are mined from the comparable corpus to prepare the parallel corpus. The proposed algorithm uses the length of the sentence and word translation model to align sentence pairs that are translations of each other. Then, the sentence pairs that are poor translations of each other (measured by a similarity score based on IBM model 1 translation probability) are filtered out. We apply this algorithm to comparable corpora, which are crawled from speeches of the President and Vice-President of India, and mined parallel corpora out of them. The prepared parallel corpus contains good quality aligned sentences (with 96.338\% f-score). Subsequently, incorrect sentence pairs are filtered out manually to make the corpus in qualitative practical use. Finally, we gather various sentences from different sources to prepare the EnIndic corpus, which comprises 1,656,207 English-Hindi sentence pairs (miscellaneous domain). We have deployed this prepared largest English-Hindi parallel corpus at https://github.com/debajyoty/EnIndic.git
and the source code at https://github.com/debajyoty/EnIndicSourceCode.git.},
note = {Just Accepted},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = aug,
keywords = {Linguistic Resources and Natural Language Processing, Machine Translation, Comparable Corpus, Parallel Corpus}
}

@proceedings{10.1145/3617694,
title = {EAAMO '23: Proceedings of the 3rd ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization},
year = {2023},
isbn = {9798400703812},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Boston, MA, USA}
}

@inproceedings{10.1145/3617694.3623257,
author = {Salinas, Abel and Shah, Parth and Huang, Yuzhong and McCormack, Robert and Morstatter, Fred},
title = {The Unequal Opportunities of Large Language Models: Examining Demographic Biases in Job Recommendations by ChatGPT and LLaMA},
year = {2023},
isbn = {9798400703812},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3617694.3623257},
doi = {10.1145/3617694.3623257},
abstract = {Warning: This paper discusses and contains content that is offensive or upsetting. Large Language Models (LLMs) have seen widespread deployment in various real-world applications. Understanding these biases is crucial to comprehend the potential downstream consequences when using LLMs to make decisions, particularly for historically disadvantaged groups. In this work, we propose a simple method for analyzing and comparing demographic bias in LLMs, through the lens of job recommendations. We demonstrate the effectiveness of our method by measuring intersectional biases within ChatGPT and LLaMA, two cutting-edge LLMs. Our experiments primarily focus on uncovering gender identity and nationality bias; however, our method can be extended to examine biases associated with any intersection of demographic identities. We identify distinct biases in both models toward various demographic identities, such as both models consistently suggesting low-paying jobs for Mexican workers or preferring to recommend secretarial roles to women. Our study highlights the importance of measuring the bias of LLMs in downstream applications to understand the potential for harm and inequitable outcomes. Our code is available at https://github.com/Abel2Code/Unequal-Opportunities-of-LLMs.},
booktitle = {Proceedings of the 3rd ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization},
articleno = {34},
numpages = {15},
keywords = {Bias across LLMs, Bias analysis, ChatGPT, Demographic Bias, Empirical experiments, Fairness in AI, Intersectionality, LLaMA, Large Language Models, Natural Language Generation, Real-world applications, State-of-the-art models},
location = {Boston, MA, USA},
series = {EAAMO '23}
}

@inproceedings{10.1145/3617694.3623258,
author = {Reid, Kathy and Williams, Elizabeth T.},
title = {Common Voice and accent choice: data contributors self-describe their spoken accents in diverse ways},
year = {2023},
isbn = {9798400703812},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3617694.3623258},
doi = {10.1145/3617694.3623258},
abstract = {The use of machine learning (ML)-powered speech technologies has increased significantly in recent years&nbsp;[40, 56, 72]. The datasets used for training speech models often represent demographic features of the speaker – such as gender, age, and accent. These axes are frequently used to evaluate the training set and model for bias&nbsp;[52]. Here, we focus on how accent is represented in voice data due to the adverse consequences of accent bias. We perform document analysis on several voice datasets to identify how accents are currently represented. We then analyse and visualise speaker-described accents from Mozilla’s Common Voice (CV) v13 English dataset, forming an emergent taxonomy of accent descriptors. We repeat this process using the CV v13 Kiswahili dataset, demonstrating that the taxonomy has use beyond English. We find that accents are currently represented in ways that are geographically, and predominantly, nationally bound. While this pattern is also shown in speaker-described accents from CV, a more diverse set of descriptors is revealed. This work provides some early evidence for re-thinking how accents are represented in datasets intended for ML applications. Our tooling is open-sourced, and we invite further work that uses our taxonomy to assess accent bias in speech data and models.},
booktitle = {Proceedings of the 3rd ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization},
articleno = {35},
numpages = {10},
keywords = {accent bias, accent data, accent recognition, bias, bias corpora, data visualization, dataset documentation, datasets, metadata, speech data, voice data},
location = {Boston, MA, USA},
series = {EAAMO '23}
}

@proceedings{10.1145/3617695,
title = {BDIOT '23: Proceedings of the 2023 7th International Conference on Big Data and Internet of Things},
year = {2023},
isbn = {9798400708015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Beijing, China}
}

@proceedings{10.1145/3617733,
title = {ICCCM '23: Proceedings of the 2023 11th International Conference on Computer and Communications Management},
year = {2023},
isbn = {9798400707735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Nagoya, Japan}
}

@inproceedings{10.1145/3618257.3624829,
author = {Hu, Tianrui and Dubois, Daniel J. and Choffnes, David},
title = {BehavIoT: Measuring Smart Home IoT Behavior Using Network-Inferred Behavior Models},
year = {2023},
isbn = {9798400703829},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3618257.3624829},
doi = {10.1145/3618257.3624829},
abstract = {Smart home IoT platforms are typically closed systems, meaning that there is poor visibility into device behavior. Understanding device behavior is important not only for determining whether devices are functioning as expected, but also can reveal implications for privacy (e.g., surreptitious audio/video recording), security (e.g., device compromise), and safety (e.g., denial of service on a baby monitor). While there has been some work on identifying devices and a handful of activities, an open question is what is the extent to which we can automatically model the entire behavior of an IoT deployment, and how it changes over time, without any privileged access to IoT devices or platform messages.In this work, we demonstrate that the vast majority of IoT behavior can indeed be modeled, using a novel multi-dimensional approach that relies only on the (often encrypted) network traffic exchanged by IoT devices. Our key insight is that IoT behavior (including cross-device interactions) can often be captured using relatively simple models such as timers (for periodic behavior) and probabilistic state-machines (for user-initiated behavior and devices interactions) during a limited observation phase. We then propose deviation metrics that can identify when the behavior of an IoT device or an IoT system changes over time. Our models and metrics successfully identify several notable changes in our IoT deployment, including a camera that changed locations, network outages that impact connectivity, and device malfunctions.},
booktitle = {Proceedings of the 2023 ACM on Internet Measurement Conference},
pages = {421–436},
numpages = {16},
keywords = {behavior modeling, iot, measurement techniques, smart home},
location = {Montreal QC, Canada},
series = {IMC '23}
}

@inproceedings{10.1145/3618257.3624845,
author = {Sarabi, Armin and Yin, Tongxin and Liu, Mingyan},
title = {An LLM-based Framework for Fingerprinting Internet-connected Devices},
year = {2023},
isbn = {9798400703829},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3618257.3624845},
doi = {10.1145/3618257.3624845},
abstract = {In this paper we propose the use of large language models (LLMs) for characterizing, clustering, and fingerprinting raw text obtained from network measurements. To this end, We first train a transformer-based masked language model, namely RoBERTa, on a dataset containing hundreds of millions of banners obtained from Internet-wide scans. We further fine-tune this model using a contrastive loss function (driven by domain knowledge) to produce temporally stable numerical representations (embeddings) that can be used out-of-the-box for downstream learning tasks. Our embeddings are robust, resilient to small random changes in the content of a banner, and maintain proximity between embeddings of similar hardware/software products. We further cluster HTTP banners using a density-based approach (HDBSCAN), and examine the obtained clusters to generate text-based fingerprints for the purpose of labeling raw scan data. We compare our fingerprints to Recog, an existing database of manually curated fingerprints, and show that we can identify new IoT devices and server products that were not previously captured by Recog. Our proposed methodology poses an important direction for future research by utilizing state-of-the-art language models to automatically analyze, interpret, and label the large amounts of data generated by Internet scans.},
booktitle = {Proceedings of the 2023 ACM on Internet Measurement Conference},
pages = {478–484},
numpages = {7},
keywords = {deep learning, device fingerprinting, internet scanning, large language models},
location = {Montreal QC, Canada},
series = {IMC '23}
}

@proceedings{10.1145/3618305,
title = {SPLASH 2023: Companion Proceedings of the 2023 ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications: Software for Humanity},
year = {2023},
isbn = {9798400703843},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to SPLASH 2023, the 38th ACM SIGPLAN International Conference on Systems, Programming, Languages and Applications: Software for Humanity, held in the peaceful town of Cascais, half an hour from Lisbon, Portugal. SPLASH usually takes place over six days, Sunday to Friday, and this year is no exception: Cascais welcomes SPLASH from the 22nd to the 27th October.},
location = {Cascais, Portugal}
}

@proceedings{10.1145/3620678,
title = {SoCC '23: Proceedings of the 2023 ACM Symposium on Cloud Computing},
year = {2023},
isbn = {9798400703874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Santa Cruz, CA, USA}
}

@inproceedings{10.1145/3620678.3624653,
author = {Du, Kuntai and Liu, Yuhan and Hao, Yitian and Zhang, Qizheng and Wang, Haodong and Huang, Yuyang and Ananthanarayanan, Ganesh and Jiang, Junchen},
title = {OneAdapt: Fast Adaptation for Deep Learning Applications via Backpropagation},
year = {2023},
isbn = {9798400703874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3620678.3624653},
doi = {10.1145/3620678.3624653},
abstract = {Deep learning inference on streaming media data, such as object detection in video or LiDAR feeds and text extraction from audio waves, is now ubiquitous. To achieve high inference accuracy, these applications typically require significant network bandwidth to gather high-fidelity data and extensive GPU resources to run deep neural networks (DNNs). While the high demand for network bandwidth and GPU resources could be substantially reduced by optimally adapting the configuration knobs, such as video resolution and frame rate, current adaptation techniques fail to meet three requirements simultaneously: adapt configurations (i) with minimum extra GPU or bandwidth overhead (ii) to reach near-optimal decisions based on how the data affects the final DNN's accuracy, and (iii) do so for a range of configuration knobs. This paper presents OneAdapt, which meets these requirements by leveraging a gradient-ascent strategy to adapt configuration knobs. The key idea is to embrace DNNs' differentiability to quickly estimate the accuracy's gradient to each configuration knob, called AccGrad. Specifically, OneAdapt estimates AccGrad by multiplying two gradients: InputGrad (i.e., how each configuration knob affects the input to the DNN) and DNNGrad (i.e., how the DNN input affects the DNN inference output). We evaluate OneAdapt across five types of configurations, four analytic tasks, and five types of input data. Compared to state-of-the-art adaptation schemes, OneAdapt cuts bandwidth usage and GPU usage by 15-59\% while maintaining comparable accuracy or improves accuracy by 1-5\% while using equal or fewer resources.},
booktitle = {Proceedings of the 2023 ACM Symposium on Cloud Computing},
pages = {158–176},
numpages = {19},
keywords = {backpropagation, configuration adaptation, data analytics},
location = {Santa Cruz, CA, USA},
series = {SoCC '23}
}

@proceedings{10.1145/3622758,
title = {Onward! 2023: Proceedings of the 2023 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
year = {2023},
isbn = {9798400703881},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 2023 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software (Onward! 2023), the premier multidisciplinary conference focused on everything to do with programming and software, including processes, methods, languages, communities and applications. Onward! is more radical, more visionary, and more open than other conferences to ideas that are well-argued but not yet fully proven. We welcome different ways of thinking about, approaching, and reporting on programming language and software engineering research.  

Onward! 2023 is co-located with SPLASH 2023, running from Sunday 22nd of October till Friday 27th of October, in Cascais, Portugal. We are delighted to have Felienne Hermans giving the Onward! keynote, on Wednesday 25th of October, on "Creating a learnable and inclusive programming language".  

All papers and essays that lie here before you received at least three reviews, leading to a decision of accept, reject, or conditional accept. Authors of conditionally accepted papers were provided with explicit requirements for acceptance, and were carefully re-reviewed in the second phase. The essays track received six submissions, out of which four were accepted. The papers track accepted nine out of nineteen submissions.  

We hope that the papers and essays in these proceedings will stimulate and challenge your thinking about programming and software engineering, and we are looking forward to many discussions at the conference.},
location = {Cascais, Portugal}
}

@inproceedings{10.1145/3622758.3622895,
author = {Marron, Mark},
title = {Toward Programming Languages for Reasoning: Humans, Symbolic Systems, and AI Agents},
year = {2023},
isbn = {9798400703881},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3622758.3622895},
doi = {10.1145/3622758.3622895},
abstract = {Integration, composition, mechanization, and AI assisted development are the driving themes in the future of software development. At their core these concepts are rooted in the increasingly important role of computing in our world, the desire to deliver functionality faster, with higher quality, and to empower more people to benefit from programmatic automation. These themes, and how they impact the human developers driving them, are the foundations for the next generation of programming languages. At first glance the needs of mechanization tools, AI agents, and human developers along with the various goals around development velocity, software quality, and software democratization are a broad and seemingly diverse set of needs. However, at their core is a single challenge that, once resolved, enables us to make radical progress in all of these areas. Our hypothesis is that, fundamentally, software development is a problem of reasoning about code and semantics. This is true for human developers implementing a feature, symbolic tools building models of application behaviour, and even for language based AI agents as they perform tasks. While the particular aspects of reasoning that each agent struggles with varies to some degree, they share many common themes and, surprisingly, most mainstream languages extensively employ (anti)features that make this task harder or infeasible! This paper proposes a novel approach to this challenge – instead of new language features or logical constructs, that add more complexity to what is already a problem of complexity, we propose radical simplification in the form of the Bosque platform and language.},
booktitle = {Proceedings of the 2023 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
pages = {136–152},
numpages = {17},
keywords = {Reasoning, Programming Language Design},
location = {Cascais, Portugal},
series = {Onward! 2023}
}

@article{10.1145/3622815,
author = {Wang, Shangwen and Lin, Bo and Sun, Zhensu and Wen, Ming and Liu, Yepang and Lei, Yan and Mao, Xiaoguang},
title = {Two Birds with One Stone: Boosting Code Generation and Code Search via a Generative Adversarial Network},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {OOPSLA2},
url = {https://doi.org/10.1145/3622815},
doi = {10.1145/3622815},
abstract = {Automatically transforming developers' natural language descriptions into source code has been a longstanding goal in software engineering research.  
Two types of approaches have been proposed in the literature to achieve this: code generation, which involves generating a new code snippet, and code search, which involves reusing existing code.  
However, despite existing efforts, the effectiveness of the state-of-the-art techniques remains limited.  
To seek for further advancement, our insight is that code generation and code search can help overcome the limitation of each other:  
the code generator can benefit from feedback on the quality of its generated code, which can be provided by the code searcher, while the code searcher can benefit from the additional training data augmented by the code generator to better understand code semantics.  
Drawing on this insight, we propose a novel approach that combines code generation and code search techniques using a generative adversarial network (GAN), enabling mutual improvement through the adversarial training.  
Specifically, we treat code generation and code search as the generator and discriminator in the GAN framework, respectively, and incorporate several customized designs for our tasks.  
We evaluate our approach in eight different settings, and consistently observe significant performance improvements for both code generation and code search.  
For instance, when using NatGen, a state-of-the-art code generator, as the generator and GraphCodeBERT, a state-of-the-art code searcher, as the discriminator, we achieve a 32\% increase in CodeBLEU score for code generation, and a 12\% increase in mean reciprocal rank for code search on a large-scale Python dataset, compared to their original performances.},
journal = {Proc. ACM Program. Lang.},
month = oct,
articleno = {239},
numpages = {30},
keywords = {Generative Adversarial Network, Code Search, Code Generation}
}

@article{10.1145/3622817,
author = {Greenman, Ben and Felleisen, Matthias and Dimoulas, Christos},
title = {How Profilers Can Help Navigate Type Migration},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {OOPSLA2},
url = {https://doi.org/10.1145/3622817},
doi = {10.1145/3622817},
abstract = {Sound migratory typing envisions a safe and smooth refactoring of untyped code bases to typed ones. However, the cost of enforcing safety with run-time checks is often prohibitively high, thus performance regressions are a likely occurrence. Additional types can often recover performance, but choosing the right components to type is difficult because of the exponential size of the migratory typing lattice. In principal though, migration could be guided by off-the-shelf profiling tools. To examine this hypothesis, this paper follows the rational programmer method and reports on the results of an experiment on tens of thousands of performance-debugging scenarios via seventeen strategies for turning profiler output into an actionable next step. The most effective strategy is the use of deep types to eliminate the most costly boundaries between typed and untyped components; this strategy succeeds in more than 50\% of scenarios if two performance degradations are tolerable along the way.},
journal = {Proc. ACM Program. Lang.},
month = oct,
articleno = {241},
numpages = {30},
keywords = {rational programmer, profiling, migratory typing, gradual typing}
}

@proceedings{10.1145/3622896,
title = {CCRIS '23: Proceedings of the 2023 4th International Conference on Control, Robotics and Intelligent System},
year = {2023},
isbn = {9798400708190},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Guangzhou, China}
}

@proceedings{10.1145/3623263,
title = {SCF '23: Proceedings of the 8th ACM Symposium on Computational Fabrication},
year = {2023},
isbn = {9798400703195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {New York City, NY, USA}
}

@proceedings{10.1145/3623264,
title = {MIG '23: Proceedings of the 16th ACM SIGGRAPH Conference on Motion, Interaction and Games},
year = {2023},
isbn = {9798400703935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rennes, France}
}

@proceedings{10.1145/3623476,
title = {SLE 2023: Proceedings of the 16th ACM SIGPLAN International Conference on Software Language Engineering},
year = {2023},
isbn = {9798400703966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 16th ACM SIGPLAN International Conference on Software Language Engineering (SLE) held in October 2023 as part of SPLASH 2023. Software Language Engineering (SLE) is a thriving research discipline targeted at establishing an engineering approach to the development, use, and maintenance of software languages, that is, of languages for the specification, modeling and tooling of software. Key topics of interest for SLE include approaches, methodologies and tools for language design and implementation with a focus on techniques for static and behavioral semantics, generative or interpretative approaches (including transformation languages and code generation) as well as meta-languages and tools (including language workbenches). Techniques enabling the testing, simulation or formal verification for language validation purposes are also of particular interest. SLE also accommodates empirical evaluation and experience reports of language engineering tools, such as user studies evaluating usability, performance benchmarks or industrial applications.},
location = {Cascais, Portugal}
}

@proceedings{10.1145/3624007,
title = {GPCE 2023: Proceedings of the 22nd ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
year = {2023},
isbn = {9798400704062},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 22nd ACM SIGPLAN International Conference on Generative Programming: Concepts \&amp; Experiences (GPCE’23). GPCE is the premiere venue for researchers and practitioners interested in techniques that use program generation to increase programmer productivity, improve software quality, and shorten the time-to-market of software products. In addition to exploring cutting-edge techniques of generative software, GPCE seeks to foster cross-fertilization between the programming languages research communities.},
location = {Cascais, Portugal}
}

@inproceedings{10.1145/3624007.3624050,
author = {Basso, Matteo and Bonetta, Daniele and Binder, Walter},
title = {Automatically Generated Supernodes for AST Interpreters Improve Virtual-Machine Performance},
year = {2023},
isbn = {9798400704062},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624007.3624050},
doi = {10.1145/3624007.3624050},
abstract = {Abstract syntax tree (AST) interpreters allow implementing programming languages in a straight-forward way. However, AST interpreters implemented in object-oriented languages, such as e.g. in Java, often suffer from two serious performance issues. First, these interpreters commonly implement AST nodes by leveraging class inheritance and polymorphism, leading to many polymorphic call sites in the interpreter implementation and hence lowering interpreter performance. Second, widely used implementations of these interpreters throw costly runtime exceptions to model the control flow. Even though Just-in-Time (JIT) compilation mitigates these issues, performance in the first stages of the program execution remains poor.  

In this paper, we propose a novel technique to improve both interpreter performance and steady-state performance, lowering also the pressure on the JIT compiler. Our technique automatically generates AST supernodes ahead-of-time, i.e., we automatically generate compound AST-node classes that encode the behavior of several other primitive AST nodes before the execution of the application. Our technique extracts common control-flow structures from an arbitrary, given set of ASTs, such as e.g. the functions of popular packages. It is based on matchmaking of AST structures, instantiation of matching supernodes, and replacement of the corresponding AST subtrees with the instantiated supernodes at load-time. We implement our technique in the GraalVM JavaScript engine, showing that our supernodes lead to an average interpreter speedup of 1.24x, an average steady-state speedup of 1.14x, and an average just-in-time compilation speedup of 1.33x on the web-tooling benchmark suite.},
booktitle = {Proceedings of the 22nd ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {1–13},
numpages = {13},
keywords = {Truffle, Performance Optimization, JavaScript, Interpreter, GraalVM, Code Generation, AST},
location = {Cascais, Portugal},
series = {GPCE 2023}
}

@proceedings{10.1145/3624032,
title = {SAST '23: Proceedings of the 8th Brazilian Symposium on Systematic and Automated Software Testing},
year = {2023},
isbn = {9798400716294},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Campo Grande, MS, Brazil}
}

@inproceedings{10.1145/3624032.3624035,
author = {Guilherme, Vitor and Vincenzi, Auri},
title = {An initial investigation of ChatGPT unit test generation capability},
year = {2023},
isbn = {9798400716294},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624032.3624035},
doi = {10.1145/3624032.3624035},
abstract = {Context: Software testing ensures software quality, but developers often disregard it. The use of automated testing generation is pursued to reduce the consequences of overlooked test cases in a software project. Problem: In the context of Java programs, several tools can completely automate generating unit test sets. Additionally, studies are conducted to offer evidence regarding the quality of the generated test sets. However, it is worth noting that these tools rely on machine learning and other AI algorithms rather than incorporating the latest advancements in Large Language Models (LLMs). Solution: This work aims to evaluate the quality of Java unit tests generated by an OpenAI LLM algorithm, using metrics like code coverage and mutation test score. Method: For this study, 33 programs used by other researchers in the field of automated test generation were selected. This approach was employed to establish a baseline for comparison purposes. For each program, 33 unit test sets were generated automatically, without human interference, by changing Open AI API parameters. After executing each test set, metrics such as code line coverage, mutation score, and success rate of test execution were collected to evaluate the efficiency and effectiveness of each set. Summary of Results: Our findings revealed that the OpenAI LLM test set demonstrated similar performance across all evaluated aspects compared to traditional automated Java test generation tools used in the previous research. These results are particularly remarkable considering the simplicity of the experiment and the fact that the generated test code did not undergo human analysis.},
booktitle = {Proceedings of the 8th Brazilian Symposium on Systematic and Automated Software Testing},
pages = {15–24},
numpages = {10},
keywords = {testing tools, software testing, mutation testing, experimental software engineering, coverage testing, automated test generation},
location = {Campo Grande, MS, Brazil},
series = {SAST '23}
}

@proceedings{10.1145/3624062,
title = {SC-W '23: Proceedings of the SC '23 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
year = {2023},
isbn = {9798400707858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Denver, CO, USA}
}

@inproceedings{10.1145/3624062.3624064,
author = {Chen, Brian and Mustakin, Nafis and Hoang, Alvin and Fuad, Sakib and Wong, Daniel},
title = {VSCuda: LLM based CUDA extension for Visual Studio Code},
year = {2023},
isbn = {9798400707858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624062.3624064},
doi = {10.1145/3624062.3624064},
abstract = {The CUDA programming language has developed to constantly accommodate new functionalities since its introduction. For beginners in particular, it is already difficult to remember the expected function parameters of commonly used CUDA features, let alone optimize their code by exploiting newly introduced functionalities. To reduce the burden for CUDA programmers, we propose VSCuda, a Visual Studio Code extension for CUDA C/C++ that includes functionalities including but not limited to CUDA syntax highlighting, code help for all CUDA APIs, code completion for all CUDA functions, and integrated code improvement suggestions from state-of-the-art large language models.},
booktitle = {Proceedings of the SC '23 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
pages = {11–17},
numpages = {7},
keywords = {CUDA, IDE extension, Large Language Models, Visual Studio Code},
location = {Denver, CO, USA},
series = {SC-W '23}
}

@inproceedings{10.1145/3624062.3624172,
author = {Ding, Xianzhong and Chen, Le and Emani, Murali and Liao, Chunhua and Lin, Pei-Hung and Vanderbruggen, Tristan and Xie, Zhen and Cerpa, Alberto and Du, Wan},
title = {HPC-GPT: Integrating Large Language Model for High-Performance Computing},
year = {2023},
isbn = {9798400707858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624062.3624172},
doi = {10.1145/3624062.3624172},
abstract = {Large Language Models (LLMs), including the LLaMA model, have exhibited their efficacy across various general-domain natural language processing (NLP) tasks. However, their performance in high-performance computing (HPC) domain tasks has been less than optimal due to the specialized expertise required to interpret the model’s responses. In response to this challenge, we propose HPC-GPT, a novel LLaMA-based model that has been supervised fine-tuning using generated QA (Question-Answer) instances for the HPC domain. To evaluate its effectiveness, we concentrate on two HPC tasks: managing AI models and datasets for HPC, and data race detection. By employing HPC-GPT, we demonstrate comparable performance with existing methods on both tasks, exemplifying its excellence in HPC-related scenarios. Our experiments on open-source benchmarks yield extensive results, underscoring HPC-GPT’s potential to bridge the performance gap between LLMs and HPC-specific tasks. With HPC-GPT, we aim to pave the way for LLMs to excel in HPC domains, simplifying the utilization of language models in complex computing applications.},
booktitle = {Proceedings of the SC '23 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
pages = {951–960},
numpages = {10},
keywords = {Data Race Detection, High-performance Computing, Large Language Model, Neural Network., OpenMP},
location = {Denver, CO, USA},
series = {SC-W '23}
}

@inproceedings{10.1145/3624062.3624238,
author = {Dhakal, Aditya and Raith, Philipp and Ward, Logan and Hong Enriquez, Rolando P. and Rattihalli, Gourav and Chard, Kyle and Foster, Ian and Milojicic, Dejan},
title = {Fine-grained accelerator partitioning for Machine Learning and Scientific Computing in Function as a Service Platform},
year = {2023},
isbn = {9798400707858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624062.3624238},
doi = {10.1145/3624062.3624238},
abstract = {Function-as-a-service (FaaS) is a promising execution environment for high-performance computing (HPC) and machine learning (ML) applications as it offers developers a simple way to write and deploy programs. Nowadays, GPUs and other accelerators are indispensable for HPC and ML workloads. These accelerators are expensive to acquire and operate; consequently, multiplexing them can increase their financial profitability. However, we have observed that state-of-the-art FaaS frameworks usually treat accelerator as a single device to run single workload and have little support for multiplexing accelerators. In this work, we have presented techniques to multiplex GPUs with Parsl, a popular FaaS framework. We demonstrate why GPU multiplexing is beneficial for certain applications and how we have implemented GPU multiplexing in Parsl. With our enhancements, we show up to 60\% lower task completion time and 250\% improvement in the inference throughput of a large language model when multiplexing a GPU compared to running a single instance without multiplexing. We plan to extend the support for GPU multiplexing in FaaS platforms by tackling the challenges of changing compute resources in the partition and approximating how to right-size a GPU partition for a function.},
booktitle = {Proceedings of the SC '23 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
pages = {1606–1613},
numpages = {8},
location = {Denver, CO, USA},
series = {SC-W '23}
}

@inproceedings{10.1145/3624062.3624539,
author = {Tian, Yongding and Reukers, Matthijs and Al-Ars, Zaid and Hofstee, Peter and Brobbel, Matthijs and Peltenburg, Johan and Straten, Jeroen},
title = {Tydi-lang: A Language for Typed Streaming Hardware},
year = {2023},
isbn = {9798400707858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624062.3624539},
doi = {10.1145/3624062.3624539},
abstract = {Transferring composite data structures with variable-length fields often requires designing unique protocols, causing incompatibility issues and decreased collaboration among hardware developers, especially in the open-source community. Because the high-level meaning of a protocol is often lost in translation to low-level languages when a custom protocol needs to be designed, extra documentation is required, the interpretation of which introduces new opportunities for errors. The Tydi specification (Tydi-spec) was proposed to address the issues by codifying the complex structures in a type and providing a standard protocol to transfer typed data among components. This paper presents Tydi-lang, a language that incorporates Tydi-spec for describing typed streams and offers templates for reusable components. An open-source compiler from Tydi-lang to Tydi intermediate representation (Tydi-IR) is implemented, and a Tydi-IR to VHDL compiler is utilized. Through Tydi-lang examples translating high-level SQL to VHDL, we demonstrate its efficiency in raising abstraction levels and reducing design effort.},
booktitle = {Proceedings of the SC '23 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
pages = {521–529},
numpages = {9},
keywords = {CAD, HDL, streaming data flow},
location = {Denver, CO, USA},
series = {SC-W '23}
}

@inproceedings{10.1145/3624062.3625132,
author = {Iwabuchi, Keita and Steil, Trevor and Priest, Benjamin and Pearce, Roger and Sanders, Geoffrey},
title = {Towards A Massive-scale Distributed Neighborhood Graph Construction},
year = {2023},
isbn = {9798400707858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624062.3625132},
doi = {10.1145/3624062.3625132},
abstract = {Graph-based approximate nearest neighbor algorithms have shown high performance and quality. However, such approaches require a large amount of memory and still take a long time to construct high-quality nearest neighbor graphs (NNGs). Using distributed memory systems is important when data is large or a shorter indexing time is desired. We develop a distributed memory version of NN-Descent, a widely known graph-based ANN algorithm, closely following algorithmic advances by PyNN-Descent authors. Our distributed NN-Descent (DNND) is built on top of MPI and leverages two existing high-performance computing libraries: YGM (an asynchronous communication library) and Metall (a persistent memory allocator). We evaluate the performance of DNND on an HPC system using billion-scale datasets, demonstrating that our approach shows high performance and strong scaling and has great potential for developing massive-scale NNG frameworks.},
booktitle = {Proceedings of the SC '23 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
pages = {730–738},
numpages = {9},
keywords = {approximate nearest neighbor, distributed computing},
location = {Denver, CO, USA},
series = {SC-W '23}
}

@article{10.1145/3624567,
author = {Eren, Maksim E. and Bhattarai, Manish and Joyce, Robert J. and Raff, Edward and Nicholas, Charles and Alexandrov, Boian S.},
title = {Semi-Supervised Classification of Malware Families Under Extreme Class Imbalance via Hierarchical Non-Negative Matrix Factorization with Automatic Model Selection},
year = {2023},
issue_date = {November 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {26},
number = {4},
issn = {2471-2566},
url = {https://doi.org/10.1145/3624567},
doi = {10.1145/3624567},
abstract = {Identification of the family to which a malware specimen belongs is essential in understanding the behavior of the malware and developing mitigation strategies. Solutions proposed by prior work, however, are often not practicable due to the lack of realistic evaluation factors. These factors include learning under class imbalance, the ability to identify new malware, and the cost of production-quality labeled data. In practice, deployed models face prominent, rare, and new malware families. At the same time, obtaining a large quantity of up-to-date labeled malware for training a model can be expensive. In this article, we address these problems and propose a novel hierarchical semi-supervised algorithm, which we call the HNMFk Classifier, that can be used in the early stages of the malware family labeling process. Our method is based on non-negative matrix factorization with automatic model selection, that is, with an estimation of the number of clusters. With HNMFk Classifier, we exploit the hierarchical structure of the malware data together with a semi-supervised setup, which enables us to classify malware families under conditions of extreme class imbalance. Our solution can perform abstaining predictions, or rejection option, which yields promising results in the identification of novel malware families and helps with maintaining the performance of the model when a low quantity of labeled data is used. We perform bulk classification of nearly 2,900 both rare and prominent malware families, through static analysis, using nearly 388,000 samples from the EMBER-2018 corpus. In our experiments, we surpass both supervised and semi-supervised baseline models with an F1 score of 0.80.},
journal = {ACM Trans. Priv. Secur.},
month = nov,
articleno = {48},
numpages = {27},
keywords = {reject-option, abstaining prediction, class imbalance, model selection, hierarchical, semi-supervised, non-negative matrix factorization, malware families, Malware}
}

@proceedings{10.1145/3625078,
title = {BIOTC '23: Proceedings of the 2023 5th Blockchain and Internet of Things Conference},
year = {2023},
isbn = {9798400708213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Osaka, Japan}
}

@inproceedings{10.1145/3625078.3625088,
author = {Shan, Xingzhou},
title = {Text Mining of User Comments Based on Deep Learning},
year = {2023},
isbn = {9798400708213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3625078.3625088},
doi = {10.1145/3625078.3625088},
abstract = {Against the backdrop of the big data era, textual data has experienced an explosive growth trend, necessitating the development of an efficient methodological framework for extracting valuable information from texts. This paper aims to apply text mining techniques to the domain of laptop sales, specifically focusing on mining user comments about laptops to identify their primary concerns when purchasing different laptop brands. The research is divided into three main parts: data acquisition and preprocessing, sentiment analysis, and Latent Dirichlet Allocation (LDA) topic modeling. The study concludes with a summary of the research findings. To begin, data related to laptop comments from JD.com, a leading e-commerce platform, is scraped using Python web scraping techniques. This is followed by a series of text preprocessing tasks, including data cleaning, text tokenization, stop word removal, frequency-based word statistics, and text vector representation. These steps lay a solid foundation for subsequent empirical analysis using models. Furthermore, LDA topic modeling is employed to extract topics from user comments specifically related to the Asus laptop brand. The results of the LDA topic extraction reveal that ASUS laptop users primarily discuss three main aspects: hardware configuration, customer service, and after-sales support, and overall performance and appearance. Finally, the paper concludes by summarizing the research findings and providing some recommendations that can be useful for laptop manufacturers, JD.com, and potential consumers.},
booktitle = {Proceedings of the 2023 5th Blockchain and Internet of Things Conference},
pages = {71–79},
numpages = {9},
location = {Osaka, Japan},
series = {BIOTC '23}
}

@proceedings{10.1145/3625135,
title = {DLfM '23: Proceedings of the 10th International Conference on Digital Libraries for Musicology},
year = {2023},
isbn = {9798400708336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Milan, Italy}
}

@proceedings{10.1145/3625156,
title = {ICISS '23: Proceedings of the 2023 6th International Conference on Information Science and Systems},
year = {2023},
isbn = {9798400708206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Edinburgh, United Kingdom}
}

@inproceedings{10.1145/3625156.3625182,
author = {Kuo, Ching and Yang, Shih-Hsuan},
title = {Image Inpainting for Passersby Removal Based on Multi-Scale Dilated Gated Convolution with Generative Adversarial Networks},
year = {2023},
isbn = {9798400708206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3625156.3625182},
doi = {10.1145/3625156.3625182},
abstract = {Passersby often appear in photos taken at popular scenic spots. To remove the unwanted passersby in photos and fill in the empty areas, a typical approach is manually labeling passersby and using software (Photoshop, Snapseed, Photo Retouch) for inpainting. This approach, however, takes long time and may not produce satisfactory and stable results. In this study, we propose an automatic image segmentation and inpainting algorithm for passersby removal, which greatly reduces the labeling and editing time. The passersby are identified by the Mask R-CNN image segmentation technique. The missing areas are estimated using a modified generative adversarial network (GAN) with gated convolutions and a coarse-to-fine refinement structure. A higher number of channels is used in the deep network to improve the learning of image features. Multi-scale dilated convolution is adopted to ensure the transfer of features and to relieve the discontinuity caused by the holes of traditional dilated convolution. Compared with the existing methods, the proposed method preserves the color and structural features of the missing areas more faithfully, and the objective image quality in PSNR is increased by 0.5 dB to 1.1 dB on average.},
booktitle = {Proceedings of the 2023 6th International Conference on Information Science and Systems},
pages = {172–178},
numpages = {7},
keywords = {Gated convolution, Generative adversarial network (GAN), Image inpainting, Passersby removal},
location = {Edinburgh, United Kingdom},
series = {ICISS '23}
}

@proceedings{10.1145/3625469,
title = {IMMS '23: Proceedings of the 2023 6th International Conference on Information Management and Management Science},
year = {2023},
isbn = {9798400707681},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Chengdu, China}
}

@proceedings{10.1145/3626485,
title = {ISS Companion '23: Companion Proceedings of the 2023 Conference on Interactive Surfaces and Spaces},
year = {2023},
isbn = {9798400704253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Pittsburgh, PA, USA}
}

@article{10.1145/3628428,
author = {B., Lalitha and V, Madhurima and Ch, Nandakrishna and Jampani, Satish Babu and J. N., Chandra Sekhar and P., Venkat Reddy},
title = {Data Augmentation based Cross-Lingual Multi-Speaker TTS using DL with Sentiment Analysis},
year = {2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2375-4699},
url = {https://doi.org/10.1145/3628428},
doi = {10.1145/3628428},
abstract = {Text to Speech (TTS) algorithms have made tremendous strides in recent years in terms of their ability to generate speech in a single language that sounds as natural as possible. However, because to a lack of available training data, the synthesis of speech from the same person in various languages continues to be difficult. It might be challenging to locate people who are proficient in numerous languages at a level equivalent to native speakers. Voice conversion is one method that may be used to create a polyglot corpus, which can then be used to solve this problem. This entails making use of a voice representation model that has been trained on 53 different languages through the application of hybrid deep learning in order to capture speaker-invariant qualities. In this study, we present a novel approach for the conversion of voices across different languages by employing Generated Adversarial Networks (GANs) to train a multilingual TTS system. The concept of individual likeness loss in order to address the special difficulty of maintaining one's individual speaking identity during the training process can be offered. This work is focused to provide the impression that voice data coming from a variety of languages and speakers was produced by the same individual, and one way to do so is by using this word. In order to determine the extent to which our model is useful, two experiments that compared it against benchmarks that made use of varying degrees of parameter sharing between languages are carried out. The purpose of these experiments was to evaluate the accuracy of pronunciation as well as the caliber of the synthetic voice during transitions between different languages.},
note = {Just Accepted},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = oct,
keywords = {Sentiment Analysis, Text to Speech Analysis, Cross Lingual Multi-Speaker Analysis}
}

@article{10.14778/3603581.3603600,
author = {Singh, Mukul and S\'{a}nchez, Jos\'{e} Cambronero and Gulwani, Sumit and Le, Vu and Negreanu, Carina and Raza, Mohammad and Verbruggen, Gust},
title = {Cornet: Learning Table Formatting Rules By Example},
year = {2023},
issue_date = {June 2023},
publisher = {VLDB Endowment},
volume = {16},
number = {10},
issn = {2150-8097},
url = {https://doi.org/10.14778/3603581.3603600},
doi = {10.14778/3603581.3603600},
abstract = {Spreadsheets are widely used for table manipulation and presentation. Stylistic formatting of these tables is an important property for presentation and analysis. As a result, popular spreadsheet software, such as Excel, supports automatically formatting tables based on rules. Unfortunately, writing such formatting rules can be challenging for users as it requires knowledge of the underlying rule language and data logic. We present Cornet, a system that tackles the novel problem of automatically learning such formatting rules from user-provided formatted cells. Cornet takes inspiration from advances in inductive programming and combines symbolic rule enumeration with a neural ranker to learn conditional formatting rules. To motivate and evaluate our approach, we extracted tables with over 450K unique formatting rules from a corpus of over 1.8M real worksheets. Since we are the first to introduce the task of automatically learning conditional formatting rules, we compare Cornet to a wide range of symbolic and neural baselines adapted from related domains. Our results show that Cornet accurately learns rules across varying setups. Additionally, we show that in some cases Cornet can find rules that are shorter than those written by users and can also discover rules in spreadsheets that users have manually formatted. Furthermore, we present two case studies investigating the generality of our approach by extending Cornet to related data tasks (e.g., filtering) and generalizing to conditional formatting over multiple columns.},
journal = {Proc. VLDB Endow.},
month = jun,
pages = {2632–2644},
numpages = {13}
}

@article{10.14778/3611479.3611498,
author = {Zhu, Jiongli and Galhotra, Sainyam and Sabri, Nazanin and Salimi, Babak},
title = {Consistent Range Approximation for Fair Predictive Modeling},
year = {2023},
issue_date = {July 2023},
publisher = {VLDB Endowment},
volume = {16},
number = {11},
issn = {2150-8097},
url = {https://doi.org/10.14778/3611479.3611498},
doi = {10.14778/3611479.3611498},
abstract = {This paper proposes a novel framework for certifying the fairness of predictive models trained on biased data. It draws from query answering for incomplete and inconsistent databases to formulate the problem of consistent range approximation (CRA) of fairness queries for a predictive model on a target population. The framework employs background knowledge of the data collection process and biased data, working with or without limited statistics about the target population, to compute a range of answers for fairness queries. Using CRA, the framework builds predictive models that are certifiably fair on the target population, regardless of the availability of external data during training. The framework's efficacy is demonstrated through evaluations on real data, showing substantial improvement over existing state-of-the-art methods.},
journal = {Proc. VLDB Endow.},
month = jul,
pages = {2925–2938},
numpages = {14}
}

@article{10.14778/3611540.3611549,
author = {Zhang, Jiashu and Jiang, Wen and Tang, Bo and Ma, Haoxiang and Cao, Lixun and Jiang, Zhongbin and Nie, Yuanyuan and Wang, Fan and Zhang, Lei and Liang, Yuming},
title = {CDSBen: Benchmarking the Performance of Storage Services in Cloud-Native Database System at ByteDance},
year = {2023},
issue_date = {August 2023},
publisher = {VLDB Endowment},
volume = {16},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3611540.3611549},
doi = {10.14778/3611540.3611549},
abstract = {In this work, we focus on the performance benchmarking problem of storage services in cloud-native database systems, which are widely used in various cloud applications. The core idea of these systems is to separate computation and storage in traditional monolithic OLTP databases. Specifically, we first present the characteristics of two representative real I/O workloads at the storage tier of ByteDance's cloud-native database veDB. We then elaborate the limitations of using standard benchmarks such as TPC-C and YCSB to resemble these workloads. To overcome these limitations, we devise a learning-based I/O workload benchmark called CDS-Ben. We demonstrate the superiority of CDSBen by deploying it at ByteDance and showing that its generated I/O traces accurately resemble the real I/O traces in production. Additionally, we verify the accuracy and flexibility of CDSBen by generating a wide range of I/O workloads with different I/O characteristics.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {3584–3596},
numpages = {13}
}

@article{10.14778/3611540.3611635,
author = {Cheung, Alvin and Ahmad, Maaz Bin Safeer and Haynes, Brandon and Kittivorawong, Chanwut and Laddad, Shadaj and Liu, Xiaoxuan and Wang, Chenglong and Yan, Cong},
title = {Towards Auto-Generated Data Systems},
year = {2023},
issue_date = {August 2023},
publisher = {VLDB Endowment},
volume = {16},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3611540.3611635},
doi = {10.14778/3611540.3611635},
abstract = {After decades of progress, database management systems (DBMSs) are now the backbones of many data applications that we interact with on a daily basis. Yet, with the emergence of new data types and hardware, building and optimizing new data systems remain as difficult as the heyday of relational databases. In this paper, we summarize our work towards automating the building and optimization of data systems. Drawing from our own experience, we further argue that any automation technique must address three aspects: user specification, code generation, and result validation. We conclude by discussing a case study using videos data processing, along with opportunities for future research towards designing data systems that are automatically generated.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {4116–4129},
numpages = {14}
}

@article{10.14778/3626292.3626294,
author = {Arora, Simran and Yang, Brandon and Eyuboglu, Sabri and Narayan, Avanika and Hojel, Andrew and Trummer, Immanuel and R\'{e}, Christopher},
title = {Language Models Enable Simple Systems for Generating Structured Views of Heterogeneous Data Lakes},
year = {2023},
issue_date = {October 2023},
publisher = {VLDB Endowment},
volume = {17},
number = {2},
issn = {2150-8097},
url = {https://doi.org/10.14778/3626292.3626294},
doi = {10.14778/3626292.3626294},
abstract = {A long standing goal in the data management community is developing systems that input documents and output queryable tables without user effort. Given the sheer variety of potential documents, state-of-the art systems make simplifying assumptions and use domain specific training. In this work, we ask whether we can maintain generality by using the in-context learning abilities of large language models (LLMs). We propose and evaluate Evaporate, a prototype system powered by LLMs. We identify two strategies for implementing this system: prompt the LLM to directly extract values from documents or prompt the LLM to synthesize code that performs the extraction. Our evaluations show a cost-quality tradeoff between these two approaches. Code synthesis is cheap, but far less accurate than directly processing each document with the LLM. To improve quality while maintaining low cost, we propose an extended implementation, Evaporate-Code+, which achieves better quality than direct extraction. Our insight is to generate many candidate functions and ensemble their extractions using weak supervision. Evaporate-Code+ outperforms the state-of-the art systems using a sublinear pass over the documents with the LLM. This equates to a 110X reduction in the number of documents the LLM needs to process across our 16 real-world evaluation settings.},
journal = {Proc. VLDB Endow.},
month = oct,
pages = {92–105},
numpages = {14}
}

@article{10.14778/3632093.3632100,
author = {Li, Xiao and Li, Huan and Lu, Hua and Jensen, Christian S. and Pandey, Varun and Markl, Volker},
title = {Missing Value Imputation for Multi-Attribute Sensor Data Streams via Message Propagation},
year = {2023},
issue_date = {November 2023},
publisher = {VLDB Endowment},
volume = {17},
number = {3},
issn = {2150-8097},
url = {https://doi.org/10.14778/3632093.3632100},
doi = {10.14778/3632093.3632100},
abstract = {Sensor data streams occur widely in various real-time applications in the context of the Internet of Things (IoT). However, sensor data streams feature missing values due to factors such as sensor failures, communication errors, or depleted batteries. Missing values can compromise the quality of real-time analytics tasks and downstream applications. Existing imputation methods either make strong assumptions about streams or have low efficiency. In this study, we aim to accurately and efficiently impute missing values in data streams that satisfy only general characteristics in order to benefit real-time applications more widely. First, we propose a message propagation imputation network (MPIN) that is able to recover the missing values of data instances in a time window. We give a theoretical analysis of why MPIN is effective. Second, we present a continuous imputation framework that consists of data update and model update mechanisms to enable MPIN to perform continuous imputation both effectively and efficiently. Extensive experiments on multiple real datasets show that MPIN can outperform the existing data imputers by wide margins and that the continuous imputation framework is efficient and accurate.},
journal = {Proc. VLDB Endow.},
month = nov,
pages = {345–358},
numpages = {14}
}

@article{10.14778/3632093.3632105,
author = {Chen, Yile and Cong, Gao and Anda, Cuauhtemoc},
title = {TERI: An Effective Framework for Trajectory Recovery with Irregular Time Intervals},
year = {2023},
issue_date = {November 2023},
publisher = {VLDB Endowment},
volume = {17},
number = {3},
issn = {2150-8097},
url = {https://doi.org/10.14778/3632093.3632105},
doi = {10.14778/3632093.3632105},
abstract = {The proliferation of trajectory data has facilitated various applications in urban spaces, such as travel time estimation, traffic monitoring, and flow prediction. These applications require a substantial volume of high-quality trajectories as the prerequisite to achieve effective performance. Unfortunately, a large number of real-world trajectories are inevitably collected in unsatisfactory quality due to device constraints. To address this issue, previous studies have proposed numerous trajectory recovery methods to augment the quality of such trajectories, thereby ensuring the performance of related applications. However, these methods all assume the awareness of the recovery positions in advance, which is a condition not always available in practice. In this paper, we discard this strong assumption and focus on trajectory recovery with irregular time intervals as a more prevalent setting in downstream scenarios. We propose a novel framework, called TERI, to tackle trajectory recovery without prior information in a two-stage process, where recovery positions are first detected, followed by the imputation of the missing data points. In each stage, TERI framework deploys a model named RETE, which is based on Transformer encoder architecture enhanced by novel designs to boost the performance for the new problem setting. Specifically, RETE features a learnable Fourier encoding module to better model spatial and temporal correlations, and integrates collective transition pattern learning and trajectory contrastive learning to effectively capture sequential transition patterns. Extensive experiments on three real-world datasets demonstrate that TERI consistently outperforms all the baselines by a significant large margin.},
journal = {Proc. VLDB Endow.},
month = nov,
pages = {414–426},
numpages = {13}
}

@article{10.14778/3632093.3632106,
author = {Chen, Yuhan and Ye, Haojie and Vedula, Sanketh and Bronstein, Alex and Dreslinski, Ronald and Mudge, Trevor and Talati, Nishil},
title = {Demystifying Graph Sparsification Algorithms in Graph Properties Preservation},
year = {2023},
issue_date = {November 2023},
publisher = {VLDB Endowment},
volume = {17},
number = {3},
issn = {2150-8097},
url = {https://doi.org/10.14778/3632093.3632106},
doi = {10.14778/3632093.3632106},
abstract = {Graph sparsification is a technique that approximates a given graph by a sparse graph with a subset of vertices and/or edges. The goal of an effective sparsification algorithm is to maintain specific graph properties relevant to the downstream task while minimizing the graph's size. Graph algorithms often suffer from long execution time due to the irregularity and the large real-world graph size. Graph sparsification can be applied to greatly reduce the run time of graph algorithms by substituting the full graph with a much smaller sparsified graph, without significantly degrading the output quality. However, the interaction between numerous sparsifiers and graph properties is not widely explored, and the potential of graph sparsification is not fully understood.In this work, we cover 16 widely-used graph metrics, 12 representative graph sparsification algorithms, and 14 real-world input graphs spanning various categories, exhibiting diverse characteristics, sizes, and densities. We developed a framework to extensively assess the performance of these sparsification algorithms against graph metrics, and provide insights to the results. Our study shows that there is no one sparsifier that performs the best in preserving all graph properties, e.g. sparsifiers that preserve distance-related graph properties (eccentricity) struggle to perform well on Graph Neural Networks (GNN). This paper presents a comprehensive experimental study evaluating the performance of sparsification algorithms in preserving essential graph metrics. The insights inform future research in incorporating matching graph sparsification to graph algorithms to maximize benefits while minimizing quality degradation. Furthermore, we provide a framework to facilitate the future evaluation of evolving sparsification algorithms, graph metrics, and ever-growing graph data.},
journal = {Proc. VLDB Endow.},
month = nov,
pages = {427–440},
numpages = {14}
}

@article{10.14778/3632093.3632113,
author = {Musleh, Mashaal and Mokbel, Mohamed F.},
title = {Kamel: A Scalable BERT-Based System for Trajectory Imputation},
year = {2023},
issue_date = {November 2023},
publisher = {VLDB Endowment},
volume = {17},
number = {3},
issn = {2150-8097},
url = {https://doi.org/10.14778/3632093.3632113},
doi = {10.14778/3632093.3632113},
abstract = {Numerous important applications rely on detailed trajectory data. Yet, unfortunately, trajectory datasets are typically sparse with large spatial and temporal gaps between each two points, which is a major hurdle for their accuracy. This paper presents Kamel; a scalable trajectory imputation system that inserts additional realistic trajectory points, boosting the accuracy of trajectory applications. Kamel maps the trajectory imputation problem to finding the missing word problem; a classical problem in the natural language processing (NLP) community. This allows employing the widely used BERT model for trajectory imputation. However, BERT, as is, does not lend itself to the special characteristics of trajectories. Hence, Kamel starts from BERT, but then adds spatial-awareness to its operations, adjusts trajectory data to be closer to the nature of language data, and adds multipoint imputation ability to it; all encapsulated in one system. Experimental results based on real datasets show that Kamel significantly outperforms its competitors and is applicable to city-scale trajectories, large gaps, and tight accuracy thresholds.},
journal = {Proc. VLDB Endow.},
month = nov,
pages = {525–538},
numpages = {14}
}

@proceedings{10.5555/3590145,
title = {ASONAM '22: Proceedings of the 2022 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
year = {2022},
isbn = {9781665456616},
publisher = {IEEE Press},
abstract = {We were delighted to welcome each participant at ASONAM 2022 and thank you for having contributed virtually or in person in Istanbul. ASONAM 2022 was the fourteenth annual conference in the successful ASONAM conferences series and also the first hybrid version of the conference. Previous ASONAM conferences were held in Athens (2009), Odense (2010), Kaohsiung (2011), Istanbul (2012), Niagara Falls (2013), Beijing (2014), Paris (2015), San Francisco (2016), Sydney (2017), Barcelona (2018), Vancouver (2019), Virtual (2020), Virtual (2021). The pre-pandemic locations of the conferences have enabled the participants to enjoy local sights and to engage in person-to-person interactions, making new contacts and form new scientific collaborations. These possibilities were only available in a limited form during the virtual conferences. As the covid pandemic seems to be moving towards an endemic form it was decided to have the conference in the hybrid form, as a move towards normal endemic in-person conferences.For more than a century, social networks have been studied in a variety of disciplines including sociology, anthropology, psychology, and economics. The Internet, the social Web, and other large-scale, sociotechnological infrastructures have triggered a growing interest and resulted in significant methodological advancements in social network analysis and mining. Method development in graph theory, statistics, data mining, machine learning, and AI have inspired new research problems and, in turn, opens up further possibilities for application. These spiraling trends have led to a rising prominence of social network analysis and mining methods and tools in academia, politics, security, and business.},
location = {Istanbul, Turkey}
}

@proceedings{10.5555/3606010,
title = {ICSE '23: Proceedings of the 45th International Conference on Software Engineering},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
abstract = {ICSE is the leading and by far the largest conference in Software Engineering, attracting researchers, practitioners and students from around the world. ICSE2023 is co-located with 10 conferences and symposia this year, many long-established and prestigious venues in their own right.},
location = {Melbourne, Victoria, Australia}
}

@proceedings{10.5555/3606013,
title = {ICSE '23: Proceedings of the 45th International Conference on Software Engineering: Companion Proceedings},
year = {2023},
isbn = {9798350322637},
publisher = {IEEE Press},
abstract = {ICSE is the leading and by far the largest conference in Software Engineering, attracting researchers, practitioners and students from around the world. ICSE2023 is co-located with 10 conferences and symposia this year, many long-established and prestigious venues in their own right.},
location = {Melbourne, Victoria, Australia}
}

@inproceedings{10.5555/3615924.3615942,
author = {Alexopoulos, Michelle and Lyons, Kelly and Mahetaji, Kaushar and Barnes, Marcus Emmanuel and Gutwillinger, Rogan},
title = {Gender Inference: Can ChatGPT Outperform Common Commercial Tools?},
year = {2023},
publisher = {IBM Corp.},
address = {USA},
abstract = {An increasing number of studies use gender information to un-derstand phenomena such as gender bias, inequity in access and participation, or the impact of the Covid pandemic response. Un-fortunately, most datasets do not include self-reported gender in-formation, which makes it necessary for researchers to infer gen-der from other information, such as from names or names and country information. In this paper, we compare the performance of the new generative Artificial Intelligence (AI) tool ChatGPT with three traditional commercially available list-based and ma-chine learning-based gender inference tools—Namsor, Gender-API, and genderize.io—on a unique dataset. Specifically, we use a large Olympic athlete dataset and report how variations in the input (e.g., first name and first \&amp; last name, with and without country information) impact the accuracy of their predictions. We find that Namsor is the best traditional commercially available tool. However, ChatGPT performs at least as well as Namsor and often outper-forms it, especially for the female sample when country and/or last name information is available. We conclude ChatGPT may be a cost-effective tool for gender prediction.},
booktitle = {Proceedings of the 33rd Annual International Conference on Computer Science and Software Engineering},
pages = {161–166},
numpages = {6},
keywords = {Name-Based Gender Inference, ChatGPT, Performance Evaluation, Data Science and AI},
location = {Las Vegas, NV, USA},
series = {CASCON '23}
}

@proceedings{10.5555/3623288,
title = {ICSE-NIER '23: Proceedings of the 45th International Conference on Software Engineering: New Ideas and Emerging Results},
year = {2023},
isbn = {9798350300390},
publisher = {IEEE Press},
abstract = {ICSE is the leading and by far the largest conference in Software Engineering, attracting researchers, practitioners and students from around the world. ICSE2023 is co-located with 10 conferences and symposia this year, many long-established and prestigious venues in their own right.},
location = {Melbourne, Australia}
}

@proceedings{10.5555/3623293,
title = {ICSE-SEIP '23: Proceedings of the 45th International Conference on Software Engineering: Software Engineering in Practice},
year = {2023},
isbn = {9798350300376},
publisher = {IEEE Press},
location = {Melbourne, Australia}
}

