@proceedings{10.1109/3655039,
title = {ASPDAC '24: Proceedings of the 29th Asia and South Pacific Design Automation Conference},
year = {2024},
isbn = {9798350393545},
publisher = {IEEE Press},
abstract = {ASP-DAC is a high-quality and premium conference on Electronic Design Automation (EDA) area like other sister conferences such as Design Automation Conference (DAC), Design, Automation \&amp; Test in Europe (DATE), International Conference on Computer-Aided Design (ICCAD), and Embedded Systems Week (ESWEEK). ASP-DAC started in 1995 and has continuously offered opportunity to know the recent advanced technologies on LSI design and design automation areas, and to communicate each other for researchers and designers around Asia and South Pacific regions.},
location = {Incheon, Republic of Korea}
}

@proceedings{10.1109/3656336,
title = {ASPDAC '22: Proceedings of the 27th Asia and South Pacific Design Automation Conference},
year = {2022},
isbn = {9781665421355},
publisher = {IEEE Press},
abstract = {ASP-DAC is a high-quality and premium conference on Electronic Design Automation (EDA) like other sister conferences such as Design Automation Conference (DAC), Design, Automation \&amp; Test in Europe (DATE), International Conference on Computer Aided Design (ICCAD), and Embedded Systems Week (ESWEEK). ASP-DAC started in 1995 and has continuously offered opportunities for researchers and designers in the world to learn about the advancements on design and automation of electronic systems.},
location = {Taipei, Taiwan}
}

@proceedings{10.1109/3656337,
title = {ASPDAC '20: Proceedings of the 25th Asia and South Pacific Design Automation Conference},
year = {2020},
isbn = {9781728141237},
publisher = {IEEE Press},
abstract = {Since 1995, ASP-DAC has been served as a great platform for researchers, academics, industrial participants and students to exchange and share their ideas and the latest advanced technologies on LSI design and design automation areas.},
location = {Beijing, China}
}

@proceedings{10.1145/3565698,
title = {Chinese CHI '22: Proceedings of the Tenth International Symposium of Chinese CHI},
year = {2022},
isbn = {9781450398695},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Guangzhou, China and Online, China}
}

@proceedings{10.1145/3570945,
title = {IVA '23: Proceedings of the 23rd ACM International Conference on Intelligent Virtual Agents},
year = {2023},
isbn = {9781450399944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {This volume contains the papers presented at the 23nd International Conference on Intelligent Virtual Agents (IVA 2023) located in W\"{u}rzburg, Germany, from 19. to 22.09.2023.},
location = {W\"{u}rzburg, Germany}
}

@proceedings{10.1145/3576882,
title = {CompEd 2023: Proceedings of the ACM Conference on Global Computing Education Vol 1},
year = {2023},
isbn = {9798400700484},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome participants to the 2nd ACM Global Conference on Computing Education (ACM CompEd 2023) being held in Hyderabad, India, 7th-9th December, 2023 with the Working Groups meetings being held on 5th and 6th December 2023.ACM CompEd is a recent addition to the list of ACM sponsored conferences devoted to research in all aspects of computing education, including education at the school and college levels. The Hyderabad edition is only the second in this promising series. The long hiatus due to Covid-19 pushed this conference by two years, but we are glad that it is finally here!This edition of ACM CompEd partly overlaps with COMPUTE 2023, ACM India's flagship conference on Computing Education. Having the two conferences adjacent to each other is a great way to build synergy between the Indian computing education community and the global community of computing education researchers.},
location = {Hyderabad, India}
}

@proceedings{10.1145/3587259,
title = {K-CAP '23: Proceedings of the 12th Knowledge Capture Conference 2023},
year = {2023},
isbn = {9798400701412},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 12th ACM International Conference on Knowledge Capture: K-CAP 2023, held in person on December 5th - 7th in Pensacola, Florida, US.Driven by the increasing demands for knowledge-based applications and the unprecedented availability of information from heterogeneous data sources, the study of knowledge capture is of crucial importance. Knowledge capture involves the extraction of useful knowledge from vast and diverse data sources as well as its acquisition directly from human experts.Nowadays knowledge is derived from an increasingly diverse set of data resources that differ with regard to their domain, format, quality, coverage, specificity, viewpoint, bias, and most importantly, consumers and producers of data. The heterogeneity, amount and complexity of data allow us to answer complex questions that could not be answered in isolation, requiring the interaction of different scientific fields and technologies. A goal of K-CAP is to develop such synergies using systematic and rigorous methodologies.The call for papers attracted 105 submissions from all over the world, covering a diverse range of topics spanning knowledge mining, large language models for information extraction, neuro-symbolic approaches for knowledge capture, knowledge engineering, question-answering, knowledge graphs, natural language processing, reasoning, entity linking, querying and knowledge-based applications. From a competitive set of high-quality submissions, we accepted 27 long research papers, 5 short papers, and 1 vision paper. The high-quality program is divided into 7 research sessions, in addition to 3 tutorials reflecting novel topics of interest in Knowledge Capture.We encourage everyone to attend the keynote talks that we have planned for K-CAP 2023. The highly anticipated talks by Dr. Robert R. Hoffman (Florida Institute for Human and Machine Cognition) and Dr. Jane Pinelis (Johns Hopkins University Applied Physics Laboratory) will guide us to a better understanding of the future of knowledge capture and explainable, resilient AI ecosystems, as they become commonplace in real world applications.},
location = {Pensacola, FL, USA}
}

@proceedings{10.1145/3589132,
title = {SIGSPATIAL '23: Proceedings of the 31st ACM International Conference on Advances in Geographic Information Systems},
year = {2023},
isbn = {9798400701689},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The conference started as a series of workshops and symposia back in 1993 with the aim of promoting interdisciplinary discussions among researchers, developers, users, and practitioners and fostering research in all aspects of geographic information systems, especially in relation to novel systems based on geospatial data and knowledge. It continues to provide a forum for original research contributions covering all conceptual, design and implementation aspects of geospatial data ranging from applications, user interfaces and visualization, to data storage, query processing, indexing, machine learning and data mining. The conference is the premier annual event of the ACM Special Interest Group on Spatial Information (ACM SIGSPATIAL).},
location = {Hamburg, Germany}
}

@inproceedings{10.1145/3589334.3645332,
author = {Yue, Linan and Liu, Qi and Liu, Ye and Gao, Weibo and Yao, Fangzhou and Li, Wenfeng},
title = {Cooperative Classification and Rationalization for Graph Generalization},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645332},
doi = {10.1145/3589334.3645332},
abstract = {Graph Neural Networks (GNNs) have achieved impressive results in graph classification tasks, but they struggle to generalize effectively when faced with out-of-distribution (OOD) data. Several approaches have been proposed to address this problem. Among them, one solution is to diversify training distributions in vanilla classification by modifying the data environment, yet accessing the environment information is complex. Besides, another promising approach involves rationalization, extracting invariant rationales for predictions. However, extracting rationales is difficult due to limited learning signals, resulting in less accurate rationales and diminished predictions. To address these challenges, in this paper, we propose a Cooperative Classification and Rationalization (C2R) method, consisting of theclassification and therationalization module. Specifically, we first assume that multiple environments are available in theclassification module. Then, we introduce diverse training distributions using an environment-conditional generative network, enabling robust graph representations. Meanwhile, therationalization module employs a separator to identify relevant rationale subgraphs while the remaining non-rationale subgraphs are de-correlated with labels. Next, we align graph representations from theclassification module with rationale subgraph representations using the knowledge distillation methods, enhancing the learning signal for rationales. Finally, we infer multiple environments by gathering non-rationale representations and incorporate them into theclassification module for cooperative learning. Extensive experimental results on both benchmarks and synthetic datasets demonstrate the effectiveness of C2R. Code is available at https://github.com/yuelinan/Codes-of-C2R.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {344–352},
numpages = {9},
keywords = {graph generalization, out-of-distribution, rationalization},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3589334.3645437,
author = {Li, Jiatong and Liu, Qi and Wang, Fei and Liu, Jiayu and Huang, Zhenya and Yao, Fangzhou and Zhu, Linbo and Su, Yu},
title = {Towards the Identifiability and Explainability for Personalized Learner Modeling: An Inductive Paradigm},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645437},
doi = {10.1145/3589334.3645437},
abstract = {Personalized learner modeling using cognitive diagnosis (CD), which aims to model learners' cognitive states by diagnosing learner traits from behavioral data, is a fundamental yet significant task in many web learning services. Existing cognitive diagnosis models (CDMs) follow theproficiency-response paradigm that views learner traits and question parameters as trainable embeddings and learns them through learner performance prediction. However, we notice that this paradigm leads to the inevitable non-identifiability and explainability overfitting problem, which is harmful to the quantification of learners' cognitive states and the quality of web learning services. To address these problems, we propose an identifiable cognitive diagnosis framework (ID-CDF) based on a novelresponse-proficiency-response paradigm inspired by encoder-decoder models. Specifically, we first devise the diagnostic module of ID-CDF, which leverages inductive learning to eliminate randomness in optimization to guarantee identifiability and captures the monotonicity between overall response data distribution and cognitive states to prevent explainability overfitting. Next, we propose a flexible predictive module for ID-CDF to ensure diagnosis preciseness. We further present an implementation of ID-CDF, i.e., ID-CDM, to illustrate its usability. Extensive experiments on four real-world datasets with different characteristics demonstrate that ID-CDF can effectively address the problems without loss of diagnosis preciseness. Our code is available at https://github.com/CSLiJT/ID-CDF.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {3420–3431},
numpages = {12},
keywords = {cognitive diagnosis, explainability, identifiability, intelligent education, user modeling},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3589334.3645440,
author = {He, Liyang and Huang, Zhenya and Liu, Jiayu and Chen, Enhong and Wang, Fei and Sha, Jing and Wang, Shijin},
title = {Bit-mask Robust Contrastive Knowledge Distillation for Unsupervised Semantic Hashing},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645440},
doi = {10.1145/3589334.3645440},
abstract = {Unsupervised semantic hashing has emerged as an indispensable technique for fast image search, which aims to convert images into binary hash codes without relying on labels. Recent advancements in the field demonstrate that employing large-scale backbones (e.g., ViT) in unsupervised semantic hashing models can yield substantial improvements. However, the inference delay has become increasingly difficult to overlook. Knowledge distillation provides a means for practical model compression to alleviate this delay. Nevertheless, the prevailing knowledge distillation approaches are not explicitly designed for semantic hashing. They ignore the unique search paradigm of semantic hashing, the inherent necessities of the distillation process, and the property of hash codes. In this paper, we propose an innovative Bit-mask Robust Contrastive knowledge Distillation (BRCD) method, specifically devised for the distillation of semantic hashing models. To ensure the effectiveness of two kinds of search paradigms in the context of semantic hashing, BRCD first aligns the semantic spaces between the teacher and student models through a contrastive knowledge distillation objective. Additionally, to eliminate noisy augmentations and ensure robust optimization, a cluster-based method within the knowledge distillation process is introduced. Furthermore, through a bit-level analysis, we uncover the presence of redundancy bits resulting from the bit independence property. To mitigate these effects, we introduce a bit mask mechanism in our knowledge distillation objective. Finally, extensive experiments not only showcase the noteworthy performance of our BRCD method in comparison to other knowledge distillation methods but also substantiate the generality of our methods across diverse semantic hashing models and backbones. The code for BRCD is available at https://github.com/hly1998/BRCD.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {1395–1406},
numpages = {12},
keywords = {image retrieval, knowledge distillation, semantic hashing},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3589334.3645467,
author = {Lin, Jianghao and Shan, Rong and Zhu, Chenxu and Du, Kounianhua and Chen, Bo and Quan, Shigang and Tang, Ruiming and Yu, Yong and Zhang, Weinan},
title = {ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645467},
doi = {10.1145/3589334.3645467},
abstract = {With large language models (LLMs) achieving remarkable breakthroughs in NLP domains, LLM-enhanced recommender systems have received much attention and have been actively explored currently. In this paper, we focus on adapting and empowering a pure large language model for zero-shot and few-shot recommendation tasks. First and foremost, we identify and formulate the lifelong sequential behavior incomprehension problem for LLMs in recommendation domains, i.e., LLMs fail to extract useful information from a textual context of long user behavior sequence, even if the length of context is far from reaching the context limitation of LLMs. To address such an issue and improve the recommendation performance of LLMs, we propose a novel framework, namely Retrieval enhanced Large Language models (ReLLa) for recommendation tasks in both zero-shot and few-shot settings. For zero-shot recommendation, we perform semantic user behavior retrieval (SUBR) to improve the data quality of testing samples, which greatly reduces the difficulty for LLMs to extract the essential knowledge from user behavior sequences. As for few-shot recommendation, we further design retrieval-enhanced instruction tuning (ReiT) by adopting SUBR as a data augmentation technique for training samples. Specifically, we develop a mixed training dataset consisting of both the original data samples and their retrieval-enhanced counterparts. We conduct extensive experiments on three real-world public datasets to demonstrate the superiority of ReLLa compared with existing baseline models, as well as its capability for lifelong sequential behavior comprehension. To be highlighted, with only less than 10\% training samples, few-shot ReLLa can outperform traditional CTR models that are trained on the entire training set (e.g., DCNv2, DIN, SIM).},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {3497–3508},
numpages = {12},
keywords = {large language models, recommender systems, user modeling},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3589334.3645525,
author = {Zhang, Chunxu and Long, Guodong and Zhou, Tianyi and Zhang, Zijian and Yan, Peng and Yang, Bo},
title = {When Federated Recommendation Meets Cold-Start Problem: Separating Item Attributes and User Interactions},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645525},
doi = {10.1145/3589334.3645525},
abstract = {Federated recommendation system usually trains a global model on the server without direct access to users' private data on their own devices. However, this separation of the recommendation model and users' private data poses a challenge in providing quality service, particularly when it comes to new items, namely cold-start recommendations in federated settings. This paper introduces a novel method called Item-aligned Federated Aggregation (IFedRec) to address this challenge. It is the first research work in federated recommendation to specifically study the cold-start scenario. The proposed method learns two sets of item representations by leveraging item attributes and interaction records simultaneously. Additionally, an item representation alignment mechanism is designed to align two item representations and learn the meta attribute network at the server within a federated learning framework. Experiments on four benchmark datasets demonstrate IFedRec's superior performance for cold-start scenarios. Furthermore, we also verify IFedRec owns good robustness when the system faces limited client participation and noise injection, which brings promising practical application potential in privacy-protection enhanced federated recommendation systems. The implementation code is available},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {3632–3642},
numpages = {11},
keywords = {cold-start, federated learning, recommendation systems},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3589334.3645547,
author = {Jia, Zhen and Christmann, Philipp and Weikum, Gerhard},
title = {Faithful Temporal Question Answering over Heterogeneous Sources},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645547},
doi = {10.1145/3589334.3645547},
abstract = {Temporal question answering (QA) involves time constraints, with phrases such as "... in 2019" or "... before COVID". In the former, time is an explicit condition, in the latter it is implicit. State-of-the-art methods have limitations along three dimensions. First, with neural inference, time constraints are merely soft-matched, giving room to invalid or inexplicable answers. Second, questions with implicit time are poorly supported. Third, answers come from a single source: either a knowledge base (KB) or a text corpus. We propose a temporal QA system that addresses these shortcomings. First, it enforces temporal constraints for faithful answering with tangible evidence. Second, it properly handles implicit questions. Third, it operates over heterogeneous sources, covering KB, text and web tables in a unified manner. The method has three stages: (i) understanding the question and its temporal conditions, (ii) retrieving evidence from all sources, and (iii) faithfully answering the question. As implicit questions are sparse in prior benchmarks, we introduce a principled method for generating diverse questions. Experiments show superior performance over a suite of baselines.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {2052–2063},
numpages = {12},
keywords = {explainability, question answering, temporal questions},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3589334.3645601,
author = {Cho, Yoon-Sik},
title = {Decoupled Variational Graph Autoencoder for Link Prediction},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645601},
doi = {10.1145/3589334.3645601},
abstract = {Link prediction is an important learning task for graph-structured data, and has become increasingly popular due to its wide application areas. Graph Neural Network (GNN)-based approaches including Variational Graph Autoencoder (VGAE) have achieved promising performance on link prediction outperforming conventional models which use hand-crafted features. VGAE learns latent node representations and predicts links based on the similarities between nodes. While the inner product based decoder effectively utilizes the node representations for link prediction, it exhibits sub-optimal performance due to the intrinsic limitation of the inner product. We found that the the cosine similarity and norm simultaneously try to explain the link probability, which hinders the gradient flow during training. We also point out the message passing scheme is unexpectedly dominated by the nodes with large norm values. In this paper, we propose a stochastic VGAE-based method that can effectively decouple the norm and angle in the embeddings. Specifically, we relate the cosine similarity and norm to two fundamental principles in graph: homophily and node popularity respectively. Our learning scheme is based on a hard expectation maximization learning method; we infer which of the two has been exerted for link formation, and subsequently optimize based on this guess. Through extensive experiments on real-world datasets, we demonstrate our model outperforms the existing state-of-the-art methods on link prediction and achieves comparable performances on other downstream tasks such as node classification and clustering. Our code is at https://github.com/yoonsikcho/d-vgae.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {839–849},
numpages = {11},
keywords = {graph neural networks, link prediction, variational graph autoencoder},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3589334.3645611,
author = {Koa, Kelvin J.L. and Ma, Yunshan and Ng, Ritchie and Chua, Tat-Seng},
title = {Learning to Generate Explainable Stock Predictions using Self-Reflective Large Language Models},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645611},
doi = {10.1145/3589334.3645611},
abstract = {Explaining stock predictions is generally a difficult task for traditional non-generative deep learning models, where explanations are limited to visualizing the attention weights on important texts. Today, Large Language Models (LLMs) present a solution to this problem, given their known capabilities to generate human-readable explanations for their decision-making process. However, the task of stock prediction remains challenging for LLMs, as it requires the ability to weigh the varying impacts of chaotic social texts on stock prices. The problem gets progressively harder with the introduction of the explanation component, which requires LLMs to explain verbally why certain factors are more important than the others. On the other hand, to fine-tune LLMs for such a task, one would need expert-annotated samples of explanation for every stock movement in the training set, which is expensive and impractical to scale.To tackle these issues, we propose our Summarize-Explain-Predict (SEP) framework, which utilizes a verbal self-reflective agent and Proximal Policy Optimization (PPO) that allow a LLM teach itself how to generate explainable stock predictions, in a fully autonomous manner. The reflective agent learns how to explain past stock movements through a self-reasoning process, while the PPO trainer trains the model to generate the most likely explanations given the input texts at test-time. The training samples for the PPO trainer are also the responses generated during the reflective process, which eliminates the need for human annotators. Using our SEP framework, we fine-tune a specialized LLM that can outperform both traditional deep-learning and LLM methods in prediction accuracy and Matthews correlation coefficient, for the stock classification task. To justify the generalization capability of our framework, we further test it on the portfolio construction task, and demonstrate its effectiveness through various portfolio metrics. Our code can be accessed through https://github.com/koa-fin/sep.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {4304–4315},
numpages = {12},
keywords = {explainable ai, large language models, stock prediction},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3589334.3645619,
author = {Ousat, Behzad and Schafir, Esteban and Hoang, Duc C. and Tofighi, Mohammad Ali and Nguyen, Cuong V. and Arshad, Sajjad and Uluagac, Selcuk and Kharraz, Amin},
title = {The Matter of Captchas: An Analysis of a Brittle Security Feature on the Modern Web},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645619},
doi = {10.1145/3589334.3645619},
abstract = {The web ecosystem is a fast-paced environment. In this dynamic landscape, new security features are offered one after another to enhance the security and robustness of web applications and the operations they handle. This paper focuses on a fragile but still in-use security feature, text-based CAPTCHAs, that had been wildly used by web applications in the past to protect against automated attacks such as credential stuffing and account hijacking. The paper first investigates what it takes to develop automated scanners that can solve previously unseen text-based CAPTCHAs. We evaluated the possibility of developing and integrating a pre-trained CAPTCHA solver in the automated web scanning process without using a significantly large training dataset. We also perform an analysis of the impact of such autonomous scanners on CAPTCHA-enabled websites. Our analysis shows that solvable text-based CAPTCHAs on login, contact, and comment pages of websites are not uncommon. In particular, we identified over 3,100 text-based CAPTCHA websites in critical sectors such as finance, government, and health with hundreds of thousands of users. We showed that a web scanner with a pre-trained solver could solve more than 20\% of previously unseen CAPTCHAs in just one single attempt. This result is worrisome considering the substantial potential to autonomously run the operation across thousands of websites on a daily basis with minimal training. The findings suggest that the integration of autonomous scanning with pre-training and local optimization of models can significantly increase adversaries' asymmetric power to launch their attacks cheaper and faster.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {1835–1846},
numpages = {12},
keywords = {automated attacks, captcha, web bots, web security},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3589334.3645622,
author = {Wu, Yuxia and Fang, Yuan and Liao, Lizi},
title = {On the Feasibility of Simple Transformer for Dynamic Graph Modeling},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645622},
doi = {10.1145/3589334.3645622},
abstract = {Dynamic graph modeling is crucial for understanding complex structures in web graphs, spanning applications in social networks, recommender systems, and more. Most existing methods primarily emphasize structural dependencies and their temporal changes. However, these approaches often overlook detailed temporal aspects or struggle with long-term dependencies. Furthermore, many solutions overly complicate the process by emphasizing intricate module designs to capture dynamic evolutions. In this work, we harness the strength of the Transformer's self-attention mechanism, known for adeptly handling long-range dependencies in sequence modeling. Our approach offers a simple Transformer model, called SimpleDyG, tailored for dynamic graph modeling without complex modifications. We re-conceptualize dynamic graphs as a sequence modeling challenge and introduce a novel temporal alignment technique. This technique not only captures the inherent temporal evolution patterns within dynamic graphs but also streamlines the modeling process of their evolution. To evaluate the efficacy of SimpleDyG, we conduct extensive experiments on four real-world datasets from various domains. The results demonstrate the competitive performance of SimpleDyG in comparison to a series of state-of-the-art approaches despite its simple design.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {870–880},
numpages = {11},
keywords = {dynamic graphs, graph representation learning, transformer},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3589334.3645635,
author = {Zhu, Jiachen and Wang, Yichao and Lin, Jianghao and Qin, Jiarui and Tang, Ruiming and Zhang, Weinan and Yu, Yong},
title = {M-scan: A Multi-Scenario Causal-driven Adaptive Network for Recommendation},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645635},
doi = {10.1145/3589334.3645635},
abstract = {We primarily focus on the field of multi-scenario recommendation, which poses a significant challenge in effectively leveraging data from different scenarios to enhance predictions in scenarios with limited data. Current mainstream efforts mainly center around innovative model network architectures, with the aim of enabling the network to implicitly acquire knowledge from diverse scenarios. However, the uncertainty of implicit learning in networks arises from the absence of explicit modeling, leading to not only difficulty in training but also incomplete user representation and suboptimal performance. Furthermore, through causal graph analysis, we have discovered that the scenario itself directly influences click behavior, yet existing approaches directly incorporate data from other scenarios during the training of the current scenario, leading to prediction biases when they directly utilize click behaviors from other scenarios to train models. To address these problems, we propose the Multi-Scenario Causal-driven Adaptive Network M-scan). This model incorporates a Scenario-Aware Co-Attention mechanism that explicitly extracts user interests from other scenarios that align with the current scenario. Additionally, it employs a Scenario Bias Eliminator module utilizing causal counterfactual inference to mitigate biases introduced by data from other scenarios. Extensive experiments on two public datasets demonstrate the efficacy of our M-scan compared to the existing baseline models.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {3844–3853},
numpages = {10},
keywords = {causal inference, counterfactual, multi-scenario recommendation},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3589334.3645642,
author = {Zhu, Yiming and Yin, Zhizhuo and Tyson, Gareth and Haq, Ehsan-Ul and Lee, Lik-Hang and Hui, Pan},
title = {APT-Pipe: A Prompt-Tuning Tool for Social Data Annotation using ChatGPT},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645642},
doi = {10.1145/3589334.3645642},
abstract = {Recent research has highlighted the potential of LLMs, like ChatGPT, for performing label annotation on social computing data. However, it is already well known that performance hinges on the quality of the input prompts. To address this, there has been a flurry of research into prompt tuning --- techniques and guidelines that attempt to improve the quality of prompts. Yet these largely rely on manual effort and prior knowledge of the dataset being annotated. To address this limitation, we propose APT-Pipe, an automated prompt-tuning pipeline. APT-Pipe aims to automatically tune prompts to enhance ChatGPT's text classification performance on any given dataset. We implement APT-Pipe and test it across twelve distinct text classification datasets. We find that prompts tuned by APT-Pipe help ChatGPT achieve higher weighted F1-score on nine out of twelve experimented datasets, with an improvement of 7.01\% on average. We further highlight APT-Pipe's flexibility as a framework by showing how it can be extended to support additional tuning mechanisms.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {245–255},
numpages = {11},
keywords = {human computation, large language models, prompt-tuning},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3589334.3645649,
author = {Gong, Jiaying and Eldardiry, Hoda},
title = {Multi-Label Zero-Shot Product Attribute-Value Extraction},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645649},
doi = {10.1145/3589334.3645649},
abstract = {E-commerce platforms should provide detailed product descriptions (attribute values) for effective product search and recommendation. However, attribute value information is typically not available for new products. To predict unseen attribute values, large quantities of labeled training data are needed to train a traditional supervised learning model. Typically, it is difficult, time-consuming, and costly to manually label large quantities of new product profiles. In this paper, we propose a novel method to efficiently and effectively extract unseen attribute values from new products in the absence of labeled data (zero-shot setting). We propose HyperPAVE, a multi-label zero-shot attribute value extraction model that leverages inductive inference in heterogeneous hypergraphs. In particular, our proposed technique constructs heterogeneous hypergraphs to capture complex higher-order relations (i.e. user behavior information) to learn more accurate feature representations for graph nodes. Furthermore, our proposed HyperPAVE model uses an inductive link prediction mechanism to infer future connections between unseen nodes. This enables HyperPAVE to identify new attribute values without the need for labeled training data. We conduct extensive experiments with ablation studies on different categories of the MAVE dataset. The results demonstrate that our proposed HyperPAVE model significantly outperforms existing classification-based, generation-based large language models for attribute value extraction in the zero-shot setting.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {2259–2270},
numpages = {12},
keywords = {attribute value extraction, heterogeneous hypergraph, inductive link prediction, zero-shot learning},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3589334.3645652,
author = {Huang, Keke and Gao, Ruize and Cautis, Bogdan and Xiao, Xiaokui},
title = {Scalable Continuous-time Diffusion Framework for Network Inference and Influence Estimation},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645652},
doi = {10.1145/3589334.3645652},
abstract = {The study of continuous-time information diffusion has been an important area of research for many applications in recent years. When only the diffusion traces (cascades) are accessible, cascade-based network inference and influence estimation are two essential problems to explore. Alas, existing methods exhibit limited capability to infer and process networks with more than a few thousand nodes, suffering from scalability issues. In this paper, we view the diffusion process as a continuous-time dynamical system, based on which we establish a continuous-time diffusion model. Subsequently, we instantiate the model to a scalable and effective framework (FIM) to approximate the diffusion propagation from available cascades, thereby inferring the underlying network structure. Furthermore, we undertake an analysis of the approximation error of FIM for network inference. To achieve the desired scalability for influence estimation, we devise an advanced sampling technique and significantly boost the efficiency. We also quantify the effect of the approximation error on influence estimation theoretically. Experimental results showcase the effectiveness and superior scalability of FIM on network inference and influence estimation.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {2660–2671},
numpages = {12},
keywords = {continuous-time dynamical system, influence estimation, network inference},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3589334.3645662,
author = {Zhao, Yuying and Xu, Minghua and Chen, Huiyuan and Chen, Yuzhong and Cai, Yiwei and Islam, Rashidul and Wang, Yu and Derr, Tyler},
title = {Can One Embedding Fit All? A Multi-Interest Learning Paradigm Towards Improving User Interest Diversity Fairness},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645662},
doi = {10.1145/3589334.3645662},
abstract = {Recommender systems (RSs) have gained widespread applications across various domains owing to the superior ability to capture users' interests. However, the complexity and nuanced nature of users' interests, which span a wide range of diversity, pose a significant challenge in delivering fair recommendations. In practice, user preferences vary significantly; some users show a clear preference toward certain item categories, while others have a broad interest in diverse ones. Even though it is expected that all users should receive high-quality recommendations, the effectiveness of RSs in catering to this disparate interest diversity remains under-explored.In this work, we investigate whether users with varied levels of interest diversity are treated fairly. Our empirical experiments reveal an inherent disparity: users with broader interests often receive lower-quality recommendations. To mitigate this, we propose a multi-interest framework that uses multiple (virtual) interest embeddings rather than single ones to represent users. Specifically, the framework consists of stacked multi-interest representation layers, which include an interest embedding generator that derives virtual interests from shared parameters, and a center embedding aggregator that facilitates multi-hop aggregation. Experiments demonstrate the effectiveness of the framework in achieving better trade-off between fairness and utility across various datasets and backbones.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {1237–1248},
numpages = {12},
keywords = {diversity, fairness, multi-interest recommendations},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3589334.3645683,
author = {Nayak, Asmit and Khandelwal, Rishabh and Fernandes, Earlence and Fawaz, Kassem},
title = {Experimental Security Analysis of Sensitive Data Access by Browser Extensions},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645683},
doi = {10.1145/3589334.3645683},
abstract = {Browser extensions offer a variety of valuable features and functionalities. They also pose a significant security risk if not properly designed or reviewed. Prior works have shown that browser extensions can access and manipulate data fields, including sensitive data such as passwords, credit card numbers, and Social Security numbers. In this paper, we present an empirical study of the security risks posed by browser extensions. Specifically, we first build a proof-of-concept extension that can steal sensitive user information. We find that the extension passes the Chrome Webstore review process. We then perform a measurement study on the top 10K website login pages to check if the extension access to password fields via JS. We find that none of the password fields are actively protected, and can be accessed using JS. Moreover, we found that 1K websites store passwords in plaintext in their page source, including popular websites like Google.com and Cloudflare.com. We also analyzed over 160K Chrome Web Store extensions for malicious behavior, finding that 28K have permission to access sensitive fields and 190 store password fields in variables. To analyze the behavioral workflow of the potentially malicious extensions, we propose an LLM-driven framework, Extension Reviewer. Finally, we discuss two countermeasures to address these risks: a bolt-on JavaScript package for immediate adoption by website developers allowing them to protect sensitive input fields, and a browser-level solution that alerts users when an extension accesses sensitive input fields. Our research highlights the urgent need for improved security measures to protect sensitive user information online.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {1283–1294},
numpages = {12},
keywords = {browser extensions, browser vulnerabilities, chrome web store, data privacy, sensitive data access},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3589334.3645711,
author = {Wu, Yihan and Song, Ruihua and Chen, Xu and Jiang, Hao and Cao, Zhao and Yu, Jin},
title = {Understanding Human Preferences: Towards More Personalized Video to Text Generation},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645711},
doi = {10.1145/3589334.3645711},
abstract = {While previous video to text models have achieved remarkable successes, they mostly focus on how to understand the video contents in a general sense, but fail to capture the human personalized preferences, which is highly demanded for an engaging multimodal chatbots. Different from user modeling in collaborative filtering, there is no other user behaviors in inference as a real-time video stream is coming. In this paper, we formally define the task of personalized video commenting task and design an end-to-end personalized framework for solving this task. In specific, we argue that the personalization for video comment generation can be reflected in two aspects, that is, (1) for the same video, different users may comment on different clips, and (2) for the same clip, different people may also express various opinions with diverse commentary styles. Motivated by these considerations, we design our framework based on two components. The first one is a clip selector, which is responsible for predicting the clips that the user may comment in the video. The second one is a text generator, which aims to produce the comment based on the above predicted clips and the user's preference. In our framework, these two components are optimized in an end-to-end manner to mutually enhance each other, where we design confidence-aware scheduled sampling and iterative inference strategies to solve the problem that the ground truth clips are absent in the inference phase. As the absence of personalized video to text dataset, we collect and release a new dataset for studying this problem. We conduct extensive experiments to demonstrate the effectiveness of our model.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {3952–3963},
numpages = {12},
keywords = {multimodal interaction, personalized content generation, user preference modeling, video comments dataset, video to text generation},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3589334.3645715,
author = {Tang, Yi-Kun and Huang, Heyan and Shi, Xuewen and Mao, Xian-Ling},
title = {Beyond Labels and Topics: Discovering Causal Relationships in Neural Topic Modeling},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645715},
doi = {10.1145/3589334.3645715},
abstract = {Topic models that can take advantage of labels are broadly used in identifying interpretable topics from textual data. However, existing topic models tend to merely view labels as names of topic clusters or as categories of texts, thereby neglecting the potential causal relationships between supervised information and latent topics, as well as within these elements themselves. In this paper, we focus on uncovering possible causal relationships both between and within the supervised information and latent topics to better understand the mechanisms behind the emergence of the topics and the labels. To this end, we propose Causal Relationship-Aware Neural Topic Model (CRNTM), a novel neural topic model that can automatically uncover interpretable causal relationships between and within supervised information and latent topics, while concurrently discovering high-quality topics. In CRNTM, both supervised information and latent topics are treated as nodes, with the causal relationships represented as directed edges in a Directed Acyclic Graph (DAG). A Structural Causal Model (SCM) is employed to model the DAG. Experiments are conducted on three public corpora with different types of labels. Experimental results show that the discovered causal relationships are both reliable and interpretable, and the learned topics are of high quality comparing with eight start-of-the-art topic model baselines.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {4460–4469},
numpages = {10},
keywords = {causal relationships discovery, neural topic model, structural causal model},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3589334.3645721,
author = {Wan, Liuhuo and Wang, Kailong and Mahadewa, Kulani and Wang, Haoyu and Bai, Guangdong},
title = {Don't Bite Off More than You Can Chew: Investigating Excessive Permission Requests in Trigger-Action Integrations},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645721},
doi = {10.1145/3589334.3645721},
abstract = {Web-based trigger-action platforms (TAP) allow users to integrate Internet of Things (IoT) systems and online services into trigger-action integrations (TAIs), facilitating rich automation tasks known as applets. Despite their benefits, these integrations~(typically involving the TAP, trigger, and action service providers) pose significant security and privacy challenges, such as mis-triggering and data leakage. This work investigates cross-entity permission management within TAIs to address the underlying causes of these security and privacy issues, emphasizing permission-functionality consistency to ensure fairness in permission requests. We introduce PFCon, a system that leverages GPT-based language models for analyzing required and requested permissions, revealing excessive permission requests in a large-scale study of IFTTT TAP. Our findings highlight the need for service providers to enforce permission-functionality consistency, raising awareness of the importance of security and privacy in TAI.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {3106–3116},
numpages = {11},
keywords = {excessive permissions, third-party services, trigger-action platforms},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3589334.3648139,
author = {Luo, Yifeng and Li, Yupeng and Wen, Dacheng and Lan, Liang},
title = {Message Injection Attack on Rumor Detection under the Black-Box Evasion Setting Using Large Language Model},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3648139},
doi = {10.1145/3589334.3648139},
abstract = {Recent analyses have disclosed that existing rumor detection techniques, despite playing a pivotal role in countering the dissemination of misinformation on social media, are vulnerable to both white-box and surrogate-based black-box adversarial attacks. However, such attacks depend heavily on unrealistic assumptions, e.g., modifiable user data and white-box access to the rumor detection models, or appropriate selections of surrogate models, which are impractical in the real world. Thus, existing analyses fail to uncover the robustness of rumor detectors in practice. In this work, we take a further step towards the investigation about the robustness of existing rumor detection solutions. Specifically, we focus on the state-of-the-art rumor detectors, which leverage graph neural network based models to predict whether a post is rumor based on the Message Propagation Tree (MPT), a conversation tree with the post as its root and the replies to the post as the descendants of the root. We propose a novel black-box attack method, HMIA-LLM, against these rumor detectors, which uses the Large Language Model to generate malicious messages and inject them into the targeted MPTs. Our extensive evaluation conducted across three rumor detection datasets, four target rumor detectors, and three baselines for comparison demonstrates the effectiveness of our proposed attack method in compromising the performance of the state-of-the-art rumor detectors.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {4512–4522},
numpages = {11},
keywords = {black-box evasion setting, graph neural networks, large language model, message injection attack, rumor detection},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3589334.3648148,
author = {Huang, Zijie and Hwang, Jeehyun and Zhang, Junkai and Baik, Jinwoo and Zhang, Weitong and Wodarz, Dominik and Sun, Yizhou and Gu, Quanquan and Wang, Wei},
title = {Causal Graph ODE: Continuous Treatment Effect Modeling in Multi-agent Dynamical Systems},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3648148},
doi = {10.1145/3589334.3648148},
abstract = {Real-world multi-agent systems are often dynamic and continuous, where the agents co-evolve and undergo changes in their trajectories and interactions over time. For example, the COVID-19 transmission in the U.S. can be viewed as a multi-agent system, where states act as agents and daily population movements between them are interactions. Estimating the counterfactual outcomes in such systems enables accurate future predictions and effective decision-making, such as formulating COVID-19 policies. However, existing methods fail to model the continuous dynamic effects of treatments on the outcome, especially when multiple treatments (e.g., "stay-at-home" and "get-vaccine" policies) are applied simultaneously. To tackle this challenge, we propose Causal Graph Ordinary Differential Equations (CAG-ODE), a novel model that captures the continuous interaction among agents using a Graph Neural Network (GNN) as the ODE function. The key innovation of our model is to learn time-dependent representations of treatments and incorporate them into the ODE function, enabling precise predictions of potential outcomes. To mitigate confounding bias, we further propose two domain adversarial learning-based objectives, which enable our model to learn balanced continuous representations that are not affected by treatments or interference. Experiments on two datasets (i.e., COVID-19 and tumor growth) demonstrate the superior performance of our proposed model.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {4607–4617},
numpages = {11},
keywords = {causal inference, dynamical system, graph neural networks, neural ode},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3589334.3648149,
author = {Guo, Muzhe and Guo, Muhao and Su, Juntao and Chen, Junyu and Yu, Jiaqian and Wang, Jiaqi and Du, Hongfei and Sahu, Parmanand and Sharma, Ashwin Assysh and Jin, Fang},
title = {Bayesian Iterative Prediction and Lexical-based Interpretation for Disturbed Chinese Sentence Pair Matching},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3648149},
doi = {10.1145/3589334.3648149},
abstract = {In an era dominated by web-based intelligent customer services, the applications of Sentence Pair Matching are profoundly broad. Web agents, for example, automatically respond to customer queries by finding similar past questions, significantly reducing customer service expenses. While current large language models (LLMs) offer powerful text generation capabilities, they often struggle with opacity, potential text toxicity, and difficulty managing domain-specific and confidential business inquiries. Consequently, the widespread adoption of web-based intelligent customer services in real-world business still greatly relies on query-based interactions. In this paper, we introduce a series of model-agnostic techniques aimed at enhancing both the accuracy and interpretability of Chinese pairwise sentence-matching models. Our contributions include (1) An Edit-distance-weighted fine-tuning method, (2) A Bayesian Iterative Prediction algorithm, (3) A Lexical-based Dual Ranking Interpreter, and (4) A Bi-criteria Denoising strategy. Experimental results on the Large-scale Chinese Question Matching Corpus (LCQMC) with a disturbed test demonstrate that our fine-tuning and prediction methods can steadily improve matching accuracy, building on the current state-of-the-art models. Besides, our interpreter with denoising strategy markedly enhances token-level interpretation in rationality and loyalty. In both matching accuracy and interpretation, our approaches outperform classic methods and even LLMs.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {4618–4629},
numpages = {12},
keywords = {bayesian iterative prediction, interpretation, lexical analysis of chinese, sentence pair matching},
location = {Singapore, Singapore},
series = {WWW '24}
}

@proceedings{10.1145/3595916,
title = {MMAsia '23: Proceedings of the 5th ACM International Conference on Multimedia in Asia},
year = {2023},
isbn = {9798400702051},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tainan, Taiwan}
}

@inproceedings{10.1145/3595916.3626418,
author = {Zhongtao, Chen and Honbu, Yuma and Yanai, Keiji},
title = {Mask-based Food Image Synthesis with Cross-Modal Recipe Embeddings},
year = {2024},
isbn = {9798400702051},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3595916.3626418},
doi = {10.1145/3595916.3626418},
abstract = {In this paper, we propose a Mask-based Recipe Embedding GAN (MRE-GAN), which enables us to generate a realistic food image based on a given mask image containing single or multiple food regions with cross-modal recipe embeddings for each food region. Thus, we can change meal shapes by modifying mask images, while by editing recipe text, we can change meal appearance. Our experimental findings confirmed that the proposed method could generate higher quality food images than the baselines, and we could change meal shapes and appearances by editing mask images and recipe texts as we liked.},
booktitle = {Proceedings of the 5th ACM International Conference on Multimedia in Asia},
articleno = {46},
numpages = {7},
keywords = {cross-modal recipe embedding, food image synthesis, mask-based image generation},
location = {Tainan, Taiwan},
series = {MMAsia '23}
}

@article{10.1145/3596490,
author = {Du, Mengnan and He, Fengxiang and Zou, Na and Tao, Dacheng and Hu, Xia},
title = {Shortcut Learning of Large Language Models in Natural Language Understanding},
year = {2023},
issue_date = {January 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {67},
number = {1},
issn = {0001-0782},
url = {https://doi.org/10.1145/3596490},
doi = {10.1145/3596490},
abstract = {Shortcuts often hinder the robustness of large language models.},
journal = {Commun. ACM},
month = dec,
pages = {110–120},
numpages = {11}
}

@proceedings{10.1145/3597503,
title = {ICSE '24: Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3597503.3608130,
author = {Arteaga Garcia, Emily Judith and Nicolaci Pimentel, Jo\~{a}o Felipe and Feng, Zixuan and Gerosa, Marco and Steinmacher, Igor and Sarma, Anita},
title = {How to Support ML End-User Programmers through a Conversational Agent},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3608130},
doi = {10.1145/3597503.3608130},
abstract = {Machine Learning (ML) is increasingly gaining significance for enduser programmer (EUP) applications. However, machine learning end-user programmers (ML-EUPs) without the right background face a daunting learning curve and a heightened risk of mistakes and flaws in their models. In this work, we designed a conversational agent named "Newton" as an expert to support ML-EUPs. Newton's design was shaped by a comprehensive review of existing literature, from which we identified six primary challenges faced by ML-EUPs and five strategies to assist them. To evaluate the efficacy of Newton's design, we conducted a Wizard of Oz within-subjects study with 12 ML-EUPs. Our findings indicate that Newton effectively assisted ML-EUPs, addressing the challenges highlighted in the literature. We also proposed six design guidelines for future conversational agents, which can help other EUP applications and software engineering activities.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {53},
numpages = {12},
keywords = {end-user programming, conversational agent, wizard of Oz},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3597503.3623298,
author = {Huang, Yuchao and Wang, Junjie and Liu, Zhe and Wang, Yawen and Wang, Song and Chen, Chunyang and Hu, Yuanzhe and Wang, Qing},
title = {CrashTranslator: Automatically Reproducing Mobile Application Crashes Directly from Stack Trace},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3623298},
doi = {10.1145/3597503.3623298},
abstract = {Crash reports are vital for software maintenance since they allow the developers to be informed of the problems encountered in the mobile application. Before fixing, developers need to reproduce the crash, which is an extremely time-consuming and tedious task. Existing studies conducted the automatic crash reproduction with the natural language described reproducing steps. Yet we find a non-neglectable portion of crash reports only contain the stack trace when the crash occurs. Such stack-trace-only crashes merely reveal the last GUI page when the crash occurs, and lack step-by-step guidance. Developers tend to spend more effort in understanding the problem and reproducing the crash, and existing techniques cannot work on this, thus calling for a greater need for automatic support. This paper proposes an approach named CrashTranslator to automatically reproduce mobile application crashes directly from the stack trace. It accomplishes this by leveraging a pre-trained Large Language Model to predict the exploration steps for triggering the crash, and designing a reinforcement learning based technique to mitigate the inaccurate prediction and guide the search holistically. We evaluate CrashTranslator on 75 crash reports involving 58 popular Android apps, and it successfully reproduces 61.3\% of the crashes, outperforming the state-of-the-art baselines by 109\% to 206\%. Besides, the average reproducing time is 68.7 seconds, outperforming the baselines by 302\% to 1611\%. We also evaluate the usefulness of CrashTranslator with promising results.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {18},
numpages = {13},
keywords = {bug reproduction, stack trace, mobile application testing},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3597503.3623306,
author = {Guo, Qi and Cao, Junming and Xie, Xiaofei and Liu, Shangqing and Li, Xiaohong and Chen, Bihuan and Peng, Xin},
title = {Exploring the Potential of ChatGPT in Automated Code Refinement: An Empirical Study},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3623306},
doi = {10.1145/3597503.3623306},
abstract = {Code review is an essential activity for ensuring the quality and maintainability of software projects. However, it is a time-consuming and often error-prone task that can significantly impact the development process. Recently, ChatGPT, a cutting-edge language model, has demonstrated impressive performance in various natural language processing tasks, suggesting its potential to automate code review processes. However, it is still unclear how well ChatGPT performs in code review tasks. To fill this gap, in this paper, we conduct the first empirical study to understand the capabilities of ChatGPT in code review tasks, specifically focusing on automated code refinement based on given code reviews. To conduct the study, we select the existing benchmark CodeReview and construct a new code review dataset with high quality. We use CodeReviewer, a state-of-the-art code review tool, as a baseline for comparison with ChatGPT. Our results show that ChatGPT outperforms CodeReviewer in code refinement tasks. Specifically, our results show that ChatGPT achieves higher EM and BLEU scores of 22.78 and 76.44 respectively, while the state-of-the-art method achieves only 15.50 and 62.88 on a high-quality code review dataset. We further identify the root causes for ChatGPT's underperformance and propose several strategies to mitigate these challenges. Our study provides insights into the potential of ChatGPT in automating the code review process, and highlights the potential research directions.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {34},
numpages = {13},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3597503.3623312,
author = {Tileria, Marcos and Blasco, Jorge and Dash, Santanu Kumar},
title = {DocFlow: Extracting Taint Specifications from Software Documentation},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3623312},
doi = {10.1145/3597503.3623312},
abstract = {Security practitioners routinely use static analysis to detect security problems and privacy violations in Android apps. The soundness of these analyses depends on how the platform is modelled and the list of sensitive methods. Collecting these methods often becomes impractical given the number of methods available, the pace at which the Android platform is updated, and the proprietary libraries Google releases on each new version. Despite the constant evolution of the Android platform, app developers cope with all these new features thanks to the documentation that comes with each new Android release. In this work, we take advantage of the rich documentation provided by platforms like Android and propose DocFlow, a framework to generate taint specifications for a platform, directly from its documentation. DocFlow models the semantics of API methods using their documentation to detect sensitive methods (sources and sinks) and assigns them semantic labels. Our approach does not require access to source code, enabling the analysis of proprietary libraries for which the code is unavailable. We evaluate DocFlow using Android platform packages and closed-source Google Play Services libraries. Our results show that our framework detects sensitive methods with high precision, adapts to new API versions, and can be easily extended to detect other method types. Our approach provides evidence that Android documentation encodes rich semantic information to categorise sensitive methods, removing the need to analyse source code or perform feature extraction.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {61},
numpages = {12},
keywords = {taint analysis, documentation, android, natural language processing},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3597503.3623314,
author = {Neelofar, Neelofar and Aleti, Aldeida},
title = {Towards Reliable AI: Adequacy Metrics for Ensuring the Quality of System-level Testing of Autonomous Vehicles},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3623314},
doi = {10.1145/3597503.3623314},
abstract = {AI-powered systems have gained widespread popularity in various domains, including Autonomous Vehicles (AVs). However, ensuring their reliability and safety is challenging due to their complex nature. Conventional test adequacy metrics, designed to evaluate the effectiveness of traditional software testing, are often insufficient or impractical for these systems. White-box metrics, which are specifically designed for these systems, leverage neuron coverage information. These coverage metrics necessitate access to the underlying AI model and training data, which may not always be available. Furthermore, the existing adequacy metrics exhibit weak correlations with the ability to detect faults in the generated test suite, creating a gap that we aim to bridge in this study.In this paper, we introduce a set of black-box test adequacy metrics called "Test suite Instance Space Adequacy" (TISA) metrics, which can be used to gauge the effectiveness of a test suite. The TISA metrics offer a way to assess both the diversity and coverage of the test suite and the range of bugs detected during testing. Additionally, we introduce a framework that permits testers to visualise the diversity and coverage of the test suite in a two-dimensional space, facilitating the identification of areas that require improvement.We evaluate the efficacy of the TISA metrics by examining their correlation with the number of bugs detected in system-level simulation testing of AVs. A strong correlation, coupled with the short computation time, indicates their effectiveness and efficiency in estimating the adequacy of testing AVs.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {68},
numpages = {12},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3597503.3623322,
author = {Zhang, Yakun and Zhang, Wenjie and Ran, Dezhi and Zhu, Qihao and Dou, Chengfeng and Hao, Dan and Xie, Tao and Zhang, Lu},
title = {Learning-based Widget Matching for Migrating GUI Test Cases},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3623322},
doi = {10.1145/3597503.3623322},
abstract = {GUI test case migration is to migrate GUI test cases from a source app to a target app. The key of test case migration is widget matching. Recently, researchers have proposed various approaches by formulating widget matching as a matching task. However, since these matching approaches depend on static word embeddings without using contextual information to represent widgets and manually formulated matching functions, there are main limitations of these matching approaches when handling complex matching relations in apps. To address the limitations, we propose the first learning-based widget matching approach named TEMdroid (TEst Migration) for test case migration. Unlike the existing approaches, TEMdroid uses BERT to capture contextual information and learns a matching model to match widgets. Additionally, to balance the significant imbalance between positive and negative samples in apps, we design a two-stage training strategy where we first train a hard-negative sample miner to mine hard-negative samples, and further train a matching model using positive samples and mined hard-negative samples. Our evaluation on 34 apps shows that TEM-droid is effective in event matching (i.e., widget matching and target event synthesis) and test case migration. For event matching, TEM-droid's Top1 accuracy is 76\%, improving over 17\% compared to baselines. For test case migration, TEMdroid's F1 score is 89\%, also 7\% improvement compared to the baseline approach.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {69},
numpages = {13},
keywords = {test migration, GUI testing, deep learning},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3597503.3623341,
author = {Lill, Alexander and Meyer, Andr\'{e} N. and Fritz, Thomas},
title = {On the Helpfulness of Answering Developer Questions on Discord with Similar Conversations and Posts from the Past},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3623341},
doi = {10.1145/3597503.3623341},
abstract = {A big part of software developers' time is spent finding answers to their coding-task-related questions. To answer their questions, developers usually perform web searches, ask questions on Q&amp;A websites, or, more recently, in chat communities. Yet, many of these questions have frequently already been answered in previous chat conversations or other online communities. Automatically identifying and then suggesting these previous answers to the askers could, thus, save time and effort. In an empirical analysis, we first explored the frequency of repeating questions on the Discord chat platform and assessed our approach to identify them automatically. The approach was then evaluated with real-world developers in a field experiment, through which we received 142 ratings on the helpfulness of the suggestions we provided to help answer 277 questions that developers posted in four Discord communities. We further collected qualitative feedback through 53 surveys and 10 follow-up interviews. We found that the suggestions were considered helpful in 40\% of the cases, that suggesting Stack Overflow posts is more often considered helpful than past Discord conversations, and that developers have difficulties describing their problems as search queries and, thus, prefer describing them as natural language questions in online communities.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {58},
numpages = {13},
keywords = {developer questions, chat community, semantic similarity},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3597503.3639074,
author = {Yang, Zhou and Zhao, Zhipeng and Wang, Chenyu and Shi, Jieke and Kim, Dongsun and Han, Donggyun and Lo, David},
title = {Unveiling Memorization in Code Models},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639074},
doi = {10.1145/3597503.3639074},
abstract = {The availability of large-scale datasets, advanced architectures, and powerful computational resources have led to effective code models that automate diverse software engineering activities. The datasets usually consist of billions of lines of code from both open-source and private repositories. A code model memorizes and produces source code verbatim, which potentially contains vulnerabilities, sensitive information, or code with strict licenses, leading to potential security and privacy issues.This paper investigates an important problem: to what extent do code models memorize their training data? We conduct an empirical study to explore memorization in large pre-trained code models. Our study highlights that simply extracting 20,000 outputs (each having 512 tokens) from a code model can produce over 40,125 code snippets that are memorized from the training data. To provide a better understanding, we build a taxonomy of memorized contents with 3 categories and 14 subcategories. The results show that the prompts sent to the code models affect the distribution of memorized contents. We identify several key factors of memorization. Specifically, given the same architecture, larger models suffer more from memorization problem. A code model produces more memorization when it is allowed to generate longer outputs. We also find a strong positive correlation between the number of an output's occurrences in the training data and that in the generated outputs, which indicates that a potential way to reduce memorization is to remove duplicates in the training data. We then identify effective metrics that infer whether an output contains memorization accurately. We also make suggestions to deal with memorization.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {72},
numpages = {13},
keywords = {open-source software, memorization, code generation},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3597503.3639075,
author = {Serafini, Raphael and Otto, Clemens and Horstmann, Stefan Albert and Naiakshina, Alena},
title = {ChatGPT-Resistant Screening Instrument for Identifying Non-Programmers},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639075},
doi = {10.1145/3597503.3639075},
abstract = {To ensure the validity of software engineering and IT security studies with professional programmers, it is essential to identify participants without programming skills. Existing screening questions are efficient, cheating robust, and effectively differentiate programmers from non-programmers. However, the release of ChatGPT raises concerns about their continued effectiveness in identifying non-programmers. In a simulated attack, we showed that Chat-GPT can easily solve existing screening questions. Therefore, we designed new ChatGPT-resistant screening questions using visual concepts and code comprehension tasks. We evaluated 28 screening questions in an online study with 121 participants involving programmers and non-programmers. Our results showed that questions using visualizations of well-known programming concepts performed best in differentiating between programmers and non-programmers. Participants prompted to use ChatGPT struggled to solve the tasks. They considered ChatGPT ineffective and changed their strategy after a few screening questions. In total, we present six ChatGPT-resistant screening questions that effectively identify non-programmers. We provide recommendations on setting up a ChatGPT-resistant screening instrument that takes less than three minutes to complete by excluding 99.47\% of non-programmers while including 94.83\% of programmers.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {181},
numpages = {13},
keywords = {chatgpt, programmer screening, developer study, study protection},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3597503.3639091,
author = {Li, Zongjie and Wang, Chaozheng and Ma, Pingchuan and Liu, Chaowei and Wang, Shuai and Wu, Daoyuan and Gao, Cuiyun and Liu, Yang},
title = {On Extracting Specialized Code Abilities from Large Language Models: A Feasibility Study},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639091},
doi = {10.1145/3597503.3639091},
abstract = {Recent advances in large language models (LLMs) significantly boost their usage in software engineering. However, training a well-performing LLM demands a substantial workforce for data collection and annotation. Moreover, training datasets may be proprietary or partially open, and the process often requires a costly GPU cluster. The intellectual property value of commercial LLMs makes them attractive targets for imitation attacks, but creating an imitation model with comparable parameters still incurs high costs. This motivates us to explore a practical and novel direction: slicing commercial black-box LLMs using medium-sized backbone models.In this paper, we explore the feasibility of launching imitation attacks on LLMs to extract their specialized code abilities, such as "code synthesis" and "code translation." We systematically investigate the effectiveness of launching code ability extraction attacks under different code-related tasks with multiple query schemes, including zero-shot, in-context, and Chain-of-Thought. We also design response checks to refine the outputs, leading to an effective imitation training process. Our results show promising outcomes, demonstrating that with a reasonable number of queries, attackers can train a medium-sized backbone model to replicate specialized code behaviors similar to the target LLMs. We summarize our findings and insights to help researchers better understand the threats posed by imitation attacks, including revealing a practical attack surface for generating adversarial code examples against LLMs.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {74},
numpages = {13},
keywords = {large language models, imitation attacks},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3597503.3639130,
author = {Keim, Jan and Corallo, Sophie and Fuch\ss{}, Dominik and Hey, Tobias and Telge, Tobias and Koziolek, Anne},
title = {Recovering Trace Links Between Software Documentation And Code},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639130},
doi = {10.1145/3597503.3639130},
abstract = {Introduction Software development involves creating various artifacts at different levels of abstraction and establishing relationships between them is essential. Traceability link recovery (TLR) automates this process, enhancing software quality by aiding tasks like maintenance and evolution. However, automating TLR is challenging due to semantic gaps resulting from different levels of abstraction. While automated TLR approaches exist for requirements and code, architecture documentation lacks tailored solutions, hindering the preservation of architecture knowledge and design decisions. Methods This paper presents our approach TransArC for TLR between architecture documentation and code, using component-based architecture models as intermediate artifacts to bridge the semantic gap. We create transitive trace links by combining the existing approach ArDoCo for linking architecture documentation to models with our novel approach ArCoTL for linking architecture models to code.Results We evaluate our approaches with five open-source projects, comparing our results to baseline approaches. The model-to-code TLR approach achieves an average F1-score of 0.98, while the documentation-to-code TLR approach achieves a promising average F1-score of 0.82, significantly outperforming baselines. Conclusion Combining two specialized approaches with an intermediate artifact shows promise for bridging the semantic gap. In future research, we will explore further possibilities for such transitive approaches.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {215},
numpages = {13},
keywords = {software traceability, software architecture, documentation, transitive links, intermediate artifacts, information retrieval},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3597503.3639149,
author = {He, Junda and Yang, Zhou and Shi, Jieke and Yang, Chengran and Kim, Kisub and Xu, Bowen and Zhou, Xin and Lo, David},
title = {Curiosity-Driven Testing for Sequential Decision-Making Process},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639149},
doi = {10.1145/3597503.3639149},
abstract = {Sequential decision-making processes (SDPs) are fundamental for complex real-world challenges, such as autonomous driving, robotic control, and traffic management. While recent advances in Deep Learning (DL) have led to mature solutions for solving these complex problems, SDMs remain vulnerable to learning unsafe behaviors, posing significant risks in safety-critical applications. However, developing a testing framework for SDMs that can identify a diverse set of crash-triggering scenarios remains an open challenge. To address this, we propose CureFuzz, a novel curiosity-driven black-box fuzz testing approach for SDMs. CureFuzz proposes a curiosity mechanism that allows a fuzzer to effectively explore novel and diverse scenarios, leading to improved detection of crash-triggering scenarios. Additionally, we introduce a multi-objective seed selection technique to balance the exploration of novel scenarios and the generation of crash-triggering scenarios, thereby optimizing the fuzzing process. We evaluate CureFuzz on various SDMs and experimental results demonstrate that CureFuzz outperforms the state-of-the-art method by a substantial margin in the total number of faults and distinct types of crash-triggering scenarios. We also demonstrate that the crash-triggering scenarios found by CureFuzz can repair SDMs, highlighting CureFuzz as a valuable tool for testing SDMs and optimizing their performance.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {165},
numpages = {14},
keywords = {fuzz testing, sequential decision making, deep learning},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3597503.3639150,
author = {Ma, Zeyang and Chen, An Ran and Kim, Dong Jae and Chen, Tse-Hsun and Wang, Shaowei},
title = {LLMParser: An Exploratory Study on Using Large Language Models for Log Parsing},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639150},
doi = {10.1145/3597503.3639150},
abstract = {Logs are important in modern software development with runtime information. Log parsing is the first step in many log-based analyses, that involve extracting structured information from unstructured log data. Traditional log parsers face challenges in accurately parsing logs due to the diversity of log formats, which directly impacts the performance of downstream log-analysis tasks. In this paper, we explore the potential of using Large Language Models (LLMs) for log parsing and propose LLMParser, an LLM-based log parser based on generative LLMs and few-shot tuning. We leverage four LLMs, Flan-T5-small, Flan-T5-base, LLaMA-7B, and ChatGLM-6B in LLMParsers. Our evaluation of 16 open-source systems shows that LLMParser achieves statistically significantly higher parsing accuracy than state-of-the-art parsers (a 96\% average parsing accuracy). We further conduct a comprehensive empirical analysis on the effect of training size, model size, and pre-training LLM on log parsing accuracy. We find that smaller LLMs may be more effective than more complex LLMs; for instance where Flan-T5-base achieves comparable results as LLaMA-7B with a shorter inference time. We also find that using LLMs pre-trained using logs from other systems does not always improve parsing accuracy. While using pre-trained Flan-T5-base shows an improvement in accuracy, pre-trained LLaMA results in a decrease (decrease by almost 55\% in group accuracy). In short, our study provides empirical evidence for using LLMs for log parsing and highlights the limitations and future research direction of LLM-based log parsers.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {99},
numpages = {13},
keywords = {log parsing, log analysis, large language model},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3597503.3639162,
author = {Liu, Tianyang and Ji, Weixing and Dong, Xiaohui and Yao, Wuhuang and Wang, Yizhuo and Liu, Hui and Peng, Haiyang and Wang, Yuxuan},
title = {JLeaks: A Featured Resource Leak Repository Collected From Hundreds of Open-Source Java Projects},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639162},
doi = {10.1145/3597503.3639162},
abstract = {High-quality defect repositories are vital in defect detection, localization, and repair. However, existing repositories collected from open-source projects are either small-scale or inadequately labeled and packed. This paper systematically summarizes the programming APIs of system resources (i.e., file, socket, and thread) in Java. Additionally, this paper demonstrates the exceptions that may cause resource leaks in the chained and nested streaming operations. A semi-automatic toolchain is built to improve the efficiency of defect extraction, including automatic building for large legacy Java projects. Accordingly, 1,094 resource leaks were collected from 321 open-source projects on GitHub. This repository, named JLeaks, was built by round-by-round filtering and cross-validation, involving the review of approximately 3,185 commits from hundreds of projects. JLeaks is currently the largest resource leak repository, and each defect in JLeaks is well-labeled and packed, including causes, locations, patches, source files, and compiled bytecode files for 254 defects. We have conducted a detailed analysis of JLeaks for defect distribution, root causes, and fix approaches. We compare JLeaks with two well-known resource leak repositories, and the results show that JLeaks is more informative and complete, with high availability, uniqueness, and consistency. Additionally, we show the usability of JLeaks in two application scenarios. Future studies can leverage our repository to encourage better design and implementation of defect-related algorithms and tools.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {140},
numpages = {13},
keywords = {resource leak, defect repository, open-source projects, java language},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3597503.3639176,
author = {OBrien, David and Biswas, Sumon and Imtiaz, Sayem Mohammad and Abdalkareem, Rabe and Shihab, Emad and Rajan, Hridesh},
title = {Are Prompt Engineering and TODO Comments Friends or Foes? An Evaluation on GitHub Copilot},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639176},
doi = {10.1145/3597503.3639176},
abstract = {Code intelligence tools such as GitHub Copilot have begun to bridge the gap between natural language and programming language. A frequent software development task is the management of technical debts, which are suboptimal solutions or unaddressed issues which hinder future software development. Developers have been found to "self-admit" technical debts (SATD) in software artifacts such as source code comments. Thus, is it possible that the information present in these comments can enhance code generative prompts to repay the described SATD? Or, does the inclusion of such comments instead cause code generative tools to reproduce the harmful symptoms of described technical debt? Does the modification of SATD impact this reaction? Despite the heavy maintenance costs caused by technical debt and the recent improvements of code intelligence tools, no prior works have sought to incorporate SATD towards prompt engineering. Inspired by this, this paper contributes and analyzes a dataset consisting of 36,381 TODO comments in the latest available revisions of their respective 102,424 repositories, from which we sample and manually generate 1,140 code bodies using GitHub Copilot. Our experiments show that GitHub Copilot can generate code with the symptoms of SATD, both prompted and unprompted. Moreover, we demonstrate the tool's ability to automatically repay SATD under different circumstances and qualitatively investigate the characteristics of successful and unsuccessful comments. Finally, we discuss gaps in which GitHub Copilot's successors and future researchers can improve upon code intelligence tasks to facilitate AI-assisted software maintenance.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {219},
numpages = {13},
keywords = {technical debt, GitHub copilot, LLM, code generation},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3597503.3639180,
author = {Liu, Zhe and Chen, Chunyang and Wang, Junjie and Chen, Mengzhuo and Wu, Boyu and Che, Xing and Wang, Dandan and Wang, Qing},
title = {Make LLM a Testing Expert: Bringing Human-like Interaction to Mobile GUI Testing via Functionality-aware Decisions},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639180},
doi = {10.1145/3597503.3639180},
abstract = {Automated Graphical User Interface (GUI) testing plays a crucial role in ensuring app quality, especially as mobile applications have become an integral part of our daily lives. Despite the growing popularity of learning-based techniques in automated GUI testing due to their ability to generate human-like interactions, they still suffer from several limitations, such as low testing coverage, inadequate generalization capabilities, and heavy reliance on training data. Inspired by the success of Large Language Models (LLMs) like ChatGPT in natural language understanding and question answering, we formulate the mobile GUI testing problem as a Q&amp;A task. We propose GPTDroid, asking LLM to chat with the mobile apps by passing the GUI page information to LLM to elicit testing scripts, and executing them to keep passing the app feedback to LLM, iterating the whole process. Within this framework, we have also introduced a functionality-aware memory prompting mechanism that equips the LLM with the ability to retain testing knowledge of the whole process and conduct long-term, functionality-based reasoning to guide exploration. We evaluate it on 93 apps from Google Play and demonstrate that it outperforms the best baseline by 32\% in activity coverage, and detects 31\% more bugs at a faster rate. Moreover, GPTDroid identifies 53 new bugs on Google Play, of which 35 have been confirmed and fixed.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {100},
numpages = {13},
keywords = {automated GUI testing, large language model},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3597503.3639195,
author = {Dong, Chunhao and Jiang, Yanjie and Niu, Nan and Zhang, Yuxia and Liu, Hui},
title = {Context-Aware Name Recommendation for Field Renaming},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639195},
doi = {10.1145/3597503.3639195},
abstract = {Renaming is one of the most popular software refactorings. Although developers may know what the new name should be when they conduct a renaming, it remains valuable for refactoring tools to recommend new names automatically so that developers can simply hit Enter and efficiently accept the recommendation to accomplish the refactoring. Consequently, most IDEs automatically recommend new names for renaming refactorings by default. However, the recommendation made by mainstream IDEs is often incorrect. For example, the precision of IntelliJ IDEA in recommending names for field renamings is as low as 6.3\%. To improve the accuracy, in this paper, we propose a context-aware lightweight approach (called CARER) to recommend new names for Java field renamings. Different from mainstream IDEs that rely heavily on initializers and data types of the to-be-renamed fields, CARER exploits both dynamic and static contexts of the renamings as well as naming conventions. We evaluate CARER on 1.1K real-world field renamings discovered from open-source applications. Our evaluation results suggest that CARER can significantly improve the state of the practice in recommending new names for field renamings, improving the precision from 6.30\% to 61.15\%, and recall from 6.30\% to 41.50\%. Our evaluation results also suggest that CARER is as efficient as IntelliJ IDEA is, making it suitable to be integrated into IDEs.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {235},
numpages = {13},
keywords = {refactoring, rename, recommendation, context-aware},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3597503.3639201,
author = {Choudhuri, Rudrajit and Liu, Dylan and Steinmacher, Igor and Gerosa, Marco and Sarma, Anita},
title = {How Far Are We? The Triumphs and Trials of Generative AI in Learning Software Engineering},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639201},
doi = {10.1145/3597503.3639201},
abstract = {Conversational Generative AI (convo-genAI) is revolutionizing Software Engineering (SE) as engineers and academics embrace this technology in their work. However, there is a gap in understanding the current potential and pitfalls of this technology, specifically in supporting students in SE tasks. In this work, we evaluate through a between-subjects study (N=22) the effectiveness of ChatGPT, a convo-genAI platform, in assisting students in SE tasks. Our study did not find statistical differences in participants' productivity or self-efficacy when using ChatGPT as compared to traditional resources, but we found significantly increased frustration levels. Our study also revealed 5 distinct faults arising from violations of Human-AI interaction guidelines, which led to 7 different (negative) consequences on participants.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {184},
numpages = {13},
keywords = {empirical study, software engineering, generative AI, ChatGPT},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3597503.3639202,
author = {Sun, Jiamou and Chen, Jieshan and Xing, Zhenchang and Lu, Qinghua and Xu, Xiwei and Zhu, Liming},
title = {Where is it? Tracing the Vulnerability-relevant Files from Vulnerability Reports},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639202},
doi = {10.1145/3597503.3639202},
abstract = {With the widely usage of open-source software, supply-chain-based vulnerability attacks, including SolarWind and Log4Shell, have posed significant risks to software security. Currently, people rely on vulnerability advisory databases or commercial software bill of materials (SBOM) to defend against potential risks. Unfortunately, these datasets do not provide finer-grained file-level vulnerability information, compromising their effectiveness. Previous works have not adequately addressed this issue, and mainstream vulnerability detection methods have their drawbacks that hinder resolving this gap. Driven by the real needs, we propose a framework that can trace the vulnerability-relevant file for each disclosed vulnerability. Our approach uses NVD descriptions with metadata as the inputs, and employs a series of strategies with a LLM model, search engine, heuristic-based text matching method and a deep learning classifier to recommend the most likely vulnerability-relevant file, effectively enhancing the completeness of existing NVD data. Our experiments confirm that the efficiency of the proposed framework, with CodeBERT achieving 0.92 AUC and 0.85 MAP, and our user study proves our approach can help with vulnerability-relevant file detection effectively. To the best of our knowledge, our work is the first one focusing on tracing vulnerability-relevant files, laying the groundwork of building finer-grained vulnerability-aware software bill of materials.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {200},
numpages = {13},
keywords = {vulnerability-relevant file, security, software supply chain},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3597503.3639222,
author = {Zhou, Xin and Kim, Kisub and Xu, Bowen and Han, Donggyun and Lo, David},
title = {Out of Sight, Out of Mind: Better Automatic Vulnerability Repair by Broadening Input Ranges and Sources},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639222},
doi = {10.1145/3597503.3639222},
abstract = {The advances of deep learning (DL) have paved the way for automatic software vulnerability repair approaches, which effectively learn the mapping from the vulnerable code to the fixed code. Nevertheless, existing DL-based vulnerability repair methods face notable limitations: 1) they struggle to handle lengthy vulnerable code, 2) they treat code as natural language texts, neglecting its inherent structure, and 3) they do not tap into the valuable expert knowledge present in the expert system. To address this, we propose VulMaster, a Transformer-based neural network model that excels at generating vulnerability repairs by comprehensively understanding the entire vulnerable code, irrespective of its length. This model also integrates diverse information, encompassing vulnerable code structures and expert knowledge from the CWE system. We evaluated VulMaster on a real-world C/C++ vulnerability repair dataset comprising 1,754 projects with 5,800 vulnerable functions. The experimental results demonstrated that VulMaster exhibits substantial improvements compared to the learning-based state-of-the-art vulnerability repair approach. Specifically, VulMaster improves the EM, BLEU, and CodeBLEU scores from 10.2\% to 20.0\%, 21.3\% to 29.3\%, and 32.5\% to 40.9\%, respectively.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {88},
numpages = {13},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3597503.3639580,
author = {OBrien, David and Dyer, Robert and Nguyen, Tien and Rajan, Hridesh},
title = {Data-Driven Evidence-Based Syntactic Sugar Design},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639580},
doi = {10.1145/3597503.3639580},
abstract = {Programming languages are essential tools for developers, and their evolution plays a crucial role in supporting the activities of developers. One instance of programming language evolution is the introduction of syntactic sugars, which are additional syntax elements that provide alternative, more readable code constructs. However, the process of designing and evolving a programming language has traditionally been guided by anecdotal experiences and intuition. Recent advances in tools and methodologies for mining open-source repositories have enabled developers to make data-driven software engineering decisions. In light of this, this paper proposes an approach for motivating data-driven programming evolution by applying frequent subgraph mining techniques to a large dataset of 166,827,154 open-source Java methods. The dataset is mined by generalizing Java control-flow graphs to capture broad programming language usages and instances of duplication. Frequent subgraphs are then extracted to identify potentially impactful opportunities for new syntactic sugars. Our diverse results demonstrate the benefits of the proposed technique by identifying new syntactic sugars involving a variety of programming constructs that could be implemented in Java, thus simplifying frequent code idioms. This approach can potentially provide valuable insights for Java language designers, and serve as a proof-of-concept for data-driven programming language design and evolution.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {203},
numpages = {12},
keywords = {syntactic sugars, data-driven language design, subgraph mining},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@proceedings{10.1145/3603166,
title = {UCC '23: Proceedings of the IEEE/ACM 16th International Conference on Utility and Cloud Computing},
year = {2023},
isbn = {9798400702341},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The IEEE/ACM International Conference on Utility and Cloud Computing (UCC) is a premier annual conference series aiming to provide a platform for researchers from both academia and industry to present new discoveries in the broad area of Cloud and Edge utility computing and applications.},
location = {Taormina (Messina), Italy}
}

@inproceedings{10.1145/3603166.3632164,
author = {Al-Ameen, Shamil and Sudharsan, Bharath and Szydlo, Tomasz and Al-Taie, Roua and Shah, Tejal and Ranjan, Rajiv},
title = {Tiny-Impute: A Framework for On-device Data Quality Validation, Hybrid Anomaly Detection, and Data Imputation at the Edge},
year = {2024},
isbn = {9798400702341},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3603166.3632164},
doi = {10.1145/3603166.3632164},
abstract = {In the landscape of Internet of Things (IoT) systems, data quality degradation can occur continuously for several reasons, such as sensor malfunctions, intermittent network availability, device maintenance, or incomplete data collection. This paper proposes three efficient data quality validation and imputation algorithms that identify and replace noisy and missing values with better-quality data. We extensively stress-tested and evaluated our algorithms by deploying them on microcontrollers and small CPU-based IoT boards with memory limited to as little as 32KB. We simulated a sensor data stream using five real-world datasets, including data collected from the Newcastle Urban Observatory. In this setup, each algorithm excelled in different areas, consistently demonstrating high performance across 100 samples in terms of high energy efficiency (0.014 J), low computation time (85.94 ms), and low error rates (0.0019 MAE, 0.0027 RMSE). Remarkably, we found that on average, our algorithms running on hardware, costing less than $10, showed performance on par with state-of-the-art methods on high-end devices. The results also demonstrated that our algorithms enabled on-device cleansing of live streaming sensor data, eliminating the dependency on cloud services and allowing for real-time data quality validation and processing at the edge.},
booktitle = {Proceedings of the IEEE/ACM 16th International Conference on Utility and Cloud Computing},
articleno = {23},
numpages = {10},
keywords = {edge computing, IoT devices, TinyML, data imputation},
location = {Taormina (Messina), Italy},
series = {UCC '23}
}

@proceedings{10.1145/3603273,
title = {AAIA '23: Proceedings of the 2023 International Conference on Advances in Artificial Intelligence and Applications},
year = {2023},
isbn = {9798400708268},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Wuhan, China}
}

@proceedings{10.1145/3603287,
title = {ACMSE '24: Proceedings of the 2024 ACM Southeast Conference},
year = {2024},
isbn = {9798400702372},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are pleased to welcome you to the 2024 ACM Southeast Conference (ACMSE 2024) sponsored by ACM and the College of Computing and Software Engineering (CCSE) at Kennesaw State University, Marietta, Georgia, USA. ACMSE 2024 continues the ACM Southeast Conference tradition of participation in all areas of computing disciplines. We hope this conference will be an excellent opportunity to share current and future hot research trends amongst researchers from around the world.},
location = {Marietta, GA, USA}
}

@inproceedings{10.1145/3603287.3651194,
author = {Jamdade, Mahesh and Liu, Yi},
title = {A Pilot Study on Secure Code Generation with ChatGPT for Web Applications},
year = {2024},
isbn = {9798400702372},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3603287.3651194},
doi = {10.1145/3603287.3651194},
abstract = {Conversational Large Language Models (LLMs), such as ChatGPT, have demonstrated their potent capabilities in natural language processing tasks. This paper presents a pilot study that uses ChatGPT for generating web application code with a specific emphasis on mitigating four prevalent web application vulnerability types: SQL Injection, Cross Site Scripting, Carriage Return Line Feed Injection, and Exposure of Sensitive Information. The paper uses a case study to illustrate how the vulnerabilities in the code are mitigated with the prompts and the subsequent refinements. The study's findings summarize the security concerns in the code generated by ChatGPT, and the paper proposes a prompt pattern designed to help mitigating the potential vulnerabilities.},
booktitle = {Proceedings of the 2024 ACM Southeast Conference},
pages = {229–234},
numpages = {6},
keywords = {ChatGPT, Secure coding, generative AI, web application vulnerabilities},
location = {Marietta, GA, USA},
series = {ACMSE '24}
}

@proceedings{10.1145/3604237,
title = {ICAIF '23: Proceedings of the Fourth ACM International Conference on AI in Finance},
year = {2023},
isbn = {9798400702402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Brooklyn, NY, USA}
}

@inproceedings{10.1145/3604237.3626866,
author = {Zhang, Boyu and Yang, Hongyang and Zhou, Tianyu and Ali Babar, Muhammad and Liu, Xiao-Yang},
title = {Enhancing Financial Sentiment Analysis via Retrieval Augmented Large Language Models},
year = {2023},
isbn = {9798400702402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604237.3626866},
doi = {10.1145/3604237.3626866},
abstract = {Financial sentiment analysis is critical for valuation and investment decision-making. Traditional NLP models, however, are limited by their parameter size and the scope of their training datasets, which hampers their generalization capabilities and effectiveness in this field. Recently, Large Language Models (LLMs) pre-trained on extensive corpora have demonstrated superior performance across various NLP tasks due to their commendable zero-shot abilities. Yet, directly applying LLMs to financial sentiment analysis presents challenges: The discrepancy between the pre-training objective of LLMs and predicting the sentiment label can compromise their predictive performance. Furthermore, the succinct nature of financial news, often devoid of sufficient context, can significantly diminish the reliability of LLMs’ sentiment analysis. To address these challenges, we introduce a retrieval-augmented LLMs framework for financial sentiment analysis. This framework includes an instruction-tuned LLMs module, which ensures LLMs behave as predictors of sentiment labels, and a retrieval-augmentation module which retrieves additional context from reliable external sources. Benchmarked against traditional models and LLMs like ChatGPT and LLaMA, our approach achieves 15\% to 48\% performance gain in accuracy and F1 score.},
booktitle = {Proceedings of the Fourth ACM International Conference on AI in Finance},
pages = {349–356},
numpages = {8},
keywords = {Instruction Tuning, Large Language Models, Retrieval Augmented Generation, Sentiment Analysis},
location = {Brooklyn, NY, USA},
series = {ICAIF '23}
}

@inproceedings{10.1145/3604237.3626880,
author = {Frey, Sascha Yves and Li, Kang and Nagy, Peer and Sapora, Silvia and Lu, Christopher and Zohren, Stefan and Foerster, Jakob and Calinescu, Anisoara},
title = {JAX-LOB: A GPU-Accelerated limit order book simulator to unlock large scale reinforcement learning for trading},
year = {2023},
isbn = {9798400702402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604237.3626880},
doi = {10.1145/3604237.3626880},
abstract = {Financial exchanges across the world use limit order books (LOBs) to process orders and match trades. For research purposes it is important to have large scale efficient simulators of LOB dynamics. LOB simulators have previously been implemented in the context of agent-based models (ABMs), reinforcement learning (RL) environments, and generative models, processing order flows from historical data sets and hand-crafted agents alike. For many applications, there is a requirement for processing multiple books, either for the calibration of ABMs or for the training of RL agents. We showcase the first GPU-enabled LOB simulator designed to process thousands of books in parallel, whether for identical or different securities, with an up to 75x faster per-message processing time. The implementation of our simulator – JAX-LOB – is based on design choices that aim to best exploit the powers of JAX without compromising on the realism of LOB-related mechanisms. We integrate JAX-LOB with other JAX packages, to provide an example of how one may address an optimal execution problem with reinforcement learning, and to share some preliminary results from end-to-end RL training on GPUs. The project code is available on GitHub 1},
booktitle = {Proceedings of the Fourth ACM International Conference on AI in Finance},
pages = {583–591},
numpages = {9},
keywords = {high frequency trading, limit order books, market replay, order book simulator, reinforcement learning, trade execution},
location = {Brooklyn, NY, USA},
series = {ICAIF '23}
}

@proceedings{10.1145/3605098,
title = {SAC '24: Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of the Organizing Committee, I extend a warm welcome to you at the 39th Annual ACM Symposium on Applied Computing (SAC 2024), taking place in \'{A}vila, Spain, and hosted by the University of Salamanca. For more than three decades, this international forum has been dedicated to computer scientists, engineers, and practitioners, providing a platform for presenting their research findings and results in various areas of applied computing. The organizing committee sincerely appreciates your participation in this exciting international event, and we hope that the conference proves interesting and beneficial for all attendees.},
location = {Avila, Spain}
}

@inproceedings{10.1145/3605098.3636010,
author = {Ul Haq, Muhammad Uzair and Frazzetto, Paolo and Sperduti, Alessandro and Da San Martino, Giovanni},
title = {Improving Soft Skill Extraction via Data Augmentation and Embedding Manipulation},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605098.3636010},
doi = {10.1145/3605098.3636010},
abstract = {Soft skills (SS) are important for Human Resource Management when recruiting suitable candidates for a job. Nowadays, enterprises aim to automatically extract such information from documents, curriculum vitae (CVs) and job descriptions, to speed up their recruitment process. State-of-the-art Large Language Models (LLMs) have been successful in Natural Language Processing (NLP) by fine-tuning them to the domain-specific task. However, annotated data for the task is very limited and costly to obtain, since it requires domain experts. Moreover, SS consists of complex long entities which are difficult to extract given few annotated examples. As a consequence, the performance of the LLMs on soft skill detection still needs improvement before being used in a real-world context. In this paper, we introduce data augmentation based entity extraction approach which shows promising performance when the entity length is long (i.e more than three tokens). Moreover, we explore the performance of pre-trained LLMs to generate synthetic data for training. The pre-trained models are used to generate contextual augmentation of the baseline dataset. We further analyse the embeddings generated by these models in aiding the extraction process of entities. We develop an Embedding Manipulation (EM) approach to further improve the performance of baseline models. We evaluated our approach on the only publicly available dataset for soft skills (SKILLSPAN), and on three Entity Extraction datasets (GUM, WNUT-2017 and CoNLL-2003) to assess the proposed approach. Empirical evidence shows that the proposed approach allows us to get 6.52\% increased F1 over the baseline model for the soft skills.},
booktitle = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
pages = {987–996},
numpages = {10},
keywords = {skill extraction, data augmentation, human resource, embeddings, NER},
location = {Avila, Spain},
series = {SAC '24}
}

@inproceedings{10.1145/3605098.3636026,
author = {Jamil, Hasan and Krawetz, Stephen and Gow, Alexander},
title = {Knowledge Synthesis using Large Language Models for a Computational Biology Workflow Ecosystem},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605098.3636026},
doi = {10.1145/3605098.3636026},
abstract = {An understanding of the molecular basis of musculoskeletal pain is necessary for the development of therapeutics, their management, and possible personalization. One-in-three Americans use OTC pain killers, and one tenth use prescription drugs to manage pain. The CDC also estimates that about 20\% Americans suffer from chronic pain. As the experience of acute or chronic pain varies due to individual genetics and physiology, it is imperative that researchers continue to find novel therapeutics to treat or manage symptoms. In this paper, our goal is to develop a seed knowledgebase computational platform, called BioNursery, that will allow biologists to computationally hypothesize, define and test molecular mechanisms underlying pain. In our knowledge ecosystem, we accumulate curated information from users about the relationships among biological databases, analysis tools, and database contents to generate biological analyses modules, called π-graphs, or process graphs. We propose a mapping function from a natural language description of a hypothesized molecular model to a computational workflow for testing in BioNursery. We use a crowd computing feedback and curation system, called Explorer, to improve proposed computational models for molecular mechanism discovery, and growing the knowledge ecosystem. Since the pain knowledge ecosystem does not yet exist, we validate our approach over a similar application in fertility research.},
booktitle = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
pages = {523–530},
numpages = {8},
keywords = {knowledge ecosystem, crowdsourcing, query reformulation},
location = {Avila, Spain},
series = {SAC '24}
}

@proceedings{10.1145/3605764,
title = {AISec '23: Proceedings of the 16th ACM Workshop on Artificial Intelligence and Security},
year = {2023},
isbn = {9798400702600},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our pleasure to welcome you to the 16th ACM Workshop on Artificial Intelligence and Security - AISec 2023. AISec, having been annually co-located with CCS for 16 consecutive years, is the premier meeting place for researchers interested in the intersection of security, privacy, AI, and machine learning. Its role as a venue has been to merge practical security problems with advances in AI and machine learning. In doing so, researchers have also been developing theories and analytics unique to this domain and have explored diverse topics such as learning in gametheoretic adversarial environments, privacy-preserving learning, and applications to malware, spam, and intrusion detection. AISec 2022 received 64 submissions, of which 21 (35\%) were selected for publication and presentation as full papers. Submissions arrived from researchers in many different countries, and from a wide variety of institutions, both academic and corporate.},
location = {Copenhagen, Denmark}
}

@inproceedings{10.1145/3605764.3623915,
author = {Imgrund, Erik and Ganz, Tom and H\"{a}rterich, Martin and Pirch, Lukas and Risse, Niklas and Rieck, Konrad},
title = {Broken Promises: Measuring Confounding Effects in Learning-based Vulnerability Discovery},
year = {2023},
isbn = {9798400702600},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605764.3623915},
doi = {10.1145/3605764.3623915},
abstract = {Several learning-based vulnerability detection methods have been proposed to assist developers during the secure software development life-cycle. In particular, recent learning-based large transformer networks have shown remarkably high performance in various vulnerability detection and localization benchmarks. However, these models have also been shown to have difficulties accurately locating the root cause of flaws and generalizing to out-of-distribution samples. In this work, we investigate this problem and identify spurious correlations as the main obstacle to transferability and generalization, resulting in performance losses of up to 30\% for current models. We propose a method to measure the impact of these spurious correlations on learning models and estimate their true, unbiased performance. We present several strategies to counteract the underlying confounding bias, but ultimately our work highlights the limitations of evaluations in the laboratory for complex learning tasks such as vulnerability discovery.},
booktitle = {Proceedings of the 16th ACM Workshop on Artificial Intelligence and Security},
pages = {149–160},
numpages = {12},
keywords = {causal learning, confounding effect, large language models, overfitting, vulnerability discovery},
location = {Copenhagen, Denmark},
series = {AISec '23}
}

@proceedings{10.1145/3605769,
title = {ASHES '23: Proceedings of the 2023 Workshop on Attacks and Solutions in Hardware Security},
year = {2023},
isbn = {9798400702624},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the Seventh Workshop on Attacks and Solutions in Hardware Security 2023 (ASHES 2023), a post-conference satellite workshop of the ACM Conference on Computer and Communications Security 2023 (CCS 2023).ASHES deals with all theoretical and practical aspects of hardware security and welcomes any contributions to this area. Besides being a mainstream platform for disseminating fundamental research, the workshop also encourages and promotes emerging and new ideas. This includes diverse topics such as physical attacks, secure hardware designs and implementations, lightweight secure systems, post-quantum security, as well as emerging topics at the intersection of nanotechnology and security, such as physical unclonable functions (PUFs). The workshop also puts a particular focus on recent applications like the internet of things, automotive security, smart homes, or pervasive and wearable computing. ASHES thereby aims at giving researchers and practitioners a unique opportunity to share their perspectives.},
location = {Copenhagen, Denmark}
}

@proceedings{10.1145/3605770,
title = {SCORED '23: Proceedings of the 2023 Workshop on Software Supply Chain Offensive Research and Ecosystem Defenses},
year = {2023},
isbn = {9798400702631},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to ACM SCORED '23, the second edition of the ACM Workshop on Software Supply Chain Offensive Research and Ecosystem Defenses. This edition is held in Copenhagen, Denmark with extensive support for in-person and virtual attendance.This year's program includes exciting work along many different dimensions of research on supply chain security: the development of security policies for software supply chains, the use of artificial intelligence and large language models, approaches on software bills of materials, and the proposals of risk mitigation techniques. Consistent with its focus, SCORED brings researchers, legislators and practitioners in both open- and closed-source ecosystems to the center of current and emerging challenges and opportunities in software supply chain security.},
location = {Copenhagen, Denmark}
}

@proceedings{10.1145/3607888,
title = {CODES/ISSS '23 Companion: Proceedings of the 2023 International Conference on Hardware/Software Codesign and System Synthesis},
year = {2023},
isbn = {9798400702891},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {CODES+ISSS is the leading conference in the domain of hardware/software codesign, embedded systems, cyber-physical systems, and Internet-of-Things, offering unique opportunities for sharing ideas and disseminating results on system-level design, modeling, analysis, and implementation aspects. The conference spans a wide range of design abstractions -- from system-level specification and optimization down to synthesis of multiprocessor systems and hardware/software implementations and optimizations.},
location = {Hamburg, Germany}
}

@proceedings{10.1145/3610538,
title = {SA '23: SIGGRAPH Asia 2023 Courses},
year = {2023},
isbn = {9798400703096},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Sydney, NSW, Australia}
}

@proceedings{10.1145/3610540,
title = {SA '23: SIGGRAPH Asia 2023 Educator's Forum},
year = {2023},
isbn = {9798400703119},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Sydney, NSW, Australia}
}

@proceedings{10.1145/3610543,
title = {SA '23: SIGGRAPH Asia 2023 Technical Communications},
year = {2023},
isbn = {9798400703140},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Sydney, NSW, Australia}
}

@proceedings{10.1145/3610548,
title = {SA '23: SIGGRAPH Asia 2023 Conference Papers},
year = {2023},
isbn = {9798400703157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Sydney, NSW, Australia}
}

@inproceedings{10.1145/3610548.3618144,
author = {Hu, Jingyu and Hui, Ka-Hei and Liu, Zhengzhe and Zhang, Hao and Fu, Chi-Wing},
title = {CLIPXPlore: Coupled CLIP and Shape Spaces for 3D Shape Exploration},
year = {2023},
isbn = {9798400703157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610548.3618144},
doi = {10.1145/3610548.3618144},
abstract = {This paper presents CLIPXPlore, a new framework that leverages a vision-language model to guide the exploration of the 3D shape space. Many recent methods have been developed to encode 3D shapes into a learned latent shape space to enable generative design and modeling. Yet, existing methods lack effective exploration mechanisms, despite the rich information. To this end, we propose to leverage CLIP, a powerful pre-trained vision-language model, to aid the shape-space exploration. Our idea is threefold. First, we couple the CLIP and shape spaces by generating paired CLIP and shape codes through sketch images and training a mapper network to connect the two spaces. Second, to explore the space around a given shape, we formulate a co-optimization strategy to search for the CLIP code that better matches the geometry of the shape. Third, we design three exploration modes, binary-attribute-guided, text-guided, and sketch-guided, to locate suitable exploration trajectories in shape space and induce meaningful changes to the shape. We perform a series of experiments to quantitatively and visually compare&nbsp;CLIPXPlore&nbsp;with different baselines in each of the three exploration modes, showing that&nbsp;CLIPXPlore&nbsp;can produce many meaningful exploration results that cannot be achieved by the existing solutions.},
booktitle = {SIGGRAPH Asia 2023 Conference Papers},
articleno = {67},
numpages = {12},
keywords = {3D shape generation, shape space exploration},
location = {Sydney, NSW, Australia},
series = {SA '23}
}

@inproceedings{10.1145/3610548.3618180,
author = {Zabari, Nir and Azulay, Aharon and Gorkor, Alexey and Halperin, Tavi and Fried, Ohad},
title = {Diffusing Colors: Image Colorization with Text Guided Diffusion},
year = {2023},
isbn = {9798400703157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610548.3618180},
doi = {10.1145/3610548.3618180},
abstract = {The colorization of grayscale images is a complex and subjective task with significant challenges. Despite recent progress in employing large-scale datasets with deep neural networks, difficulties with controllability and visual quality persist. To tackle these issues, we present a novel image colorization framework that utilizes image diffusion techniques with granular text prompts. This integration not only produces colorization outputs that are semantically appropriate but also greatly improves the level of control users have over the colorization process. Our method provides a balance between automation and control, outperforming existing techniques in terms of visual quality and semantic coherence. We leverage a pretrained generative Diffusion Model, and show that we can finetune it for the colorization task without losing its generative power or attention to text prompts. Moreover, we present a novel CLIP-based ranking model that evaluates color vividness, enabling automatic selection of the most suitable level of vividness based on the specific scene semantics. Our approach holds potential particularly for color enhancement and historical image colorization.},
booktitle = {SIGGRAPH Asia 2023 Conference Papers},
articleno = {61},
numpages = {11},
keywords = {Controlled Colorization., Language-Guided Colorization},
location = {Sydney, NSW, Australia},
series = {SA '23}
}

@inproceedings{10.1145/3610548.3618219,
author = {Kodnongbua, Milin and Jones, Benjamin and Ahmad, Maaz Bin Safeer and Kim, Vladimir and Schulz, Adriana},
title = {ReparamCAD: Zero-shot CAD Re-Parameterization for Interactive Manipulation},
year = {2023},
isbn = {9798400703157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610548.3618219},
doi = {10.1145/3610548.3618219},
abstract = {Parametric CAD models encode entire families of shapes that should, in principle, be easy for designers to explore. However, in practice, parametric CAD models can be difficult to manipulate due to implicit semantic constraints among parameter values. Finding and enforcing these semantic constraints solely from geometry or programmatic shape representations is not possible because these constraints ultimately reflect design intent. They are informed by the designer’s experience and semantics in the real world. To address this challenge, we introduce ReparamCAD, a zero-shot pipeline that leverages pre-trained large language and image model to infer meaningful space of variations for a shape We then re-parameterize a new constrained parametric CAD program that captures these variations, enabling effortless exploration of the design space along meaningful design axes. We evaluated our approach through five examples and a user study. The result showed that the inferred spaces are meaningful and comparable to those defined by experts. Code and data are at: https://github.com/milmillin/ReparamCAD.},
booktitle = {SIGGRAPH Asia 2023 Conference Papers},
articleno = {69},
numpages = {12},
keywords = {parametric modeling, program synthesis},
location = {Sydney, NSW, Australia},
series = {SA '23}
}

@proceedings{10.1145/3610591,
title = {SA '23: SIGGRAPH Asia 2023 Art Papers},
year = {2023},
isbn = {9798400703201},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Sydney, NSW, Australia}
}

@proceedings{10.1145/3610977,
title = {HRI '24: Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
year = {2024},
isbn = {9798400703225},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome one and all to the 19th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI)!We are so pleased to re-welcome the HRI community to Boulder, Colorado, where HRI 2021 would have been held, had the COVID pandemic not interfered. Following up on the successful in-person conference held last year in Sweden, this year's theme is "HRI in the Real World," and focuses on advances that aim to bring human-robot interaction out of the lab and into everyday life.One aspect of this that we are very excited about is the introduction of a robot challenge to the conference activities, where teams from around the world will showcase their research and development via actual, interactive robots in the "real world" of an academic conference. It is our hope that this feature will grow and develop over the coming years into a staple of the HRI conference.This year's HRI conference saw an impressive surge in global interest, with 352 full paper submissions from around the world, marking a significant 40\% increase compared to the previous year. These papers were categorized under relevant thematic subcommittees and underwent a double-blind review process, a rebuttal phase, and selective shepherding by the HRI program committee. From this process, 87 outstanding papers (24.7\%) were chosen for full presentation at the conference. Reflecting our joint sponsorship with IEEE and ACM, all accepted papers will be accessible in the ACM Digital Library and IEEE Xplore.},
location = {Boulder, CO, USA}
}

@proceedings{10.1145/3610978,
title = {HRI '24: Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
year = {2024},
isbn = {9798400703232},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome one and all to the 19th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI)!We are so pleased to re-welcome the HRI community to Boulder, Colorado, where HRI 2021 would have been held, had the COVID pandemic not interfered. Following up on the successful in-person conference held last year in Sweden, this year's theme is "HRI in the Real World," and focuses on advances that aim to bring human-robot interaction out of the lab and into everyday life.One aspect of this that we are very excited about is the introduction of a robot challenge to the conference activities, where teams from around the world will showcase their research and development via actual, interactive robots in the "real world" of an academic conference. It is our hope that this feature will grow and develop over the coming years into a staple of the HRI conference.This year's HRI conference saw an impressive surge in global interest, with 352 full paper submissions from around the world, marking a significant 40\% increase compared to the previous year. These papers were categorized under relevant thematic subcommittees and underwent a double-blind review process, a rebuttal phase, and selective shepherding by the HRI program committee. From this process, 87 outstanding papers (24.7\%) were chosen for full presentation at the conference. Reflecting our joint sponsorship with IEEE and ACM, all accepted papers will be accessible in the ACM Digital Library and IEEE Xplore.},
location = {Boulder, CO, USA}
}

@inproceedings{10.1145/3610978.3641263,
author = {Greenberg, Benjamin and Nakhimovich, Daniel and Magnotti, Richard and Purohit, Hriday and Shah, Sanskar and Kulkarni, Aniket Satish and Gonzalez-Bravo, Uriel and Carver, Noah R.},
title = {Development of a Socially Cognizant Robotic Campus Guide},
year = {2024},
isbn = {9798400703232},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610978.3641263},
doi = {10.1145/3610978.3641263},
abstract = {A robotic system to help lost students find their way around a college campus was designed, built, and tested. Socially cognizant design practices, including stakeholder engagement, and interdisciplinary team-building, were practiced. Users can interact with the robot through speech or touchscreen interfaces. The robot can provide verbal instructions on reaching a destination, or can guide the user to the destination, navigating in a socially conscious way. The speech, person detection, and navigation modules perform well in isolation and in concert. Future work includes technical improvements to the person detection and navigation systems, and evaluating social acceptance.},
booktitle = {Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {1229–1232},
numpages = {4},
keywords = {human-computer interaction, navigation, person detection, robot, social, speech, voice},
location = {Boulder, CO, USA},
series = {HRI '24}
}

@proceedings{10.1145/3611380,
title = {MMAsia '23 Workshops: Proceedings of the 5th ACM International Conference on Multimedia in Asia Workshops},
year = {2023},
isbn = {9798400703263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tainan, Taiwan}
}

@proceedings{10.1145/3611643,
title = {ESEC/FSE 2023: Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are pleased to welcome all delegates to ESEC/FSE 2023, the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering. ESEC/FSE is an internationally renowned forum for researchers, practitioners, and educators to present and discuss the most recent innovations, trends, experiences, and challenges in the field of software engineering. ESEC/FSE brings together experts from academia and industry to exchange the latest research results and trends as well as their practical application in all areas of software engineering.},
location = {San Francisco, CA, USA}
}

@inproceedings{10.1145/3611643.3613083,
author = {Happe, Andreas and Cito, J\"{u}rgen},
title = {Getting pwn’d by AI: Penetration Testing with Large Language Models},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3613083},
doi = {10.1145/3611643.3613083},
abstract = {The field of software security testing, more specifically penetration testing, requires high levels of expertise and involves many manual testing and analysis steps. This paper explores the potential use of large-language models, such as GPT3.5, to augment penetration testers with AI sparring partners. We explore two distinct use cases: high-level task planning for security testing assignments and low-level vulnerability hunting within a vulnerable virtual machine. For the latter, we implemented a closed-feedback loop between LLM-generated low-level actions with a vulnerable virtual machine (connected through SSH) and allowed the LLM to analyze the machine state for vulnerabilities and suggest concrete attack vectors which were automatically executed within the virtual machine. We discuss promising initial results, detail avenues for improvement, and close deliberating on the ethics of AI sparring partners.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {2082–2086},
numpages = {5},
keywords = {large language models, penetration testing, security testing},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3611643.3613861,
author = {Xie, Zhe and Pei, Changhua and Li, Wanxue and Jiang, Huai and Su, Liangfei and Li, Jianhui and Xie, Gaogang and Pei, Dan},
title = {From Point-wise to Group-wise: A Fast and Accurate Microservice Trace Anomaly Detection Approach},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3613861},
doi = {10.1145/3611643.3613861},
abstract = {As Internet applications continue to scale up, microservice architecture has become increasingly popular due to its flexibility and logical structure. Anomaly detection in traces that record inter-microservice invocations is essential for diagnosing system failures. Deep learning-based approaches allow for accurate modeling of structural features (i.e., call paths) and latency features (i.e., call response time), which can determine the anomaly of a particular trace sample. However, the point-wise manner employed by these methods results in substantial system detection overhead and impracticality, given the massive volume of traces (billion-level). Furthermore, the point-wise approach lacks high-level information, as identical sub-structures across multiple traces may be encoded differently. In this paper, we introduce the first Group-wise Trace anomaly detection algorithm, named GTrace. This method categorizes the traces into distinct groups based on their shared sub-structure, such as the entire tree or sub-tree structure. A group-wise Variational AutoEncoder (VAE) is then employed to obtain structural representations. Moreover, the innovative "predicting latency with structure" learning paradigm facilitates the association between the grouped structure and the latency distribution within each group. With the group-wise design, representation caching, and batched inference strategies can be implemented, which significantly reduces the burden of detection on the system. Our comprehensive evaluation reveals that GTrace outperforms state-of-the-art methods in both performances (2.64\% to 195.45\% improvement in AUC metrics and 2.31\% to 40.92\% improvement in best F-Score) and efficiency (21.9x to 28.2x speedup). We have deployed and assessed the proposed algorithm on eBay's microservices cluster, and our code is available at https://github.com/NetManAIOps/GTrace.git.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1739–1749},
numpages = {11},
keywords = {anomaly detection, microservice trace, variational autoencoder},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3611643.3616253,
author = {Gupta, Priyanshu and Khare, Avishree and Bajpai, Yasharth and Chakraborty, Saikat and Gulwani, Sumit and Kanade, Aditya and Radhakrishna, Arjun and Soares, Gustavo and Tiwari, Ashish},
title = {Grace: Language Models Meet Code Edits},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3616253},
doi = {10.1145/3611643.3616253},
abstract = {Developers spend a significant amount of time in editing code for a variety of reasons such as bug fixing or adding new features. Designing effective methods to predict code edits has been an active yet challenging area of research due to the diversity of code edits and the difficulty of capturing the developer intent. In this work, we address these challenges by endowing pre-trained large language models (LLMs) with the knowledge of relevant prior associated edits, which we call the Grace (Generation conditioned on Associated Code Edits) method. The generative capability of the LLMs helps address the diversity in code changes and conditioning code generation on prior edits helps capture the latent developer intent. We evaluate two well-known LLMs, codex and CodeT5, in zero-shot and fine-tuning settings respectively. In our experiments with two datasets, Grace boosts the performance of the LLMs significantly, enabling them to generate 29\% and 54\% more correctly edited code in top-1 suggestions relative to the current state-of-the-art symbolic and neural approaches, respectively.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1483–1495},
numpages = {13},
keywords = {Associated edits, Code editing, Large language models, Pre-trained model, Programming language processing},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3611643.3616288,
author = {Fronchetti, Felipe and Shepherd, David C. and Wiese, Igor and Treude, Christoph and Gerosa, Marco Aur\'{e}lio and Steinmacher, Igor},
title = {Do CONTRIBUTING Files Provide Information about OSS Newcomers’ Onboarding Barriers?},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3616288},
doi = {10.1145/3611643.3616288},
abstract = {Effectively onboarding newcomers is essential for the success of open source projects. These projects often provide onboarding guidelines in their ’CONTRIBUTING’ files (e.g., CONTRIBUTING.md on GitHub). These files explain, for example, how to find open tasks, implement solutions, and submit code for review. However, these files often do not follow a standard structure, can be too large, and miss barriers commonly found by newcomers. In this paper, we propose an automated approach to parse these CONTRIBUTING files and assess how they address onboarding barriers. We manually classified a sample of files according to a model of onboarding barriers from the literature, trained a machine learning classifier that automatically predicts the categories of each paragraph (precision: 0.655, recall: 0.662), and surveyed developers to investigate their perspective of the predictions’ adequacy (75\% of the predictions were considered adequate). We found that CONTRIBUTING files typically do not cover the barriers newcomers face (52\% of the analyzed projects missed at least 3 out of the 6 barriers faced by newcomers; 84\% missed at least 2). Our analysis also revealed that information about choosing a task and talking with the community, two of the most recurrent barriers newcomers face, are neglected in more than 75\% of the projects. We made available our classifier as an online service that analyzes the content of a given CONTRIBUTING file. Our approach may help community builders identify missing information in the project ecosystem they maintain and newcomers can understand what to expect in CONTRIBUTING files.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {16–28},
numpages = {13},
keywords = {FLOSS, novices, onboarding, open source, software engineering},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3611643.3616306,
author = {Mao, Yuetian and Wan, Chengcheng and Jiang, Yuze and Gu, Xiaodong},
title = {Self-Supervised Query Reformulation for Code Search},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3616306},
doi = {10.1145/3611643.3616306},
abstract = {Automatic query reformulation is a widely utilized technology for enriching user requirements and enhancing the outcomes of code search. It can be conceptualized as a machine translation task, wherein the objective is to rephrase a given query into a more comprehensive alternative. While showing promising results, training such a model typically requires a large parallel corpus of query pairs (i.e., the original query and a reformulated query) that are confidential and unpublished by online code search engines. This restricts its practicality in software development processes. In this paper, we propose SSQR, a self-supervised query reformulation method that does not rely on any parallel query corpus. Inspired by pre-trained models, SSQR treats query reformulation as a masked language modeling task conducted on an extensive unannotated corpus of queries. SSQR extends T5 (a sequence-to-sequence model based on Transformer) with a new pre-training objective named corrupted query completion (CQC), which randomly masks words within a complete query and trains T5 to predict the masked content. Subsequently, for a given query to be reformulated, SSQR identifies potential locations for expansion and leverages the pre-trained T5 model to generate appropriate content to fill these gaps. The selection of expansions is then based on the information gain associated with each candidate. Evaluation results demonstrate that SSQR outperforms unsupervised baselines significantly and achieves competitive performance compared to supervised methods.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {363–374},
numpages = {12},
keywords = {Code Search, Query Reformulation, Self-supervised Learning},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3611643.3616309,
author = {Sun, Ruoxi and Xue, Minhui and Tyson, Gareth and Dong, Tian and Li, Shaofeng and Wang, Shuo and Zhu, Haojin and Camtepe, Seyit and Nepal, Surya},
title = {Mate! Are You Really Aware? An Explainability-Guided Testing Framework for Robustness of Malware Detectors},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3616309},
doi = {10.1145/3611643.3616309},
abstract = {Numerous open-source and commercial malware detectors are available. However, their efficacy is threatened by new adversarial attacks, whereby malware attempts to evade detection, e.g., by performing feature-space manipulation. In this work, we propose an explainability-guided and model-agnostic testing framework for robustness of malware detectors when confronted with adversarial attacks. The framework introduces the concept of Accrued Malicious Magnitude (AMM) to identify which malware features could be manipulated to maximize the likelihood of evading detection. We then use this framework to test several state-of-the-art malware detectors' ability to detect manipulated malware. We find that (i) commercial antivirus engines are vulnerable to AMM-guided test cases; (ii) the ability of a manipulated malware generated using one detector to evade detection by another detector (i.e., transferability) depends on the overlap of features with large AMM values between the different detectors; and (iii) AMM values effectively measure the fragility of features (i.e., capability of feature-space manipulation to flip the prediction results) and explain the robustness of malware detectors facing evasion attacks. Our findings shed light on the limitations of current malware detectors, as well as how they can be improved.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1573–1585},
numpages = {13},
keywords = {Explainability, Malware detectors, Robustness},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3611643.3616310,
author = {Wan, Yuxuan and Wang, Wenxuan and He, Pinjia and Gu, Jiazhen and Bai, Haonan and Lyu, Michael R.},
title = {BiasAsker: Measuring the Bias in Conversational AI System},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3616310},
doi = {10.1145/3611643.3616310},
abstract = {Powered by advanced Artificial Intelligence (AI) techniques, conversational AI systems, such as ChatGPT, and digital assistants like Siri, have been widely deployed in daily life. However, such systems may still produce content containing biases and stereotypes, causing potential social problems. Due to modern AI techniques’ data-driven, black-box nature, comprehensively identifying and measuring biases in conversational systems remains challenging. Particularly, it is hard to generate inputs that can comprehensively trigger potential bias due to the lack of data containing both social groups and biased properties. In addition, modern conversational systems can produce diverse responses (e.g., chatting and explanation), which makes existing bias detection methods based solely on sentiment and toxicity hardly being adopted. In this paper, we propose BiasAsker, an automated framework to identify and measure social bias in conversational AI systems. To obtain social groups and biased properties, we construct a comprehensive social bias dataset containing a total of 841 groups and 5,021 biased properties. Given the dataset, BiasAsker automatically generates questions and adopts a novel method based on existence measurement to identify two types of biases (i.e., absolute bias and related bias) in conversational systems. Extensive experiments on eight commercial systems and two famous research models, such as ChatGPT and GPT-3, show that 32.83\% of the questions generated by BiasAsker can trigger biased behaviors in these widely deployed conversational systems. All the code, data, and experimental results have been released to facilitate future research.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {515–527},
numpages = {13},
keywords = {Software testing, conversational models, social bias},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3611643.3616331,
author = {Yang, Jun and Wang, Yuehan and Lou, Yiling and Wen, Ming and Zhang, Lingming},
title = {A Large-Scale Empirical Review of Patch Correctness Checking Approaches},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3616331},
doi = {10.1145/3611643.3616331},
abstract = {Automated Program Repair (APR) techniques have drawn wide attention from both academia and industry. Meanwhile, one main limitation with the current state-of-the-art APR tools is that patches passing all the original tests are not necessarily the correct ones wanted by developers, i.e., the plausible patch problem. To date, various Patch-Correctness Checking (PCC) techniques have been proposed to address this important issue. However, they are only evaluated on very limited datasets as the APR tools used for generating such patches can only explore a small subset of the search space of possible patches, posing serious threats to external validity to existing PCC studies. In this paper, we construct an extensive PCC dataset, PraPatch (the largest manually labeled PCC dataset to our knowledge), to revisit all nine state-of-the-art PCC techniques. More specifically, our PCC dataset PraPatch includes 1,988 patches generated from the recent PraPR APR tool, which leverages highly-optimized bytecode-level patch executions and can exhaustively explore all possible plausible patches within its large predefined search space (including well-known fixing patterns from various prior APR tools). Our extensive study of representative PCC techniques on PraPatch has revealed various findings, including: 1) the assumption made by existing static PCC techniques that correct patches are more similar to buggy code than incorrect plausible patches no longer holds, 2) state-of-the-art learning-based techniques tend to suffer from the dataset overfitting problem, 3) while dynamic techniques overall retain their effectiveness on our new dataset, their performance drops substantially on patches with more complicated changes and 4) the very recent naturalness-based techniques can substantially outperform traditional static techniques and could be a promising direction for PCC. Based on our findings, we also provide various guidelines/suggestions for advancing PCC in the near future.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1203–1215},
numpages = {13},
keywords = {Empirical assessment, Patch correctness, Program repair},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3611643.3616332,
author = {Ye, Guixin and Hu, Tianmin and Tang, Zhanyong and Fan, Zhenye and Tan, Shin Hwei and Zhang, Bo and Qian, Wenxiang and Wang, Zheng},
title = {A Generative and Mutational Approach for Synthesizing Bug-Exposing Test Cases to Guide Compiler Fuzzing},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3616332},
doi = {10.1145/3611643.3616332},
abstract = {Random test case generation, or fuzzing, is a viable means for uncovering compiler bugs. Unfortunately, compiler fuzzing can be time-consuming and inefficient with purely randomly generated test cases due to the complexity of modern compilers. We present COMFUZZ, a focused compiler fuzzing framework. COMFUZZ aims to improve compiler fuzzing efficiency by focusing on testing components and language features that are likely to trigger compiler bugs. Our key insight is human developers tend to make common and repeat errors across compiler implementations; hence, we can leverage the previously reported buggy-exposing test cases of a programming language to test a new compiler implementation. To this end, COMFUZZ employs deep learning to learn a test program generator from open-source projects hosted on GitHub. With the machine-generated test programs in place, COMFUZZ then leverages a set of carefully designed mutation rules to improve the coverage and bug-exposing capabilities of the test cases. We evaluate COMFUZZ on 11 compilers for JS and Java programming languages. Within 260 hours of automated testing runs, we discovered 33 unique bugs across nine compilers, of which 29 have been confirmed and 22, including an API documentation defect, have already been fixed by the developers. We also compared COMFUZZ to eight prior fuzzers on four evaluation metrics. In a 24-hour comparative test, COMFUZZ uncovers at least 1.5\texttimes{} more bugs than the state-of-the-art baselines.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1127–1139},
numpages = {13},
keywords = {Compiler, Deep learning, Fuzzing, Guided testing, Historical bug},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3611643.3616337,
author = {Liu, Jiawei and Peng, Jinjun and Wang, Yuyao and Zhang, Lingming},
title = {NeuRI: Diversifying DNN Generation via Inductive Rule Inference},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3616337},
doi = {10.1145/3611643.3616337},
abstract = {Deep Learning (DL) is prevalently used in various industries to improve decision-making and automate processes, driven by the ever-evolving DL libraries and compilers. The correctness of DL systems is crucial for trust in DL applications.  
As such, the recent wave of research has been studying the automated synthesis of test-cases (i.e., DNN models and their inputs) for fuzzing DL systems. However, existing model generators only subsume a limited number of operators, lacking the ability to pervasively model operator constraints.  
To address this challenge, we propose NeuRI, a fully automated approach for generating valid and diverse DL models composed of hundreds of types of operators. NeuRI adopts a three-step process:  
(i) collecting valid and invalid API traces from various sources;  
(ii) applying inductive program synthesis over the traces to infer the constraints for constructing valid models; and  
(iii) using hybrid model generation which incorporates both symbolic and concrete operators.  
Our evaluation shows that NeuRI improves branch coverage of TensorFlow and PyTorch by 24\% and 15\% over the state-of-the-art model-level fuzzers. NeuRI finds 100 new bugs for PyTorch and TensorFlow in four months, with 81 already fixed or confirmed. Of these, 9 bugs are labelled as high priority or security vulnerability, constituting 10\% of all high-priority bugs of the period.  
Open-source developers regard error-inducing tests reported by us as "high-quality" and "common in practice".},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {657–669},
numpages = {13},
keywords = {Compiler Testing, Deep Learning Compilers, Fuzzing},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3611643.3616343,
author = {Zhao, Kunsong and Li, Zihao and Li, Jianfeng and Ye, He and Luo, Xiapu and Chen, Ting},
title = {DeepInfer: Deep Type Inference from Smart Contract Bytecode},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3616343},
doi = {10.1145/3611643.3616343},
abstract = {Smart contracts play an increasingly important role in Ethereum platform. It provides various functions implementing numerous services, whose bytecode runs on Ethereum Virtual Machine. To use services by invoking corresponding functions, the callers need to know the function signatures. Moreover, such signatures provide crucial information for many downstream applications, e.g., identifying smart contracts, fuzzing, detecting vulnerabilities, etc. However, it is challenging to infer function signatures from the bytecode due to a lack of type information. Existing work solving this problem depended heavily on limited databases or hard-coded heuristic patterns. However, these approaches are hard to be adapted to semantic differences in distinct languages and various compiler versions when developing smart contracts. In this paper, we propose a novel framework DeepInfer that first leverages deep learning techniques to automatically infer function signatures and returns. The novelties of DeepInfer are: 1) DeepInfer lifts the bytecode into the Intermediate Representation (IR) to preserve code semantics; 2) DeepInfer extracts the type-related knowledge (e.g., critical data flows, constant values, and control flow graphs) from the IR to recover function signatures and returns. We conduct experiments on Solidity and Vyper smart contracts and the results show that DeepInfer performs faster and more accurate than existing tools, while being immune to changes in different languages and various compiler versions.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {745–757},
numpages = {13},
keywords = {Deep Learning, Smart Contract, Type Inference},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3611643.3616350,
author = {Zhang, Jiyang and Nie, Pengyu and Li, Junyi Jessy and Gligoric, Milos},
title = {Multilingual Code Co-evolution using Large Language Models},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3616350},
doi = {10.1145/3611643.3616350},
abstract = {Many software projects implement APIs and algorithms in multiple programming languages. Maintaining such projects is tiresome, as developers have to ensure that any change (e.g., a bug fix or a new feature) is being propagated, timely and without errors, to implementations in other programming languages. In the world of ever-changing software, using rule-based translation tools (i.e., transpilers) or machine learning models for translating code from one language to another provides limited value. Translating each time the entire codebase from one language to another is not the way developers work. In this paper, we target a novel task: translating code changes from one programming language to another using large language models (LLMs). We design and implement the first LLM, dubbed Codeditor, to tackle this task. Codeditor explicitly models code changes as edit sequences and learns to correlate changes across programming languages. To evaluate Codeditor, we collect a corpus of 6,613 aligned code changes from 8 pairs of open-source software projects implementing similar functionalities in two programming languages (Java and C#). Results show that Codeditor outperforms the state-of-the-art approaches by a large margin on all commonly used automatic metrics. Our work also reveals that Codeditor is complementary to the existing generation-based models, and their combination ensures even greater performance.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {695–707},
numpages = {13},
keywords = {Language model, code translation, software evolution},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3611643.3617850,
author = {Gu, Qiuhan},
title = {LLM-Based Code Generation Method for Golang Compiler Testing},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3617850},
doi = {10.1145/3611643.3617850},
abstract = {Modern optimizing compilers are among the most complex software systems humans build. One way to identify subtle compiler bugs is fuzzing. Both the quantity and the quality of testcases are crucial to the performance of fuzzing. Traditional testcase-generation methods, such as Csmith and YARPGen, have been proven successful at discovering compiler bugs. However, such generated testcases have limited coverage and quantity. In this paper, we present a code generation method for compiler testing based on LLM to maximize the quality and quantity of the generated code. In particular, to avoid undefined behavior and syntax errors in generated testcases, we design a filter strategy to clean the source code, preparing a high-quality dataset for the model training. Besides, we present a seed schedule strategy to improve code generation. We apply the method to test the Golang compiler and the result shows that our pipeline outperforms previous methods both qualitatively and quantitatively. It produces testcases with an average coverage of 3.38\%, in contrast to the testcases generated by GoFuzz, which have an average coverage of 0.44\%. Moreover, among all the generated testcases, only 2.79\% exhibited syntax errors, and none displayed undefined behavior.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {2201–2203},
numpages = {3},
keywords = {Code generation, Compiler testing, Go language, Large model},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@proceedings{10.1145/3612783,
title = {Interacci\'{o}n '23: Proceedings of the XXIII International Conference on Human Computer Interaction},
year = {2023},
isbn = {9798400707902},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lleida, Spain}
}

@proceedings{10.1145/3613347,
title = {ICoMS '23: Proceedings of the 2023 6th International Conference on Mathematics and Statistics},
year = {2023},
isbn = {9798400700187},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Leipzig, Germany}
}

@proceedings{10.1145/3613424,
title = {MICRO '23: Proceedings of the 56th Annual IEEE/ACM International Symposium on Microarchitecture},
year = {2023},
isbn = {9798400703294},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Toronto, ON, Canada}
}

@inproceedings{10.1145/3613424.3614274,
author = {Tan, Siwei and Lang, Congliang and Xiang, Liang and Wang, Shudi and Jia, Xinghui and Tan, Ziqi and Li, Tingting and Yin, Jieming and Shang, Yongheng and Python, Andre and Lu, Liqiang and Yin, Jianwei},
title = {QuCT: A Framework for Analyzing Quantum Circuit by Extracting Contextual and Topological Features},
year = {2023},
isbn = {9798400703294},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613424.3614274},
doi = {10.1145/3613424.3614274},
abstract = {In the current Noisy Intermediate-Scale Quantum era, quantum circuit analysis is an essential technique for designing high-performance quantum programs. Current analysis methods exhibit either accuracy limitations or high computational complexity for obtaining precise results. To reduce this tradeoff, we propose QuCT, a unified framework for extracting, analyzing, and optimizing quantum circuits. The main innovation of QuCT is to vectorize each gate with each element, quantitatively describing the degree of the interaction with neighboring gates. Extending from the vectorization model, we propose two representative downstream models for fidelity prediction and unitary decomposition. The fidelity prediction model performs a linear transformation on all gate vectors and aggregates the results to estimate the overall circuit fidelity. By identifying critical weights in the transformation matrix, we propose two optimizations to improve the circuit fidelity. In the unitary decomposition model, we significantly reduce the search space by bridging the gap between unitary and circuit via gate vectors. Experiments show that QuCT improves the accuracy of fidelity prediction by 4.2 \texttimes{} on 5-qubit and 18-qubit quantum devices and achieves 2.5 \texttimes{} fidelity improvement compared to existing quantum compilers&nbsp;[19, 55]. In unitary decomposition, QuCT achieves 46.3 \texttimes{} speedup for 5-qubit unitary and more than hundreds of speedup for 8-qubit unitary, compared to the state-of-the-art method&nbsp;[87].},
booktitle = {Proceedings of the 56th Annual IEEE/ACM International Symposium on Microarchitecture},
pages = {494–508},
numpages = {15},
keywords = {quantum error correction, quantum computing, quantum circuit synthesis},
location = {Toronto, ON, Canada},
series = {MICRO '23}
}

@proceedings{10.1145/3613904,
title = {CHI '24: Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Honolulu, HI, USA}
}

@inproceedings{10.1145/3613904.3641895,
author = {Hoque, Md Naimul and Mashiat, Tasfia and Ghai, Bhavya and Shelton, Cecilia D. and Chevalier, Fanny and Kraus, Kari and Elmqvist, Niklas},
title = {The HaLLMark Effect: Supporting Provenance and Transparent Use of Large Language Models in Writing with Interactive Visualization},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641895},
doi = {10.1145/3613904.3641895},
abstract = {The use of Large Language Models (LLMs) for writing has sparked controversy both among readers and writers. On one hand, writers are concerned that LLMs will deprive them of agency and ownership, and readers are concerned about spending their time on text generated by soulless machines. On the other hand, AI-assistance can improve writing as long as writers can conform to publisher policies, and as long as readers can be assured that a text has been verified by a human. We argue that a system that captures the provenance of interaction with an LLM can help writers retain their agency, conform to policies, and communicate their use of AI to publishers and readers transparently. Thus we propose HaLLMark, a tool for visualizing the writer’s interaction with the LLM. We evaluated HaLLMark with 13 creative writers, and found that it helped them retain a sense of control and ownership of the text.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {1045},
numpages = {15},
keywords = {Creative writing, LLMs, agency, co-writing, visualization.},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3613904.3642038,
author = {van Rijn, Pol and Mertes, Silvan and Janowski, Kathrin and Weitz, Katharina and Jacoby, Nori and Andr\'{e}, Elisabeth},
title = {Giving Robots a Voice: Human-in-the-Loop Voice Creation and open-ended Labeling},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642038},
doi = {10.1145/3613904.3642038},
abstract = {Speech is a natural interface for humans to interact with robots. Yet, aligning a robot’s voice to its appearance is challenging due to the rich vocabulary of both modalities. Previous research has explored a few labels to describe robots and tested them on a limited number of robots and existing voices. Here, we develop a robot-voice creation tool followed by large-scale behavioral human experiments (N=2,505). First, participants collectively tune robotic voices to match 175 robot images using an adaptive human-in-the-loop pipeline. Then, participants describe their impression of the robot or their matched voice using another human-in-the-loop paradigm for open-ended labeling. The elicited taxonomy is then used to rate robot attributes and to predict the best voice for an unseen robot. We offer a web interface to aid engineers in customizing robot voices, demonstrating the synergy between cognitive science and machine learning for engineering tools.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {584},
numpages = {34},
keywords = {Crowdsourcing, Personalization, Robot, Text/Speech/Language},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3613904.3642116,
author = {Lee, Hao-Ping (Hank) and Yang, Yu-Ju and Von Davier, Thomas Serban and Forlizzi, Jodi and Das, Sauvik},
title = {Deepfakes, Phrenology, Surveillance, and More! A Taxonomy of AI Privacy Risks},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642116},
doi = {10.1145/3613904.3642116},
abstract = {Privacy is a key principle for developing ethical AI technologies, but how does including AI technologies in products and services change privacy risks? We constructed a taxonomy of AI privacy risks by analyzing 321 documented AI privacy incidents. We codified how the unique capabilities and requirements of AI technologies described in those incidents generated new privacy risks, exacerbated known ones, or otherwise did not meaningfully alter the risk. We present 12 high-level privacy risks that AI technologies either newly created (e.g., exposure risks from deepfake pornography) or exacerbated (e.g., surveillance risks from collecting training data). One upshot of our work is that incorporating AI technologies into a product can alter the privacy risks it entails. Yet, current approaches to privacy-preserving AI/ML (e.g., federated learning, differential privacy, checklists) only address a subset of the privacy risks arising from the capabilities and data requirements of AI.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {775},
numpages = {19},
keywords = {AI incidents, Human-centered AI, Privacy, Privacy risks, Privacy taxonomy},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3613904.3642165,
author = {Zeng, Xingchen and Gao, Ziyao and Ye, Yilin and Zeng, Wei},
title = {IntentTuner: An Interactive Framework for Integrating Human Intentions in Fine-tuning Text-to-Image Generative Models},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642165},
doi = {10.1145/3613904.3642165},
abstract = {Fine-tuning facilitates the adaptation of text-to-image generative models to novel concepts (e.g., styles and portraits), empowering users to forge creatively customized content. Recent efforts on fine-tuning focus on reducing training data and lightening computation overload but neglect alignment with user intentions, particularly in manual curation of multi-modal training data and intent-oriented evaluation. Informed by a formative study with fine-tuning practitioners for comprehending user intentions, we propose IntentTuner, an interactive framework that intelligently incorporates human intentions throughout each phase of the fine-tuning workflow. IntentTuner enables users to articulate training intentions with imagery exemplars and textual descriptions, automatically converting them into effective data augmentation strategies. Furthermore, IntentTuner introduces novel metrics to measure user intent alignment, allowing intent-aware monitoring and evaluation of model training. Application exemplars and user studies demonstrate that IntentTuner streamlines fine-tuning, reducing cognitive effort and yielding superior models compared to the common baseline tool.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {182},
numpages = {18},
keywords = {and data augmentation, text-to-image generative model, user intent understanding},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3613904.3642191,
author = {Kotturi, Yasmine and Anderson, Angel and Ford, Glenn and Skirpan, Michael and Bigham, Jeffrey P},
title = {Deconstructing the Veneer of Simplicity: Co-Designing Introductory Generative AI Workshops with Local Entrepreneurs},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642191},
doi = {10.1145/3613904.3642191},
abstract = {Generative AI platforms and features are permeating many aspects of work. Entrepreneurs from lean economies in particular are well positioned to outsource tasks to generative AI given limited resources. In this paper, we work to address a growing disparity in use of these technologies by building on a four-year partnership with a local entrepreneurial hub dedicated to equity in tech and entrepreneurship. Together, we co-designed an interactive workshops series aimed to onboard local entrepreneurs to generative AI platforms. Alongside four community-driven and iterative workshops with entrepreneurs across five months, we conducted interviews with 15 local entrepreneurs and community providers. We detail the importance of communal and supportive exposure to generative AI tools for local entrepreneurs, scaffolding actionable use (and supporting non-use), demystifying generative AI technologies by emphasizing entrepreneurial power, while simultaneously deconstructing the veneer of simplicity to address the many operational skills needed for successful application.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {1014},
numpages = {16},
keywords = {community-based research, entrepreneurship, generative artificial intelligence},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3613904.3642333,
author = {Schaffner, Brennan and Bhagoji, Arjun Nitin and Cheng, Siyuan and Mei, Jacqueline and Shen, Jay L and Wang, Grace and Chetty, Marshini and Feamster, Nick and Lakier, Genevieve and Tan, Chenhao},
title = {"Community Guidelines Make this the Best Party on the Internet": An In-Depth Study of Online Platforms' Content Moderation Policies},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642333},
doi = {10.1145/3613904.3642333},
abstract = {Moderating user-generated content on online platforms is crucial for balancing user safety and freedom of speech. Particularly in the United States, platforms are not subject to legal constraints prescribing permissible content. Each platform has thus developed bespoke content moderation policies, but there is little work towards a comparative understanding of these policies across platforms and topics. This paper presents the first systematic study of these policies from the 43 largest online platforms hosting user-generated content, focusing on policies around copyright infringement, harmful speech, and misleading content. We build a custom web-scraper to obtain policy text and develop a unified annotation scheme to analyze the text for the presence of critical components. We find significant structural and compositional variation in policies across topics and platforms, with some variation attributable to disparate legal groundings. We lay the groundwork for future studies of ever-evolving content moderation policies and their impact on users.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {486},
numpages = {16},
keywords = {content moderation, dataset, qualitative analysis, quantitative analysis},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3613904.3642461,
author = {Shelby, Renee and Rismani, Shalaleh and Rostamzadeh, Negar},
title = {Generative AI in Creative Practice: ML-Artist Folk Theories of T2I Use, Harm, and Harm-Reduction},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642461},
doi = {10.1145/3613904.3642461},
abstract = {Understanding how communities experience algorithms is necessary to mitigate potential harmful impacts. This paper presents folk theories of text-to-image (T2I) models to enrich understanding of how artist communities experience creative machine learning systems. This research draws on data collected from a workshop with 15 artists from 10 countries who incorporate T2I models in their creative practice. Through reflexive thematic analysis of workshop data, we highlight artist folk theories of T2I use, harm, and harm reduction. Folk theories of use envision T2I models as an artistic medium, a mundane tool, and locate true creativity as rising above model affordances. Theories of harm articulate T2I models as harmed by engineering efforts to eliminate glitches and product policy efforts to limit functionality. Theories of harm-reduction orient towards protecting T2I models for creative practice through transparency and distributed governance. We examine how these theories relate, and conclude by discussing how folk theorization informs responsible AI efforts.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {32},
numpages = {17},
keywords = {Art \&amp; Technology, Creativity, Folk Theory, Generative AI, T2I},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3613904.3642466,
author = {Weisz, Justin D. and He, Jessica and Muller, Michael and Hoefer, Gabriela and Miles, Rachel and Geyer, Werner},
title = {Design Principles for Generative AI Applications},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642466},
doi = {10.1145/3613904.3642466},
abstract = {Generative AI applications present unique design challenges. As generative AI technologies are increasingly being incorporated into mainstream applications, there is an urgent need for guidance on how to design user experiences that foster effective and safe use. We present six principles for the design of generative AI applications that address unique characteristics of generative AI UX and offer new interpretations and extensions of known issues in the design of AI applications. Each principle is coupled with a set of design strategies for implementing that principle via UX capabilities or through the design process. The principles and strategies were developed through an iterative process involving literature review, feedback from design practitioners, validation against real-world generative AI applications, and incorporation into the design process of two generative AI applications. We anticipate the principles to usefully inform the design of generative AI applications by driving actionable design recommendations.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {378},
numpages = {22},
keywords = {Generative AI, design principles, foundation models, human-centered AI},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3613904.3642514,
author = {Tan, Felicia Fang-Yi and Xu, Peisen and Ram, Ashwin and Suen, Wei Zhen and Zhao, Shengdong and Huang, Yun and Hurter, Christophe},
title = {AudioXtend: Assisted Reality Visual Accompaniments for Audiobook Storytelling During Everyday Routine Tasks},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642514},
doi = {10.1145/3613904.3642514},
abstract = {The rise of multitasking in contemporary lifestyles has positioned audio-first content as an essential medium for information consumption. We present AudioXtend, an approach to augment audiobook experiences during daily tasks by integrating glanceable, AI-generated visuals through optical see-through head-mounted displays (OHMDs). Our initial study showed that these visual augmentations not only preserved users’ primary task efficiency but also dramatically enhanced immediate auditory content recall by 33.3\% and 7-day recall by 32.7\%, alongside a marked improvement in narrative engagement. Through participatory design workshops involving digital arts designers, we crafted a set of design principles for visual augmentations that are attuned to the requirements of multitaskers. Finally, a 3-day take-home field study further revealed new insights for everyday use, underscoring the potential of assisted reality (aR) to enhance heads-up listening and incidental learning experiences.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {83},
numpages = {22},
keywords = {Assisted Reality, Audiobook Augmentation, Heads-Up Computing, Incidental learning, Optical See-Through Head-Mounted Displays, Recall Enhancement, Smart-glasses, Visual Storytelling},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3613904.3642697,
author = {Lee, Mina and Gero, Katy Ilonka and Chung, John Joon Young and Shum, Simon Buckingham and Raheja, Vipul and Shen, Hua and Venugopalan, Subhashini and Wambsganss, Thiemo and Zhou, David and Alghamdi, Emad A. and August, Tal and Bhat, Avinash and Choksi, Madiha Zahrah and Dutta, Senjuti and Guo, Jin L.C. and Hoque, Md Naimul and Kim, Yewon and Knight, Simon and Neshaei, Seyed Parsa and Shibani, Antonette and Shrivastava, Disha and Shroff, Lila and Sergeyuk, Agnia and Stark, Jessi and Sterman, Sarah and Wang, Sitong and Bosselut, Antoine and Buschek, Daniel and Chang, Joseph Chee and Chen, Sherol and Kreminski, Max and Park, Joonsuk and Pea, Roy and Rho, Eugenia Ha Rim and Shen, Zejiang and Siangliulue, Pao},
title = {A Design Space for Intelligent and Interactive Writing Assistants},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642697},
doi = {10.1145/3613904.3642697},
abstract = {In our era of rapid technological advancement, the research landscape for writing assistants has become increasingly fragmented across various research communities. We seek to address this challenge by proposing a design space as a structured way to examine and explore the multidimensional space of intelligent and interactive writing assistants. Through community collaboration, we explore five aspects of writing assistants: task, user, technology, interaction, and ecosystem. Within each aspect, we define dimensions and codes by systematically reviewing 115 papers, while leveraging the expertise of researchers in various disciplines. Our design space aims to offer researchers and designers a practical tool to navigate, comprehend, and compare the various possibilities of writing assistants, and aid in the design of new writing assistants.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {1054},
numpages = {35},
keywords = {Artificial Intelligence, Design Space, Language Models, Writing Assistants, Writing Support Tools},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3613904.3642700,
author = {Woodruff, Allison and Shelby, Renee and Kelley, Patrick Gage and Rousso-Schindler, Steven and Smith-Loud, Jamila and Wilcox, Lauren},
title = {How Knowledge Workers Think Generative AI Will (Not) Transform Their Industries},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642700},
doi = {10.1145/3613904.3642700},
abstract = {Generative AI is expected to have transformative effects in multiple knowledge industries. To better understand how knowledge workers expect generative AI may affect their industries in the future, we conducted participatory research workshops for seven different industries, with a total of 54 participants across three US cities. We describe participants’ expectations of generative AI’s impact, including a dominant narrative that cut across the groups’ discourse: participants largely envision generative AI as a tool to perform menial work, under human review. Participants do not generally anticipate the disruptive changes to knowledge industries currently projected in common media and academic narratives. Participants do however envision generative AI may amplify four social forces currently shaping their industries: deskilling, dehumanization, disconnection, and disinformation. We describe these forces, and then we provide additional detail regarding attitudes in specific knowledge industries. We conclude with a discussion of implications and research challenges for the HCI community.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {641},
numpages = {26},
keywords = {generative AI, industries, knowledge work},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3613904.3642749,
author = {Precel, Heila and McDonald, Allison and Hecht, Brent and Vincent, Nicholas},
title = {A Canary in the AI Coal Mine: American Jews May Be Disproportionately Harmed by Intellectual Property Dispossession in Large Language Model Training},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642749},
doi = {10.1145/3613904.3642749},
abstract = {Systemic property dispossession from minority groups has often been carried out in the name of technological progress. In this paper, we identify evidence that the current paradigm of large language models (LLMs) likely continues this long history. Examining common LLM training datasets, we find that a disproportionate amount of content authored by Jewish Americans is used for training without their consent. The degree of over-representation ranges from around 2x to around 6.5x. Given that LLMs may substitute for the paid labor of those who produced their training data, they have the potential to cause even more substantial and disproportionate economic harm to Jewish Americans in the coming years. This paper focuses on Jewish Americans as a case study, but it is probable that other minority communities (e.g., Asian Americans, Hindu Americans) may be similarly affected and, most importantly, the results should likely be interpreted as a “canary in the coal mine” that highlights deep structural concerns about the current LLM paradigm whose harms could soon affect nearly everyone. We discuss the implications of these results for the policymakers thinking about how to regulate LLMs as well as for those in the AI field who are working to advance LLMs. Our findings stress the importance of working together towards alternative LLM paradigms that avoid both disparate impacts and widespread societal harms.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {761},
numpages = {17},
keywords = {dataset documentation, economic impacts, large language models},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3613904.3642774,
author = {Chen, Jonathan and Yoon, Dongwook},
title = {Exploring the Diminishing Allure of Paper and Low-Fidelity Prototyping Among Designers in the Software Industry: Impacts of Hybrid Work, Digital Tools, and Corporate Culture},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642774},
doi = {10.1145/3613904.3642774},
abstract = {In a rapidly evolving UX/UI design landscape marked by technological advancements and shifts toward hybrid work, understanding the implications of these changes on software prototyping practices is crucial. This study investigates the influence of evolving work practices, tool advancements, and designers’ attitudes on prototyping practices and design processes in the contemporary software industry. Based on in-depth interviews with 10 practitioners and educators, we explore the factors contributing to the preference for digital-first prototypes and the diminishing appeal of low-fidelity prototyping methods. Our findings reveal how digital prototypes outshine physical counterparts in hybrid work, the role of all-in-one digital tools in centralizing designers’ workflows and encouraging high-fidelity prototyping, corporate preferences for visually appealing prototypes, and the impact of designers’ educational backgrounds, generational differences, and professional maturity. This research offers valuable insights to inform decision-making and strategies for design practitioners, educators, and organizations in adapting to current and future prototyping practices.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {1024},
numpages = {14},
keywords = {design practices, digital prototyping tools, expert interviews, hybrid and remote work, industry, lo-fi prototyping, paper prototyping},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3613904.3642787,
author = {Cai, Jie and Lin, Ya-Fang and Zhang, He and Carroll, John M.},
title = {Third-Party Developers and Tool Development For Community Management on Live Streaming Platform Twitch},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642787},
doi = {10.1145/3613904.3642787},
abstract = {Community management is critical for stakeholders to collaboratively build and sustain communities with socio-technical support. However, most of the existing research has mainly focused on the community members and the platform, with little attention given to the developers who act as intermediaries between the platform and community members and develop tools to support community management. This study focuses on third-party developers (TPDs) for the live streaming platform Twitch and explores their tool development practices. Using a mixed method with in-depth qualitative analysis, we found that TPDs maintain complex relationships with different stakeholders (streamers, viewers, platform, professional developers), and the multi-layered policy restricts their agency regarding idea innovation and tool development. We argue that HCI research should shift its focus from tool users to tool developers with regard to community management. We propose designs to support closer collaboration between TPDS and the platform and professional developers and streamline TPDs’ development process with unified toolkits and policy documentation.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {926},
numpages = {18},
keywords = {Community Management, Community moderation, Discord, Extension and Bot Development, Live Streaming, Moderation Tools, Platform Governance, Third-Party Developers, Twitch},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3613904.3642943,
author = {Ko, Hyung-Kwon and Jeon, Hyeon and Park, Gwanmo and Kim, Dae Hyun and Kim, Nam Wook and Kim, Juho and Seo, Jinwook},
title = {Natural Language Dataset Generation Framework for Visualizations Powered by Large Language Models},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642943},
doi = {10.1145/3613904.3642943},
abstract = {We introduce VL2NL, a Large Language Model (LLM) framework that generates rich and diverse NL datasets using Vega-Lite specifications as input, thereby streamlining the development of Natural Language Interfaces (NLIs) for data visualization. To synthesize relevant chart semantics accurately and enhance syntactic diversity in each NL dataset, we leverage 1) a guided discovery incorporated into prompting so that LLMs can steer themselves to create faithful NL datasets in a self-directed manner; 2) a score-based paraphrasing to augment NL syntax along with four language axes. We also present a new collection of 1,981 real-world Vega-Lite specifications that have increased diversity and complexity than existing chart collections. When tested on our chart collection, VL2NL extracted chart semantics and generated L1/L2 captions with 89.4\% and 76.0\% accuracy, respectively. It also demonstrated generating and paraphrasing utterances and questions with greater diversity compared to the benchmarks. Last, we discuss how our NL datasets and framework can be utilized in real-world scenarios. The codes and chart collection are available at https://github.com/hyungkwonko/chart-llm.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {843},
numpages = {22},
keywords = {Vega-Lite, data visualization, framework, large language models, natural language datasets, natural language interfaces},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@proceedings{10.1145/3613905,
title = {CHI EA '24: Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Honolulu, HI, USA}
}

@inproceedings{10.1145/3613905.3644051,
author = {Robinson, Raquel Breejon and Alvarez, Alberto and Mekler, Elisa D.},
title = {How to write a CHI paper (asking for a friend)},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3644051},
doi = {10.1145/3613905.3644051},
abstract = {Writing and genre conventions are extant to any scientific community, and CHI is no different. In this paper, we present the early phases of an AI tool called KITSUNE, which takes text and adapts it toward the writing conventions of a CHI paper. We describe the development of the tool with the intent to promote discussion around how writing conventions are upheld and unquestioned by the CHI community, and how this translates to the work produced. In addition, we bring up questions surrounding how the introduction of LLMs into academic writing will fundamentally change how conventions will be upheld now and in the future.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {558},
numpages = {8},
keywords = {CHI, LLMs, artificial intelligence, writing conventions},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@proceedings{10.1145/3613944,
title = {ICSLT '23: Proceedings of the 2023 9th International Conference on e-Society, e-Learning and e-Technologies},
year = {2023},
isbn = {9798400700415},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Portsmouth, United Kingdom}
}

@proceedings{10.1145/3614407,
title = {CSLAW '24: Proceedings of the 2024 Symposium on Computer Science and Law},
year = {2024},
isbn = {9798400703331},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Boston, MA, USA}
}

@inproceedings{10.1145/3614407.3643696,
author = {Lee, Katherine and Cooper, A. Feder and Grimmelmann, James},
title = {Talkin' 'Bout AI Generation: Copyright and the Generative-AI Supply Chain (The Short Version)},
year = {2024},
isbn = {9798400703331},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3614407.3643696},
doi = {10.1145/3614407.3643696},
abstract = {"Does generative AI infringe copyright?" is an urgent question. It is also a difficult question, for two reasons. First, "generative AI" is not just one product from one company. It is a catch-all name for a massive ecosystem of loosely related technologies. These systems behave differently and raise different legal issues. Second, copyright law is notoriously complicated, and generative-AI systems manage to touch on a great many corners of it. They raise issues of authorship, similarity, direct and indirect liability, and fair use, among much else. These issues cannot be analyzed in isolation, because there are connections everywhere. We aim to bring order to the chaos. To do so, we introduce the generative-AI supply chain: an interconnected set of stages that transform training data into generations. The supply chain reveals all of the places at which companies and users make choices that have copyright consequences. It enables us to trace the effects of upstream technical designs on downstream uses, and to assess who in these complicated sociotechnical systems bears responsibility for infringement when it happens. Because we engage so closely with the technology of generative AI, we are able to shed more light on the copyright questions. We identify the key decisions that courts will need to make as they grapple with these issues, and point out the consequences that would likely flow from different liability regimes. This article is a much-abbreviated version of a forthcoming law review article at The Journal of the Copyright Society.},
booktitle = {Proceedings of the 2024 Symposium on Computer Science and Law},
pages = {48–63},
numpages = {16},
location = {Boston, MA, USA},
series = {CSLAW '24}
}

@proceedings{10.1145/3614419,
title = {WEBSCI '24: Proceedings of the 16th ACM Web Science Conference},
year = {2024},
isbn = {9798400703348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Stuttgart, Germany}
}

@inproceedings{10.1145/3614419.3644007,
author = {Meier, Florian},
title = {Using Wikipedia Pageview Data to Investigate Public Interest in Climate Change at a Global Scale},
year = {2024},
isbn = {9798400703348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3614419.3644007},
doi = {10.1145/3614419.3644007},
abstract = {Addressing the climate crisis calls for global efforts to mitigate greenhouse gas emissions, with effective mitigation efforts depending on an informed public with a high degree of climate change awareness. This study examines global engagement with climate change and related concepts through an analysis of around 517 Million Wikipedia pageviews of 3965 items from WikiProject Climate Change across 213 countries in the years 2017 to 2022. We take advantage of Wikimedia Foundation’s differentially-private daily pageview dataset, which makes it possible to study Wikipedia viewing behavior in a language edition agnostic way and on a per-country basis. Temporal analysis reveals a stagnant engagement with climate change articles, contrary to societal trends, possibly due to the attitude-behavior gap. We also found substantial regional differences, with countries from the global north displaying greater traffic compared to the global south. Specific events, notably Greta Thunberg’s speech at the UN climate summit in 2019, drive peaks in climate change engagement, highlighting the social dimension and influence of prominent figures in climate change information seeking. However, causal time series analyses show that events like these do not lead to long-lasting increased traffic.},
booktitle = {Proceedings of the 16th ACM Web Science Conference},
pages = {365–375},
numpages = {11},
keywords = {Climate change, Public interest, Time series analysis, Wikipedia},
location = {Stuttgart, Germany},
series = {WEBSCI '24}
}

@inproceedings{10.1145/3614419.3644014,
author = {Wu, Chuhao and Wang, Xinyu and Carroll, John and Rajtmajer, Sarah},
title = {Reacting to Generative AI: Insights from Student and Faculty Discussions on Reddit},
year = {2024},
isbn = {9798400703348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3614419.3644014},
doi = {10.1145/3614419.3644014},
abstract = {Generative Artificial intelligence (GenAI) such as ChatGPT has elicited strong reactions from almost all stakeholders across the education system. Education-oriented and academic social media communities provide an important venue for these stakeholders to share experiences and exchange ideas about GenAI, which is constructive for developing human-centered policies. This study examines early user reactions to GenAI, consisting of 725 Reddit threads between 06/2022 and 05/2023. Through natural language processing (NLP) and content analysis, we observe an increasingly negative sentiment in the discussion and identify six main categories of student and faculty experiences of GenAI in education. These experiences reflect concerns about academic integrity and AI’s negative impact on the values of traditional education. Our analysis also highlights the tension and burden imposed by new technologies. Our findings suggest that dialogue between stakeholders in the education community is critical and can mitigate sources of tension between students and faculty.},
booktitle = {Proceedings of the 16th ACM Web Science Conference},
pages = {103–113},
numpages = {11},
keywords = {Generative AI, Higher Education, Social Media, Topic Modeling},
location = {Stuttgart, Germany},
series = {WEBSCI '24}
}

@proceedings{10.1145/3615360,
title = {mmNets '23: Proceedings of the 7th ACM Workshop on Millimeter-Wave and Terahertz Networks and Sensing Systems},
year = {2023},
isbn = {9798400703386},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Madrid, Spain}
}

@proceedings{10.1145/3615593,
title = {FedEdge '23: Proceedings of the 2nd ACM Workshop on Data Privacy and Federated Learning Technologies for Mobile Edge Network},
year = {2023},
isbn = {9798400703447},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Madrid, Spain}
}

@proceedings{10.1145/3615890,
title = {GeoSearch '23: Proceedings of the 2nd ACM SIGSPATIAL International Workshop on Searching and Mining Large Collections of Geospatial Data},
year = {2023},
isbn = {9798400703522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {In this 2nd International Workshop on Searching and Mining Large Collections of Geospatial Data (GeoSearch 2023), we built on the success of the previous edition and continued to bring together the art of search engine construction with both geospatial data modeling, data processing, and management to provide a forum for researchers and practitioners interested in the general topic of GeoSearch.},
location = {Hamburg, Germany}
}

@proceedings{10.1145/3615895,
title = {IWCTS '23: Proceedings of the 16th ACM SIGSPATIAL International Workshop on Computational Transportation Science},
year = {2023},
isbn = {9798400703577},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The 16th International Workshop on Computational Transportation Science (IWCTS 2023) - Smart Mobility track is particularly timely given the prominence of human mobility data, such as probe data from cell phones and connected automated vehicles, volunteered geographic information, and other sensing and simulation data. This unprecedented access to sensing data of mobility and integration of this analytics into smart cities and mobility management has led to innovations in intelligent transportation systems, building information management, human dynamics modeling, and urban planning. Due to the scale of these data and simulations, these developments are deeply computational.},
location = {Hamburg, Germany}
}

@proceedings{10.1145/3615899,
title = {SuMob '23: Proceedings of the 1st ACM SIGSPATIAL International Workshop on Sustainable Mobility},
year = {2023},
isbn = {9798400703614},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems holds a half-day workshop on Sustainable Mobility. This is a first of its kind, and distinct from other workshops on mobility at this conference: it explicitly focuses on urban mobility as an open, complex system, and hence, on a wicked problem: We know that any intervention, such as improvements of efficiencies on the mobility supply side, would have unintended consequences on the demand side. While we typically ignore such interrelations as "too difficult", this workshop sets out to explore what the spatial computing community can contribute.},
location = {Hamburg, Germany}
}

@proceedings{10.1145/3615900,
title = {UrbanAI '23: Proceedings of the 1st ACM SIGSPATIAL International Workshop on Advances in Urban-AI},
year = {2023},
isbn = {9798400703621},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Given the growing research in the area of Urban AI, the 1st ACM SIGSPATIAL International Workshop on Advances in Urban AI (Urban-Al 2023) seeks to congregate urban scientists, planners, AI experts, engineers, policymakers, and industry leaders from both academic and corporate sectors. Urban-Al 2023 aspires to offer a forum for discussing the forefront advancements, breakthroughs, potential roadblocks, and future avenues in the rapidly evolving domain of urban-centric artificial intelligence. This platform aims to inspire and disseminate the latest insights on methodologies, tools, data infrastructures, and innovative strategies pivotal to Urban AI dynamics. Merging advanced AI techniques with urban informatics, real-time data analysis, and multidisciplinary urban studies, Urban-Al 2023 aims to accentuate core topics within the broader digital city community. Through the workshop, participants will be exposed to the most recent innovations driving AI-powered urban solutions, thereby empowering modern cities to be more adaptable, resilient, and citizen-centric.},
location = {Hamburg, Germany}
}

@proceedings{10.1145/3616712,
title = {ICEME '23: Proceedings of the 2023 14th International Conference on E-business, Management and Economics},
year = {2023},
isbn = {9798400708022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Beijing, China}
}

@proceedings{10.1145/3616855,
title = {WSDM '24: Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 17th ACM International Conference on Web Search and Data Mining - WSDM 2024. WSDM is one of the premier conferences in the fields of web search and data mining, with a dynamic and growing community from academia and industry. After two years of virtual conferences and in-person conferences in Singapore, the 2024 edition is an in-person conference with virtual elements. We hope you enjoy the conference at the "Centro Internacional de Congresos de Yucatan (CIC)" in Merida from March 4 to March 8, 2024.We are excited to kick off the program with a dynamic mix of Tutorials and Industry Day. Our seven tutorials will cover a broad range of search and data mining topics. Industry Day will provide valuable insights from leaders at major technology companies. The core technical program continues WSDM's tradition of a single-track format, featuring 109 thought-provoking papers from both academic and industry experts. We're honored to have inspiring keynote speakers each day: Nicolas Christin (CMU), Elizabeth Reid (Google), and Saiph Savage (Civic A.I. Lab). Additionally, 17 interactive demonstrations will showcase the latest prototypes and systems. The final day offers a stimulating Doctoral Consortium and six engaging workshops on topics including integrity in social networks, large language model for society, psychology-informed information access system, interactive and scalable information retrieval system and machine learning on graphs. WSDM 2024 proudly presents WSDM day on information retrieval and Web in the region. WSDM Cup Day highlights finalists' presentations addressing challenges in Conversational Multi-Doc QA. This diverse and stimulating program promises to be an enriching experience for all!.},
location = {Merida, Mexico}
}

@inproceedings{10.1145/3616855.3635779,
author = {Lin, Ziqian and Ding, Hao and Hoang, Nghia Trong and Kveton, Branislav and Deoras, Anoop and Wang, Hao},
title = {Pre-trained Recommender Systems: A Causal Debiasing Perspective},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616855.3635779},
doi = {10.1145/3616855.3635779},
abstract = {Recent studies on pre-trained vision/language models have demonstrated the practical benefit of a new, promising solution-building paradigm in AI where models can be pre-trained on broad data describing a generic task space and then adapted successfully to solve a wide range of downstream tasks, even when training data is severely limited (e.g., in zero- or few-shot learning scenarios). Inspired by such progress, we investigate in this paper the possibilities and challenges of adapting such a paradigm to the context of recommender systems, which is less investigated from the perspective of pre-trained model. In particular, we propose to develop a generic recommender that captures universal interaction patterns by training on generic user-item interaction data extracted from different domains, which can then be fast adapted to improve few-shot learning performance in unseen new domains (with limited data).  However, unlike vision/language data which share strong conformity in the semantic space, universal patterns underlying recommendation data collected across different domains (e.g., different countries or different E-commerce platforms) are often occluded by both in-domain and cross-domain biases implicitly imposed by the cultural differences in their user and item bases, as well as their uses of different e-commerce platforms. As shown in our experiments, such heterogeneous biases in the data tend to hinder the effectiveness of the pre-trained model. To address this challenge, we further introduce and formalize a causal debiasing perspective, which is substantiated via a hierarchical Bayesian deep learning model, named model. Our empirical studies on real-world data show that the proposed model could significantly improve the recommendation performance in zero- and few-shot learning settings under both cross-market and cross-platform scenarios.},
booktitle = {Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
pages = {424–433},
numpages = {10},
keywords = {bayesian inference, causality, pre-trained models, probabilistic methods, recommender systems},
location = {Merida, Mexico},
series = {WSDM '24}
}

@inproceedings{10.1145/3616855.3635795,
author = {Deldari, Shohreh and Spathis, Dimitris and Malekzadeh, Mohammad and Kawsar, Fahim and Salim, Flora D. and Mathur, Akhil},
title = {CroSSL: Cross-modal Self-Supervised Learning for Time-series through Latent Masking},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616855.3635795},
doi = {10.1145/3616855.3635795},
abstract = {Limited availability of labeled data for machine learning on multimodal time-series extensively hampers progress in the field. Self-supervised learning (SSL) is a promising approach to learn data representations without relying on labels. However, existing SSL methods require expensive computations of negative pairs and are typically designed for single modalities, which limits their versatility. We introduce CroSSL (Cross-modal SSL), which puts forward two novel concepts: masking intermediate embeddings produced by modality-specific encoders, and their aggregation into a global embedding through a cross-modal aggregator CroSSL allows for handling missing modalities and end-to-end cross-modal earning without requiring prior data preprocessing for handling missing inputs or negative-pair sampling for contrastive learning. We evaluate our method on a wide range of data, including motion sensors such as accelerometers or gyroscopes and biosignals (heart rate, electroencephalograms, electromyograms, electrooculograms, and electrodermal). Overall, CroSSL outperforms previous SSL and supervised benchmarks using minimal labeled data, and also sheds light on how latent masking can improve cross-modal learning.},
booktitle = {Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
pages = {152–160},
numpages = {9},
keywords = {cross-modal time-series., masking, self-supervised learning},
location = {Merida, Mexico},
series = {WSDM '24}
}

@inproceedings{10.1145/3616855.3635811,
author = {Yang, Mingdai and Liu, Zhiwei and Yang, Liangwei and Liu, Xiaolong and Wang, Chen and Peng, Hao and Yu, Philip S.},
title = {Unified Pretraining for Recommendation via Task Hypergraphs},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616855.3635811},
doi = {10.1145/3616855.3635811},
abstract = {Although pretraining has garnered significant attention and popularity in recent years, its application in graph-based recommender systems is relatively limited. It is challenging to exploit prior knowledge by pretraining in widely used ID-dependent datasets. On the one hand, user-item interaction history in one dataset can hardly be transferred to other datasets through pretraining, where IDs are different. On the other hand, pretraining and finetuning on the same dataset leads to a high risk of overfitting. In this paper, we propose a novel multitask pretraining framework named Unified Pretraining for Recommendation via Task Hypergraphs. For a unified learning pattern to handle diverse requirements and nuances of various pretext tasks, we design task hypergraphs to generalize pretext tasks to hyperedge prediction. A novel transitional attention layer is devised to discriminatively learn the relevance between each pretext task and recommendation. Experimental results on three benchmark datasets verify the superiority of UPRTH. Additional detailed investigations are conducted to demonstrate the effectiveness of the proposed framework.},
booktitle = {Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
pages = {891–900},
numpages = {10},
keywords = {hypergraph learning., multitask pretraining, recommender system},
location = {Merida, Mexico},
series = {WSDM '24}
}

@inproceedings{10.1145/3616855.3635836,
author = {Chen, Changyu and Li, Yanran and Wei, Chen and Cui, Jianwei and Wang, Bin and Yan, Rui},
title = {Empathetic Response Generation with Relation-aware Commonsense Knowledge},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616855.3635836},
doi = {10.1145/3616855.3635836},
abstract = {The development of AI in mental health is a growing field with potential global impact. Machine agents need to perceive users' mental states and respond empathically. Since mental states are often latent and implicit, building such chatbots requires both knowledge learning and knowledge utilization. Our work contributes to this by developing a chatbot that aims to recognize and empathetically respond to users' mental states. We introduce a Conditional Variational Autoencoders (CVAE)-based model that utilizes relation-aware commonsense knowledge to generate responses. This model, while not a replacement for professional mental health support, demonstrates promise in offering informative and empathetic interactions in a controlled environment. On the dataset EmpatheticDialogues, we compare with several SOTA methods and empirically validate the effectiveness of our approach on response informativeness and empathy exhibition. Detailed analysis is also given to demonstrate the learning capability as well as model interpretability. Our code is accessible at http://github.com/ChangyuChen347/COMET-VAE.},
booktitle = {Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
pages = {87–95},
numpages = {9},
keywords = {conditional variational autoencoders, dialong system, empathetic response generation},
location = {Merida, Mexico},
series = {WSDM '24}
}

@inproceedings{10.1145/3616855.3635850,
author = {Jiang, Yangqin and Yang, Yuhao and Xia, Lianghao and Huang, Chao},
title = {DiffKG: Knowledge Graph Diffusion Model for Recommendation},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616855.3635850},
doi = {10.1145/3616855.3635850},
abstract = {Knowledge Graphs (KGs) have emerged as invaluable resources for enriching recommendation systems by providing a wealth of factual information and capturing semantic relationships among items. Leveraging KGs can significantly enhance recommendation performance. However, not all relations within a KG are equally relevant or beneficial for the target recommendation task. In fact, certain item-entity connections may introduce noise or lack informative value, thus potentially misleading our understanding of user preferences. To bridge this research gap, we propose a novel knowledge graph diffusion model for recommendation, referred to as DiffKG. Our framework integrates a generative diffusion model with a data augmentation paradigm, enabling robust knowledge graph representation learning. This integration facilitates a better alignment between knowledge-aware item semantics and collaborative relation modeling. Moreover, we introduce a collaborative knowledge graph convolution mechanism that incorporates collaborative signals reflecting user-item interaction patterns, guiding the knowledge graph diffusion process. We conduct extensive experiments on three publicly available datasets, consistently demonstrating the superiority of our DiffKG compared to various competitive baselines. We provide the source code repository of our proposed DiffKG model at the following link: https://github.com/HKUDS/DiffKG},
booktitle = {Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
pages = {313–321},
numpages = {9},
keywords = {diffusion model, knowledge graph learning, recommendation},
location = {Merida, Mexico},
series = {WSDM '24}
}

@inproceedings{10.1145/3616855.3635851,
author = {Deng, Zhirui and Dou, Zhicheng and Zhu, Yutao and Wen, Ji-Rong},
title = {CL4DIV: A Contrastive Learning Framework for Search Result Diversification},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616855.3635851},
doi = {10.1145/3616855.3635851},
abstract = {Search result diversification aims to provide a diversified document ranking list so as to cover as many intents as possible and satisfy the various information needs of different users. Existing approaches usually represented documents by pretrained embeddings (such as doc2vec and Glove). These document representations cannot adequately represent the document's content and are hard to capture the intrinsic user's intent coverage of the given query. Moreover, the limited number of labeled data for search result diversification exacerbates the difficulty of obtaining more efficient document representations. To alleviate these problems and learn more effective document representations, we propose a Contrastive Learning framework for search result DIVersification (CL4DIV). Specifically, we design three contrastive learning tasks from the perspective of subtopics, documents, and candidate document sequences, which correspond to three essential elements in search result diversification. These training tasks are employed to pretrain the document encoder and the document sequence encoder, which are used in the diversified ranking model. Experimental results show that \o{}urs significantly outperforms all existing diversification models. Further analysis demonstrates that our method has wide applicability and can also be used to improve several existing methods.},
booktitle = {Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
pages = {171–180},
numpages = {10},
keywords = {contrastive learning, search result diversification, self-supervised learning},
location = {Merida, Mexico},
series = {WSDM '24}
}

@proceedings{10.1145/3616901,
title = {FAIML '23: Proceedings of the 2023 International Conference on Frontiers of Artificial Intelligence and Machine Learning},
year = {2023},
isbn = {9798400707544},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Beijing, China}
}

@proceedings{10.1145/3617184,
title = {ICCSIE '23: Proceedings of the 8th International Conference on Cyber Security and Information Engineering},
year = {2023},
isbn = {9798400708800},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Putrajaya, Malaysia}
}

@proceedings{10.1145/3617233,
title = {CBMI '23: Proceedings of the 20th International Conference on Content-based Multimedia Indexing},
year = {2023},
isbn = {9798400709128},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Orleans, France}
}

@inproceedings{10.1145/3617233.3617274,
author = {Moholdt, Eivind and Khan, Sohail Ahmed and Dang-Nguyen, Duc-Tien},
title = {Detecting Out-of-Context Image-Caption Pair in News: A Counter-Intuitive Method},
year = {2023},
isbn = {9798400709128},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3617233.3617274},
doi = {10.1145/3617233.3617274},
abstract = {The growth of misinformation and re-contextualized media in social media and news leads to an increasing need for fact-checking methods. Concurrently, the advancement in generative models makes cheapfakes and deepfakes both easier to make and harder to detect. In this paper, we present a novel approach using generative image models to our advantage for detecting Out-of-Context (OOC) use of images-caption pairs in news. We present two new datasets with a total of 6800 images generated using two different generative models including (1) DALL-E 2, and (2) Stable-Diffusion. We are confident that the method proposed in this paper can further research on generative models in the field of cheapfake detection, and that the resulting datasets can be used to train and evaluate new models aimed at detecting cheapfakes. We run a preliminary qualitative and quantitative analysis to evaluate the performance of each image generation model for this task, and evaluate a handful of methods for computing image similarity.},
booktitle = {Proceedings of the 20th International Conference on Content-Based Multimedia Indexing},
pages = {203–209},
numpages = {7},
keywords = {Cheapfake Detection, Computer Vision, Dataset, Generative Models, Image Similarity, Text-to-Image},
location = {Orleans, France},
series = {CBMI '23}
}

@book{10.1145/3617448,
author = {Myers, Brad A.},
title = {Pick, Click, Flick! The Story of Interaction Techniques},
year = {2024},
isbn = {9798400709494},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {1},
volume = {57},
abstract = {This book provides a comprehensive study of the many ways to interact with computers and computerized devices. An “interaction technique” starts when the user performs an action that causes an electronic device to respond, and includes the direct feedback from the device to the user. Examples include physical buttons and switches, on-screen menus and scrollbars operated by a mouse, touchscreen widgets, gestures such as flick-to-scroll, text entry on computers and touchscreens, input for virtual reality systems, interactions with conversational agents such as Apple Siri, Google Assistant, Amazon Alexa, and Microsoft Cortana, and adaptations of all of these for people with disabilities. Pick, Click, Flick! is written for anyone interested in interaction techniques, including computer scientists and designers working on human-computer interaction, as well as implementers and consumers who want to understand and get the most out of their digital devices.REVIEWS“Pick, Click, Flick! is an impressive reference manual of the many years of interaction design development. It is a reference book, invaluable when questions arise, whether while you are busy designing something, or learning, or teaching, where assigning sections of the reference will be a valuable resource and learning tool for students. Brad Myers has provided a great service to the interaction community.” ‐ Don Norman, Distinguished Prof. Emeritus, Design Lab, University of California, San Diego“Every UX professional should immerse themselves in this book. Not only does it unravel the fascinating and complex history of GUI widgets that will captivate any user interface nerd, but it also stands as the definitive guide to an incredibly diverse array of interaction techniques. This is not just an engaging read; it’s an essential toolkit.” ‐ Jakob Nielsen, Principal, Nielsen Design Group}
}

@proceedings{10.1145/3617553,
title = {Gamify 2023: Proceedings of the 2nd International Workshop on Gamification in Software Development, Verification, and Validation},
year = {2023},
isbn = {9798400703737},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of the Program Committee, we are pleased to present the proceedings of the 2nd International Workshop on Gamification in Software Development, Verification, and Validation (Gamify 2023). The workshop is virtually co-located with the 2023 edition of the ESEC/FSE conference, held in San Francisco (CA, USA). The workshop will be held online only the 4th of December 2023.},
location = {San Francisco, CA, USA}
}

@proceedings{10.1145/3617555,
title = {PROMISE 2023: Proceedings of the 19th International Conference on Predictive Models and Data Analytics in Software Engineering},
year = {2023},
isbn = {9798400703751},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our pleasure to welcome you to the 19th ACM International Conference on Predictive Models and Data Analytics in Software Engineering (PROMISE 2023), to be held in presence on December 8th, 2023, co-located with the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE 2023).},
location = {San Francisco, CA, USA}
}

@proceedings{10.1145/3617574,
title = {SE4SafeML 2023: Proceedings of the 1st International Workshop on Dependability and Trustworthiness of Safety-Critical Systems with Machine Learned Components},
year = {2023},
isbn = {9798400703799},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the First Workshop on Dependability and Trustworthiness of Safety-Critical Systems with Machine Learned Components (SE4SafeML) co-located with ESEC/FSE 2023.},
location = {San Francisco, CA, USA}
}

@proceedings{10.1145/3617650,
title = {CompEd 2023: Proceedings of the ACM Conference on Global Computing Education Vol 2},
year = {2023},
isbn = {9798400703744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome participants to the 2nd ACM Global Conference on Computing Education (ACM CompEd 2023) being held in Hyderabad, India, 7th-9th December, 2023 with the Working Groups meetings being held on 5th and 6th December 2023.ACM CompEd is a recent addition to the list of ACM sponsored conferences devoted to research in all aspects of computing education, including education at the school and college levels. The Hyderabad edition is only the second in this promising series. The long hiatus due to Covid-19 pushed this conference by two years, but we are glad that it is finally here!This edition of ACM CompEd partly overlaps with COMPUTE 2023, ACM India's flagship conference on Computing Education. Having the two conferences adjacent to each other is a great way to build synergy between the Indian computing education community and the global community of computing education researchers.},
location = {Hyderabad, India}
}

@proceedings{10.1145/3618260,
title = {STOC 2024: Proceedings of the 56th Annual ACM Symposium on Theory of Computing},
year = {2024},
isbn = {9798400703836},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The papers in this volume were presented at the 56th Annual ACM Symposium on Theory of Computing (STOC 2024), sponsored by the ACM Special Interest Group on Algorithms and Computation Theory (SIGACT).
 
 
 
 
 
 
 
The conference was held in Vancouver, Canada, June 24--28, 2024, with the papers being presented as live talks.},
location = {Vancouver, BC, Canada}
}

@article{10.1145/3618309,
author = {Zhou, Yuxiao and Chai, Menglei and Pepe, Alessandro and Gross, Markus and Beeler, Thabo},
title = {GroomGen: A High-Quality Generative Hair Model Using Hierarchical Latent Representations},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/3618309},
doi = {10.1145/3618309},
abstract = {Despite recent successes in hair acquisition that fits a high-dimensional hair model to a specific input subject, generative hair models, which establish general embedding spaces for encoding, editing, and sampling diverse hairstyles, are way less explored. In this paper, we present GroomGen, the first generative model designed for hair geometry composed of highly-detailed dense strands. Our approach is motivated by two key ideas. First, we construct hair latent spaces covering both individual strands and hairstyles. The latent spaces are compact, expressive, and well-constrained for high-quality and diverse sampling. Second, we adopt a hierarchical hair representation that parameterizes a complete hair model to three levels: single strands, sparse guide hairs, and complete dense hairs. This representation is critical to the compactness of latent spaces, the robustness of training, and the efficiency of inference. Based on this hierarchical latent representation, our proposed pipeline consists of a strand-VAE and a hairstyle-VAE that encode an individual strand and a set of guide hairs to their respective latent spaces, and a hybrid densification step that populates sparse guide hairs to a dense hair model. GroomGen not only enables novel hairstyle sampling and plausible hairstyle interpolation, but also supports interactive editing of complex hairstyles, or can serve as strong data-driven prior for hairstyle reconstruction from images. We demonstrate the superiority of our approach with qualitative examples of diverse sampled hairstyles and quantitative evaluation of generation quality regarding every single component and the entire pipeline.},
journal = {ACM Trans. Graph.},
month = dec,
articleno = {270},
numpages = {16},
keywords = {hairstyle generation, strand-level hair modeling}
}

@article{10.1145/3618336,
author = {Shuai, Qing and Yu, Zhiyuan and Zhou, Zhize and Fan, Lixin and Yang, Haijun and Yang, Can and Zhou, Xiaowei},
title = {Reconstructing Close Human Interactions from Multiple Views},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/3618336},
doi = {10.1145/3618336},
abstract = {This paper addresses the challenging task of reconstructing the poses of multiple individuals engaged in close interactions, captured by multiple calibrated cameras. The difficulty arises from the noisy or false 2D keypoint detections due to inter-person occlusion, the heavy ambiguity in associating keypoints to individuals due to the close interactions, and the scarcity of training data as collecting and annotating motion data in crowded scenes is resource-intensive. We introduce a novel system to address these challenges. Our system integrates a learning-based pose estimation component and its corresponding training and inference strategies. The pose estimation component takes multi-view 2D keypoint heatmaps as input and reconstructs the pose of each individual using a 3D conditional volumetric network. As the network doesn't need images as input, we can leverage known camera parameters from test scenes and a large quantity of existing motion capture data to synthesize massive training data that mimics the real data distribution in test scenes. Extensive experiments demonstrate that our approach significantly surpasses previous approaches in terms of pose accuracy and is generalizable across various camera setups and population sizes. The code is available on our project page: https://github.com/zju3dv/CloseMoCap.},
journal = {ACM Trans. Graph.},
month = dec,
articleno = {273},
numpages = {14},
keywords = {human pose estimation, motion capture}
}

@article{10.1145/3618361,
author = {Puhachov, Ivan and Martens, Cedric and Kry, Paul G. and Bessmeltsev, Mikhail},
title = {Reconstruction of Machine-Made Shapes from Bitmap Sketches},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/3618361},
doi = {10.1145/3618361},
abstract = {We propose a method of reconstructing 3D machine-made shapes from bitmap sketches by separating an input image into individual patches and jointly optimizing their geometry. We rely on two main observations: (1) human observers interpret sketches of man-made shapes as a collection of simple geometric primitives, and (2) sketch strokes often indicate occlusion contours or sharp ridges between those primitives. Using these main observations we design a system that takes a single bitmap image of a shape, estimates image depth and segmentation into primitives with neural networks, then fits primitives to the predicted depth while determining occlusion contours and aligning intersections with the input drawing via optimization. Unlike previous work, our approach does not require additional input, annotation, or templates, and does not require retraining for a new category of man-made shapes. Our method produces triangular meshes that display sharp geometric features and are suitable for downstream applications, such as editing, rendering, and shading.},
journal = {ACM Trans. Graph.},
month = dec,
articleno = {268},
numpages = {16},
keywords = {3D reconstruction, industrial design, line drawing, sketch-based modeling, sketches}
}

@proceedings{10.1145/3620665,
title = {ASPLOS '24: Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
year = {2024},
isbn = {9798400703850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
abstract = {Welcome to the second volume of ASPLOS'24: the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems. This document is dedicated to the 2024 summer review cycle.We introduced several notable changes to ASPLOS this year, many of which were discussed in the previous message from program chairs in Volume 1. Here, to avoid repetition, we assume that readers have already read the latter message and will only describe differences between the current cycle and the previous one. These include: (1) developing and utilizing an automated format violation identifier script focused on uncovering disallowed vertical space manipulations that "squeeze" space; (2) incorporating authors-declared best-matching topics into our review assignment process; (3) introducing the new ASPLOS role of Program Vice Chairs to cope with the increased number of submissions and the added load caused by foregoing synchronous program committee (PC) meetings, which necessitated additional managerial involvement in online dissensions; and (4) characterizing a systematic problem that ASPLOS is facing in reviewing quantum computing submissions, describing how we addressed it, and highlighting how we believe that it should be handled in the future.Key statistics of the ASPLOS'24 summer cycle include: 409 submissions were finalized (about 1.5x more than last year's summer count and nearly 2.4x more than our spring cycle), with 107 related to accelerators/FPGAs/GPUs, 97 to machine learning, 88 to storage/memory, 80 to security, and 69 to datacenter/cloud; 179 (44\%) submissions were promoted to the second review round; 54 (13.2\%) papers were accepted (with 20 awarded one or more artifact evaluation badges); 33 (8.1\%) submissions were allowed to submit major revisions, of which 27 were subsequently accepted during the fall cycle (with 13 awarded one or more artifact evaluation badges); 1,499 reviews were uploaded; and 5,557 comments were generated during online discussions.Analyzing the per-submission most-related broader areas of research, which we asked authors to associate with their work in the submission form, revealed that 71\%, 47\%, and 28\% of the submissions are categorized by their authors as related to architecture, operating systems, and programming languages, respectively, with about 45\% being "interdisciplinary" submissions (associated with more than one area). The full details are available in the PDF of the front matter.},
location = {La Jolla, CA, USA}
}

@inproceedings{10.1145/3620665.3640365,
author = {Ghodrati, Soroush and Kinzer, Sean and Xu, Hanyang and Mahapatra, Rohan and Kim, Yoonsung and Ahn, Byung Hoon and Wang, Dong Kai and Karthikeyan, Lavanya and Yazdanbakhsh, Amir and Park, Jongse and Kim, Nam Sung and Esmaeilzadeh, Hadi},
title = {Tandem Processor: Grappling with Emerging Operators in Neural Networks},
year = {2024},
isbn = {9798400703850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3620665.3640365},
doi = {10.1145/3620665.3640365},
abstract = {With the ever increasing prevalence of neural networks and the upheaval from the language models, it is time to rethink neural acceleration. Up to this point, the broader research community, including ourselves, has disproportionately focused on GEneral Matrix Multiplication (GEMM) operations. The supporting argument was that the large majority of the neural operations are GEMM. This argument guided the research in Neural Processing Units (NPUs) for the last decade. However, scant attention was paid to non-GEMM operations and they are rather overlooked. As deep learning evolved and progressed, these operations have grown in diversity and also large variety of structural patterns have emerged that interweave them with the GEMM operations. However, conventional NPU designs have taken rather simplistic approaches by supporting these operations through either a number of dedicated blocks or fall back to general-purpose processors.This work sets out to challenge the conventional wisdom in neural accelerator design and explore the architecture of an on-chip companion, dubbed Tandem Processor, that complements the rather optimized GEMM unit in neural accelerators. This processor needs to be specialized to keep up with the GEMM unit; and yet needs to be programmable to address the (1) structural and (2) operational variations. To strike a balance between specialization and programmability, on the one hand, we specialize its memory access logic with a novel ISA/microarchitecture that alleviates the register file and its associated load/store operations. On the other hand, the calculations of the non-GEMM layers are only supported through primitive arithmetic/logic vector operations. Therefore, programmability is offered at the mathematical level. The enhancements due to the specialization of the memory access logic in the Tandem Processor and its tight integration with the GEMM unit sustain the throughput and the utilization of the neural accelerator. Comprehensive evaluations of the proposed design based on the end-to-end execution of seven diverse DNNs including emerging language models show significant performance improvements and energy reduction enabled by leveraging the Tandem Processor. We provide the RTL code that is synthesizable both for FPGA and ASIC implementations in addition to the associated compiler as part of the open-source GeneSys project (https://actlab-genesys.github.io/). We also present the chip floorplan and post-layout analysis. This work is the result of 10 years of effort in building real NPUs that support end-to-end neural network execution.},
booktitle = {Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
pages = {1165–1182},
numpages = {18},
keywords = {neural processing unit (NPU), domain specific architecture (DSA), accelerator, deep neural networks (DNN), end-to-end acceleration, non-gemm layers, large language models (LLM), single instruction multiple data (SIMD), instruction set architecture (ISA), tandem processor},
location = {La Jolla, CA, USA},
series = {ASPLOS '24}
}

@inproceedings{10.1145/3620665.3640423,
author = {Guo, Cong and Zhang, Rui and Xu, Jiale and Leng, Jingwen and Liu, Zihan and Huang, Ziyu and Guo, Minyi and Wu, Hao and Zhao, Shouren and Zhao, Junping and Zhang, Ke},
title = {GMLake: Efficient and Transparent GPU Memory Defragmentation for Large-scale DNN Training with Virtual Memory Stitching},
year = {2024},
isbn = {9798400703850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3620665.3640423},
doi = {10.1145/3620665.3640423},
abstract = {Large-scale deep neural networks (DNNs), such as large language models (LLMs), have revolutionized the artificial intelligence (AI) field and become increasingly popular. However, training or fine-tuning such models requires substantial computational power and resources, where the memory capacity of a single acceleration device like a GPU is one of the most important bottlenecks. Owing to the prohibitively large overhead (e.g., 10\texttimes{}) of GPUs' native memory allocator, DNN frameworks like PyTorch and TensorFlow adopt a caching allocator that maintains a memory pool with a splitting mechanism for fast memory (de)allocation. Unfortunately, the caching allocator's efficiency degrades quickly for popular memory reduction techniques such as re-computation, offloading, distributed training, and low-rank adaptation. The primary reason is that those memory reduction techniques introduce frequent and irregular memory (de)allocation requests, leading to severe fragmentation problems for the splitting-based caching allocator. To mitigate this fragmentation problem, we propose a novel memory allocation framework based on low-level GPU virtual memory management called GPU memory lake (GMLake). GMLake employs a novel virtual memory stitching (VMS) mechanism, which can fuse or combine non-contiguous memory blocks with a virtual memory address mapping. GMLake can reduce average of 9.2 GB (up to 25 GB) GPU memory usage and 15\% (up to 33\%) fragmentation among eight LLM models on GPU A100 with 80 GB memory. GMLake is completely transparent to the DNN models and memory reduction techniques and ensures the seamless execution of resource-intensive deep-learning tasks. We have open-sourced GMLake at https://github.com/intelligent-machine-learning/glake/tree/main/GMLake.},
booktitle = {Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
pages = {450–466},
numpages = {17},
keywords = {memory defragmentation, GPU, deep learning, virtual memory stitching},
location = {La Jolla, CA, USA},
series = {ASPLOS '24}
}

@proceedings{10.1145/3620666,
title = {ASPLOS '24: Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3},
year = {2024},
isbn = {9798400703867},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
abstract = {Welcome to the third volume of ASPLOS'24: the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems. This document is mostly dedicated to the 2024 fall cycle but also provides some statistics summarizing all three cycles.We introduced several notable changes to ASPLOS this year, most of which were discussed in our previous messages from program chairs in Volume 1 and 2, including: (1) significantly increasing the program committee size to over 220 members (more than twice the size of last year); (2) foregoing synchronous program committee (PC) meetings and instead making all decisions online; (3) overhauling the review assignment process; (4) developing an automated submission format violation identifier script that uncovers, e.g., disallowed vertical space manipulations that "squeeze" space; (5) introducing the new ASPLOS role of Program Vice Chairs to cope with the increased number of submissions and the added load caused by foregoing synchronous program committee; and (6) characterizing a systematic problem that ASPLOS is facing in reviewing quantum computing submissions, describing how we addressed it and highlighting how we believe that it should be handled in the future.Assuming readers have read our previous messages, here, we will only describe differences between the current cycle and the previous ones. These include: (1) Finally unifying submission and acceptance paper formatting instructions (forgoing the `jpaper' class) to rid authors of accepted papers from the need to reformat; (2) Describing the methodology we employed to select best papers, which we believe ensures quality and hope will persist; and (3) Reporting the ethical incidents we encountered and how we handled them. In the final, fourth volume, when the outcome of the ASPLOS'24 fall major revisions will become known, we plan to conduct a broader analysis of all the data we have gathered throughout the year.Following are some key statistics of the fall cycle: 340 submissions were finalized (43\% more than last year's fall count and 17\% less than our summer cycle) of which 111 are related to accelerators/FPGAs/GPUs, 105 to machine learning, 54 to security, 50 to datacenter/cloud and 50 to storage/memory; 183 (54\%) submissions were promoted to the second review round; 39 (11.5\%) papers were accepted (of which 19 were awarded artifact evaluation badges); 33 (9.7\%) submissions were allowed to submit major revisions and are currently under review (these will be addressed in the fourth volume of ASPLOS'24 and will be presented in ASPLOS'25 if accepted); 1,368 reviews were uploaded; and 4,949 comments were generated during online discussions, of which 4,070 were dedicated to the submissions that made it to the second review round.This year, in the submission form, we asked authors to specify which of the three ASPLOS research areas are related to their submitted work. Analyzing this data revealed that 80\%, 39\%, and 29\% of the submissions are categorized by their authors as related to architecture, operating systems, and programming languages, respectively, generating the highest difference we have observed across the cycles between architecture and the other two. About 46\% of the fall submissions are "interdisciplinary," namely, were associated with two or more of the three areas.Overall, throughout all the ASPLOS'24 cycles, we received 922 submissions, constituting a 1.54x increase compared to last year. Our reviewers submitted a total of 3,634 reviews containing more than 2.6 million words, and we also generated 12,655 online comments consisting of nearly 1.2 million words. As planned, PC members submitted an average of 15.7 reviews and a median of 15, and external review committee (ERC) members submitted an average of 4.7 and a median of 5.We accepted 170 papers thus far, written by 1100 authors, leading to an 18.4\% acceptance rate, with the aforementioned 33 major revisions still under review. Assuming that the revision acceptance rate will be similar to that of previous cycles, we estimate that ASPLOS'24 will accept nearly 200 (!) papers, namely, 21\%–22\% of the submissions.The ASPLOS'24 program consists of 193 papers: the 170 papers we accepted thus far and, in addition, 23 major revisions from the fall cycle of ASPLOS'23, which were re-reviewed and accepted. The full details are available in the PDF of the front matter.},
location = {La Jolla, CA, USA}
}

@inproceedings{10.1145/3620666.3651351,
author = {Guan, Yue and Yu, Changming and Zhou, Yangjie and Leng, Jingwen and Li, Chao and Guo, Minyi},
title = {Fractal: Joint Multi-Level Sparse Pattern Tuning of Accuracy and Performance for DNN Pruning},
year = {2024},
isbn = {9798400703867},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3620666.3651351},
doi = {10.1145/3620666.3651351},
abstract = {Model pruning, which eliminates redundant parameters and reduces computational complexity, emerges as a viable strategy for efficient deep neural network (DNN) deployment. Owing to the irregular memory access and computation patterns in the sparse DNN models after pruning, existing arts have suggested various structured sparse patterns to enhance sparse DNN performance. In this work, we propose a unique perspective of understanding existing sparse pattern design as computation-skipping after tiling the tensor computation into multi-level hierarchies. This unified perspective opens up a new design space of multi-level sparse tiling to maximize the sparsity benefits of DNNs, as opposed to the single-level choice in current practices. We present Fractal, an auto-tuning system for sparse patterns that identifies the optimal multi-level sparse tiling pattern. We introduce PatternIR, a novel high-level intermediate representation (IR), to express a diverse range of multi-level sparse patterns. By leveraging insights from prior dense operator optimizations, we translate PatternIR into low-level compiler IRs, facilitating further operator optimization and code generation. Our evaluations demonstrate that Fractal yields substantial speedups of up to on average 3.16\texttimes{} on CUDA Core, 2.52\texttimes{} on TensorCore of GPUs compared to the state-of-art dense baseline under 75\% sparsity while upholding minimal accuracy degradation compared to prior sparse operator libraries.},
booktitle = {Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3},
pages = {416–430},
numpages = {15},
keywords = {structural pruning, sparse tensor compiler, sparse computation acceleration, deep learning},
location = {La Jolla, CA, USA},
series = {ASPLOS '24}
}

@proceedings{10.1145/3620679,
title = {ICBET '23: Proceedings of the 2023 13th International Conference on Biomedical Engineering and Technology},
year = {2023},
isbn = {9798400707438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tokyo, Japan}
}

@proceedings{10.1145/3623053,
title = {SA '23: SIGGRAPH Asia 2023 Doctoral Consortium},
year = {2023},
isbn = {9798400703928},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Sydney, NSW, Australia}
}

@proceedings{10.1145/3623278,
title = {ASPLOS '23: Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 4},
year = {2023},
isbn = {9798400703942},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Vancouver, BC, Canada}
}

@inproceedings{10.1145/3623278.3624758,
author = {Gan, Yu and Liu, Guiyang and Zhang, Xin and Zhou, Qi and Wu, Jiesheng and Jiang, Jiangwei},
title = {Sleuth: A Trace-Based Root Cause Analysis System for Large-Scale Microservices with Graph Neural Networks},
year = {2024},
isbn = {9798400703942},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623278.3624758},
doi = {10.1145/3623278.3624758},
abstract = {Cloud microservices are being scaled up due to the rising demand for new features and the convenience of cloud-native technologies. However, the growing scale of microservices complicates the remote procedure call (RPC) dependency graph, exacerbates the tail-of-scale effect, and makes many of the empirical rules for detecting the root cause of end-to-end performance issues unreliable. Additionally, existing open-source microservice benchmarks are too small to evaluate performance debugging algorithms at a production-scale with hundreds or even thousands of services and RPCs.To address these challenges, we present Sleuth, a trace-based root cause analysis (RCA) system for large-scale microservices using un-supervised graph learning. Sleuth leverages a graph neural network to capture the causal impact of each span in a trace, and trace clustering using a trace distance metric to reduce the amount of traces required for root cause localization. A pre-trained Sleuth model can be transferred to different microservice applications without any retraining or with few-shot fine-tuning. To quantitatively evaluate the performance and scalability of Sleuth, we propose a method to generate microservice benchmarks comparable to a production-scale. The experiments on the existing benchmark suites and synthetic large-scale microservices indicate that Sleuth has significantly outperformed the prior work in detection accuracy, performance, and adaptability on a large-scale deployment.},
booktitle = {Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 4},
pages = {324–337},
numpages = {14},
location = {Vancouver, BC, Canada},
series = {ASPLOS '23}
}

@proceedings{10.1145/3623462,
title = {KUI '23: Proceedings of the 20th International Conference on Culture and Computer Science: Code and Materiality},
year = {2023},
isbn = {9798400708367},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3623509,
title = {TEI '24: Proceedings of the Eighteenth International Conference on Tangible, Embedded, and Embodied Interaction},
year = {2024},
isbn = {9798400704024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Cork, Ireland}
}

@inproceedings{10.1145/3623509.3633400,
author = {Albaugh, Lea and Gonzalez, Jesse T and Hudson, Scott E},
title = {Tensions and Resolutions in Hybrid Basketry: Joining 3D Printing and Handweaving},
year = {2024},
isbn = {9798400704024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623509.3633400},
doi = {10.1145/3623509.3633400},
abstract = {By documenting and annotating one author's ongoing project combining 3D printing and handweaving to produce computational hybrid baskets, we contribute a framework for understanding hybrid craft. We identify three levels of material practice as observed in the basketry project—physical joinery between rigid printed-plastic parts and soft textiles, seamful multipart fabrication workflows, and aesthetics which negotiate between “basketlike” and “computational” forms—and analyze tensions and possible resolutions at each level.},
booktitle = {Proceedings of the Eighteenth International Conference on Tangible, Embedded, and Embodied Interaction},
articleno = {52},
numpages = {13},
keywords = {Hybrid fabrication, computational craft, exploratory fabrication, material practice, weaving},
location = {Cork, Ireland},
series = {TEI '24}
}

@proceedings{10.1145/3623762,
title = {ITiCSE-WGR '23: Proceedings of the 2023 Working Group Reports on Innovation and Technology in Computer Science Education},
year = {2023},
isbn = {9798400704055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {In these proceedings, we present papers from the Working Groups that worked in the context of the 28th Annual Conference on Innovation \&amp; Technology in Computer Science Education (ITiCSE), held in Turku Finland, and hosted by University of Turku from the 10th to the 12th of July 2023.The concept of Working Groups has been a unique feature of the ITiCSE conference series since its inception, with CompEd adopting the Working Group practice in 2019. A Working Group typically comprises 5 to 10 researchers who work together on a project related to computing education. Working Groups provide a wonderful opportunity to work intensively on a topic of interest with an international group of computing education researchers. This unique experience is one that, in our opinion, each Computer Science Educator should strive to participate in at least once.In 2023, 13 proposals for Working Groups were received and six Working Groups were selected by the Working Group chairs to recruit members and proceed for ITiCSE 2023. There were over 100 member applications to Working Groups, with 67 being accepted across the six Working Groups.},
location = {Turku, Finland}
}

@inproceedings{10.1145/3623762.3633494,
author = {Cutts, Quintin and Kallia, Maria and Anderson, Ruth and Crick, Tom and Devlin, Marie and Farghally, Mohammed and Mirolo, Claudio and Runde, Ragnhild Kobro and Sepp\"{a}l\"{a}, Otto and Urquiza-Fuentes, Jaime and Vahrenhold, Jan},
title = {Arguments for and Approaches to Computing Education in Undergraduate Computer Science Programmes},
year = {2023},
isbn = {9798400704055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623762.3633494},
doi = {10.1145/3623762.3633494},
abstract = {Computing education (CE), the scientific foundation of the teaching and learning of subject matter specific to computing, has matured into a field with its own research journals and conferences as well as graduate programmes. Yet, and unlike other mature subfields of computer science (CS), it is rarely taught as part of undergraduate CS programmes. In this report, we present a gap analysis resulting from semi-structured interviews with various types of stakeholders and derive a set of arguments for teaching CE courses in undergraduate CS programmes. This analysis and the arguments highlight a number of opportunities for the discipline of CS at large, in academia, in industry, and in school education, that would be opened up with undergraduate CE courses, as well as potential barriers to implementation that will need to be overcome. We also report on the results of a Delphi process performed to elicit topics for such a course with various audiences in mind. The Delphi process yielded 19 high-level categories that encompass the subject matter CE courses should incorporate, tailored to the specific needs of their intended student audiences. This outcome underscores the extensive range of content that can be integrated into a comprehensive CE programme. Based on these two stakeholder interactions as well as a systematic literature review aiming to explore the current practices in teaching CE to undergraduate students, we develop two prototypical outlines of such a course, keeping in mind that departments may have different preferences and affordances resulting in different kinds of CE offerings. Overall, input from external stakeholders underscores the clear significance of undergraduate CE courses. We anticipate leveraging this valuable feedback to actively promote these courses on a broader scale.},
booktitle = {Proceedings of the 2023 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {160–195},
numpages = {36},
keywords = {argument, computing education, curriculum outline, undergraduate},
location = {Turku, Finland},
series = {ITiCSE-WGR '23}
}

@inproceedings{10.1145/3623762.3633499,
author = {Prather, James and Denny, Paul and Leinonen, Juho and Becker, Brett A. and Albluwi, Ibrahim and Craig, Michelle and Keuning, Hieke and Kiesler, Natalie and Kohn, Tobias and Luxton-Reilly, Andrew and MacNeil, Stephen and Petersen, Andrew and Pettit, Raymond and Reeves, Brent N. and Savelka, Jaromir},
title = {The Robots Are Here: Navigating the Generative AI Revolution in Computing Education},
year = {2023},
isbn = {9798400704055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623762.3633499},
doi = {10.1145/3623762.3633499},
abstract = {Recent advancements in artificial intelligence (AI) and specifically generative AI (GenAI) are threatening to fundamentally reshape computing and society. Largely driven by large language models (LLMs), many tools are now able to interpret and generate both natural language instructions and source code. These capabilities have sparked urgent questions in the computing education community around how educators should adapt their pedagogy to address the challenges and to leverage the opportunities presented by this new technology. In this working group report, we undertake a comprehensive exploration of generative AI in the context of computing education and make five significant contributions. First, we provide a detailed review of the literature on LLMs in computing education and synthesise findings from 71 primary articles, nearly 80\% of which have been published in the first 8 months of 2023. Second, we report the findings of a survey of computing students and instructors from across 20 countries, capturing prevailing attitudes towards GenAI/LLMs and their use in computing education contexts. Third, to understand how pedagogy is already changing, we offer insights collected from in-depth interviews with 22 computing educators from five continents. Fourth, we use the ACM Code of Ethics to frame a discussion of ethical issues raised by the use of large language models in computing education, and we provide concrete advice for policy makers, educators, and students. Finally, we benchmark the performance of several current GenAI models/tools on various computing education datasets, and highlight the extent to which the capabilities of current models are rapidly improving.There is little doubt that LLMs and other forms of GenAI will have a profound impact on computing education over the coming years. However, just as the technology will continue to improve, so will our collective knowledge about how to leverage these new models and tools in educational settings. We expect many important conversations around this topic will emerge as the community explores how to provide more effective, inclusive, and personalised learning experiences. Our aim is that this report will serve as a focal point for both researchers and practitioners who are exploring, adapting, using, and evaluating GenAI and LLM-based tools in computing classrooms.},
booktitle = {Proceedings of the 2023 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {108–159},
numpages = {52},
keywords = {ai, artificial intelligence, chatgpt, code generation, codex, computer programming, copilot, cs1, curriculum, generative ai, github, gpt, gpt-3, gpt-4, large language models, llm, llms, novice programming, openai, pedagogical practices, programming},
location = {Turku, Finland},
series = {ITiCSE-WGR '23}
}

@proceedings{10.1145/3623809,
title = {HAI '23: Proceedings of the 11th International Conference on Human-Agent Interaction},
year = {2023},
isbn = {9798400708244},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Gothenburg, Sweden}
}

@proceedings{10.1145/3624288,
title = {ICBDC '23: Proceedings of the 2023 8th International Conference on Big Data and Computing},
year = {2023},
isbn = {9781450399975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Shenzhen, China}
}

@proceedings{10.1145/3624323,
title = {Ergo'IA '23: Proceedings of the 18th "Ergonomie et Informatique Avanc\'{e}e" Conference},
year = {2023},
isbn = {9798400709104},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bidart, France}
}

@article{10.1145/3624725,
author = {Tang, Ruixiang and Chuang, Yu-Neng and Hu, Xia},
title = {The Science of Detecting LLM-Generated Text},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {67},
number = {4},
issn = {0001-0782},
url = {https://doi.org/10.1145/3624725},
doi = {10.1145/3624725},
abstract = {While many detection methods have been proposed, understanding the challenges is far more daunting.},
journal = {Commun. ACM},
month = mar,
pages = {50–59},
numpages = {10}
}

@inproceedings{10.1145/3624918.3625331,
author = {Yu, Yi and Sugiyama, Kazunari and Jatowt, Adam},
title = {AdaReX: Cross-Domain, Adaptive, and Explainable Recommender System},
year = {2023},
isbn = {9798400704086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624918.3625331},
doi = {10.1145/3624918.3625331},
abstract = {Explainability is an inherent issue of recommender systems and has received a lot of attention recently. Generative explainable recommendation, which provides personalized explanations by generating textual rationales, is emerging as an effective solution. Despite promising, current methods face limitations in their reliance on dense training data, which hinders the generalizability of explainable recommender systems. Our work tackles a novel problem of cross-domain explainable recommendation aiming to extend the generalizability of explainable recommender systems. To solve this, we propose a novel approach that models aspects extracted from past reviews, to empower the explainable recommender systems by leveraging knowledge from other domains. Specifically, we propose AdaReX (Adaptive eXplainable Recommendation), to model auxiliary and target domains simultaneously. By performing specific tasks in respective domains and their interconnection via a discriminator model, AdaReX allows the aspect sequences to learn common knowledge across different domains and tasks. Furthermore, through our proposed optimization objective, the learning of aspect sequence is deeply cross-interacted with in-domain users and items’ latent factors, enabling the enhanced sharing of knowledge between domains. Our extensive experiments on real datasets demonstrate that our approach not only generates better explanations and recommendations for sparse users but also improves performance for general users.},
booktitle = {Proceedings of the Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region},
pages = {272–281},
numpages = {10},
keywords = {Explainable Recommender System, Natural Language Generation},
location = {Beijing, China},
series = {SIGIR-AP '23}
}

@inproceedings{10.1145/3624918.3625339,
author = {Hua, Wenyue and Xu, Shuyuan and Ge, Yingqiang and Zhang, Yongfeng},
title = {How to Index Item IDs for Recommendation Foundation Models},
year = {2023},
isbn = {9798400704086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624918.3625339},
doi = {10.1145/3624918.3625339},
abstract = {Recommendation foundation model utilizes large language models (LLM) for recommendation by converting recommendation tasks into natural language tasks. It enables generative recommendation which directly generates the item(s) to recommend rather than calculating a ranking score for each and every candidate item as in traditional recommendation models, simplifying the recommendation pipeline from multi-stage filtering to single-stage filtering. To avoid generating excessively long text and hallucinated recommendations when deciding which item(s) to recommend, creating LLM-compatible item IDs to uniquely identify each item is essential for recommendation foundation models. In this study, we systematically examine the item ID creation and indexing problem for recommendation foundation models, using P5 as an example of the backbone LLM. To emphasize the importance of item indexing, we first discuss the issues of several trivial item indexing methods, such as random indexing, title indexing, and independent indexing. We then propose four simple yet effective solutions, including sequential indexing, collaborative indexing, semantic (content-based) indexing, and hybrid indexing. Our study highlights the significant influence of item indexing methods on the performance of LLM-based recommendation, and our results on real-world datasets validate the effectiveness of our proposed solutions. The research also demonstrates how recent advances on language modeling and traditional IR principles such as indexing can help each other for better learning and inference. Source code and data are available at https://github.com/Wenyueh/LLM-RecSys-ID.},
booktitle = {Proceedings of the Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region},
pages = {195–204},
numpages = {10},
keywords = {Item ID and Indexing, Large Language Model, Recommendation},
location = {Beijing, China},
series = {SIGIR-AP '23}
}

@proceedings{10.1145/3625007,
title = {ASONAM '23: Proceedings of the 2023 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
year = {2023},
isbn = {9798400704093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The ASONAM conference series brings together researchers from around the world to share the latest advances in the attractive field of Social Networks Analysis and Mining.},
location = {Kusadasi, Turkiye}
}

@proceedings{10.1145/3625008,
title = {SVR '23: Proceedings of the 25th Symposium on Virtual and Augmented Reality},
year = {2023},
isbn = {9798400709432},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rio Grande, Brazil}
}

@proceedings{10.1145/3625468,
title = {MMSys '24: Proceedings of the 15th ACM Multimedia Systems Conference},
year = {2024},
isbn = {9798400704123},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Dear MMSys 2024 Participants,On behalf of the organizers, we are very pleased to welcome you to the 15th ACM Multimedia Systems Conference, taking place for the first time in Italy, in the city of Bari.MMSys is a premier conference dedicated to the exciting and multidisciplinary field of multimedia, with a specific focus on its systems and applications. The conference provides a platform for researchers from both academia and industry to share their latest findings in the multimedia systems research area. Many international researchers, practitioners, engineers, and students from academia, industry, standardization bodies, and government agencies join the MMSys conference each year.},
location = {Bari, Italy}
}

@inproceedings{10.1145/3625468.3647623,
author = {Barbato, Francesco and Michieli, Umberto and Yucel, Mehmet Kerim and Zanuttigh, Pietro and Ozay, Mete},
title = {A Modular System for Enhanced Robustness of Multimedia Understanding Networks via Deep Parametric Estimation},
year = {2024},
isbn = {9798400704123},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3625468.3647623},
doi = {10.1145/3625468.3647623},
abstract = {Performance degradation caused by corrupted multimedia samples is a critical challenge for machine learning models. Previously, three groups of approaches have been proposed to tackle this issue: i) enhancer and denoiser modules to improve the quality of the noisy data, ii) data augmentation approaches, and iii) domain adaptation strategies. All have drawbacks limiting applicability; the first requires paired clean-corrupted data for training and has an high computational cost, while the others can only be used on the same task they were trained on. In this paper, we propose SyMPIE to solve these shortcomings, designing a small, modular, and efficient system to enhance input data for robust downstream multimedia understanding with minimal computational cost. Our SyMPIE is pre-trained on an upstream task/network that should not match the downstream ones and does not need paired clean-corrupted samples. Our key insight is that most input corruptions found in real-world tasks can be modeled through global operations on color channels of images or spatial filters with small kernels. We validate our approach on multiple datasets and tasks, such as image classification (on ImageNetC, ImageNetC-Bar, VizWiz, and a newly proposed mixed corruption benchmark named ImageNetC-mixed) and semantic segmentation (on Cityscapes, ACDC, and DarkZurich) with consistent improvements of about 5\% relative accuracy gain across the board1.},
booktitle = {Proceedings of the 15th ACM Multimedia Systems Conference},
pages = {190–201},
numpages = {12},
keywords = {Content Enhancement, Denoising, Image Classification, Image Segmentation, Model Robustness},
location = {Bari, Italy},
series = {MMSys '24}
}

@proceedings{10.1145/3625687,
title = {SenSys '23: Proceedings of the 21st ACM Conference on Embedded Networked Sensor Systems},
year = {2023},
isbn = {9798400704147},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {SenSys is a highly selective, single-track forum for cutting-edge research on systems issues of sensors and sensor-enabled smart systems. Built on the community's effort over the years, the 21st episode marks the beginning of its 3rd decade.},
location = {Istanbul, Turkiye}
}

@proceedings{10.1145/3625704,
title = {ICEMT '23: Proceedings of the 7th International Conference on Education and Multimedia Technology},
year = {2023},
isbn = {9798400709142},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tokyo, Japan}
}

@proceedings{10.1145/3626111,
title = {HotNets '23: Proceedings of the 22nd ACM Workshop on Hot Topics in Networks},
year = {2023},
isbn = {9798400704154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Cambridge, MA, USA}
}

@inproceedings{10.1145/3626111.3628176,
author = {Hamadanian, Pouya and Arzani, Behnaz and Fouladi, Sadjad and Kakarla, Siva Kesava Reddy and Fonseca, Rodrigo and Billor, Denizcan and Cheema, Ahmad and Nkposong, Edet and Chandra, Ranveer},
title = {A Holistic View of AI-driven Network Incident Management},
year = {2023},
isbn = {9798400704154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626111.3628176},
doi = {10.1145/3626111.3628176},
abstract = {We discuss the potential improvement large language models (LLM) can provide in incident management and how they can overhaul the ways operators conduct incident management today. We propose a holistic framework for building an AI helper for incident management and discuss the several avenues of future research needed to achieve it.We thoroughly analyze the fundamental requirements the community should consider when designing such helpers. Our work is based on discussions with operators of a large public cloud provider and their prior experiences both in incident management and with attempts to improve the incident management experience through various forms of automation.},
booktitle = {Proceedings of the 22nd ACM Workshop on Hot Topics in Networks},
pages = {180–188},
numpages = {9},
keywords = {Large Language Models, Incident Management},
location = {Cambridge, MA, USA},
series = {HotNets '23}
}

@inproceedings{10.1145/3626111.3628183,
author = {Mani, Sathiya Kumaran and Zhou, Yajie and Hsieh, Kevin and Segarra, Santiago and Eberl, Trevor and Azulai, Eliran and Frizler, Ido and Chandra, Ranveer and Kandula, Srikanth},
title = {Enhancing Network Management Using Code Generated by Large Language Models},
year = {2023},
isbn = {9798400704154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626111.3628183},
doi = {10.1145/3626111.3628183},
abstract = {Analyzing network topologies and communication graphs is essential in modern network management. However, the lack of a cohesive approach results in a steep learning curve, increased errors, and inefficiencies. In this paper, we present a novel approach that enables natural-language-based network management experiences, leveraging large language models (LLMs) to generate task-specific code from natural language queries. This method addresses the challenges of explainability, scalability, and privacy by allowing network operators to inspect the generated code, removing the need to share network data with LLMs, and focusing on application-specific requests combined with program synthesis techniques. We develop and evaluate a prototype system using benchmark applications, demonstrating high accuracy, cost-effectiveness, and potential for further improvements using complementary program synthesis techniques.},
booktitle = {Proceedings of the 22nd ACM Workshop on Hot Topics in Networks},
pages = {196–204},
numpages = {9},
keywords = {Program synthesis, Network management, Network lifecycle management, Natural language processing, Large language model, Graph manipulation, Communication graphs},
location = {Cambridge, MA, USA},
series = {HotNets '23}
}

@proceedings{10.1145/3626183,
title = {SPAA '24: Proceedings of the 36th ACM Symposium on Parallelism in Algorithms and Architectures},
year = {2024},
isbn = {9798400704161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 36th ACM Symposium on Parallelism in Algorithms and Architectures - SPAA 2024. SPAA aims to develop a deeper understanding of parallel and distributed computing, both in theory and in practice. Topics relevant to SPAA include algorithms, data structures, computational models, complexity theory, architectures, performance engineering, languages, runtime systems, compilers, programming systems, and networking systems. This year, there were 125 submissions to SPAA (117 regular submission and 8 brief announcements). The program committee accepted 35 regular papers and 19 brief announcements.},
location = {Nantes, France}
}

@inproceedings{10.1145/3626183.3659941,
author = {Kim, Jeonghyeon and Jung, Jaehwang and Kang, Jeehoon},
title = {Expediting Hazard Pointers with Bounded RCU Critical Sections},
year = {2024},
isbn = {9798400704161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626183.3659941},
doi = {10.1145/3626183.3659941},
abstract = {Reclamation schemes for concurrent data structures tackle the challenge of synchronizing memory accesses and reclamation. Early schemes faced a tradeoff between robustness and efficiency : hazard pointers (HP) bounds the number of unreclaimed nodes, but it is inefficient due to per-node protection; and RCU sacrifices robustness for efficiency as a single thread may block the entire reclamation. Recent schemes attempt to break the tradeoff by sending signals to blocking threads to abort their operations. However, they are (1)inefficient due to starvation in long-running operations and frequent signals, and (2)inapplicable to a wide class of data structures. We design a novel reclamation scheme that overcomes the above limitations. To address the long-running operations and applicability, we propose HP-RCU, integrating RCU-expedited traversal that alternates between HP and RCU phases. To additionally ensure robustness against stalled threads, we develop HP-BRCU by modularly replacing RCU with bounded RCU (BRCU) that efficiently bounds the duration of RCU phases by rarely sending signals. We show that HP-BRCU is robust, widely applicable, and as efficient as RCU, outperforming robust schemes across various workloads.},
booktitle = {Proceedings of the 36th ACM Symposium on Parallelism in Algorithms and Architectures},
pages = {1–13},
numpages = {13},
keywords = {concurrency, hazard pointers, memory management, read-copy-update},
location = {Nantes, France},
series = {SPAA '24}
}

@proceedings{10.1145/3626184,
title = {ISPD '24: Proceedings of the 2024 International Symposium on Physical Design},
year = {2024},
isbn = {9798400704178},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of the organizing committee, we are delighted to welcome you to the 33rd ACM International Symposium on Physical Design (ISPD). After the COVID-19 pandemic, we return to a fully in-person ISPD, held in Taipei, Taiwan for the first time. We continue the great tradition established by its thirtytwo predecessors, providing a premier forum to exchange ideas, highlight key technology challenges, present leading-edge theoretical and experimental contributions, and identify future research directions in this field. We extend the good practice, adopted during the pandemic, of having a YouTube channel to view the talks during the symposium and afterwards, improving access to the presentations.Across three days, ISPD 2024 has 3 keynotes, 18 accepted papers, 16 invited talks; one panel on Wednesday with 6 panelists; and 4 speakers with longer talks in Professor Martin D. F. Wong's commemorative session, and finally the ISPD 2024 contest results. ISPD 2024 is co-located with the 25th Workshop on Synthesis and System Integration of Mixed Information technologies (SASIMI). This year, we received a total of 62 abstracts and we received 48 full manuscripts, from which 18 were selected - a 37.5\% acceptance rate. The regular papers in the ISPD 2024 program were selected, after a rigorous month-long double-blind review process and virtual meetings, by the Technical Program Committee with 20 outstanding international professionals from both academia and industry. These papers exhibit the latest advancements in a variety of topics in physical design, including partitioning and clustering; mixed cell-height placement and legalization; macro placement; global placement; standard cell design automation; timing and power optimization; reliability (IR drop); quantum circuits and quantum computing systems; and mask optimization in lithography. A number of these papers utilize advanced mathematical programming, satisfiability problem solving, GPU acceleration, and machine learning techniques.},
location = {Taipei, Taiwan}
}

@inproceedings{10.1145/3626184.3635277,
author = {Kahng, Andrew B.},
title = {Solvers, Engines, Tools and Flows: The Next Wave for AI/ML in Physical Design},
year = {2024},
isbn = {9798400704178},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626184.3635277},
doi = {10.1145/3626184.3635277},
abstract = {It has been six years since an ISPD-2018 invited talk on "Machine Learning Applications in Physical Design". Since then, despite considerable activity across both academia and industry, many R&amp;D targets remain open. At the same time, there is now clearer understanding of where AI/ML can and cannot (yet) move the needle in physical design, as well as some of the difficult blockers and technical challenges that lie ahead. Some futures for AI/ML-boosted physical design are visible across solvers, engines, tools and flows - and in contexts that span generative AI, the modeling of "magic" handoffs at flow interstices, academic research infrastructure, and the culture of benchmarking and open-source EDA.},
booktitle = {Proceedings of the 2024 International Symposium on Physical Design},
pages = {117–124},
numpages = {8},
keywords = {artificial intelligence, machine learning for eda},
location = {Taipei, Taiwan},
series = {ISPD '24}
}

@proceedings{10.1145/3626202,
title = {FPGA '24: Proceedings of the 2024 ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
year = {2024},
isbn = {9798400704185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 32nd ACM International Symposium on Field-Programmable Gate Arrays (FPGA 2024)! We are thrilled to host a premier forum for the presentation of new and exciting research across various facets of FPGA technology. These include:Novel FPGA architectures and circuits.Advances in CAD tools for FPGAs, in areas such as technology mapping, placement, routing, and others.High-level design methodologies that permit FPGA design at higher levels of abstraction.New applications for FPGAs, particularly for energy efficient and high-performance computation.Uses of FPGAs in reconfigurable computing, datacenter, and cloudMachine Learning on and for FPGAs.This year, our program committee diligently reviewed 89 papers with 25.8\% of them earning acceptance for presentation. The symposium spans three days: Sunday features 9 invited tutorials and workshops, while the main event on Monday and Tuesday includes 20 full research papers (10 pages), 3 short research papers (6 pages), and 2 invited keynotes. Keynote abstracts are published in the proceedings. Additionally, 18 submissions are presented as posters, appearing in the proceedings as abstracts. We encourage you to make the most of live presentations, engage with authors and fellow researchers during breaks and poster sessions, and take advantage of social opportunities offered by an in-person conference.},
location = {Monterey, CA, USA}
}

@proceedings{10.1145/3626221,
title = {RecSysChallenge '23: Proceedings of the Recommender Systems Challenge 2023},
year = {2023},
isbn = {9798400716133},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Singapore, Singapore}
}

@proceedings{10.1145/3626246,
title = {SIGMOD/PODS '24: Companion of the 2024 International Conference on Management of Data},
year = {2024},
isbn = {9798400704222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of the SIGMOD 2024 organizing committee, it is our distinct honor, as General Chairs, to welcome you to the 2024 ACM International Conference on Management of Data - SIGMOD 2024. We are thrilled to be hosting this prestigious event for the very first time in Latin America, and specifically in Santiago de Chile, a recognized leader in data technology within the region. This marks a significant milestone for the SIGMOD community, and we are honored to have you join us for a fully in-person experience in this vibrant and innovative city.},
location = {Santiago AA, Chile}
}

@inproceedings{10.1145/3626246.3653378,
author = {Pavlenko, Anna and Cahoon, Joyce and Zhu, Yiwen and Kroth, Brian and Nelson, Michael and Carter, Andrew and Liao, David and Wright, Travis and Camacho-Rodr\'{\i}guez, Jes\'{u}s and Saur, Karla},
title = {Vertically Autoscaling Monolithic Applications with CaaSPER: Scalable Container-as-a-Service Performance Enhanced Resizing Algorithm for the Cloud},
year = {2024},
isbn = {9798400704222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626246.3653378},
doi = {10.1145/3626246.3653378},
abstract = {Kubernetes has emerged as a prominent open-source platform for managing cloud applications, including stateful databases. These monolithic applications rely on vertical scaling, adjusting CPU cores based on load fluctuations. However, our analysis of Kubernetes-based Database-as-a-Service (DBaaS) offerings at Microsoft revealed that many customers consistently over-provision resources for peak workloads, neglecting cost-saving opportunities through resource scale-down. We found that there is a gap in the ability of existing vertical autoscaling tools to minimize resource slack and respond promptly to throttling, leading to increased costs and impacting crucial metrics such as throughput and availability.To address this challenge, we propose CaaSPER, a vertical autoscaling algorithm that blends reactive and proactive strategies. By dynamically adjusting CPU resources, CaaSPER minimizes resource slack, maintains optimal CPU utilization, and reduces throttling. Importantly, customers have the flexibility to prioritize either cost savings or high performance based on their preferences. Extensive testing demonstrates that CaaSPER effectively reduces throttling and keeps CPU utilization within target levels. CaaSPER is designed to be application-agnostic and platform-agnostic, with potential for extension to other applications requiring vertical autoscaling.},
booktitle = {Companion of the 2024 International Conference on Management of Data},
pages = {241–254},
numpages = {14},
keywords = {containers, kubernetes, resource optimization, vertical auto-scaling},
location = {Santiago AA, Chile},
series = {SIGMOD/PODS '24}
}

@inproceedings{10.1145/3626246.3653385,
author = {Chen, Daoyuan and Huang, Yilun and Ma, Zhijian and Chen, Hesen and Pan, Xuchen and Ge, Ce and Gao, Dawei and Xie, Yuexiang and Liu, Zhaoyang and Gao, Jinyang and Li, Yaliang and Ding, Bolin and Zhou, Jingren},
title = {Data-Juicer: A One-Stop Data Processing System for Large Language Models},
year = {2024},
isbn = {9798400704222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626246.3653385},
doi = {10.1145/3626246.3653385},
abstract = {The immense evolution in Large Language Models (LLMs) has underscored the importance of massive, heterogeneous, and high-quality data. A data recipe is a mixture of data from different sources for training LLMs, which plays a vital role in LLMs' performance. Existing open-source tools for LLM data processing are mostly tailored for specific data recipes. To continuously uncover the potential of LLMs, incorporate data from new sources, and improve LLMs' performance, we build a new system named Data-Juicer, with which we can efficiently generate diverse data recipes, explore different possibilities in forming data mixtures, and evaluate their effects on model performance. Different from traditional data-analytics pipelines, Data-Juicer faces some unique challenges. Firstly, the possible data sources for forming data recipes are truly heterogeneous and massive with various qualities. Secondly, it is extremely expensive to precisely evaluate data recipes' impact on LLMs' performance. Thirdly, the end users of Data-Juicer, model developers, need sufficient flexibility to configure and evaluate different data recipes.Data-Juicer features a fine-grained abstraction of pipelines for constructing data recipes, with over 50 built-in operators for easy composition and extension. By incorporating visualization and auto-evaluation capabilities, Data-Juicer enables a timely feedback loop for both LLM pre-training and fine-tuning. Further, Data-Juicer is optimized and integrated with ecosystems for LLM training, evaluation, and distributed computing. The data recipes derived with Data-Juicer gain notable improvements on state-of-the-art LLMs, by up to 7.45\% increase in averaged score across 16 benchmarks and 17.5\% higher win rate in pair-wise GPT-4 evaluations. Our system, recipes, and tutorials are released, calling for broader data-centric research on training and understanding LLMs.},
booktitle = {Companion of the 2024 International Conference on Management of Data},
pages = {120–134},
numpages = {15},
keywords = {data processing system, large language models},
location = {Santiago AA, Chile},
series = {SIGMOD/PODS '24}
}

@proceedings{10.1145/3626252,
title = {SIGCSE 2024: Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 55th annual SIGCSE Technical Symposium on Computer Science Education (SIGCSE TS 2024)! This year, we have returned to Portland, Oregon. We hope that, like us, you are looking forward to a highly productive and engaging symposium that provides ample opportunity to renew old relationships, build new connections, and learn about the latest advances in our field. While we are sure that there will be a few surprises along the way, we hope and expect that we won't experience anything nearly as disruptive as the opening days of the pandemic, which occurred when we last tried to gather here in 2020.Our theme for this year's symposium is "Blazing New Trails in CS Education." This broad theme captures the exceptional work being performed by this community to enhance our teaching, improve our assessments, attract diverse students, and all of the other laudable projects, initiatives, and undertakings that affect positive change. The breadth of the program is substantial - there truly should be something for everyone. In fact, your biggest challenge may be deciding which session to attend in each time slot because there is so much going on! We know that many of you want to attend as many sessions as possible while you are here in Portland, but we encourage you to also find a little bit of time for yourself so that you leave Portland refreshed, renewed and encouraged, rather than exhausted or burnt out.},
location = {Portland, OR, USA}
}

@inproceedings{10.1145/3626252.3630761,
author = {Mason, Raina and Simon and Becker, Brett A. and Crick, Tom and Davenport, James H.},
title = {A Global Survey of Introductory Programming Courses},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630761},
doi = {10.1145/3626252.3630761},
abstract = {We present results of an in-depth survey of nearly 100 introductory programming (CS1) instructors in 18 countries spanning six continents. Although CS1 is well studied, relatively few broadly-scoped studies have been conducted, and none prior have exceeded regional scale. In addition, CS1 is a notoriously fickle and often changing course, and many might find it beneficial to know what other instructors are doing across the globe; perhaps more so as we continue to understand the impact of the COVID-19 pandemic on computing education and as the effects of Generative AI take hold. Expanding upon several surveys conducted in Australasia, the UK, and Ireland, this survey facilitates a direct comparison of global trends in CS1. The survey goes beyond environmental factors such as languages used, and examines why CS1 instructors teach what they do, in the ways they do. In total the survey spans 84 institutions and 91 courses in which a total of over 40,000 students are enrolled.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {799–805},
numpages = {7},
keywords = {covid-19, cs 1, cs-1, cs1, global, instructors, introductory programming, novice programmers, programming languages, survey, teaching languages},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626252.3630822,
author = {Taylor, Andrew and Vassar, Alexandra and Renzella, Jake and Pearce, Hammond},
title = {dcc --help: Transforming the Role of the Compiler by Generating Context-Aware Error Explanations with Large Language Models},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630822},
doi = {10.1145/3626252.3630822},
abstract = {In the challenging field of introductory programming, high enrolments and failure rates drive us to explore tools and systems to enhance student outcomes, especially automated tools that scale to large cohorts. This paper presents and evaluates the dcc --help tool, an integration of a Large Language Model (LLM) into the Debugging C Compiler (DCC) to generate unique, novice-focused explanations tailored to each error. dcc --help prompts an LLM with contextual information of compile- and run-time error occurrences, including the source code, error location and standard compiler error message. The LLM is instructed to generate novice-focused, actionable error explanations and guidance, designed to help students understand and resolve problems without providing solutions. dcc --help was deployed to our CS1 and CS2 courses, with 2,565 students using the tool over 64,000 times in ten weeks. We analysed a subset of these error/explanation pairs to evaluate their properties, including conceptual correctness, relevancy, and overall quality. We found that the LLM-generated explanations were conceptually accurate in 90\% of compile-time and 75\% of run-time cases, but often disregarded the instruction not to provide solutions in code. Our findings, observations and reflections following deployment indicate that dcc --help provides novel opportunities for scaffolding students' introduction to programming.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1314–1320},
numpages = {7},
keywords = {ai in cs1, ai in education, compiler error messages, cs1, debugging, error message enhancement, generative ai, large language models, programming error messages},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626252.3630903,
author = {Smith, Gillian},
title = {Pairing Ungrading with Project-Based Learning in CS1 for Inherently Flexible Course Design},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630903},
doi = {10.1145/3626252.3630903},
abstract = {This experience report details the pedagogical approach and curriculum for an introductory programming course for non-majors that combines creative coding, ungrading, and project-based learning, with typical enrollment between 120-140 students. Through a series of skills labs, a term-long group project, and regular self-evaluation milestones, students both build their confidence and motivation to learn programming, as well as typical introductory programming skills. Key to the course's success is the integration of project-based learning with a self-evaluation approach to ungrading. In this paper, I present the design of the course, the underlying pedagogical approach leading to course design decisions, and offer resources for adopting this approach in similar CS1 courses. The paper closes with discussion reflecting on the experiences observed throughout teaching this course, and suggests that the approach of blending ungrading with project-based learning shows promise as an inherently flexible course design that supports student wellbeing, confidence, and motivation.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1265–1271},
numpages = {7},
keywords = {creative coding, experience report, inclusive pedagogy, project-based learning, ungrading},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@proceedings{10.1145/3626253,
title = {SIGCSE 2024: Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 55th annual SIGCSE Technical Symposium on Computer Science Education (SIGCSE TS 2024)! This year, we have returned to Portland, Oregon. We hope that, like us, you are looking forward to a highly productive and engaging symposium that provides ample opportunity to renew old relationships, build new connections, and learn about the latest advances in our field. While we are sure that there will be a few surprises along the way, we hope and expect that we won't experience anything nearly as disruptive as the opening days of the pandemic, which occurred when we last tried to gather here in 2020.Our theme for this year's symposium is "Blazing New Trails in CS Education." This broad theme captures the exceptional work being performed by this community to enhance our teaching, improve our assessments, attract diverse students, and all of the other laudable projects, initiatives, and undertakings that affect positive change. The breadth of the program is substantial - there truly should be something for everyone. In fact, your biggest challenge may be deciding which session to attend in each time slot because there is so much going on! We know that many of you want to attend as many sessions as possible while you are here in Portland, but we encourage you to also find a little bit of time for yourself so that you leave Portland refreshed, renewed and encouraged, rather than exhausted or burnt out.},
location = {Portland, OR, USA}
}

@proceedings{10.1145/3626495,
title = {CVMP '23: Proceedings of the 20th ACM SIGGRAPH European Conference on Visual Media Production},
year = {2023},
isbn = {9798400704260},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {London, United Kingdom}
}

@proceedings{10.1145/3626562,
title = {Middleware '23: Proceedings of the 24th International Middleware Conference: Industrial Track},
year = {2023},
isbn = {9798400704277},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bologna, Italy}
}

@proceedings{10.1145/3626564,
title = {Middleware '23: Proceedings of the 24th International Middleware Conference: Demos, Posters and Doctoral Symposium},
year = {2023},
isbn = {9798400704291},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bologna, Italy}
}

@proceedings{10.1145/3626641,
title = {SIET '23: Proceedings of the 8th International Conference on Sustainable Information Engineering and Technology},
year = {2023},
isbn = {9798400708503},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Badung, Bali, Indonesia}
}

@proceedings{10.1145/3626705,
title = {MUM '23: Proceedings of the 22nd International Conference on Mobile and Ubiquitous Multimedia},
year = {2023},
isbn = {9798400709210},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Vienna, Austria}
}

@article{10.1145/3626730,
author = {Bussotti, Jean-Flavien and Veltri, Enzo and Santoro, Donatello and Papotti, Paolo},
title = {Generation of Training Examples for Tabular Natural Language Inference},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {4},
url = {https://doi.org/10.1145/3626730},
doi = {10.1145/3626730},
abstract = {Tabular data is becoming increasingly important in Natural Language Processing (NLP) tasks, such as Tabular Natural Language Inference (TNLI). Given a table and a hypothesis expressed in NL text, the goal is to assess if the former structured data supports or refutes the latter. In this work, we focus on the role played by the annotated data in training the inference model. We introduce a system, Tenet, for the automatic augmentation and generation of training examples for TNLI. Given the tables, existing approaches are either based on human annotators, and thus expensive, or on methods that produce simple examples that lack data variety and complex reasoning. Instead, our approach is built around the intuition that SQL queries are the right tool to achieve variety in the generated examples, both in terms of data variety and reasoning complexity. The first is achieved by evidence-queries that identify cell values over tables according to different data patterns. Once the data for the example is identified, semantic-queries describe the different ways such data can be identified with standard SQL clauses. These rich descriptions are then verbalized as text to create the annotated examples for the TNLI task. The same approach is also extended to create counterfactual examples, i.e., examples where the hypothesis is false, with a method based on injecting errors in the original (clean) table. For all steps, we introduce generic generation algorithms that take as input only the tables. For our experimental study, we use three datasets from the TNLI literature and two crafted by us on more complex tables. Tenet generates human-like examples, which lead to the effective training of several inference models with results comparable to those obtained by training the same models with manually-written examples.},
journal = {Proc. ACM Manag. Data},
month = dec,
articleno = {243},
numpages = {27},
keywords = {SQL-based NL generation, data augmentation, natural language processing (NLP) for databases, query generation, tabular natural language inference (TNLI), text generation}
}

@proceedings{10.1145/3627050,
title = {IoT '23: Proceedings of the 13th International Conference on the Internet of Things},
year = {2023},
isbn = {9798400708541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Nagoya, Japan}
}

@proceedings{10.1145/3627106,
title = {ACSAC '23: Proceedings of the 39th Annual Computer Security Applications Conference},
year = {2023},
isbn = {9798400708862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Austin, TX, USA}
}

@inproceedings{10.1145/3627106.3627122,
author = {Weeks, Connor and Cheruvu, Aravind and Abdullah, Sifat Muhammad and Kanchi, Shravya and Yao, Daphne and Viswanath, Bimal},
title = {A First Look at Toxicity Injection Attacks on Open-domain Chatbots},
year = {2023},
isbn = {9798400708862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627106.3627122},
doi = {10.1145/3627106.3627122},
abstract = {Chatbot systems have improved significantly because of the advances made in language modeling. These machine learning systems follow an end-to-end data-driven learning paradigm and are trained on large conversational datasets. Imperfections or harmful biases in the training datasets can cause the models to learn toxic behavior, and thereby expose their users to harmful responses. Prior work has focused on measuring the inherent toxicity of such chatbots, by devising queries that are more likely to produce toxic responses. In this work, we ask the question: How easy or hard is it to inject toxicity into a chatbot after deployment? We study this in a practical scenario known as Dialog-based Learning (DBL), where a chatbot is periodically trained on recent conversations with its users after deployment. A DBL setting can be exploited to poison the training dataset for each training cycle. Our attacks would allow an adversary to manipulate the degree of toxicity in a model and also enable control over what type of queries can trigger a toxic response. Our fully automated attacks only require LLM-based software agents masquerading as (malicious) users to inject high levels of toxicity. We systematically explore the vulnerability of popular chatbot pipelines to this threat. Lastly, we show that several existing toxicity mitigation strategies (designed for chatbots) can be significantly weakened by adaptive attackers.},
booktitle = {Proceedings of the 39th Annual Computer Security Applications Conference},
pages = {521–534},
numpages = {14},
keywords = {Chatbots, adversarial inputs, data poisoning, toxicity injection and detection},
location = {Austin, TX, USA},
series = {ACSAC '23}
}

@inproceedings{10.1145/3627106.3627123,
author = {Severi, Giorgio and Boboila, Simona and Oprea, Alina and Holodnak, John and Kratkiewicz, Kendra and Matterer, Jason},
title = {Poisoning Network Flow Classifiers},
year = {2023},
isbn = {9798400708862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627106.3627123},
doi = {10.1145/3627106.3627123},
abstract = {As machine learning (ML) classifiers increasingly oversee the automated monitoring of network traffic, studying their resilience against adversarial attacks becomes critical. This paper focuses on poisoning attacks, specifically backdoor attacks, against network traffic flow classifiers. We investigate the challenging scenario of clean-label poisoning where the adversary’s capabilities are constrained to tampering only with the training data — without the ability to arbitrarily modify the training labels or any other component of the training process. We describe a trigger crafting strategy that leverages model interpretability techniques to generate trigger patterns that are effective even at very low poisoning rates. Finally, we design novel strategies to generate stealthy triggers, including an approach based on generative Bayesian network models, with the goal of minimizing the conspicuousness of the trigger, and thus making detection of an ongoing poisoning campaign more challenging. Our findings provide significant insights into the feasibility of poisoning attacks on network traffic classifiers used in multiple scenarios, including detecting malicious communication and application classification.},
booktitle = {Proceedings of the 39th Annual Computer Security Applications Conference},
pages = {337–351},
numpages = {15},
location = {Austin, TX, USA},
series = {ACSAC '23}
}

@inproceedings{10.1145/3627106.3627196,
author = {Chen, Yufan and Arunasalam, Arjun and Celik, Z. Berkay},
title = {Can Large Language Models Provide Security \&amp; Privacy Advice? Measuring the Ability of LLMs to Refute Misconceptions},
year = {2023},
isbn = {9798400708862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627106.3627196},
doi = {10.1145/3627106.3627196},
abstract = {Users seek security \&amp; privacy (S&amp;P) advice from online resources, including trusted websites and content-sharing platforms. These resources help users understand S&amp;P technologies and tools and suggest actionable strategies. Large Language Models (LLMs) have recently emerged as trusted information sources. However, their accuracy and correctness have been called into question. Prior research has outlined the shortcomings of LLMs in answering multiple-choice questions and user ability to inadvertently circumvent model restrictions (e.g.,&nbsp;to produce toxic content). Yet, the ability of LLMs to provide reliable S&amp;P advice is not well-explored. In this paper, we measure their ability to refute popular S&amp;P misconceptions that the general public holds. We first study recent academic literature to curate a dataset of over a hundred S&amp;P-related misconceptions across six different topics. We then query two popular LLMs (Bard and ChatGPT) and develop a labeling guide to evaluate their responses to these misconceptions. To comprehensively evaluate their responses, we further apply three strategies: query each misconception multiple times, generate and query their paraphrases, and solicit source URLs of the responses. Both models demonstrate, on average, a 21.3\% non-negligible error rate, incorrectly supporting popular S&amp;P misconceptions. The error rate increases to 32.6\% when we repeatedly query LLMs with the same or paraphrased misconceptions. We also expose that models may partially support a misconception or remain noncommittal, refusing a firm stance on misconceptions. Our exploration of information sources for responses revealed that LLMs are susceptible to providing invalid URLs ( for Bard and for ChatGPT) or point to unrelated sources ( returned by Bard and by ChatGPT). Our findings highlight that existing LLMs are not completely reliable for S&amp;P advice and motivate future work in understanding how users can better interact with this technology.},
booktitle = {Proceedings of the 39th Annual Computer Security Applications Conference},
pages = {366–378},
numpages = {13},
keywords = {Large language models, misconception, security and privacy advice},
location = {Austin, TX, USA},
series = {ACSAC '23}
}

@proceedings{10.1145/3627217,
title = {COMPUTE '23: Proceedings of the 16th Annual ACM India Compute Conference},
year = {2023},
isbn = {9798400708404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hyderabad, India}
}

@inproceedings{10.1145/3627217.3627233,
author = {Balse, Rishabh and Kumar, Viraj and Prasad, Prajish and Warriem, Jayakrishnan Madathil},
title = {Evaluating the Quality of LLM-Generated Explanations for Logical Errors in CS1 Student Programs},
year = {2023},
isbn = {9798400708404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627217.3627233},
doi = {10.1145/3627217.3627233},
abstract = {When students in CS1 (Introductory Programming) write erroneous code, course staff can use automated tools to provide various types of helpful feedback. In this paper, we focus on syntactically correct student code containing logical errors. Tools that explain logical errors typically require course staff to invest greater effort than tools that detect such errors. To reduce this effort, prior work has investigated the use of Large Language Models (LLMs) such as GPT-3 to generate explanations. Unfortunately, these explanations can be incomplete or incorrect, and therefore unhelpful if presented to students directly. Nevertheless, LLM-generated explanations may be of adequate quality for Teaching Assistants (TAs) to efficiently craft helpful explanations on their basis. We evaluate the quality of explanations generated by an LLM (GPT-3.5-turbo) in two ways, for 30&nbsp;buggy student solutions across 6&nbsp;code-writing problems. First, in a study with 5&nbsp;undergraduate TAs, we compare TA perception of LLM-generated and peer-generated explanation quality. TAs were unaware which explanations were LLM-generated, but they found them to be comparable in quality to peer-generated explanations. Second, we performed a detailed manual analysis of LLM-generated explanations for all 30&nbsp;buggy solutions. We found at least one incorrect statement in 15/30 explanations (50\%). However, in 28/30 cases (93\%), the LLM-generated explanation correctly identified at least one logical error. Our results suggest that for large CS1 courses, TAs with adequate training to detect erroneous statements may be able to extract value from such explanations.},
booktitle = {Proceedings of the 16th Annual ACM India Compute Conference},
pages = {49–54},
numpages = {6},
keywords = {Explanation, GPT-3.5-Turbo, Large language models (LLMs), Logical Errors, Python Programming},
location = {Hyderabad, India},
series = {COMPUTE '23}
}

@proceedings{10.1145/3627341,
title = {ICCVIT '23: Proceedings of the 2023 International Conference on Computer, Vision and Intelligent Technology},
year = {2023},
isbn = {9798400708701},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Chenzhou, China}
}

@proceedings{10.1145/3627345,
title = {CCIOT '23: Proceedings of the 2023 8th International Conference on Cloud Computing and Internet of Things},
year = {2023},
isbn = {9798400708046},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Okinawa, Japan}
}

@proceedings{10.1145/3627377,
title = {ICBDT '23: Proceedings of the 2023 6th International Conference on Big Data Technologies},
year = {2023},
isbn = {9798400707667},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Qingdao, China}
}

@proceedings{10.1145/3627508,
title = {CHIIR '24: Proceedings of the 2024 Conference on Human Information Interaction and Retrieval},
year = {2024},
isbn = {9798400704345},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Sheffield, United Kingdom}
}

@inproceedings{10.1145/3627508.3638326,
author = {Cheng, Hao-Fei and Krikon, Eyal and Murdock, Vanessa},
title = {Why Do Customers Return Products? Using Customer Reviews to Predict Product Return Behaviors},
year = {2024},
isbn = {9798400704345},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627508.3638326},
doi = {10.1145/3627508.3638326},
abstract = {Product returns are an increasing environmental problem, as an estimated 25\% of returned products end up as landfill&nbsp;[10]. Returns are expensive for retailers as well, and it is estimated that 15-40\% of all online purchases are returned&nbsp;[34]. The problem could be mitigated by identifying issues with a product that are likely to lead to its return, before many have sold. Understanding and predicting return reasons can help identify manufacturing defects, misleading information in the product description or reviews, issues with a seller or shipping company, and customers who are habitual returners. While there has been much work to identify and predict return volume, little attention has been given to the reasons for the return. In this paper we explore how customer reviews could be used as signals to identify return reasons. We developed a multi-class classifier to predict return reasons, with a fine-tuned BERT-based model to encode customer review text as features. The classifier with customer review text yields an increase of more than 20\% average precision over the baseline classifier with no reviews text. We also showed that we can use aggregated review information to predict product return in case the customer returning the product did not write a review. Lastly we show that reviews can be used to identify nuanced return reasons beyond what the customer indicated.},
booktitle = {Proceedings of the 2024 Conference on Human Information Interaction and Retrieval},
pages = {12–22},
numpages = {11},
location = {Sheffield, United Kingdom},
series = {CHIIR '24}
}

@proceedings{10.1145/3627535,
title = {PPoPP '24: Proceedings of the 29th ACM SIGPLAN Annual Symposium on Principles and Practice of Parallel Programming},
year = {2024},
isbn = {9798400704352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {PPoPP is the foremost platform for showcasing groundbreaking research in both the practical and theoretical aspects of parallel computing. In today's technological landscape, parallelism is ubiquitous, encompassing everything from microscale devices to vast cloud infrastructures, and from fundamental software layers to advanced applications in artificial intelligence and beyond. The PPoPP community is at the forefront of expanding our understanding and capabilities in these diverse fields.},
location = {Edinburgh, United Kingdom}
}

@proceedings{10.1145/3627631,
title = {ICVGIP '23: Proceedings of the Fourteenth Indian Conference on Computer Vision, Graphics and Image Processing},
year = {2023},
isbn = {9798400716256},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rupnagar, India}
}

@proceedings{10.1145/3627676,
title = {DAI '23: Proceedings of the Fifth International Conference on Distributed Artificial Intelligence},
year = {2023},
isbn = {9798400708480},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Singapore, Singapore}
}

@proceedings{10.1145/3627703,
title = {EuroSys '24: Proceedings of the Nineteenth European Conference on Computer Systems},
year = {2024},
isbn = {9798400704376},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Athens, Greece}
}

@inproceedings{10.1145/3627703.3650085,
author = {Gupta, Tanmaey and Krishnan, Sanjeev and Kumar, Rituraj and Vijeev, Abhishek and Gulavani, Bhargav and Kwatra, Nipun and Ramjee, Ramachandran and Sivathanu, Muthian},
title = {Just-In-Time Checkpointing: Low Cost Error Recovery from Deep Learning Training Failures},
year = {2024},
isbn = {9798400704376},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627703.3650085},
doi = {10.1145/3627703.3650085},
abstract = {Deep Learning training jobs process large amounts of training data using many GPU devices, often running for weeks or months. When hardware or software failures happen, these jobs need to restart, losing the memory state for the Deep Neural Network (DNN) model trained so far, unless checkpointing mechanisms are used to save training state periodically. However, for large models, periodic checkpointing incurs significant steady state overhead, and during recovery, a large number of GPUs need to redo work since the last checkpoint. This is especially problematic when failures are frequent for large DNN (such as Large Language Model) training jobs using many GPUs. In this paper, we present a novel approach of just-in-time checkpointing when failures happen, which enables recovery from failures with just a single minibatch iteration of work replayed by all GPUs. This reduces the cost of error recovery from several minutes to a few seconds per GPU, with nearly zero steady state overhead. This also avoids the guesswork of choosing a checkpointing frequency since failure rates usually have high variance. We discuss how just-in-time checkpointing can be enabled in training code, as well as design of key mechanisms for transparent just-in-time checkpointing without user code change. We analyze the wasted GPU work of just-in-time checkpointing and show that it is less than periodic checkpointing for large numbers of GPUs. We present results from our implementation in modern AI cluster infrastructure.},
booktitle = {Proceedings of the Nineteenth European Conference on Computer Systems},
pages = {1110–1125},
numpages = {16},
keywords = {Large Scale DNN Training Reliability, Reliable Distributed Systems, Systems for Machine Learning},
location = {Athens, Greece},
series = {EuroSys '24}
}

@proceedings{10.1145/3627915,
title = {CSAE '23: Proceedings of the 7th International Conference on Computer Science and Application Engineering},
year = {2023},
isbn = {9798400700590},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Virtual Event, China}
}

@proceedings{10.1145/3628034,
title = {EuroPLoP '23: Proceedings of the 28th European Conference on Pattern Languages of Programs},
year = {2023},
isbn = {9798400700408},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Irsee, Germany}
}

@proceedings{10.1145/3628096,
title = {AfriCHI '23: Proceedings of the 4th African Human Computer Interaction Conference},
year = {2023},
isbn = {9798400708879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {East London, South Africa}
}

@inproceedings{10.1145/3628096.3628752,
author = {Abdulhamid, Najeeb Gambo and Ochieng, Millicent and Bali, Kalika and Ankrah, Elizabeth and Karusala, Naveena and Ronen, Keshet and O'Neill, Jacki},
title = {Can Large Language Models Support Medical Facilitation Work? A Speculative Analysis},
year = {2024},
isbn = {9798400708879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3628096.3628752},
doi = {10.1145/3628096.3628752},
abstract = {Mobile messaging apps and SMS-based tools have been deployed to extend healthcare services beyond the clinic; peer support chat groups, consisting of patients and healthcare providers, can improve medication adherence. However, moderation can be burdensome for busy healthcare professionals who must respond to patients, provide accurate and timely information, and engage and build community among patients. In this paper, taking an ethnographic approach, we examine the moderation of chat groups for young people living with HIV in Kenya. We describe the roles and responsibilities of the moderator while striving to engage and build community among the participants and manage the group chat, highlighting the challenges they face. Grounded in the moderators' work, we explore how an LLM-enabled copilot could help or hinder group facilitation. In doing so, we contribute to discussions about the potential of Artificial Intelligence in supporting healthcare professionals.},
booktitle = {Proceedings of the 4th African Human Computer Interaction Conference},
pages = {64–70},
numpages = {7},
keywords = {AI copilot, Large language models (LLMs), ethnography, facilitators, peer support chatgroups, roles and responsibility},
location = {East London, South Africa},
series = {AfriCHI '23}
}

@proceedings{10.1145/3628454,
title = {IAIT '23: Proceedings of the 13th International Conference on Advances in Information Technology},
year = {2023},
isbn = {9798400708497},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bangkok, Thailand}
}

@proceedings{10.1145/3628516,
title = {IDC '24: Proceedings of the 23rd Annual ACM Interaction Design and Children Conference},
year = {2024},
isbn = {9798400704420},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Delft, Netherlands}
}

@proceedings{10.1145/3628797,
title = {SOICT '23: Proceedings of the 12th International Symposium on Information and Communication Technology},
year = {2023},
isbn = {9798400708916},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Ho Chi Minh, Vietnam}
}

@inproceedings{10.1145/3628797.3628805,
author = {Vuong, Gia-Huy and Ho, Van-Son and Nguyen-Dang, Tien-Thanh and Thai, Xuan-Dang and Ninh, Van-Tu and Pham, Minh-Khoi and Le, Tu-Khiem and Healy, Graham and Tran, Minh-Triet},
title = {NewsInsight: A Comprehensive Video Event Retrieval System with Spatial Insights and Query Assistance},
year = {2023},
isbn = {9798400708916},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3628797.3628805},
doi = {10.1145/3628797.3628805},
abstract = {Video event retrieval is the task of finding videos that are relevant to a given query. It is a challenging problem because videos are typically much larger than images, and they can contain a variety of different objects and scenes. However, there are a number of different approaches to video retrieval, and the field is rapidly evolving. Some of the most promising research directions include the use of deep learning and multimodal features. In this paper, we introduce NewsInsight – a comprehensive video event retrieval system developed for participating AI Challenge 2023. The system under investigation leverages the Bootstrapping Language-Image Pre-training (BLIP) model for zero-shot image-text retrieval, demonstrating superior recall scores on the Flickr30K dataset compared to the Contrastive Language–Image Pretraining (CLIP) model. In addition, it employs an Elastic Search filtering mechanism to discard irrelevant images. Beyond semantic search mechanisms, the system supports visual similarity search by calculating the inner product distance between vectors in the video frames corpus and the query image. The system also incorporates an explicit relevance feedback function, AI-based query description rewriting, and visual-example-generating features, enhancing the precision of the query description and aiding end-users in formulating a more accurate depiction of the targeted image for retrieval.},
booktitle = {Proceedings of the 12th International Symposium on Information and Communication Technology},
pages = {893–900},
numpages = {8},
keywords = {AI-based Assistance, Interactive Retrieval, Lifelog, Spatial Insights, Video Event retrieval},
location = {Ho Chi Minh, Vietnam},
series = {SOICT '23}
}

@proceedings{10.1145/3629188,
title = {NSysS '23: Proceedings of the 10th International Conference on Networking, Systems and Security},
year = {2023},
isbn = {9798400708787},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Khulna, Bangladesh}
}

@inproceedings{10.1145/3629188.3629189,
author = {Rashid, Syed Md. Mukit and Toufikuzzaman, Md. and Hossain, Md. Shohrab},
title = {A Deep Learning Based Semi-Supervised Network Intrusion Detection System Robust to Adversarial Attacks},
year = {2023},
isbn = {9798400708787},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3629188.3629189},
doi = {10.1145/3629188.3629189},
abstract = {Network intrusion detection systems (NIDS) are used to detect abnormal behavior in network traffic, which is vital for secure communication. Recently, deep learning based solutions have been adopted for NIDS which suffer from two main problems. Most of them are based on supervised learning and cannot utilize the information that can be obtained from unlabeled data. Also, deep learning based methods are shown to be vulnerable to adversarial attacks. In this paper, we propose a novel semi-supervised and adversarially robust deep learning based approach which can utilize both labeled and unlabeled training samples. Our IDS first performs K-Means clustering to soft label part of the unlabeled data and then obtain a decision tree based on labeled and soft labeled samples. It then pretrains an autoencoder based multi-layer perceptron and later learns separate multi-layer perceptrons on each individual leaf of the decision tree. Our results show that the performance of our system is comparable to state-of-the art supervised learning approaches and outperforms existing state-of-the-art semi-supervised NIDS. Furthermore, we have extensively tested the adversarial robustness of our method using the popular blackbox Fast Gradient Sign Method (FGSM) and Generative Adversarial Network based IDSGAN approaches. Comparisons with other state-of-the-art NIDS baselines show that our proposed mechanism provides significantly higher adversarial detection rates, proving the robustness of our system to adversarial attacks.},
booktitle = {Proceedings of the 10th International Conference on Networking, Systems and Security},
pages = {25–34},
numpages = {10},
keywords = {Adversarial Testing, Deep Learning, Intrusion Detection, Semi-supervised},
location = {Khulna, Bangladesh},
series = {NSysS '23}
}

@proceedings{10.1145/3629264,
title = {ICCDA '23: Proceedings of the 2023 7th International Conference on Computing and Data Analysis},
year = {2023},
isbn = {9798400700576},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Guiyang, China}
}

@proceedings{10.1145/3629296,
title = {ICETC '23: Proceedings of the 15th International Conference on Education Technology and Computers},
year = {2023},
isbn = {9798400709111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Barcelona, Spain}
}

@inproceedings{10.1145/3629296.3629346,
author = {Segarra-Faggioni, Veronica and Romero-Pelaez, Audrey},
title = {Automatic topic terms identification from OER},
year = {2024},
isbn = {9798400709111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3629296.3629346},
doi = {10.1145/3629296.3629346},
abstract = {Currently, there are valuable educational materials in digital format need to be analyzed automatically about covered topics. OER metadata about covered topics is essentially required by learners to build effective learning pathways towards their individual learning objectives. Using natural language processing techniques, topic terms can be automatically identified from metadata OER. Topic modeling allows identifying topics automatically from a set of documents. Based on the LDA model, we propose an automatic topic terms identification from OERs. A total of 4142 OER about “Information Technology” were collected from SkillsCommons. Finally, to identify the best experiment, we used the values of coherence and the distance inter-topic. Results reveal that discovered topics can help to improve the accessibility, discoverability, and usefulness of open educational resources. In addition to supporting the development of more effective and efficient teaching and learning practices.},
booktitle = {Proceedings of the 15th International Conference on Education Technology and Computers},
pages = {304–307},
numpages = {4},
keywords = {LDA, OER, educational materials, text mining},
location = {Barcelona, Spain},
series = {ICETC '23}
}

@proceedings{10.1145/3629526,
title = {ICPE '24: Proceedings of the 15th ACM/SPEC International Conference on Performance Engineering},
year = {2024},
isbn = {9798400704444},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Years of planning have gone into preparing for ICPE 2024 in London, UK. For the first time in UK, the organization of ICPE has generated a great deal of excitement and expectation of productive interactions between the usual participants of ICPE conferences, the members of the various SPEC working groups, and a desire to increase the involvement of the local scientific community with ICPE.It is our pleasure to welcome you to the 15th ACM/SPEC International Conference on Performance Engineering (ICPE), hosted at South Kensington, London, UK, from May 7-11, 2024. ICPE is the leading international forum for presenting and discussing novel ideas, innovations, trends and experiences in the field of performance engineering.ICPE formed from merging the ACM Workshop on Software Performance (WOSP, since 1998) and the SPEC International Performance Engineering Workshop (SIPEW, since 2008). Despite the peculiar time we are all living in around the world, we are pleased to introduce an exciting program, which is the result of hard work by the authors, the program committee, and the conference organizers.},
location = {London, United Kingdom}
}

@proceedings{10.1145/3629527,
title = {ICPE '24 Companion: Companion of the 15th ACM/SPEC International Conference on Performance Engineering},
year = {2024},
isbn = {9798400704451},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to present the ICPE 2024 workshops program. ICPE workshops extend the main conference by providing a forum to foster discussion on hot and emerging topics from the broad field of performance engineering. They offer a highly dynamic venue to exchange ideas, establish new collaborations, and bootstrap debates on novel techniques, methodologies, and their associated early research results. Workshops feature various presentation formats, including research paper presentations, panel discussions, and keynote talks. Through these presentations and discussions with peer researchers, ICPE workshops help shape future research and identify promising research directions for performance engineering.},
location = {London, United Kingdom}
}

@proceedings{10.1145/3629606,
title = {CHCHI '23: Proceedings of the Eleventh International Symposium of Chinese CHI},
year = {2023},
isbn = {9798400716454},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Denpasar, Bali, Indonesia}
}

@inproceedings{10.1145/3629606.3629675,
author = {He, Qingyang and Zheng, Weicheng and Bao, Hanxi and Chen, Ruiqi and Tong, Xin},
title = {Exploring Designers’ Perceptions and Practices of Collaborating with Generative AI as a Co-creative Agent in a Multi-stakeholder Design Process: Take the Domain of Avatar Design as an Example},
year = {2024},
isbn = {9798400716454},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3629606.3629675},
doi = {10.1145/3629606.3629675},
abstract = {Nowadays, the traditional workflow of designers’ completing complicated design tasks has undergone a profound transformation due to the pervasive intervention of generative artificial intelligence (AI) tools, especially when multi-stakeholder participation is getting involved in the design process. Yet we know little about the designers’ perceptions and practices of collaborating with generative AI as a co-creative agent within the context of multi-stakeholder participation. To investigate these questions, we took the domain of avatar design as an example and conducted a qualitative interview study with 21 expert avatar designers who have got different levels of experience and expertise in utilizing generative AI tools in their design workflow. We found that designers not only would fall in a dilemma when deciding whether to consider AI as a co-creative agent according to different stakeholders’ interests, but they also face many challenges in effectively co-creating with the current systems, including challenges in consistently adjusting AI outputs and getting design inspiration within the iterative generation process, etc. Based on our findings, we concluded both the epistemological and creative patterns of collaborating with generative AI and highlighted several design opportunities from both technical and ethical perspectives to better support future designer-AI co-creation.},
booktitle = {Proceedings of the Eleventh International Symposium of Chinese CHI},
pages = {596–613},
numpages = {18},
keywords = {AI-assisted Design, Avatar Design, Co-creation Experience, Generative AI, Human-AI Collaboration, Stakeholder Identification},
location = {Denpasar, Bali, Indonesia},
series = {CHCHI '23}
}

@proceedings{10.1145/3630048,
title = {DistributedML '23: Proceedings of the 4th International Workshop on Distributed Machine Learning},
year = {2023},
isbn = {9798400704475},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Following up the prior three successful versions of DistributedML, it is our great honour and pleasure to welcome you again, this time physically in the 4rd edition of the Distributed Machine Learning Workshop (DistributedML '23). The workshop is co-located with the 19th International Conference on emerging Networking EXperiments and Technologies (CoNEXT '23) and held in Paris, France, on the 8th of December 2023.Distributed ML is a rapidly evolving, interdisciplinary field bringing together techniques from Distributed Systems, Networks and Machine Learning. With Deep Learning at the forefront, we are seeing an explosion of AI-driven technologies, from immersive VR experiences and smart digital assistants to advanced robotics and autonomous vehicles. These applications not only challenge the limits of local device capabilities but also many times necessitate a shift towards distributed models of computation to enhance performance and efficiency, while respecting privacy and sustainability. At the cornerstone of innovation, foundational models further push the boundaries of today's computational infrastructure. Therefore, scaling up to support the new training workloads and efficiently deploying Large Language or Vision Models become key research areas.},
location = {Paris, France}
}

@proceedings{10.1145/3630106,
title = {FAccT '24: Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rio de Janeiro, Brazil}
}

@inproceedings{10.1145/3630106.3658900,
author = {Gausen, Anna and Mitra, Bhaskar and Lindley, Si\^{a}n},
title = {A Framework for Exploring the Consequences of AI-Mediated Enterprise Knowledge Access and Identifying Risks to Workers},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658900},
doi = {10.1145/3630106.3658900},
abstract = {Organisations generate vast amounts of information, which has resulted in a long-term research effort into knowledge access systems for enterprise settings. Recent developments in artificial intelligence, in relation to large language models, are poised to have significant impact on knowledge access. This has the potential to shape the workplace and knowledge in new and unanticipated ways. Many risks can arise from the deployment of these types of AI systems, due to interactions between the technical system and organisational power dynamics. This paper presents the Consequences-Mechanisms-Risks framework to identify risks to workers from AI-mediated enterprise knowledge access systems. We have drawn on wide-ranging literature detailing risks to workers, and categorised risks as being to worker value, power, and wellbeing. The contribution of our framework is to additionally consider (i) the consequences of these systems that are of moral import: commodification, appropriation, concentration of power, and marginalisation, and (ii) the mechanisms, which represent how these consequences may take effect in the system. The mechanisms are a means of contextualising risk within specific system processes, which is critical for mitigation. This framework is aimed at helping practitioners involved in the design and deployment of AI-mediated knowledge access systems to consider the risks introduced to workers, identify the precise system mechanisms that introduce those risks, and begin to approach mitigation. Future work could apply this framework to other technological systems to promote the protection of workers and other groups.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {207–220},
numpages = {14},
keywords = {enterprise knowledge access systems, large language models, risks, workers},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.1145/3630106.3658923,
author = {Globus-Harris, Ira and Harrison, Declan and Kearns, Michael and Perona, Pietro and Roth, Aaron},
title = {Diversified Ensembling: An Experiment in Crowdsourced Machine Learning},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658923},
doi = {10.1145/3630106.3658923},
abstract = {Crowdsourced machine learning on competition platforms such as Kaggle is a popular and often effective method for generating accurate models. Typically, teams vie for the most accurate model, as measured by overall error on a holdout set, and it is common towards the end of such competitions for teams at the top of the leaderboard to ensemble or average their models outside the platform mechanism to get the final, best global model. In [12], the authors developed an alternative crowdsourcing framework in the context of fair machine learning, in order to integrate community feedback into models when subgroup unfairness is present and identifiable. There, unlike in classical crowdsourced ML, participants deliberately specialize their efforts by working on subproblems, such as demographic subgroups in the service of fairness. Here, we take a broader perspective on this work: we note that within this framework, participants may both specialize in the service of fairness and simply to cater to their particular expertise (e.g., focusing on identifying bird species in an image classification task). Unlike traditional crowdsourcing, this allows for the diversification of participants’ efforts and may provide a participation mechanism to a larger range of individuals (e.g. a machine learning novice who has insight into a specific fairness concern). We present the first medium-scale experimental evaluation of this framework, with 46 participating teams attempting to generate models to predict income from American Community Survey data. We provide an empirical analysis of teams’ approaches, and discuss the novel system architecture we developed. From here, we give concrete guidance for how best to deploy such a framework.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {529–545},
numpages = {17},
keywords = {Crowdsourcing, Ensembling Methods, Fairness},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.1145/3630106.3658927,
author = {Hall, Melissa and Bell, Samuel J. and Ross, Candace and Williams, Adina and Drozdzal, Michal and Soriano, Adriana Romero},
title = {Towards Geographic Inclusion in the Evaluation of Text-to-Image Models},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658927},
doi = {10.1145/3630106.3658927},
abstract = {Rapid progress in text-to-image generative models coupled with their deployment for visual content creation has magnified the importance of thoroughly evaluating their performance and identifying potential biases. In pursuit of models that generate images that are realistic, diverse, visually appealing, and consistent with the given prompt, researchers and practitioners often turn to automated metrics to facilitate scalable and cost-effective performance profiling. However, commonly-used metrics often fail to account for the full diversity of human preference; often even in-depth human evaluations face challenges with subjectivity, especially as interpretations of evaluation criteria vary across regions and cultures. In this work, we conduct a large, cross-cultural study to study how much annotators in Africa, Europe, and Southeast Asia vary in their perception of geographic representation, visual appeal, and consistency in real and generated images from state-of-the art public APIs. We collect over 65,000 image annotations and 20 survey responses. We contrast human annotations with common automated metrics, finding that human preferences vary notably across geographic location and that current metrics do not fully account for this diversity. For example, annotators in different locations often disagree on whether exaggerated, stereotypical depictions of a region are considered geographically representative. In addition, the utility of automatic evaluations is dependent on assumptions about their set-up, such as the alignment of feature extractors with human perception of object similarity or the definition of “appeal” captured in reference datasets used to ground evaluations. We recommend steps for improved automatic and human evaluations. This includes collecting annotations from people located inside and outside the region of interest, instructing annotators on whether they should follow specific definitions of evaluation criteria or utilize their own interpretation, and reporting assumptions underlying automatic evaluations.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {585–601},
numpages = {17},
keywords = {evaluation, geography, text-to-image generation},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.1145/3630106.3658936,
author = {Staufer, Dimitri and Pallas, Frank and Berendt, Bettina},
title = {Silencing the Risk, Not the Whistle: A Semi-automated Text Sanitization Tool for Mitigating the Risk of Whistleblower Re-Identification},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658936},
doi = {10.1145/3630106.3658936},
abstract = {Whistleblowing is essential for ensuring transparency and accountability in both public and private sectors. However, (potential) whistleblowers often fear or face retaliation, even when reporting anonymously. The specific content of their disclosures and their distinct writing style may re-identify them as the source. Legal measures, such as the EU Whistleblower Directive, are limited in their scope and effectiveness. Therefore, computational methods to prevent re-identification are important complementary tools for encouraging whistleblowers to come forward. However, current text sanitization tools follow a one-size-fits-all approach and take an overly limited view of anonymity. They aim to mitigate identification risk by replacing typical high-risk words (such as person names and other labels of named entities) and combinations thereof with placeholders. Such an approach, however, is inadequate for the whistleblowing scenario since it neglects further re-identification potential in textual features, including the whistleblower’s writing style. Therefore, we propose, implement, and evaluate a novel classification and mitigation strategy for rewriting texts that involves the whistleblower in the assessment of the risk and utility. Our prototypical tool semi-automatically evaluates risk at the word/term level and applies risk-adapted anonymization techniques to produce a grammatically disjointed yet appropriately sanitized text. We then use a Large Language Model (LLM) that we fine-tuned for paraphrasing to render this text coherent and style-neutral. We evaluate our tool’s effectiveness using court cases from the European Court of Human Rights (ECHR) and excerpts from a real-world whistleblower testimony and measure the protection against authorship attribution attacks and utility loss statistically using the popular IMDb62 movie reviews dataset, which consists of 62 individuals. Our method can significantly reduce authorship attribution accuracy from 98.81\% to 31.22\%, while preserving up to 73.1\% of the original content’s semantics, as measured by the established cosine similarity of sentence embeddings.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {733–745},
numpages = {13},
keywords = {Authorship Obfuscation, Fine-tuning Language Models, LLM-based Rephrasing, Text Sanitization, Whistleblower Anonymity},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.1145/3630106.3658942,
author = {Rivera, Juan-Pablo and Mukobi, Gabriel and Reuel, Anka and Lamparth, Max and Smith, Chandler and Schneider, Jacquelyn},
title = {Escalation Risks from Language Models in Military and Diplomatic Decision-Making},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658942},
doi = {10.1145/3630106.3658942},
abstract = {Governments are increasingly considering integrating autonomous AI agents in high-stakes military and foreign-policy decision-making, especially with the emergence of advanced generative AI models like GPT-4. Our work aims to scrutinize the behavior of multiple AI agents in simulated wargames, specifically focusing on their predilection to take escalatory actions that may exacerbate multilateral conflicts. Drawing on political science and international relations literature about escalation dynamics, we design a novel wargame simulation and scoring framework to assess the escalation risks of actions taken by these agents in different scenarios. Contrary to prior studies, our research provides both qualitative and quantitative insights and focuses on large language models (LLMs). We find that all five studied off-the-shelf LLMs show forms of escalation and difficult-to-predict escalation patterns. We observe that models tend to develop arms-race dynamics, leading to greater conflict, and in rare cases, even to the deployment of nuclear weapons. Qualitatively, we also collect the models’ reported reasoning for chosen actions and observe worrying justifications based on deterrence and first-strike tactics. Given the high stakes of military and foreign-policy contexts, we recommend further examination and cautious consideration before deploying autonomous language model agents for strategic military or diplomatic decision-making.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {836–898},
numpages = {63},
keywords = {Evaluation, Language Model Agents, Military Applications, Multi-Agent Security, Natural Language Processing, Safety, Socio-Technical Impact},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.1145/3630106.3658982,
author = {Antoniak, Maria and Naik, Aakanksha and Alvarado, Carla S. and Wang, Lucy Lu and Chen, Irene Y.},
title = {NLP for Maternal Healthcare: Perspectives and Guiding Principles in the Age of LLMs},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658982},
doi = {10.1145/3630106.3658982},
abstract = {Ethical frameworks for the use of natural language processing (NLP) are urgently needed to shape how large language models (LLMs) and similar tools are used for healthcare applications. Healthcare faces existing challenges including the balance of power in clinician-patient relationships, systemic health disparities, historical injustices, and economic constraints. Drawing directly from the voices of those most affected, and focusing on a case study of a specific healthcare setting, we propose a set of guiding principles for the use of NLP in maternal healthcare. We led an interactive session centered on an LLM-based chatbot demonstration during a full-day workshop with 39 participants, and additionally surveyed 30 healthcare workers and 30 birthing people about their values, needs, and perceptions of NLP tools in the context of maternal health. We conducted quantitative and qualitative analyses of the survey results and interactive discussions to consolidate our findings into a set of guiding principles. We propose nine principles for ethical use of NLP for maternal healthcare, grouped into three themes: (i) recognizing contextual significance (ii) holistic measurements, and (iii) who/what is valued. For each principle, we describe its underlying rationale and provide practical advice. This set of principles can provide a methodological pattern for other researchers and serve as a resource to practitioners working on maternal health and other healthcare fields to emphasize the importance of technical nuance, historical context, and inclusive design when developing NLP technologies for clinical use.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1446–1463},
numpages = {18},
keywords = {ethical guidelines, large language models, maternal health, natural language processing},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.1145/3630106.3658983,
author = {Kinahan, Sean and Saidi, Pouria and Daliri, Ayoub and Liss, Julie and Berisha, Visar},
title = {Achieving Reproducibility in EEG-Based Machine Learning},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658983},
doi = {10.1145/3630106.3658983},
abstract = {Despite the inherent complexity of electroencephalogram (EEG) data characterized by its high dimensionality, artifactual noise, and biological variability, many machine learning (ML) studies claim impressive performance in decoding or classifying EEG signals. Recently, several studies have highlighted that flawed data analysis is a prevalent issue in the literature, leading to irreproducible results and exaggerated claims. To address this issue, we propose a framework that addresses three primary obstacles in EEG ML research: data leakage, data scarcity, and flawed model selection. We introduce the EEG ML Model Card, a standardized and transparent EEG ML model documentation tool that aims to directly address these pitfalls and enhance reproducibility and trustworthiness in EEG ML research.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1464–1474},
numpages = {11},
keywords = {EEG, Machine Learning, Reproducibility},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.1145/3630106.3658984,
author = {Wang, Ruotong and Cheng, Ruijia and Ford, Denae and Zimmermann, Thomas},
title = {Investigating and Designing for Trust in AI-powered Code Generation Tools},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658984},
doi = {10.1145/3630106.3658984},
abstract = {Trust is a crucial factor for the adoption and responsible usage of generative AI tools in complex tasks such as software engineering. However, we have a limited understanding of how software developers evaluate the trustworthiness of AI-powered code generation tools in real-world settings. To address this gap, we conducted Study 1, an interview study with 17 developers who use AI-powered code generation tools in professional or personal settings. We found that developers’ trust is rooted in the AI tool’s perceived ability, integrity, and benevolence, and is situational, varying according to the context of usage. Existing AI code generation tools lack the affordances for developers to efficiently and effectively evaluate the trustworthiness of AI-powered code generation tools. To explore designs that can augment the existing interface of AI-powered code generation tools, we explored three sets of design concepts (suggestion quality indicators, usage stats, and control mechanisms) that derived from Study 1 findings. In Study 2, a design probe study with 12 developers, we investigated the potential of these design concepts to help developers make effective trust judgments. We discuss the implication of our findings on the design of AI-powered code generation tools and future research on trust in AI.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1475–1493},
numpages = {19},
keywords = {generative AI, human-AI interaction, software engineering tooling, trust in AI},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.1145/3630106.3659002,
author = {Whitney, Cedric Deslandes and Norman, Justin},
title = {Real Risks of Fake Data: Synthetic Data, Diversity-Washing and Consent Circumvention},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3659002},
doi = {10.1145/3630106.3659002},
abstract = {Machine learning systems require representations of the real world for training and testing - they require data, and lots of it. Collecting data at scale has logistical and ethical challenges, and synthetic data promises a solution to these challenges. Instead of needing to collect photos of real people’s faces to train a facial recognition system, a model creator could create and use photo-realistic, synthetic faces. The comparative ease of generating this synthetic data rather than relying on collecting data has made it a common practice. We present two key risks of using synthetic data in model development. First, we detail the high risk of false confidence when using synthetic data to increase dataset diversity and representation. We base this in the examination of a real world use-case of synthetic data, where synthetic datasets were generated for an evaluation of facial recognition technology. Second, we examine how using synthetic data risks circumventing consent for data usage. We illustrate this by considering the importance of consent to the U.S. Federal Trade Commission’s regulation of data collection and affected models. Finally, we discuss how these two risks exemplify how synthetic data complicates existing governance and ethical practice; by decoupling data from those it impacts, synthetic data is prone to consolidating power away those most impacted by algorithmically-mediated harm.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1733–1744},
numpages = {12},
keywords = {dataset development, ethical guidelines, responsible model development, standards, synthetic data},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.1145/3630106.3659009,
author = {Grill, Gabriel},
title = {Constructing Capabilities: The Politics of Testing Infrastructures for Generative AI},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3659009},
doi = {10.1145/3630106.3659009},
abstract = {The advertised and perceived capabilities of generative AI products like ChatGPT have recently stimulated considerable investments and discourse surrounding their potential to aid and replace work. The prominence of these systems, and their promise to be general-purpose, has resulted in an avalanche of tests to discover and certify their capabilities. This new testing regime is concerned with creating ever-more tasks for generative AI products instead of testing a model for one specialized task. Beyond efforts to understand products’ capabilities, the construction of tasks and corresponding tests are also performative enactments meant to convince others and thus to gain attention, scientific legitimacy, and investment. The current market concentration of a few big AI companies points to a concerning conflict of interest: those with a vested interest in the success of the technology also have control over globalized testing infrastructures and thereby the exclusive means to create extensive knowledge claims about these systems. In this paper, I theorize capabilities as contested constructions and situated accomplishments shaped by power imbalances. I further unpack the globalized testing infrastructures involved in the construction and stabilization of generative AI products’ capabilities. Furthermore, I discuss how the testing of these AI models and products is externalized, extracting value from the unpaid or under-paid labor of researcher and developer communities, content creators, subcontractors, and users. Lastly, I discuss a reflexive and critical approach to testing that challenges depoliticization and seeks to produce lasting critiques that serve more emancipatory goals.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1838–1849},
numpages = {12},
keywords = {ML benchmarks, affordances, capabilities, generative AI, infrastructure studies, testing},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.1145/3630106.3659036,
author = {Gomez, Juan Felipe and Machado, Caio and Paes, Lucas Monteiro and Calmon, Flavio},
title = {Algorithmic Arbitrariness in Content Moderation},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3659036},
doi = {10.1145/3630106.3659036},
abstract = {Machine learning (ML) is widely used to moderate online content. Despite its scalability relative to human moderation, the use of ML introduces unique challenges to content moderation. One such challenge is predictive multiplicity: multiple competing models for content classification may perform equally well on average, yet assign conflicting predictions to the same content. This multiplicity can result from seemingly innocuous choices made during training, which do not meaningfully change the accuracy of the ML model, but can nevertheless change what the model gets wrong. We experimentally demonstrate how content moderation tools can arbitrarily classify samples as “toxic,” leading to arbitrary restrictions on speech. We use the principles set by the International Covenant on Civil and Political Rights (ICCPR), namely freedom of expression, non-discrimination, and procedural justice to interpret the effects of these findings in terms of Human Rights. We analyze (i) the extent of predictive multiplicity among popular state-of-the-art LLMs used for detecting “toxic” content; (ii) the disparate impact of this arbitrariness across social groups; and (iii) the magnitude of model multiplicity on content that is unanimously recognized as toxic by human annotators. Our findings indicate that the up-scaled algorithmic moderation risks legitimizing an “algorithmic leviathan”, where an algorithm disproportionately manages human rights. To mitigate such risks, our study underscores the need to identify and increase the transparency of arbitrariness in content moderation applications. Our findings have implications to content moderation and intermediary liability laws being discussed and passed in many countries, such as the Digital Services Act in the European Union, the Online Safety Act in the United Kingdom, and the recent TSE resolutions in Brazil.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {2234–2253},
numpages = {20},
keywords = {Rashomon effect, content moderation, predictive multiplicity},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.1145/3630106.3659037,
author = {Casper, Stephen and Ezell, Carson and Siegmann, Charlotte and Kolt, Noam and Curtis, Taylor Lynn and Bucknall, Benjamin and Haupt, Andreas and Wei, Kevin and Scheurer, J\'{e}r\'{e}my and Hobbhahn, Marius and Sharkey, Lee and Krishna, Satyapriya and Von Hagen, Marvin and Alberti, Silas and Chan, Alan and Sun, Qinyi and Gerovitch, Michael and Bau, David and Tegmark, Max and Krueger, David and Hadfield-Menell, Dylan},
title = {Black-Box Access is Insufficient for Rigorous AI Audits},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3659037},
doi = {10.1145/3630106.3659037},
abstract = {External audits of AI systems are increasingly recognized as a key mechanism for AI governance. The effectiveness of an audit, however, depends on the degree of access granted to auditors. Recent audits of state-of-the-art AI systems have primarily relied on black-box access, in which auditors can only query the system and observe its outputs. However, white-box access to the system’s inner workings (e.g., weights, activations, gradients) allows an auditor to perform stronger attacks, more thoroughly interpret models, and conduct fine-tuning. Meanwhile, outside-the-box access to training and deployment information (e.g., methodology, code, documentation, data, deployment details, findings from internal evaluations) allows auditors to scrutinize the development process and design more targeted evaluations. In this paper, we examine the limitations of black-box audits and the advantages of white- and outside-the-box audits. We also discuss technical, physical, and legal safeguards for performing these audits with minimal security risks. Given that different forms of access can lead to very different levels of evaluation, we conclude that (1) transparency regarding the access and methods used by auditors is necessary to properly interpret audit results, and (2) white- and outside-the-box access allow for substantially more scrutiny than black-box access alone.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {2254–2272},
numpages = {19},
keywords = {Adversarial Attacks, Auditing, Black-Box Access, Evaluation, Explainability, Fairness, Fine-Tuning, Governance, Interpretability, Policy, Regulation, Risk, White-Box Access},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.1145/3630106.3659039,
author = {Moayeri, Mazda and Rabbat, Michael and Ibrahim, Mark and Bouchacourt, Diane},
title = {Embracing Diversity: Interpretable Zero-shot Classification Beyond One Vector Per Class},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3659039},
doi = {10.1145/3630106.3659039},
abstract = {Vision-language models enable open-world classification of objects without the need for any retraining. While this zero-shot paradigm marks a significant advance, even today’s best models exhibit skewed performance when objects are dissimilar from their typical depiction. Real world objects such as pears appear in a variety of forms — from diced to whole, on a table or in a bowl — yet standard VLM classifiers map all instances of a class to a single vector based on the class label. We argue that to represent this rich diversity within a class, zero-shot classification should move beyond a single vector. We propose a method to encode and account for diversity within a class using inferred attributes, still in the zero-shot setting without retraining. We find our method consistently outperforms standard zero-shot classification over a large suite of datasets encompassing hierarchies, diverse object states, and real-world geographic diversity, as well finer-grained datasets where intra-class diversity may be less prevalent. Importantly, our method is inherently interpretable, offering faithful explanations for each inference to facilitate model debugging and enhance transparency. We also find our method scales efficiently to a large number of attributes to account for diversity—leading to more accurate predictions for atypical instances. Finally, we characterize a principled trade-off between overall and worst class accuracy, which can be tuned via a hyperparameter of our method. We hope this work spurs further research into the promise of zero-shot classification beyond a single class vector for capturing diversity in the world, and building transparent AI systems without compromising performance.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {2302–2321},
numpages = {20},
keywords = {Bias, Classification, Fairness, Vision Language Models (VLMs), Zero-shot},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.1145/3630106.3659045,
author = {Engelmann, Severin and Choksi, Madiha Zahrah and Wang, Angelina and Fiesler, Casey},
title = {Visions of a Discipline: Analyzing Introductory AI Courses on YouTube},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3659045},
doi = {10.1145/3630106.3659045},
abstract = {Education plays an indispensable role in fostering societal well-being and is widely regarded as one of the most influential factors in shaping the future of generations to come. As artificial intelligence (AI) becomes more deeply integrated into our daily lives and the workforce, educational institutions at all levels are directing their focus on resources that cater to AI education. Yet, informal education, including online learning on social media platforms like YouTube, plays an increasingly significant role for both students and the general public. Offering greater accessibility compared to formal education, millions of individuals use YouTube for educational resources on AI today. Due to the substantial societal impact of AI, it is crucial for introductory AI courses to meaningfully address the ethical implications associated with AI. Our work investigates the current landscape of introductory AI courses on YouTube, and the potential for introducing ethics in this context. We qualitatively analyze the 20 most watched introductory AI courses on YouTube, coding a total of 92.2 hours of educational content viewed by close to 50 million people. We find that these introductory AI courses do not meaningfully engage with ethical or societal challenges of AI (RQ1). When defining and framing AI, introductory AI courses foreground excitement around AI’s transformative role in society, over-exaggerate AI’s current and future abilities, and anthropomorphize AI (RQ2). In teaching AI, we see a widespread reliance on corporate AI tools and frameworks as well as a prioritization on a hands-on approach to learning rather than on conceptual foundations (RQ3). In promoting key AI practices, introductory AI courses abstract away entirely the socio-technical nature of AI classification and prediction, for example by favoring data quantity over data quality (RQ4). Given the power of openly available introductory courses to shape enduring beliefs around AI and its field at the onset of a learning journey, we extend our analysis with recommendations that aim to integrate ethical reflections into introductory AI courses. We recommend that introductory AI courses should (1) highlight ethical challenges of AI to present a more balanced perspective, (2) raise ethical issues explicitly relevant to the technical concepts discussed and (3) nurture a sense of accountability in future AI developers.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {2400–2420},
numpages = {21},
keywords = {Computer science education, accountability in computer science, artificial intelligence ethics, ethics in computer science education},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@proceedings{10.1145/3630138,
title = {PCCNT '23: Proceedings of the 2023 International Conference on Power, Communication, Computing and Networking Technologies},
year = {2023},
isbn = {9781450399951},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Wuhan, China}
}

@proceedings{10.1145/3630202,
title = {CoNEXT-SW '23: Proceedings of the on CoNEXT Student Workshop 2023},
year = {2023},
isbn = {9798400704529},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 19th edition of the ACM Conference on Emerging Networking Experiment and Technologies (ACM CoNEXT 2022). CoNEXT is a premier and highly selective venue in computer networking. The first edition of the conference was organized in Toulouse in 2005 and we are back in France, but this time in Paris.Last year, the CoNEXT Steering Committee decided to move from a traditional conference model with a single submission deadline in June to a hybrid model with two submission deadlines (late November and late June). Two types of papers can be submitted to CoNEXT: (i) long papers presenting significant and novel research results on emerging computer networks and applications and (ii) short papers for contributions whose novelty and impact show the same technical excellence, but whose description fits within 6 pages. The accepted long papers are published in the journal Proceedings of the ACM on Networking (PACMNET) while the short papers appear in the conference proceedings.},
location = {Paris, France}
}

@proceedings{10.1145/3630744,
title = {Websci Companion '24: Companion Publication of the 16th ACM Web Science Conference},
year = {2024},
isbn = {9798400704536},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Stuttgart, Germany}
}

@proceedings{10.1145/3631085,
title = {SBGames '23: Proceedings of the 22nd Brazilian Symposium on Games and Digital Entertainment},
year = {2023},
isbn = {9798400716270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rio Grande (RS), Brazil}
}

@article{10.1145/3631406,
author = {Venugopalan, Hari and Din, Zainul Abi and Carpenter, Trevor and Lowe-Power, Jason and King, Samuel T. and Shafiq, Zubair},
title = {Aragorn: A Privacy-Enhancing System for Mobile Cameras},
year = {2024},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {4},
url = {https://doi.org/10.1145/3631406},
doi = {10.1145/3631406},
abstract = {Mobile app developers often rely on cameras to implement rich features. However, giving apps unfettered access to the mobile camera poses a privacy threat when camera frames capture sensitive information that is not needed for the app's functionality. To mitigate this threat, we present Aragorn, a novel privacy-enhancing mobile camera system that provides fine grained control over what information can be present in camera frames before apps can access them. Aragorn automatically sanitizes camera frames by detecting regions that are essential to an app's functionality and blocking out everything else to protect privacy while retaining app utility. Aragorn can cater to a wide range of camera apps and incorporates knowledge distillation and crowdsourcing to extend robust support to previously unsupported apps. In our evaluations, we see that, with no degradation in utility, Aragorn detects credit cards with 89\% accuracy and faces with 100\% accuracy in context of credit card scanning and face recognition respectively. We show that Aragorn's implementation in the Android camera subsystem only suffers an average drop of 0.01 frames per second in frame rate. Our evaluations show that the overhead incurred by Aragorn to system performance is reasonable.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jan,
articleno = {181},
numpages = {31},
keywords = {Knowledge Distillation, Object Detection}
}

@article{10.1145/3631420,
author = {Kang, Dong-Sig and Baek, Eunsu and Son, Sungwook and Lee, Youngki and Gong, Taesik and Kim, Hyung-Sin},
title = {MIRROR: Towards Generalizable On-Device Video Virtual Try-On for Mobile Shopping},
year = {2024},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {4},
url = {https://doi.org/10.1145/3631420},
doi = {10.1145/3631420},
abstract = {We present MIRROR, an on-device video virtual try-on (VTO) system that provides realistic, private, and rapid experiences in mobile clothes shopping. Despite recent advancements in generative adversarial networks (GANs) for VTO, designing MIRROR involves two challenges: (1) data discrepancy due to restricted training data that miss various poses, body sizes, and backgrounds and (2) local computation overhead that uses up 24\% of battery for converting only a single video. To alleviate the problems, we propose a generalizable VTO GAN that not only discerns intricate human body semantics but also captures domain-invariant features without requiring additional training data. In addition, we craft lightweight, reliable clothes/pose-tracking that generates refined pixel-wise warping flow without neural-net computation. As a holistic system, MIRROR integrates the new VTO GAN and tracking method with meticulous pre/post-processing, operating in two distinct phases (on/offline). Our results on Android smartphones and real-world user videos show that compared to a cutting-edge VTO GAN, MIRROR achieves 6.5\texttimes{} better accuracy with 20.1\texttimes{} faster video conversion and 16.9\texttimes{} less energy consumption.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jan,
articleno = {163},
numpages = {27}
}

@article{10.1145/3631428,
author = {Kang, Hua and Hu, Qingyong and Zhang, Qian},
title = {SF-Adapter: Computational-Efficient Source-Free Domain Adaptation for Human Activity Recognition},
year = {2024},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {4},
url = {https://doi.org/10.1145/3631428},
doi = {10.1145/3631428},
abstract = {Wearable sensor-based human activity recognition (HAR) has gained significant attention due to the widespread use of smart wearable devices. However, variations in different subjects can cause a domain shift that impedes the scaling of the recognition model. Unsupervised domain adaptation has been proposed as a solution to recognize activities in new, unlabeled target domains by training the source and target data together. However, the need for accessing source data raises privacy concerns. Source-free domain adaptation has emerged as a practical setting, where only a pre-trained source model is provided for the unlabeled target domain. This setup aligns with the need for personalized activity model adaptation on target local devices. As the edge devices are resource-constrained with limited memory, it is crucial to take the computational efficiency, i.e., memory cost into consideration. In this paper, we develop a source-free domain adaptation framework for wearable sensor-based HAR, with a focus on computational efficiency for target edge devices. Firstly, we design a lightweight add-on module called adapter to adapt the frozen pre-trained model to the unlabeled target domain. Secondly, to optimize the adapter, we adopt a simple yet effective model adaptation method that leverages local representation similarity and prediction consistency. Additionally, we design a set of sample selection optimization strategies to select samples effective for adaptation and further enhance computational efficiency while maintaining adaptation performance. Our extensive experiments on three datasets demonstrate that our method achieves comparable recognition accuracy to the state-of-the-art source free domain adaptation methods with fewer than 1\% of the parameters updated and saves up to 4.99X memory cost.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jan,
articleno = {164},
numpages = {23},
keywords = {adapter, computation efficiency, human activity recognition, source free domain adaptation}
}

@proceedings{10.1145/3631461,
title = {ICDCN '24: Proceedings of the 25th International Conference on Distributed Computing and Networking},
year = {2024},
isbn = {9798400716737},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Chennai, India}
}

@proceedings{10.1145/3631802,
title = {Koli Calling '23: Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
year = {2023},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Koli, Finland}
}

@inproceedings{10.1145/3631802.3631830,
author = {Liffiton, Mark and Sheese, Brad E and Savelka, Jaromir and Denny, Paul},
title = {CodeHelp: Using Large Language Models with Guardrails for Scalable Support in Programming Classes},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631830},
doi = {10.1145/3631802.3631830},
abstract = {Computing educators face significant challenges in providing timely support to students, especially in large class settings. Large language models (LLMs) have emerged recently and show great promise for providing on-demand help at a large scale, but there are concerns that students may over-rely on the outputs produced by these models. In this paper, we introduce CodeHelp, a novel LLM-powered tool designed with guardrails to provide on-demand assistance to programming students without directly revealing solutions. We detail the design of the tool, which incorporates a number of useful features for instructors, and elaborate on the pipeline of prompting strategies we use to ensure generated outputs are suitable for students. To evaluate CodeHelp, we deployed it in a first-year computer and data science course with 52 students and collected student interactions over a 12-week period. We examine students’ usage patterns and perceptions of the tool, and we report reflections from the course instructor and a series of recommendations for classroom use. Our findings suggest that CodeHelp is well-received by students who especially value its availability and help with resolving errors, and that for instructors it is easy to deploy and complements, rather than replaces, the support that they provide to students.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {8},
numpages = {11},
keywords = {Guardrails, Intelligent programming tutors, Intelligent tutoring systems, Large language models, Natural language interfaces, Novice programmers, Programming assistance},
location = {Koli, Finland},
series = {Koli Calling '23}
}

@proceedings{10.1145/3631882,
title = {MEMSYS '23: Proceedings of the International Symposium on Memory Systems},
year = {2023},
isbn = {9798400716447},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Alexandria, VA, USA}
}

@proceedings{10.1145/3631908,
title = {ICACS '23: Proceedings of the 7th International Conference on Algorithms, Computing and Systems},
year = {2023},
isbn = {9798400709098},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Larissa, Greece}
}

@proceedings{10.1145/3631991,
title = {WSSE '23: Proceedings of the 2023 5th World Symposium on Software Engineering},
year = {2023},
isbn = {9798400708053},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tokyo, Japan}
}

@inproceedings{10.1145/3631991.3632038,
author = {Ruhela, Riya and Lamba, Subir S. and Gupta, Bhupendra},
title = {Structure-Preserving Image Smoothing using Adaptive Bilateral Filter},
year = {2023},
isbn = {9798400708053},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631991.3632038},
doi = {10.1145/3631991.3632038},
abstract = {Structure-preserving image smoothing is an important image processing problem that plays significant role in many applications of image processing and computer vision such as detail enhancement, edge detection, tone mapping, image segmentation, and image abstraction. We suggest a structure-aware bilateral filter to accomplish smoothing on an image without altering the salient structure information. The main contribution of the proposed work is the designing of the scale map, which has been used to choose the size of the spatial kernel at each pixel in accordance with the structure information. The aim behind using the scale map is to perform filtering on the homogeneous and texture regions while preventing filtering on the prominent structure regions. The proposed method has excellent structure-preserving and texture removal properties. The qualitative and quantitative analysis of the experimental results has shown the outperformance of the proposed method over the existing state-of-the-art methods.},
booktitle = {Proceedings of the 2023 5th World Symposium on Software Engineering},
pages = {286–291},
numpages = {6},
keywords = {Bilateral filter, Scale map, Structure component, Structure- preserving, Texture component},
location = {Tokyo, Japan},
series = {WSSE '23}
}

@proceedings{10.1145/3632047,
title = {ICBRA '23: Proceedings of the 2023 10th International Conference on Bioinformatics Research and Applications},
year = {2023},
isbn = {9798400708152},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Barcelona, Spain}
}

@proceedings{10.1145/3632314,
title = {ISIA '23: Proceedings of the 2023 International Conference on Intelligent Sensing and Industrial Automation},
year = {2023},
isbn = {9798400709401},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Virtual Event, China}
}

@proceedings{10.1145/3632366,
title = {BDCAT '23: Proceedings of the IEEE/ACM 10th International Conference on Big Data Computing, Applications and Technologies},
year = {2023},
isbn = {9798400704734},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The IEEE/ACM International Conference on Big Data Computing, Applications, and Technologies (BDCAT) is a premier annual conference series aiming to provide a platform for researchers from both academia and industry to present new discoveries in the broad area of big data computing and applications.},
location = {Taormina (Messina), Italy}
}

@proceedings{10.1145/3632410,
title = {CODS-COMAD '24: Proceedings of the 7th Joint International Conference on Data Science \&amp; Management of Data (11th ACM IKDD CODS and 29th COMAD)},
year = {2024},
isbn = {9798400716348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bangalore, India}
}

@proceedings{10.1145/3632634,
title = {SIGMIS-CPR '24: Proceedings of the 2024 Computers and People Research Conference},
year = {2024},
isbn = {9798400704772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Murfreesboro, TN, USA}
}

@proceedings{10.1145/3632754,
title = {FIRE '23: Proceedings of the 15th Annual Meeting of the Forum for Information Retrieval Evaluation},
year = {2023},
isbn = {9798400716324},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Panjim, India}
}

@proceedings{10.1145/3632775,
title = {e-Energy '24: Proceedings of the 15th ACM International Conference on Future and Sustainable Energy Systems},
year = {2024},
isbn = {9798400704802},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Singapore, Singapore}
}

@proceedings{10.1145/3632776,
title = {ARTECH '23: Proceedings of the 11th International Conference on Digital and Interactive Arts},
year = {2023},
isbn = {9798400708725},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Faro, Portugal}
}

@article{10.1145/3632860,
author = {Patton, Noah and Rahmani, Kia and Missula, Meghana and Biswas, Joydeep and Dillig, I\c{s}\i{}l},
title = {Programming-by-Demonstration for Long-Horizon Robot Tasks},
year = {2024},
issue_date = {January 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {POPL},
url = {https://doi.org/10.1145/3632860},
doi = {10.1145/3632860},
abstract = {The goal of programmatic Learning from Demonstration (LfD) is to learn a policy in a programming language that can be used to control a robot’s behavior from a set of user demonstrations. This paper presents a new programmatic LfD algorithm that targets long-horizon robot tasks which require synthesizing programs with complex control flow structures, including nested loops with multiple conditionals. Our proposed method first learns a program sketch that captures the target program’s control flow and then completes this sketch using an LLM-guided search procedure that incorporates a novel technique for proving unrealizability of programming-by-demonstration problems. We have implemented our approach in a new tool called PROLEX and present the results of a comprehensive experimental evaluation on 120 benchmarks involving complex tasks and environments. We show that, given a 120 second time limit, PROLEX can find a program consistent with the demonstrations in 80\% of the cases. Furthermore, for 81\% of the tasks for which a solution is returned, PROLEX is able to find the ground truth program with just one demonstration. In comparison, CVC5, a syntax-guided synthesis tool, is only able to solve 25\% of the cases even when given the ground truth program sketch, and an LLM-based approach, GPT-Synth, is unable to solve any of the tasks due to the environment complexity.},
journal = {Proc. ACM Program. Lang.},
month = jan,
articleno = {18},
numpages = {34},
keywords = {Abstract Interpretation, Learning from Demonstrations, Program Synthesis}
}

@article{10.1145/3632870,
author = {Pailoor, Shankara and Wang, Yuepeng and Dillig, I\c{s}\i{}l},
title = {Semantic Code Refactoring for Abstract Data Types},
year = {2024},
issue_date = {January 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {POPL},
url = {https://doi.org/10.1145/3632870},
doi = {10.1145/3632870},
abstract = {Modifications to the data representation of an abstract data type (ADT) can require significant semantic refactoring of the code. Motivated by this observation, this paper presents a new method to automate semantic code refactoring tasks. Our method takes as input the original ADT implementation, a new data representation, and a so-called relational representation invariant (relating the old and new data representations), and automatically generates a new ADT implementation that is semantically equivalent to the original version. Our method is based on counterexample-guided inductive synthesis (CEGIS) but leverages three key ideas that allow it to handle real-world refactoring tasks. First, our approach reduces the underlying relational synthesis problem to a set of (simpler) programming-by-example problems, one for each method in the ADT. Second, it leverages symbolic reasoning techniques, based on logical abduction, to deduce code snippets that should occur in the refactored version. Finally, it utilizes a notion of partial equivalence to make inductive synthesis much more effective in this setting. We have implemented the proposed approach in a new tool called Revamp ‍ for automatically refactoring Java classes and evaluated it on 30 Java class mined from Github. Our evaluation shows that Revamp can correctly refactor the entire ADT in 97\% of the cases and that it can successfully re-implement 144 out of the 146 methods that require modifications.},
journal = {Proc. ACM Program. Lang.},
month = jan,
articleno = {28},
numpages = {32},
keywords = {Abstract Data Types, Program Synthesis, Refactoring}
}

@article{10.1145/3632896,
author = {Tang, Wenhao and Hillerstr\"{o}m, Daniel and Lindley, Sam and Morris, J. Garrett},
title = {Soundly Handling Linearity},
year = {2024},
issue_date = {January 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {POPL},
url = {https://doi.org/10.1145/3632896},
doi = {10.1145/3632896},
abstract = {We propose a novel approach to soundly combining linear types with multi-shot effect handlers. circear type systems statically ensure that resources such as file handles and communication channels are used exactly once. Effect handlers provide a rich modular programming abstraction for implementing features ranging from exceptions to concurrency to backtracking. Whereas conventional linear type systems bake in the assumption that continuations are invoked exactly once, effect handlers allow continuations to be discarded (e.g. for exceptions) or invoked more than once (e.g. for backtracking). This mismatch leads to soundness bugs in existing systems such as the programming language Links, which combines linearity (for session types) with effect handlers. We introduce control-flow linearity as a means to ensure that continuations are used in accordance with the linearity of any resources they capture, ruling out such soundness bugs. We formalise the notion of control-flow linearity in a System F-style core calculus Feff∘ equipped with linear types, an effect type system, and effect handlers. We define a linearity-aware semantics in order to formally prove that Feff∘ preserves the integrity of linear values in the sense that no linear value is discarded or duplicated. In order to show that control-flow linearity can be made practical, we adapt circks based on the design of Feff∘, in doing so fixing a long-standing soundness bug. Finally, to better expose the potential of control-flow linearity, we define an ML-style core calculus Qeff∘, based on qualified types, which requires no programmer provided annotations, and instead relies entirely on type inference to infer control-flow linearity. Both linearity and effects are captured by qualified types. Qeff∘ overcomes a number of practical limitations of Feff∘, supporting abstraction over linearity, linearity dependencies between type variables, and a much more fine-grained notion of control-flow linearity.},
journal = {Proc. ACM Program. Lang.},
month = jan,
articleno = {54},
numpages = {29},
keywords = {control-flow linearity, linear resources, multi-shot continuations}
}

@article{10.1145/3632904,
author = {Sotiropoulos, Thodoris and Chaliasos, Stefanos and Su, Zhendong},
title = {API-Driven Program Synthesis for Testing Static Typing Implementations},
year = {2024},
issue_date = {January 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {POPL},
url = {https://doi.org/10.1145/3632904},
doi = {10.1145/3632904},
abstract = {We introduce a novel approach for testing static typing implementations based on the concept of API-driven program synthesis. The idea is to synthesize type-intensive but small and well-typed programs by leveraging and combining application programming interfaces (APIs) derived from existing software libraries. Our primary insight is backed up by real-world evidence: a significant number of compiler typing bugs are caused by small test cases that employ APIs from the standard library of the language under test. This is attributed to the inherent complexity of the majority of these APIs, which often exercise a wide range of sophisticated type-related features. The main contribution of our approach is the ability to produce small client programs with increased feature coverage, without bearing the burden of generating the corresponding well-formed API definitions from scratch. To validate diverse aspects of static typing procedures (i.e., soundness, precision of type inference), we also enrich our API-driven approach with fault-injection and semantics-preserving modes, along with their corresponding test oracles.  

We evaluate our implemented tool, Thalia on testing the static typing implementations of the compilers for three popular languages, namely, Scala, Kotlin, and Groovy. Thalia has uncovered 84 typing bugs (77 confirmed and 22 fixed), most of which are triggered by test cases featuring APIs that rely on parametric polymorphism, overloading, and higher-order functions. Our comparison with state-of-the-art shows that Thalia yields test programs with distinct characteristics, offering additional and complementary benefits.},
journal = {Proc. ACM Program. Lang.},
month = jan,
articleno = {62},
numpages = {32},
keywords = {API, compiler bug, compiler testing, enumeration, library, type system}
}

@proceedings{10.1145/3632971,
title = {JCRAI '23: Proceedings of the 2023 International Joint Conference on Robotics and Artificial Intelligence},
year = {2023},
isbn = {9798400707704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Shanghai, China}
}

@proceedings{10.1145/3633053,
title = {CEP '24: Proceedings of the 8th Conference on Computing Education Practice},
year = {2024},
isbn = {9798400709326},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Durham, United Kingdom}
}

@proceedings{10.1145/3633083,
title = {HCAIep '23: Proceedings of the 2023 Conference on Human Centered Artificial Intelligence: Education and Practice},
year = {2023},
isbn = {9798400716461},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Dublin, Ireland}
}

@article{10.1145/3633287,
author = {Richards, Mike and Waugh, Kevin and Slaymaker, Mark and Petre, Marian and Woodthorpe, John and Gooch, Daniel},
title = {Bob or Bot: Exploring ChatGPT's Answers to University Computer Science Assessment},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {1},
url = {https://doi.org/10.1145/3633287},
doi = {10.1145/3633287},
abstract = {Cheating has been a long-standing issue in university assessments. However, the release of ChatGPT and other free-to-use generative AI tools has provided a new and distinct method for cheating. Students can run many assessment questions through the tool and generate a superficially compelling answer, which may or may not be accurate.&nbsp;We ran a dual-anonymous “quality assurance” marking exercise across four end-of-module assessments across a distance university computer science (CS) curriculum. Each marker received five ChatGPT-generated scripts alongside 10 student scripts. A total of 90 scripts were marked; every ChatGPT-generated script for the undergraduate modules received at least a passing grade (&gt;40\%), with all of the introductory module CS1 scripts receiving a distinction (&gt;85\%). None of the ChatGPT-taught postgraduate scripts received a passing grade (&gt;50\%). We also present the results of interviewing the markers and of running our sample scripts through a GPT-2 detector and the TurnItIn AI detector, which both identified every ChatGPT-generated script but differed in the number of false positives. As such, we contribute a baseline understanding of how the public release of generative AI is likely to significantly impact quality assurance processes. Our analysis demonstrates that in most cases, across a range of question formats, topics, and study levels, ChatGPT is at least capable of producing adequate answers for undergraduate assessment.},
journal = {ACM Trans. Comput. Educ.},
month = jan,
articleno = {5},
numpages = {32},
keywords = {ChatGPT, generative AI, cheating, quality assurance, university assessment’}
}

@proceedings{10.1145/3633598,
title = {ICAAI '23: Proceedings of the 2023 7th International Conference on Advances in Artificial Intelligence},
year = {2023},
isbn = {9798400708985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Istanbul, Turkiye}
}

@proceedings{10.1145/3633624,
title = {BDSIC '23: Proceedings of the 2023 5th International Conference on Big-data Service and Intelligent Computation},
year = {2023},
isbn = {9798400708923},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Singapore, Singapore}
}

@proceedings{10.1145/3633637,
title = {ICCPR '23: Proceedings of the 2023 12th International Conference on Computing and Pattern Recognition},
year = {2023},
isbn = {9798400707988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Qingdao, China}
}

@proceedings{10.1145/3634713,
title = {VaMoS '24: Proceedings of the 18th International Working Conference on Variability Modelling of Software-Intensive Systems},
year = {2024},
isbn = {9798400708770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bern, Switzerland}
}

@proceedings{10.1145/3634769,
title = {IGSC '23: Proceedings of the 14th International Green and Sustainable Computing Conference},
year = {2023},
isbn = {9798400716690},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Toronto, ON, Canada}
}

@proceedings{10.1145/3634814,
title = {ASSE '23: Proceedings of the 2023 4th Asia Service Sciences and Software Engineering Conference},
year = {2023},
isbn = {9798400708534},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Aizu-Wakamatsu City, Japan}
}

@proceedings{10.1145/3634848,
title = {ICSIE '23: Proceedings of the 2023 12th International Conference on Software and Information Engineering},
year = {2023},
isbn = {9798400708107},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Sharm El-Sheikh, Egypt}
}

@proceedings{10.1145/3634865,
title = {ICSCC '23: Proceedings of the 2023 8th International Conference on Systems, Control and Communications},
year = {2023},
isbn = {9798400707810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Chongqing, China}
}

@proceedings{10.1145/3635035,
title = {HPCAsia '24: Proceedings of the International Conference on High Performance Computing in Asia-Pacific Region},
year = {2024},
isbn = {9798400708893},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Nagoya, Japan}
}

@proceedings{10.1145/3635059,
title = {PCI '23: Proceedings of the 27th Pan-Hellenic Conference on Progress in Computing and Informatics},
year = {2023},
isbn = {9798400716263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lamia, Greece}
}

@proceedings{10.1145/3635118,
title = {ICAIP '23: Proceedings of the 2023 7th International Conference on Advances in Image Processing},
year = {2023},
isbn = {9798400708275},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Beijing, China}
}

@proceedings{10.1145/3635175,
title = {ICIIP '23: Proceedings of the 2023 8th International Conference on Intelligent Information Processing},
year = {2023},
isbn = {9798400708091},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bucharest, Romania}
}

@proceedings{10.1145/3635638,
title = {MLMI '23: Proceedings of the 6th International Conference on Machine Learning and Machine Intelligence},
year = {2023},
isbn = {9798400709456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Chongqing, China}
}

@proceedings{10.1145/3635800,
title = {PEPM 2024: Proceedings of the 2024 ACM SIGPLAN International Workshop on Partial Evaluation and Program Manipulation},
year = {2024},
isbn = {9798400704871},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are pleased to present the proceedings of the 2024 ACM SIGPLAN Workshop on Partial Evaluation and Program Manipulation (PEPM 2024), held January 16th, 2024 in London, in affiliation with the annual Symposium on Principles of Programming Languages (POPL 2024).},
location = {London, UK}
}

@proceedings{10.1145/3636243,
title = {ACE '24: Proceedings of the 26th Australasian Computing Education Conference},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Sydney, NSW, Australia}
}

@inproceedings{10.1145/3636243.3636247,
author = {Hou, Irene and Man, Owen and Mettille, Sophia and Gutierrez, Sebastian and Angelikas, Kenneth and MacNeil, Stephen},
title = {More Robots are Coming: Large Multimodal Models (ChatGPT) can Solve Visually Diverse Images of Parsons Problems},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636247},
doi = {10.1145/3636243.3636247},
abstract = {Large language models are reshaping computing education. Based on recent research, these models explain code better than students, answer multiple choice questions at or above the class average, and generate code that can pass automated tests in introductory courses. In response to these capabilities, instructors have quickly adjusted their courses and assessment methods to align with shifting learning goals and the increased risk of academic integrity issues. While some scholars have advocated for the integration of visual problems as a safeguard against the capabilities of language models, new multimodal models now have vision and language capabilities that may allow them to analyze and solve visual problems. In this paper, we compare the large multimodal model (LMMs) GPT-4V with Bard, an LLM that uses Google Lens for text recognition. We find that LMMs, which have learned both pixel features (from images) and text features (from prompts) in the same embedding space, performed substantially better than Bard which uses a piecemeal approach. With a specific focus on Parsons problems presented across diverse visual representations, our results show that GPT-4V solved 96.7\% these visual problems, struggling minimally with a single Parsons problem. Conversely, Bard performed poorly by only solving 69.2\% of problems, struggling with common issues like hallucinations and refusals. These findings suggest that merely transitioning to visual programming problems might not be a panacea to issues of academic integrity in the generative AI era.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {29–38},
numpages = {10},
keywords = {Bard, ChatGPT, GPT-4V, Generative AI, LLMs, Parsons Problems, computing education, visual programming problems},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3636243.3636249,
author = {Sheese, Brad and Liffiton, Mark and Savelka, Jaromir and Denny, Paul},
title = {Patterns of Student Help-Seeking When Using a Large Language Model-Powered Programming Assistant},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636249},
doi = {10.1145/3636243.3636249},
abstract = {Providing personalized assistance at scale is a long-standing challenge for computing educators, but a new generation of tools powered by large language models (LLMs) offers immense promise. Such tools can, in theory, provide on-demand help in large class settings and be configured with appropriate guardrails to prevent misuse and mitigate common concerns around learner over-reliance. However, the deployment of LLM-powered tools in authentic classroom settings is still rare, and very little is currently known about how students will use them in practice and what type of help they will seek. To address this, we examine students’ use of an innovative LLM-powered tool that provides on-demand programming assistance without revealing solutions directly. We deployed the tool for 12 weeks in an introductory computer and data science course&nbsp;(n = 52), collecting more than 2,500 queries submitted by students throughout the term. We manually categorized all student queries based on the type of assistance sought, and we automatically analyzed several additional query characteristics. We found that most queries requested immediate help with programming assignments, whereas fewer requests asked for help on related concepts or for deepening conceptual understanding. Furthermore, students often provided minimal information to the tool, suggesting this is an area in which targeted instruction would be beneficial. We also found that students who achieved more success in the course tended to have used the tool more frequently overall. Lessons from this research can be leveraged by programming educators and institutions who plan to augment their teaching with emerging LLM-powered tools.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {49–57},
numpages = {9},
keywords = {Guardrails, Intelligent programming tutors, Intelligent tutoring systems, Large language models, Natural language interfaces, Novice programmers, Programming assistance},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3636243.3636256,
author = {Doughty, Jacob and Wan, Zipiao and Bompelli, Anishka and Qayum, Jubahed and Wang, Taozhi and Zhang, Juran and Zheng, Yujia and Doyle, Aidan and Sridhar, Pragnya and Agarwal, Arav and Bogart, Christopher and Keylor, Eric and Kultur, Can and Savelka, Jaromir and Sakr, Majd},
title = {A Comparative Study of AI-Generated (GPT-4) and Human-crafted MCQs in Programming Education},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636256},
doi = {10.1145/3636243.3636256},
abstract = {There is a constant need for educators to develop and maintain effective up-to-date assessments. While there is a growing body of research in computing education on utilizing large language models&nbsp;(LLMs) in generation and engagement with coding exercises, the use of LLMs for generating programming MCQs has not been extensively explored. We analyzed the capability of GPT-4 to produce multiple-choice questions (MCQs) aligned with specific learning objectives (LOs) from Python programming classes in higher education. Specifically, we developed an LLM-powered (GPT-4) system for generation of MCQs from high-level course context and module-level LOs. We evaluated 651 LLM-generated and 449 human-crafted MCQs aligned to 246 LOs from 6 Python courses. We found that GPT-4 was capable of producing MCQs with clear language, a single correct choice, and high-quality distractors. We also observed that the generated MCQs appeared to be well-aligned with the LOs. Our findings can be leveraged by educators wishing to take advantage of the state-of-the-art generative models to support MCQ authoring efforts.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {114–123},
numpages = {10},
keywords = {Assessments, Automated Content Generation, Automatic Generation, GPT-4, LLMs, LOs, Large Language Models, Learning Objectives, MCQs, Multiple-choice Questions},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3636243.3636259,
author = {Roest, Lianne and Keuning, Hieke and Jeuring, Johan},
title = {Next-Step Hint Generation for Introductory Programming Using Large Language Models},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636259},
doi = {10.1145/3636243.3636259},
abstract = {Large Language Models possess skills such as answering questions, writing essays or solving programming exercises. Since these models are easily accessible, researchers have investigated their capabilities and risks for programming education. This work explores how LLMs can contribute to programming education by supporting students with automated next-step hints. We investigate prompt practices that lead to effective next-step hints and use these insights to build our StAP-tutor. We evaluate this tutor by conducting an experiment with students, and performing expert assessments. Our findings show that most LLM-generated feedback messages describe one specific next step and are personalised to the student’s code and approach. However, the hints may contain misleading information and lack sufficient detail when students approach the end of the assignment. This work demonstrates the potential for LLM-generated feedback, but further research is required to explore its practical implementation.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {144–153},
numpages = {10},
keywords = {Generative AI, Large Language Models, Next-step hints, automated feedback, learning programming},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3636534.3649379,
author = {Wen, Hao and Li, Yuanchun and Liu, Guohong and Zhao, Shanhui and Yu, Tao and Li, Toby Jia-Jun and Jiang, Shiqi and Liu, Yunhao and Zhang, Yaqin and Liu, Yunxin},
title = {AutoDroid: LLM-powered Task Automation in Android},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649379},
doi = {10.1145/3636534.3649379},
abstract = {Mobile task automation is an attractive technique that aims to enable voice-based hands-free user interaction with smartphones. However, existing approaches suffer from poor scalability due to the limited language understanding ability and the non-trivial manual efforts required from developers or endusers. The recent advance of large language models (LLMs) in language understanding and reasoning inspires us to rethink the problem from a model-centric perspective, where task preparation, comprehension, and execution are handled by a unified language model. In this work, we introduce AutoDroid, a mobile task automation system capable of handling arbitrary tasks on any Android application without manual efforts. The key insight is to combine the commonsense knowledge of LLMs and domain-specific knowledge of apps through automated dynamic analysis. The main components include a functionality-aware UI representation method that bridges the UI with the LLM, exploration-based memory injection techniques that augment the app-specific domain knowledge of LLM, and a multi-granularity query optimization module that reduces the cost of model inference. We integrate AutoDroid with off-the-shelf LLMs including online GPT-4/GPT-3.5 and on-device Vicuna, and evaluate its performance on a new benchmark for memory-augmented Android task automation with 158 common tasks. The results demonstrated that AutoDroid is able to precisely generate actions with an accuracy of 90.9\%, and complete tasks with a success rate of 71.3\%, outperforming the GPT-4-powered baselines by 36.4\% and 39.7\%.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {543–557},
numpages = {15},
keywords = {task automation, large language models, app analysis},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}

@proceedings{10.1145/3636555,
title = {LAK '24: Proceedings of the 14th Learning Analytics and Knowledge Conference},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Kyoto, Japan}
}

@inproceedings{10.1145/3636555.3636853,
author = {Singh, Anjali and Brooks, Christopher and Wang, Xu and Li, Warren and Kim, Juho and Wilson, Deepti},
title = {Bridging Learnersourcing and AI: Exploring the Dynamics of Student-AI Collaborative Feedback Generation},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636853},
doi = {10.1145/3636555.3636853},
abstract = {This paper explores the space of optimizing feedback mechanisms in complex domains such as data science, by combining two prevailing approaches: Artificial Intelligence (AI) and learnersourcing. Towards addressing the challenges posed by each approach, this work compares traditional learnersourcing with an AI-supported approach. We report on the results of a randomized controlled experiment conducted with 72 Master’s level students in a data visualization course, comparing two conditions: students writing hints independently versus revising hints generated by GPT-4. The study aimed to evaluate the quality of learnersourced hints, examine the impact of student performance on hint quality, gauge learner preference for writing hints with versus without AI support, and explore the potential of the student-AI collaborative exercise in fostering critical thinking about LLMs. Based on our findings, we provide insights for designing learnersourcing activities leveraging AI support and optimizing students’ learning as they interact with LLMs.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {742–748},
numpages = {7},
keywords = {Data Visualization, Feedback Generation, GPT-4, Learnersourcing},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3636555.3636868,
author = {Jiang, Lan and Belitz, Clara and Bosch, Nigel},
title = {Synthetic Dataset Generation for Fairer Unfairness Research},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636868},
doi = {10.1145/3636555.3636868},
abstract = {Recent research has made strides toward fair machine learning. Relatively few datasets, however, are commonly examined to evaluate these fairness-aware algorithms, and even fewer in education domains, which can lead to a narrow focus on particular types of fairness issues. In this paper, we describe a novel dataset modification method that utilizes a genetic algorithm to induce many types of unfairness into datasets. Additionally, our method can generate an unfairness benchmark dataset from scratch (thus avoiding data collection in situations that might exploit marginalized populations), or modify an existing dataset used as a reference point. Our method can increase the unfairness by 156.3\% on average across datasets and unfairness definitions while preserving AUC scores for models trained on the original dataset (just 0.3\% change, on average). We investigate the generalization of our method across educational datasets with different characteristics and evaluate three common unfairness mitigation algorithms. The results show that our method can generate datasets with different types of unfairness, large and small datasets, different types of features, and which affect models trained with different classifiers. Datasets generated with this method can be used for benchmarking and testing for future research on the measurement and mitigation of algorithmic unfairness.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {200–209},
numpages = {10},
keywords = {data generation, datasets, fair machine learning, student data},
location = {Kyoto, Japan},
series = {LAK '24}
}

@article{10.1145/3637302,
author = {Elsden, Chris and Morgan, Evan and Tallyn, Ella and Black, Suzanne R. and Disley, Martin and Schafer, Burkhard and Murray-Rust, Dave and Speed, Chris},
title = {A Token Gesture: Non-Transferable NFTs, Digital Possessions and Ownership Design},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW1},
url = {https://doi.org/10.1145/3637302},
doi = {10.1145/3637302},
abstract = {This paper presents the design, deployment and qualitative study of a large-scale, public, generative art exhibition, through which passers-by could create artworks, and mint a non-fungible-token (NFT). Following the month-long exhibition, during which 229 anonymous participants produced artworks, 69 non-transferable NFTs were minted, we surveyed (33) and interviewed (14) expert and novice participants about their experiences. We explored contemporary challenges of owning digital things, and the extent to which NFTs, and 'Web3' technologies offer meaningful forms of ownership. Our findings describe how the inability to trade this NFT, and its unique circumstances of acquisition, made it meaningful in ways that extended beyond its immediate (limited) utility and offered participants something through which to construct identity. Reflecting on the aspirations, contradictions, and misconceptions of forms of ownership enabled by NFTs, we conclude with proposals for renewed attention in HCI to the nature of digital possessions, and the potential for 'ownership design'.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {25},
numpages = {29},
keywords = {blockchain, digital possessions, generative art, nfts, non-transferable, ownership, public experiences, web3}
}

@article{10.1145/3637305,
author = {Xiao, Yunpeng and Deng, Bufan and Chen, Siqi and Zhou, Kyrie Zhixuan and LC, Ray and Zhang, Luyao and Tong, Xin},
title = {"Centralized or Decentralized?": Concerns and Value Judgments of Stakeholders in the Non-Fungible Tokens (NFTs) Market},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW1},
url = {https://doi.org/10.1145/3637305},
doi = {10.1145/3637305},
abstract = {Non-fungible tokens (NFTs) are decentralized digital tokens to represent the unique ownership of items. Recently, NFTs have been gaining popularity and at the same time bringing up issues, such as scams, racism, and sexism. Decentralization, a key attribute of NFT, contributes to some of the issues that are easier to regulate under centralized schemes, which are intentionally left out of the NFT marketplace. In this work, we delved into this centralization-decentralization dilemma in the NFT space through mixed quantitative and qualitative methods. Centralization-decentralization dilemma is the dilemma caused by the conflict between the slogan of decentralization and the interests of stakeholders. We first analyzed over 30,000 NFT-related tweets to obtain a high-level understanding of stakeholders' concerns in the NFT space. We then interviewed 15 NFT stakeholders (both creators and collectors) to obtain their in-depth insights into these concerns and potential solutions. Our findings identify concerning issues among users: financial scams, counterfeit NFTs, hacking, and unethical NFTs. We further reflected on the centralization-decentralization dilemma drawing upon the perspectives of the stakeholders in the interviews. Finally, we gave some inferences to solve the centralization-decentralization dilemma in the NFT market and thought about the future of NFT and decentralization.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {28},
numpages = {34},
keywords = {ai ethics, blockchain, decentralization, interviews, nft, social computing}
}

@article{10.1145/3637336,
author = {Lu, Yuwen and Zhang, Chao and Yang, Yuewen and Yao, Yaxing and Li, Toby Jia-Jun},
title = {From Awareness to Action: Exploring End-User Empowerment Interventions for Dark Patterns in UX},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW1},
url = {https://doi.org/10.1145/3637336},
doi = {10.1145/3637336},
abstract = {The study of UX dark patterns, i.e., UI designs that seek to manipulate user behaviors, often for the benefit of online services, has drawn significant attention in the CHI and CSCW communities in recent years. To complement previous studies in addressing dark patterns from (1) the designer's perspective on education and advocacy for ethical designs; and (2) the policymaker's perspective on new regulations, we propose an end-user-empowerment intervention approach that helps users (1) raise the awareness of dark patterns and understand their underlying design intents; (2) take actions to counter the effects of dark patterns using a web augmentation approach. Through a two-phase co-design study, including 5 co-design workshops (N=12) and a 2-week technology probe study (N=15), we reported findings on the understanding of users' needs, preferences, and challenges in handling dark patterns and investigated the feedback and reactions to users' awareness of and action on dark patterns being empowered in a realistic in-situ setting.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {59},
numpages = {41},
keywords = {dark patterns, design ethics, end-user empowerment, user experience, web augmentation}
}

@article{10.1145/3637343,
author = {Pinter, Anthony T. and Brubaker, Jed R.},
title = {I'm Working on Erasing You, Just Don't Have the Proper Tools: Supporting Online Identity Management After the End of Romantic Relationships},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW1},
url = {https://doi.org/10.1145/3637343},
doi = {10.1145/3637343},
abstract = {After a break-up, people are left with data representative of their lost relationship - pictures, posts, and connections that exist because of that relationship. As part of breaking up and moving on, people often make decisions about managing that data. Prior work has identified two broad types of curatorial philosophies people adopt in data management: archivists and revisionists. However, what drives individuals to one approach remains unknown and is difficult to design sociotechnical systems for. Through focus group interviews with couples still together, we present a decision-making framework for data management. We outline factors that can influence individuals' decision to act as an archivist or revisionist in the wake of a break-up. From our data and framework, we identify six implications for design to improve user experiences in the wake of a break-up, and from those implications, offer concrete suggestions for design for social media platforms.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {66},
numpages = {32},
keywords = {digital identity, empirical work, life transitions, relationship dissolution, social media}
}

@article{10.1145/3637358,
author = {Tan, Mei and Lee, Hansol and Wang, Dakuo and Subramonyam, Hari},
title = {Is a Seat at the Table Enough? Engaging Teachers and Students in Dataset Specification for ML in Education},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW1},
url = {https://doi.org/10.1145/3637358},
doi = {10.1145/3637358},
abstract = {Despite the promises of ML in education, its adoption in the classroom has surfaced numerous issues regarding fairness, accountability, and transparency, as well as concerns about data privacy and student consent. A root cause of these issues is the lack of understanding of the complex dynamics of education, including teacher-student interactions, collaborative learning, and classroom environments. To overcome these challenges and fully utilize the potential of ML in education, software practitioners need to work closely with educators and students to fully understand the context of the data (the backbone of ML applications) and collaboratively define the ML data specifications. To gain a deeper understanding of such a collaborative process, we conduct ten co-design sessions with ML software practitioners, educators, and students. In the sessions, teachers and students work with ML engineers, UX designers, and legal practitioners to define dataset characteristics for a given ML application. We find that stakeholders contextualize data based on their domain and procedural knowledge, proactively design data requirements to mitigate downstream harms and data reliability concerns, and exhibit role-based collaborative strategies and contribution patterns. Further, we find that beyond a seat at the table, meaningful stakeholder participation in ML requires structured supports: defined processes for continuous iteration and co-evaluation, shared contextual data quality standards, and information scaffolds for both technical and non-technical stakeholders to traverse expertise boundaries.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {81},
numpages = {32},
keywords = {data-centric ai, participatory ai, teacher engagement}
}

@article{10.1145/3637384,
author = {Kotturi, Yasmine and Yu, Jenny and Khadpe, Pranav and Gatz, Erin and Zheng, Harvey and Fox, Sarah E. and Kulkarni, Chinmay},
title = {Peerdea: Co-Designing a Peer Support Platform with Creative Entrepreneurs},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW1},
url = {https://doi.org/10.1145/3637384},
doi = {10.1145/3637384},
abstract = {Creative entrepreneurs rely on online platforms to build community and overcome isolated work conditions. However, because of frequent attempts by larger brands to use their work without permission, creative entrepreneurs constrain their use of social platforms to safeguard their intellectual property. In this paper, we describe a multi-year partnership with a feminist makerspace to build a social platform, called Peerdea, that centered creative entrepreneurs' needs such that online feedback, information exchange, goal setting, and accountability were more readily available to them. Through an iterative, community-collaborative approach with 46 creative entrepreneurs, we report on the kinds of peer support entrepreneurs sought on Peerdea such as feedback on in-progress and unpolished work. We argue that by aligning Peerdea's design with the makerspace's community of practice, Peerdea leveraged the relationship and trust building that occurs more readily in person for entrepreneurs. In addition, we highlight the role of a community leader who actively managed the relationships between researchers and entrepreneurs, surfaced research failures and championed successes, and provided critical mediation for co-design when participants' livelihoods were implicated.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {107},
numpages = {24},
keywords = {community-based research, creative economy, entrepreneurship, future of work, makerspace, participatory design, peer support}
}

@article{10.1145/3637411,
author = {Razi, Afsaneh and Seberger, John S. and Alsoubai, Ashwaq and Naher, Nurun and De Choudhury, Munmun and Wisniewski, Pamela J.},
title = {Toward Trauma-Informed Research Practices with Youth in HCI: Caring for Participants and Research Assistants When Studying Sensitive Topics},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW1},
url = {https://doi.org/10.1145/3637411},
doi = {10.1145/3637411},
abstract = {Research involving sensitive data often leads to valuable human-centered insights. Yet, the effects of participating in and conducting research about sensitive data with youth are poorly understood. We conducted meta-level research to improve our understanding of these effects. We did the following: (i) asked youth (aged 13-21) to share their private Instagram Direct Messages (DMs) and flag their unsafe DMs; (ii) interviewed 30 participants about the experience of reflecting on this sensitive data; (iii) interviewed research assistants (RAs, n=12) about their experience analyzing youth's data. We found that reflecting about DMs brought discomfort for participants and RAs, although both benefited from increasing their awareness about online risks, their behavior, and privacy and social media practices. Participants had high expectations for safeguarding their private data while their concerns were mitigated by the potential to improve online safety. We provide implications for ethical research practices and the development of reflective practices among participants and RAs through applying trauma-informed principles to HCI research.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {134},
numpages = {31},
keywords = {Instagram, adolescents, data collection, datasets, online safety, research ethics, sensitive research, teens, trauma-informed research}
}

@article{10.1145/3637419,
author = {Nishal, Sachita and Sinchai, Jasmine and Diakopoulos, Nicholas},
title = {Understanding Practices around Computational News Discovery Tools in the Domain of Science Journalism},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW1},
url = {https://doi.org/10.1145/3637419},
doi = {10.1145/3637419},
abstract = {Science and technology journalists today face challenges in finding newsworthy leads due to increased workloads, reduced resources, and expanding scientific publishing ecosystems. Given this context, we explore computational methods to aid these journalists' news discovery in terms of their agency and time-efficiency. We prototyped three computational information subsidies into an interactive tool that we used as a probe to better understand how such a tool may offer utility or more broadly shape the practices of professional science journalists. Our findings highlight central considerations around science journalists' user agency, contexts of use, and professional responsibility that such tools can influence and could account for in design. Based on this, we suggest design opportunities for enhancing and extending user agency over the longer-term; incorporating contextual, personal and collaborative notions of newsworthiness; and leveraging flexible interfaces and generative models. Overall, our findings contribute a richer view of the sociotechnical system around computational news discovery tools, and suggest ways to improve such tools to better support the practices of science journalists.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {142},
numpages = {36},
keywords = {computational news discovery, human-ai interaction, large language models, newsworthiness, science communication}
}

@proceedings{10.1145/3637494,
title = {CECCT '23: Proceedings of the 2023 International Conference on Electronics, Computers and Communication Technology},
year = {2023},
isbn = {9798400716300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Guilin, China}
}

@proceedings{10.1145/3637684,
title = {DMIP '23: Proceedings of the 2023 6th International Conference on Digital Medicine and Image Processing},
year = {2023},
isbn = {9798400709425},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Kyoto, Japan}
}

@proceedings{10.1145/3637732,
title = {ICBBE '23: Proceedings of the 2023 10th International Conference on Biomedical and Bioinformatics Engineering},
year = {2023},
isbn = {9798400708343},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Kyoto, Japan}
}

@proceedings{10.1145/3637907,
title = {ICETM '23: Proceedings of the 2023 6th International Conference on Educational Technology Management},
year = {2023},
isbn = {9798400716676},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Guangzhou, China}
}

@proceedings{10.1145/3637989,
title = {ICEEL '23: Proceedings of the 2023 7th International Conference on Education and E-Learning},
year = {2023},
isbn = {9798400708732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tokyo, Japan}
}

@proceedings{10.1145/3638036,
title = {MHV '24: Proceedings of the 3rd Mile-High Video Conference},
year = {2024},
isbn = {9798400704932},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {For the third installment of ACM MHV, we received a total of 80 submissions which underwent careful scrutiny from an international program committee composed of experts from both industries and academia. To ensure quality, ACM MHV/2024 implemented a two-step submission system: the first step involved the submission of an extended abstract or short paper (maximum of one page or approximately 400 words), and the second step required accepted short papers to submit a full-length paper (up to six pages).},
location = {Denver, CO, USA}
}

@proceedings{10.1145/3638067,
title = {IHC '23: Proceedings of the XXII Brazilian Symposium on Human Factors in Computing Systems},
year = {2023},
isbn = {9798400717154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Macei\'{o}, Brazil}
}

@inproceedings{10.1145/3638067.3638100,
author = {Freire, Andr\'{e} Pimenta and Cardoso, Paula Christina Figueira and Salgado, Andr\'{e} de Lima},
title = {May We Consult ChatGPT in Our Human-Computer Interaction Written Exam? An Experience Report After a Professor Answered Yes},
year = {2024},
isbn = {9798400717154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638067.3638100},
doi = {10.1145/3638067.3638100},
abstract = {Using ChatGPT in education presents challenges for evaluating students. It requires distinguishing between original ideas and those generated by the model, assessing critical thinking skills, and gauging subject mastery accurately, which can impact fair assessment practices. The Human-Computer Interaction course described in this experience report has enabled consultation with textbooks, slides and other materials for over five years. This experience report describes reflections regarding using ChatGPT as a source of consultation in a written HCI exam in 2023. The paper describes experiences with analysis of the types of questions ChatGPT was able to solve immediately without mediation and the types of questions that could benefit from ChatGPT’s assistance without compromising the assessment of higher-level learning outcomes that professors want to analyse in teaching HCI. The paper uses Bloom’s taxonomy to analyse different questions and abilities to be evaluated and how they can be solved solely by using ChatGPT. The paper discusses questions that need mediation, previous lived experience in class and understanding of the knowledge acquired in class that cannot be answered directly by copying and pasting questions into ChatGPT. The discussions can raise reflections on the learning outcomes that can be assessed in HCI written exams and how professors should reflect upon their experiences and expectations for exams in the age of growing generative artificial intelligence resources.},
booktitle = {Proceedings of the XXII Brazilian Symposium on Human Factors in Computing Systems},
articleno = {6},
numpages = {11},
keywords = {ChatGPT, HCI education, evaluation, open-book exams},
location = {Macei\'{o}, Brazil},
series = {IHC '23}
}

@proceedings{10.1145/3638209,
title = {CIIS '23: Proceedings of the 2023 6th International Conference on Computational Intelligence and Intelligent Systems},
year = {2023},
isbn = {9798400709067},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tokyo, Japan}
}

@article{10.1145/3638243,
author = {Oakes, Bentley James and Famelis, Michalis and Sahraoui, Houari},
title = {Building Domain-Specific Machine Learning Workflows: A Conceptual Framework for the State of the Practice},
year = {2024},
issue_date = {May 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3638243},
doi = {10.1145/3638243},
abstract = {Domain experts are increasingly employing machine learning to solve their domain-specific problems. This article presents to software engineering researchers the six key challenges that a domain expert faces in addressing their problem with a computational workflow, and the underlying executable implementation. These challenges arise out of our conceptual framework which presents the “route” of transformations that a domain expert may choose to take while developing their solution.To ground our conceptual framework in the state of the practice, this article discusses a selection of available textual and graphical workflow systems and their support for the transformations described in our framework. Example studies from the literature in various domains are also examined to highlight the tools used by the domain experts as well as a classification of the domain specificity and machine learning usage of their problem, workflow, and implementation.The state of the practice informs our discussion of the six key challenges, where we identify which challenges and transformations are not sufficiently addressed by available tools. We also suggest possible research directions for software engineering researchers to increase the automation of these tools and disseminate best-practice techniques between software engineering and various scientific domains.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {91},
numpages = {50},
keywords = {Computational workflow, workflow composition, domain experts, machine learning, machine learning pipelines, software engineering framework}
}

@proceedings{10.1145/3638264,
title = {MICML '23: Proceedings of the 2023 International Conference on Mathematics, Intelligent Computing and Machine Learning},
year = {2023},
isbn = {9798400709258},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Chengdu, China}
}

@proceedings{10.1145/3638380,
title = {OzCHI '23: Proceedings of the 35th Australian Computer-Human Interaction Conference},
year = {2023},
isbn = {9798400717079},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Wellington, New Zealand}
}

@inproceedings{10.1145/3638380.3638395,
author = {Tricaud, Martin and Beaudouin-Lafon, Michel},
title = {Revisiting creative behaviour as an epistemic process: lessons from 12 computational artists and designers},
year = {2024},
isbn = {9798400717079},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638380.3638395},
doi = {10.1145/3638380.3638395},
abstract = {In this article, we investigate creative behavior among computational artists and designers, in order to improve our understanding of the interaction mechanisms that they rely on to identify and appropriate the mediating properties of code and computational representations. We conducted an observational study with 12 computational artists and designers working with visual media. The results lead us to analyze creative behavior as an epistemic process, whereby agents generate knowledge about their medium through epistemic actions, and produce their medium by externalizing this knowledge into epistemic artifacts. We discuss the implications of these findings for the design and evaluation of interactive systems for creativity.},
booktitle = {Proceedings of the 35th Australian Computer-Human Interaction Conference},
pages = {175–190},
numpages = {16},
keywords = {creative behaviour, creative coding, digital arts, epistemic action, epistemic artifact, generative design, instrumental interaction, procedural computer graphics},
location = {Wellington, New Zealand},
series = {OzCHI '23}
}

@proceedings{10.1145/3638550,
title = {HotMobile '24: Proceedings of the 25th International Workshop on Mobile Computing Systems and Applications},
year = {2024},
isbn = {9798400704970},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {San Diego, CA, USA}
}

@inproceedings{10.1145/3638550.3641130,
author = {Xu, Huatao and Han, Liying and Yang, Qirui and Li, Mo and Srivastava, Mani},
title = {Penetrative AI: Making LLMs Comprehend the Physical World},
year = {2024},
isbn = {9798400704970},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638550.3641130},
doi = {10.1145/3638550.3641130},
abstract = {Recent developments in Large Language Models (LLMs) have demonstrated their remarkable capabilities across a range of tasks. Questions, however, persist about the nature of LLMs and their potential to integrate common-sense human knowledge when performing tasks involving information about the real physical world. This paper delves into these questions by exploring how LLMs can be extended to interact with and reason about the physical world through IoT sensors and actuators, a concept that we term "Penetrative AI". The paper explores such an extension at two levels of LLMs' ability to penetrate into the physical world via the processing of sensory signals. Our preliminary findings indicate that LLMs, with ChatGPT being the representative example in our exploration, have considerable and unique proficiency in employing the embedded world knowledge for interpreting IoT sensor data and reasoning over them about tasks in the physical realm. Not only this opens up new applications for LLMs beyond traditional text-based tasks, but also enables new ways of incorporating human knowledge in cyber-physical systems.},
booktitle = {Proceedings of the 25th International Workshop on Mobile Computing Systems and Applications},
pages = {1–7},
numpages = {7},
keywords = {LLM, CPS, IoT, penetrative AI},
location = {San Diego, CA, USA},
series = {HotMobile '24}
}

@proceedings{10.1145/3638569,
title = {ICCBB '23: Proceedings of the 2023 7th International Conference on Computational Biology and Bioinformatics},
year = {2023},
isbn = {9798400716331},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Kuala Lumpur, Malaysia}
}

@proceedings{10.1145/3638584,
title = {CSAI '23: Proceedings of the 2023 7th International Conference on Computer Science and Artificial Intelligence},
year = {2023},
isbn = {9798400708688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Beijing, China}
}

@proceedings{10.1145/3638682,
title = {VSIP '23: Proceedings of the 2023 5th International Conference on Video, Signal and Image Processing},
year = {2023},
isbn = {9798400709272},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Harbin, China}
}

@proceedings{10.1145/3638837,
title = {ICNCC '23: Proceedings of the 2023 12th International Conference on Networks, Communication and Computing},
year = {2023},
isbn = {9798400709265},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Osaka, Japan}
}

@inproceedings{10.1145/3638837.3638880,
author = {Chen, Zhuohui and Lin, Zhicong and Lin, Chunlian and Wang, Mingchen and Chen, Ling},
title = {Offline Signature Verification Using a 2D Attention Encoder-Decoder Network},
year = {2024},
isbn = {9798400709265},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638837.3638880},
doi = {10.1145/3638837.3638880},
abstract = {Verifying an individual's Chinese handwritten signature is a vital biometric technology that is widely used in banking, finance, and legal business. Forged signatures for the purpose of deception endanger these industries’ interests. As a result, this paper proposes a network based on 2D Attention to verify the authenticity of the signature. In this paper, we have developed a Chinese handwritten signature dataset (CNSig) and proposed an offline signature verification network (att-OfSVNet) based on 2D Attention. The att-OfSVNet model includes two weight-sharing Encoders and Decoders. The two weight-sharing Encoders receive the inverted genuine and the inverted test signature image, and the Decoder reduces the dimension and concatenates the two extracted feature images. We use 2D Attention to fuse the features extracted by the Encoder and Decoder, which minimizes the information loss in the convolutional layers during the extraction process and enhances the effect of feature extraction by the Encoder. The experimental results show that our att-OfSVNet achieves satisfactory performance on other handwritten signature datasets in three different languages: CEDAR, BHSig-B, and BHSig-H, and it also demonstrates good generalization ability in cross-lingual tests.},
booktitle = {Proceedings of the 2023 12th International Conference on Networks, Communication and Computing},
pages = {274–287},
numpages = {14},
keywords = {2D Attention, Chinese handwritten signature dataset, Offline signature verification},
location = {Osaka, Japan},
series = {ICNCC '23}
}

@proceedings{10.1145/3638884,
title = {ICCIP '23: Proceedings of the 2023 9th International Conference on Communication and Information Processing},
year = {2023},
isbn = {9798400708909},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lingshui, China}
}

@proceedings{10.1145/3638985,
title = {ICIT '23: Proceedings of the 2023 11th International Conference on Information Technology: IoT and Smart City},
year = {2023},
isbn = {9798400709043},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Kyoto, Japan}
}

@proceedings{10.1145/3639233,
title = {NLPIR '23: Proceedings of the 2023 7th International Conference on Natural Language Processing and Information Retrieval},
year = {2023},
isbn = {9798400709227},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Seoul, Republic of Korea}
}

@article{10.1145/3639304,
author = {Kurmanji, Meghdad and Triantafillou, Eleni and Triantafillou, Peter},
title = {Machine Unlearning in Learned Databases: An Experimental Analysis},
year = {2024},
issue_date = {February 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {1},
url = {https://doi.org/10.1145/3639304},
doi = {10.1145/3639304},
abstract = {Machine learning models based on neural networks (NNs) are enjoying ever-increasing attention in the Database (DB) community, both in research and practice. However, an important issue has been largely overlooked, namely the challenge of dealing with the inherent, highly dynamic nature of DBs, where data updates are fundamental, highly-frequent operations (unlike, for instance, in ML classification tasks). Although some recent research has addressed the issues of maintaining updated NN models in the presence of new data insertions, the effects of data deletions (a.k.a., "machine unlearning") remain a blind spot. With this work, for the first time to our knowledge, we pose and answer the following key questions: What is the effect of unlearning algorithms on NN-based DB models? How do these effects translate to effects on key downstream DB tasks, such as cardinality/selectivity estimation (SE), approximate query processing (AQP), data generation (DG), and upstream tasks like data classification (DC)? What metrics should we use to assess the impact and efficacy of unlearning algorithms in learned DBs? Is the problem of (and solutions for) machine unlearning in DBs different from that of machine learning in DBs in the face of data insertions? Is the problem of (and solutions for) machine unlearning for DBs different from unlearning in the ML literature? what are the overhead and efficiency of unlearning algorithms (versus the naive solution of retraining from scratch)? What is the sensitivity of unlearning on batching delete operations (in order to reduce model updating overheads)? If we have a suitable unlearning algorithm (forgetting old knowledge), can we combine it with an algorithm handling data insertions (new knowledge) en route to solving the general adaptability/updatability requirement in learned DBs in the face of both data inserts and deletes? We answer these questions using a comprehensive set of experiments, various unlearning algorithms, a variety of downstream DB tasks (such as SE, AQP, and DG), and an upstream task (DC), each with different NNs, and using a variety of metrics (model-internal, and downstream-task specific) on a variety of real datasets, making this also a first key step towards a benchmark for learned DB unlearning.},
journal = {Proc. ACM Manag. Data},
month = mar,
articleno = {49},
numpages = {26},
keywords = {data deletions, learned database systems, machine unlearning}
}

@article{10.1145/3639326,
author = {Perini, Massimo and Nikolic, Milos},
title = {In-Database Data Imputation},
year = {2024},
issue_date = {February 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {1},
url = {https://doi.org/10.1145/3639326},
doi = {10.1145/3639326},
abstract = {Missing data is a widespread problem in many domains, creating challenges in data analysis and decision making. Traditional techniques for dealing with missing data, such as excluding incomplete records or imputing simple estimates (e.g., mean), are computationally efficient but may introduce bias and disrupt variable relationships, leading to inaccurate analyses. Model-based imputation techniques offer a more robust solution that preserves the variability and relationships in the data, but they demand significantly more computation time, limiting their applicability to small datasets.This work enables efficient, high-quality, and scalable data imputation within a database system using the widely used MICE method. We adapt this method to exploit computation sharing and a ring abstraction for faster model training. To impute both continuous and categorical values, we develop techniques for in-database learning of stochastic linear regression and Gaussian discriminant analysis models. Our MICE implementations in PostgreSQL and DuckDB outperform alternative MICE implementations and model-based imputation techniques by up to two orders of magnitude in terms of computation time, while maintaining high imputation quality.},
journal = {Proc. ACM Manag. Data},
month = mar,
articleno = {70},
numpages = {27},
keywords = {MICE, factorized computation, incomplete data, missing data, ring}
}

@proceedings{10.1145/3639390,
title = {ICVIP '23: Proceedings of the 2023 7th International Conference on Video and Image Processing},
year = {2023},
isbn = {9798400709388},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Kyoto, Japan}
}

@proceedings{10.1145/3639474,
title = {ICSE-SEET '24: Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3639474.3640058,
author = {Lehtinen, Teemu and Koutcheme, Charles and Hellas, Arto},
title = {Let's Ask AI About Their Programs: Exploring ChatGPT's Answers To Program Comprehension Questions},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640058},
doi = {10.1145/3639474.3640058},
abstract = {Recent research has explored the creation of questions from code submitted by students. These Questions about Learners' Code (QLCs) are created through program analysis, exploring execution paths, and then creating code comprehension questions from these paths and the broader code structure. Responding to the questions requires reading and tracing the code, which is known to support students' learning. At the same time, computing education researchers have witnessed the emergence of Large Language Models (LLMs) that have taken the community by storm. Researchers have demonstrated the applicability of these models especially in the introductory programming context, outlining their performance in solving introductory programming problems and their utility in creating new learning resources. In this work, we explore the capability of the state-of-the-art LLMs (GPT-3.5 and GPT-4) in answering QLCs that are generated from code that the LLMs have created. Our results show that although the state-of-the-art LLMs can create programs and trace program execution when prompted, they easily succumb to similar errors that have previously been recorded for novice programmers. These results demonstrate the fallibility of these models and perhaps dampen the expectations fueled by the recent LLM hype. At the same time, we also highlight future research possibilities such as using LLMs to mimic students as their behavior can indeed be similar for some specific tasks.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {221–232},
numpages = {12},
keywords = {QLCs, large language models, artificial intelligence, introductory programming, program comprehension},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3639474.3640059,
author = {Fwa, Hua Leong},
title = {Experience Report: Identifying common misconceptions and errors of novice programmers with ChatGPT},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640059},
doi = {10.1145/3639474.3640059},
abstract = {Identifying the misconceptions of novice programmers is pertinent for informing instructors of the challenges faced by their students in learning computer programming. In the current literature, custom tools, test scripts were developed and, in most cases, manual effort to go through the individual codes were required to identify and categorize the errors latent within the students' code submissions. This entails investment of substantial effort and time from the instructors. In this study, we thus propose the use of ChatGPT in identifying and categorizing the errors. Using prompts that were seeded only with the student's code and the model code solution for questions from two lab tests, we were able to leverage on ChatGPT's natural language processing and knowledge representation capabilities to automatically collate frequencies of occurrence of the errors by error types. We then clustered the generated error descriptions for further insights into the misconceptions of the students. The results showed that although ChatGPT was not able to identify the errors perfectly, the achieved accuracy of 93.3\% is sufficiently high for instructors to have an aggregated picture of the common errors of their students. To conclude, we have proposed a method for instructors to automatically collate the errors latent within the students' code submissions using ChatGPT. Notably, with the novel use of generated error descriptions, the instructors were able to have a more granular view of the misconceptions of their students, without the onerous effort of manually going through the students' codes.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {233–241},
numpages = {9},
keywords = {LLM, ChatGPT, misconception, programming, errors, cluster, prompts},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3639474.3640062,
author = {Ouhbi, Sofia},
title = {Bridging the Theory-Practice Gap in a Maintenance Programming Course: An Experience Report},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640062},
doi = {10.1145/3639474.3640062},
abstract = {This paper presents our experience in teaching a maintenance programming course with the aim of bridging the gap between theory and practice, a recurring issue in previous course offerings. To achieve this goal, we implemented active learning strategies within an active learning classroom setting and redesigned the project work. Our approach involves peer learning and teamwork activities to cover various aspects of legacy code maintenance. For the project work, we adopted an open-ended approach that allowed students to choose their legacy code projects, which could be open-source software or a previous software project they had worked on. Analysis of students' feedback and project reports highlighted the effectiveness of our approach in bridging the gap between theory and practice. We believe that our approach had the potential to enhance students' engagement and critical thinking abilities, as well as improve practical maintenance skills relevant to their future careers.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {359–367},
numpages = {9},
keywords = {software maintenance, software engineering education, open-ended project, group work, active learning, students engagement, generative AI},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@proceedings{10.1145/3639475,
title = {ICSE-SEIS'24: Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Society},
year = {2024},
isbn = {9798400704994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3639476,
title = {ICSE-NIER'24: Proceedings of the 2024 ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results},
year = {2024},
isbn = {9798400705007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3639477,
title = {ICSE-SEIP '24: Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Practice},
year = {2024},
isbn = {9798400705014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3639477.3639721,
author = {Brandt, Carolin and Castelluccio, Marco and Holler, Christian and Kratzer, Jason and Zaidman, Andy and Bacchelli, Alberto},
title = {Mind the Gap: What Working With Developers on Fuzz Tests Taught Us About Coverage Gaps},
year = {2024},
isbn = {9798400705014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639477.3639721},
doi = {10.1145/3639477.3639721},
abstract = {Can fuzzers generate partial tests that developers find useful enough to complete into functional tests (e.g., by adding assertions)? To address this question, we develop a prototype within the Mozilla ecosystem and open 13 bug reports proposing partial generated tests for currently uncovered code. We found that the majority of the reactions focus on whether the targeted coverage gap is actually worth testing. To investigate further which coverage gaps developers find relevant to close, we design an automated filter to exclude irrelevant coverage gaps before generating tests. From conversations with 13 developers about whether the remaining coverage gaps are worth closing when a partially generated test is available, we learn that the filtering indeed removes clearly non-test-worthy gaps. The developers propose a variety of additional strategies to address the coverage gaps and how to make fuzz tests and reports more useful for developers.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Practice},
pages = {157–167},
numpages = {11},
location = {Lisbon, Portugal},
series = {ICSE-SEIP '24}
}

@inproceedings{10.1145/3639477.3639729,
author = {Alshahwan, Nadia and Blasi, Arianna and Bojarczuk, Kinga and Ciancone, Andrea and Gucevska, Natalija and Harman, Mark and Krolikowski, Michal and Rojas, Rubmary and Martac, Dragos and Schellaert, Simon and Ustiuzhanina, Kate and Harper, Inna and Jia, Yue and Lewis, Will},
title = {Enhancing Testing at Meta with Rich-State Simulated Populations},
year = {2024},
isbn = {9798400705014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639477.3639729},
doi = {10.1145/3639477.3639729},
abstract = {This paper reports the results of the deployment of Rich-State Simulated Populations at Meta for both automated and manual testing. We use simulated users (aka test users) to mimic user interactions and acquire state in much the same way that real user accounts acquire state. For automated testing, we present empirical results from deployment on the Facebook, Messenger, and Instagram apps for iOS and Android Platforms. These apps consist of tens of millions of lines of code, communicating with hundreds of millions of lines of backend code, and are used by over 2 billion people every day. Our results reveal that rich state increases average code coverage by 38\%, and endpoint coverage by 61\%. More importantly, it also yields an average increase of 115\% in the faults found by automated testing. The rich-state test user populations are also deployed in a (continually evolving) Test Universe; a web-enabled simulation platform for privacy-safe manual testing, which has been used by over 21,000 Meta engineers since its deployment in November 2022.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Practice},
pages = {1–12},
numpages = {12},
keywords = {software testing, cyber cyber digital twins, simulation-based testing, machine learning},
location = {Lisbon, Portugal},
series = {ICSE-SEIP '24}
}

@inproceedings{10.1145/3639477.3639745,
author = {Kuang, Jinxi and Liu, Jinyang and Huang, Junjie and Zhong, Renyi and Gu, Jiazhen and Yu, Lan and Tan, Rui and Yang, Zengyin and Lyu, Michael R.},
title = {Knowledge-aware Alert Aggregation in Large-scale Cloud Systems: a Hybrid Approach},
year = {2024},
isbn = {9798400705014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639477.3639745},
doi = {10.1145/3639477.3639745},
abstract = {Due to the scale and complexity of cloud systems, a system failure would trigger an "alert storm", i.e., massive correlated alerts. Although these alerts can be traced back to a few root causes, the overwhelming number makes it infeasible for manual handling. Alert aggregation is thus critical to help engineers concentrate on the root cause and facilitate failure resolution. Existing methods typically utilize semantic similarity-based methods or statistical methods to aggregate alerts. However, semantic similarity-based methods overlook the causal rationale of alerts, while statistical methods can hardly handle infrequent alerts.To tackle these limitations, we introduce leveraging external knowledge, i.e., Standard Operation Procedure (SOP) of alerts as a supplement. We propose COLA, a novel hybrid approach based on correlation mining and LLM (Large Language Model) reasoning for online alert aggregation. The correlation mining module effectively captures the temporal and spatial relations between alerts, measuring their correlations in an efficient manner. Subsequently, only uncertain pairs with low confidence are forwarded to the LLM reasoning module for detailed analysis. This hybrid design harnesses both statistical evidence for frequent alerts and the reasoning capabilities of computationally intensive LLMs, ensuring the overall efficiency of COLA in handling large volumes of alerts in practical scenarios. We evaluate COLA on three datasets collected from the production environment of a large-scale cloud platform. The experimental results show COLA achieves F1-scores from 0.901 to 0.930, outperforming state-of-the-art methods and achieving comparable efficiency. We also share our experience in deploying COLA in our real-world cloud system, Cloud X1.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Practice},
pages = {369–380},
numpages = {12},
keywords = {alert aggregation, cloud systems, software reliability},
location = {Lisbon, Portugal},
series = {ICSE-SEIP '24}
}

@inproceedings{10.1145/3639477.3639751,
author = {Pinto, Gustavo and De Souza, Cleidson and Neto, Joao Batista and Souza, Alberto and Gotto, Tarci­sio and Monteiro, Edward},
title = {Lessons from Building StackSpot AI: A Contextualized AI Coding Assistant},
year = {2024},
isbn = {9798400705014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639477.3639751},
doi = {10.1145/3639477.3639751},
abstract = {With their exceptional natural language processing capabilities, tools based on Large Language Models (LLMs) like ChatGPT and CoPilot have swiftly become indispensable resources in the software developer's toolkit. While recent studies suggest the potential productivity gains these tools can unlock, users still encounter drawbacks, such as generic or incorrect answers. Additionally, the pursuit of improved responses often leads to extensive prompt engineering efforts, diverting valuable time from writing code that delivers actual value. To address these challenges, a new breed of tools, built atop LLMs, is emerging. These tools aim to mitigate drawbacks by employing techniques like fine-tuning or enriching user prompts with contextualized information.In this paper, we delve into the lessons learned by a software development team venturing into the creation of such a contextualized LLM-based application, using retrieval-based techniques, called StackSpot AI. Over a four-month period, the team, despite lacking prior professional experience in LLM-based applications, built the product from scratch. Following the initial product release, we engaged with the development team responsible for the code generative components. Through interviews and analysis of the application's issue tracker, we uncover various intriguing challenges that teams working on LLM-based applications might encounter. For instance, we found three main group of lessons: LLM-based lessons, User-based lessons, and Technical lessons. By understanding these lessons, software development teams could become better prepared to build LLM-based applications.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Practice},
pages = {408–417},
numpages = {10},
keywords = {LLM, LLM-based applications, LLM for code, LLM4code, code LLMs, challenges},
location = {Lisbon, Portugal},
series = {ICSE-SEIP '24}
}

@proceedings{10.1145/3639478,
title = {ICSE-Companion '24: Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {ICSE is the leading and, by far, the largest conference in Software Engineering, attracting researchers, practitioners, and students worldwide. ICSE2024 is co-located with 11 conferences and symposia this year, many long-established and prestigious venues in their own right.},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3639478.3647634,
author = {Wang, Xinchen and Hu, Ruida and Gao, Cuiyun and Wen, Xin-Cheng and Chen, Yujia and Liao, Qing},
title = {ReposVul: A Repository-Level High-Quality Vulnerability Dataset},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639478.3647634},
doi = {10.1145/3639478.3647634},
abstract = {Open-Source Software (OSS) vulnerabilities bring great challenges to the software security and pose potential risks to our society. Enormous efforts have been devoted into automated vulnerability detection, among which deep learning (DL)-based approaches have proven to be the most effective. However, the performance of the DL-based approaches generally relies on the quantity and quality of labeled data, and the current labeled data present the following limitations: (1) Tangled Patches: Developers may submit code changes unrelated to vulnerability fixes within patches, leading to tangled patches. (2) Lacking Inter-procedural Vulnerabilities: The existing vulnerability datasets typically contain function-level and file-level vulnerabilities, ignoring the relations between functions, thus rendering the approaches unable to detect the inter-procedural vulnerabilities. (3) Outdated Patches: The existing datasets usually contain outdated patches, which may bias the model during training.To address the above limitations, in this paper, we propose an automated data collection framework and construct the first repository-level high-quality vulnerability dataset named ReposVul. The proposed framework mainly contains three modules: (1) A vulnerability untangling module, aiming at distinguishing vulnerability-fixing related code changes from tangled patches, in which the Large Language Models (LLMs) and static analysis tools are jointly employed. (2) A multi-granularity dependency extraction module, aiming at capturing the inter-procedural call relationships of vulnerabilities, in which we construct multiple-granularity information for each vulnerability patch, including repository-level, file-level, function-level, and line-level. (3) A trace-based filtering module, aiming at filtering the outdated patches, which leverages the file path trace-based filter and commit time trace-based filter to construct an up-to-date dataset.The constructed repository-level ReposVul encompasses 6,134 CVE entries representing 236 CWE types across 1,491 projects and four programming languages. Thorough data analysis and manual checking demonstrate that ReposVul is high in quality and alleviates the problems of tangled and outdated patches in previous vulnerability datasets.},
booktitle = {Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
pages = {472–483},
numpages = {12},
keywords = {open-source software, software vulnerability datasets, data quality},
location = {Lisbon, Portugal},
series = {ICSE-Companion '24}
}

@proceedings{10.1145/3639479,
title = {MLNLP '23: Proceedings of the 2023 6th International Conference on Machine Learning and Natural Language Processing},
year = {2023},
isbn = {9798400709241},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Sanya, China}
}

@proceedings{10.1145/3639592,
title = {AICCC '23: Proceedings of the 2023 6th Artificial Intelligence and Cloud Computing Conference},
year = {2023},
isbn = {9798400716225},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Kyoto, Japan}
}

@proceedings{10.1145/3639631,
title = {ACAI '23: Proceedings of the 2023 6th International Conference on Algorithms, Computing and Artificial Intelligence},
year = {2023},
isbn = {9798400709203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Sanya, China}
}

@proceedings{10.1145/3639701,
title = {IMX '24: Proceedings of the 2024 ACM International Conference on Interactive Media Experiences},
year = {2024},
isbn = {9798400705038},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Stockholm, Sweden}
}

@proceedings{10.1145/3639856,
title = {AIMLSystems '23: Proceedings of the Third International Conference on AI-ML Systems},
year = {2023},
isbn = {9798400716492},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bangalore, India}
}

@proceedings{10.1145/3640115,
title = {ICITEE '23: Proceedings of the 6th International Conference on Information Technologies and Electrical Engineering},
year = {2023},
isbn = {9798400708299},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Changde, Hunan, China}
}

@book{10.1145/3640479,
author = {Baecker, Ronald M. and Grudin, Jonathan},
title = {Digital Dreams Have Become Nightmares: What We Must Do},
year = {2024},
isbn = {9798400717703},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {2},
volume = {56},
abstract = {This book offers a compelling discussion of the digital dreams that have come true, their often unintended side effects (nightmares), and what must be done to counteract the nightmares. It is intended as an impetus to further conversation not only in homes and workplaces, but in academic courses and even legislative debates. Equally importantly, the book is a presentation of what digital technology professionals need to know about these topics and the actions they should undertake individually and in support of other citizens, societal initiatives, and government. The author begins by introducing the amazing progress made in digital technologies over the past 80 years. Pioneering engineers dreamed of potential uses of technology through their writing and technical achievements, further inspiring thousands of researchers to bring the dreams to life, and to dream new dreams as well. The second part of the book describes the myriad adverse side effects and unanticipated challenges that arose as those dreams were pursued and achieved. Examples include rampant misinformation on social media, ransomware, autonomous weapons, and the premature use of AI before it is reliable and safe.The book closes with a positive call to action, outlining ways to address the challenges through ethical career choices, careful analysis, thoughtful design, research, citizen engagement, legislation/regulation, and careful consideration of how bad actors may use technology. Readers of Digital Dreams Have Become Nightmares should become more knowledgeable, wiser, and also cautiously optimistic, determined to affect positive changes through their design, creation, and use of technology.“Are you feeling happy about the role of information technology in the world today? You should read this book for a dose of reality. Are you in despair about it? This book is the prescription for that condition, too! Nobody else could cover the landscape as Ron Baecker does.” - Clayton Lewis, Emeritus Professor, University of Colorado Boulder“This book is a captivating review of important computing developments. Many things talked about as new today have been around for a long time. Much can be learned from the past. The book also teaches a careful and consistent method that enables the reader to do this kind of work as the need arises. The book suggests the need will arise.” - John Leslie King, Emeritus Professor, University of Michigan}
}

@inbook{10.1145/3640479.3640486,
title = {Disinformation and Hate Speech},
year = {2024},
isbn = {9798400717703},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640479.3640486},
abstract = {This book offers a compelling discussion of the digital dreams that have come true, their often unintended side effects (nightmares), and what must be done to counteract the nightmares. It is intended as an impetus to further conversation not only in homes and workplaces, but in academic courses and even legislative debates. Equally importantly, the book is a presentation of what digital technology professionals need to know about these topics and the actions they should undertake individually and in support of other citizens, societal initiatives, and government. The author begins by introducing the amazing progress made in digital technologies over the past 80 years. Pioneering engineers dreamed of potential uses of technology through their writing and technical achievements, further inspiring thousands of researchers to bring the dreams to life, and to dream new dreams as well. The second part of the book describes the myriad adverse side effects and unanticipated challenges that arose as those dreams were pursued and achieved. Examples include rampant misinformation on social media, ransomware, autonomous weapons, and the premature use of AI before it is reliable and safe.The book closes with a positive call to action, outlining ways to address the challenges through ethical career choices, careful analysis, thoughtful design, research, citizen engagement, legislation/regulation, and careful consideration of how bad actors may use technology. Readers of Digital Dreams Have Become Nightmares should become more knowledgeable, wiser, and also cautiously optimistic, determined to affect positive changes through their design, creation, and use of technology.“Are you feeling happy about the role of information technology in the world today? You should read this book for a dose of reality. Are you in despair about it? This book is the prescription for that condition, too! Nobody else could cover the landscape as Ron Baecker does.” - Clayton Lewis, Emeritus Professor, University of Colorado Boulder“This book is a captivating review of important computing developments. Many things talked about as new today have been around for a long time. Much can be learned from the past. The book also teaches a careful and consistent method that enables the reader to do this kind of work as the need arises. The book suggests the need will arise.” - John Leslie King, Emeritus Professor, University of Michigan},
booktitle = {Digital Dreams Have Become Nightmares: What We Must Do}
}

@inbook{10.1145/3640479.3640487,
title = {Work, Automation, and Job Loss},
year = {2024},
isbn = {9798400717703},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640479.3640487},
abstract = {This book offers a compelling discussion of the digital dreams that have come true, their often unintended side effects (nightmares), and what must be done to counteract the nightmares. It is intended as an impetus to further conversation not only in homes and workplaces, but in academic courses and even legislative debates. Equally importantly, the book is a presentation of what digital technology professionals need to know about these topics and the actions they should undertake individually and in support of other citizens, societal initiatives, and government. The author begins by introducing the amazing progress made in digital technologies over the past 80 years. Pioneering engineers dreamed of potential uses of technology through their writing and technical achievements, further inspiring thousands of researchers to bring the dreams to life, and to dream new dreams as well. The second part of the book describes the myriad adverse side effects and unanticipated challenges that arose as those dreams were pursued and achieved. Examples include rampant misinformation on social media, ransomware, autonomous weapons, and the premature use of AI before it is reliable and safe.The book closes with a positive call to action, outlining ways to address the challenges through ethical career choices, careful analysis, thoughtful design, research, citizen engagement, legislation/regulation, and careful consideration of how bad actors may use technology. Readers of Digital Dreams Have Become Nightmares should become more knowledgeable, wiser, and also cautiously optimistic, determined to affect positive changes through their design, creation, and use of technology.“Are you feeling happy about the role of information technology in the world today? You should read this book for a dose of reality. Are you in despair about it? This book is the prescription for that condition, too! Nobody else could cover the landscape as Ron Baecker does.” - Clayton Lewis, Emeritus Professor, University of Colorado Boulder“This book is a captivating review of important computing developments. Many things talked about as new today have been around for a long time. Much can be learned from the past. The book also teaches a careful and consistent method that enables the reader to do this kind of work as the need arises. The book suggests the need will arise.” - John Leslie King, Emeritus Professor, University of Michigan},
booktitle = {Digital Dreams Have Become Nightmares: What We Must Do}
}

@proceedings{10.1145/3640543,
title = {IUI '24: Proceedings of the 29th International Conference on Intelligent User Interfaces},
year = {2024},
isbn = {9798400705083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Greenville, SC, USA}
}

@inproceedings{10.1145/3640543.3645142,
author = {Coscia, Adam and Holmes, Langdon and Morris, Wesley and Choi, Joon Suh and Crossley, Scott and Endert, Alex},
title = {iScore: Visual Analytics for Interpreting How Language Models Automatically Score Summaries},
year = {2024},
isbn = {9798400705083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640543.3645142},
doi = {10.1145/3640543.3645142},
abstract = {The recent explosion in popularity of large language models (LLMs) has inspired learning engineers to incorporate them into adaptive educational tools that automatically score summary writing. Understanding and evaluating LLMs is vital before deploying them in critical learning environments, yet their unprecedented size and expanding number of parameters inhibits transparency and impedes trust when they underperform. Through a collaborative user-centered design process with several learning engineers building and deploying summary scoring LLMs, we characterized fundamental design challenges and goals around interpreting their models, including aggregating large text inputs, tracking score provenance, and scaling LLM interpretability methods. To address their concerns, we developed iScore, an interactive visual analytics tool for learning engineers to upload, score, and compare multiple summaries simultaneously. Tightly integrated views allow users to iteratively revise the language in summaries, track changes in the resulting LLM scores, and visualize model weights at multiple levels of abstraction. To validate our approach, we deployed iScore with three learning engineers over the course of a month. We present a case study where interacting with iScore led a learning engineer to improve their LLM’s score accuracy by three percentage points. Finally, we conducted qualitative interviews with the learning engineers that revealed how iScore enabled them to understand, evaluate, and build trust in their LLMs during deployment.},
booktitle = {Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {787–802},
numpages = {16},
keywords = {Data visualization, educational technology, explainable AI, large language models, visual analytics},
location = {Greenville, SC, USA},
series = {IUI '24}
}

@inproceedings{10.1145/3640543.3645143,
author = {Wang, Bryan and Li, Yuliang and Lv, Zhaoyang and Xia, Haijun and Xu, Yan and Sodhi, Raj},
title = {LAVE: LLM-Powered Agent Assistance and Language Augmentation for Video Editing},
year = {2024},
isbn = {9798400705083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640543.3645143},
doi = {10.1145/3640543.3645143},
abstract = {Video creation has become increasingly popular, yet the expertise and effort required for editing often pose barriers to beginners. In this paper, we explore the integration of large language models (LLMs) into the video editing workflow to reduce these barriers. Our design vision is embodied in LAVE, a novel system that provides LLM-powered agent assistance and language-augmented editing features. LAVE automatically generates language descriptions for the user’s footage, serving as the foundation for enabling the LLM to process videos and assist in editing tasks. When the user provides editing objectives, the agent plans and executes relevant actions to fulfill them. Moreover, LAVE allows users to edit videos through either the agent or direct UI manipulation, providing flexibility and enabling manual refinement of agent actions. Our user study, which included eight participants ranging from novices to proficient editors, demonstrated LAVE’s effectiveness. The results also shed light on user perceptions of the proposed LLM-assisted editing paradigm and its impact on users’ creativity and sense of co-creation. Based on these findings, we propose design implications to inform the future development of agent-assisted content editing.},
booktitle = {Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {699–714},
numpages = {16},
keywords = {Agents, Human-AI Co-Creation, LLMs, Video Editing},
location = {Greenville, SC, USA},
series = {IUI '24}
}

@inproceedings{10.1145/3640543.3645144,
author = {Petridis, Savvas and Wedin, Benjamin D and Wexler, James and Pushkarna, Mahima and Donsbach, Aaron and Goyal, Nitesh and Cai, Carrie J and Terry, Michael},
title = {ConstitutionMaker: Interactively Critiquing Large Language Models by Converting Feedback into Principles},
year = {2024},
isbn = {9798400705083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640543.3645144},
doi = {10.1145/3640543.3645144},
abstract = {Large language model (LLM) prompting is a promising new approach for users to create and customize their own chatbots. However, current methods for steering a chatbot’s outputs, such as prompt engineering and fine-tuning, do not support users in converting their natural feedback on the model’s outputs to changes in the prompt or model. In this work, we explore how to enable users to interactively refine model outputs through their feedback, by helping them convert their feedback into a set of principles (i.e. a constitution) that dictate the model’s behavior. From a formative study, we (1) found that users needed support converting their feedback into principles for the chatbot and (2) classified the different principle types desired by users. Inspired by these findings, we developed ConstitutionMaker, an interactive tool for converting user feedback into principles, to steer LLM-based chatbots. With ConstitutionMaker, users can provide either positive or negative feedback in natural language, select auto-generated feedback, or rewrite the chatbot’s response; each mode of feedback automatically generates a principle that is inserted into the chatbot’s prompt. In a user study with 14 participants, we compare ConstitutionMaker to an ablated version, where users write their own principles. With ConstitutionMaker, participants felt that their principles could better guide the chatbot, that they could more easily convert their feedback into principles, and that they could write principles more efficiently, with less mental demand. ConstitutionMaker helped users identify ways to improve the chatbot, formulate their intuitive responses to the model into feedback, and convert this feedback into specific and clear principles. Together, these findings inform future tools that support the interactive critiquing of LLM outputs.},
booktitle = {Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {853–868},
numpages = {16},
keywords = {Conversational AI, Feedback, Generative AI, Interactive Critique, Large Language Models},
location = {Greenville, SC, USA},
series = {IUI '24}
}

@inproceedings{10.1145/3640543.3645173,
author = {Evirgen, Noyan and Wang, Ruolin and Chen, Xiang 'Anthony},
title = {From Text to Pixels: Enhancing User Understanding through Text-to-Image Model Explanations},
year = {2024},
isbn = {9798400705083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640543.3645173},
doi = {10.1145/3640543.3645173},
abstract = {Recent progress in Text-to-Image (T2I) models promises transformative applications in art, design, education, medicine, and entertainment. These models, exemplified by Dall-e, Imagen, and Stable Diffusion, have the potential to revolutionize various industries. However, a primary concern is their operation as a ‘black-box’ for many users. Without understanding the underlying mechanics, users are unable to harness the full potential of these models. This study focuses on bridging this gap by developing and evaluating explanation techniques for T2I models, targeting inexperienced end users. While prior works have delved into Explainable AI (XAI) methods for classification or regression tasks, T2I generation poses distinct challenges. Through formative studies with experts, we identified unique explanation goals and subsequently designed tailored explanation strategies. We then empirically evaluated these methods with a cohort of 473 participants from Amazon Mechanical Turk (AMT) across three tasks. Our results highlight users’ ability to learn new keywords through explanations, a preference for example-based explanations, and challenges in comprehending explanations that significantly shift the image’s theme. Moreover, findings suggest users benefit from a limited set of concurrent explanations. Our main contributions include a curated dataset for evaluating T2I explainability techniques, insights from a comprehensive AMT user study, and observations critical for future T2I model explainability research.},
booktitle = {Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {74–87},
numpages = {14},
keywords = {Explainability Methods, Text-to-Image, User-Study, XAI},
location = {Greenville, SC, USA},
series = {IUI '24}
}

@proceedings{10.1145/3640544,
title = {IUI '24 Companion: Companion Proceedings of the 29th International Conference on Intelligent User Interfaces},
year = {2024},
isbn = {9798400705090},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Greenville, SC, USA}
}

@proceedings{10.1145/3640771,
title = {ISCAI '23: Proceedings of the 2023 2nd International Symposium on Computing and Artificial Intelligence},
year = {2023},
isbn = {9798400708954},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Shanghai, China}
}

@proceedings{10.1145/3640824,
title = {CCEAI '24: Proceedings of the 2024 8th International Conference on Control Engineering and Artificial Intelligence},
year = {2024},
isbn = {9798400707971},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Shanghai, China}
}

@proceedings{10.1145/3640872,
title = {BDE '23: Proceedings of the 2023 5th International Conference on Big Data Engineering},
year = {2023},
isbn = {9798400708695},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Zhuhai, China}
}

@proceedings{10.1145/3640900,
title = {ICBBB '24: Proceedings of the 2024 14th International Conference on Bioscience, Biochemistry and Bioinformatics},
year = {2024},
isbn = {9798400716768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Kyoto, Japan}
}

@proceedings{10.1145/3640912,
title = {CNML '23: Proceedings of the 2023 International Conference on Communication Network and Machine Learning},
year = {2023},
isbn = {9798400716683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Zhengzhou, China}
}

@article{10.1145/3641002,
author = {Jia, Chenyan and Lam, Michelle S. and Mai, Minh Chau and Hancock, Jeffrey T. and Bernstein, Michael S.},
title = {Embedding Democratic Values into Social Media AIs via Societal Objective Functions},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW1},
url = {https://doi.org/10.1145/3641002},
doi = {10.1145/3641002},
abstract = {Mounting evidence indicates that the artificial intelligence (AI) systems that rank our social media feeds bear nontrivial responsibility for amplifying partisan animosity: negative thoughts, feelings, and behaviors toward political out-groups. Can we design these AIs to consider democratic values such as mitigating partisan animosity as part of their objective functions? We introduce a method for translating established, vetted social scientific constructs into AI objective functions, which we term societal objective functions, and demonstrate the method with application to the political science construct of anti-democratic attitudes. Traditionally, we have lacked observable outcomes to use to train such models-however, the social sciences have developed survey instruments and qualitative codebooks for these constructs, and their precision facilitates translation into detailed prompts for large language models. We apply this method to create a democratic attitude model that estimates the extent to which a social media post promotes anti-democratic attitudes, and test this democratic attitude model across three studies. In Study 1, we first test the attitudinal and behavioral effectiveness of the intervention among US partisans (N=1,380) by manually annotating (alpha=.895) social media posts with anti-democratic attitude scores and testing several feed ranking conditions based on these scores. Removal (d=.20) and downranking feeds (d=.25) reduced participants' partisan animosity without compromising their experience and engagement. In Study 2, we scale up the manual labels by creating the democratic attitude model, finding strong agreement with manual labels (rho=.75). Finally, in Study 3, we replicate Study 1 using the democratic attitude model instead of manual labels to test its attitudinal and behavioral impact (N=558), and again find that the feed downranking using the societal objective function reduced partisan animosity (d=.25). This method presents a novel strategy to draw on social science theory and methods to mitigate societal harms in social media AIs.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {163},
numpages = {36},
keywords = {affective polarization, algorithms, partisan animosity, social media ais, social media users}
}

@article{10.1145/3641017,
author = {Kotturi, Yasmine and Hui, Julie and Johnson, TJ and Sanifu, Lutalo and Dillahunt, Tawanna R.},
title = {Sustaining Community-Based Research in Computing: Lessons from Two Tech Capacity Building Initiatives for Local Businesses},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW1},
url = {https://doi.org/10.1145/3641017},
doi = {10.1145/3641017},
abstract = {The field of human-computer interaction (HCI) has traditionally focused on the design of novel technology artifacts. However, ensuring considerations for artifact maintenance and repair is crucial to sustainably supporting the populations they aim to serve over the long term. Drawing on two multi-year programs for tech capacity building in post-industrial U.S. cities, this article presents a comparative analysis to investigate the challenges and strategies for sustained community-based research in computing. In particular, our work detailed three considerations for academic-community partnerships. First, long-term partnerships prioritized transferring trust across academic and community personnel and continually set expectations that responded to evolving community initiatives (i.e., relational sustainability). Second, partnerships used academic support as a way to kickstart community initiatives, and flexibly reframed interventions to stay aligned with evolving community goals (i.e., economic sustainability). Third, partnerships trained personnel to provide technical support alongside interventions and prioritized advice that resisted short-term trends (i.e., technical sustainability). We provide concrete examples of how our two academic-community partnerships carried out such suggestions-such details go unreported in scholarly articles yet are essential for sustainability considerations. We discuss ongoing challenges, such as rethinking when longevity should and should not be the end goal.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {178},
numpages = {31},
keywords = {business, community-based research, entrepreneurship, sustainability, technical capacity building, technology}
}

@article{10.1145/3641019,
author = {Ye, Yilin and Zhu, Qian and Xiao, Shishi and Zhang, Kang and Zeng, Wei},
title = {The Contemporary Art of Image Search: Iterative User Intent Expansion via Vision-Language Model},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW1},
url = {https://doi.org/10.1145/3641019},
doi = {10.1145/3641019},
abstract = {Image search is an essential and user-friendly method to explore vast galleries of digital images. However, existing image search methods heavily rely on proximity measurements like tag matching or image similarity, requiring precise user inputs for satisfactory results. To meet the growing demand for a contemporary image search engine that enables accurate comprehension of users' search intentions, we introduce an innovative user intent expansion framework. Our framework leverages visual-language models to parse and compose multi-modal user inputs to provide more accurate and satisfying results. It comprises two-stage processes: 1) a parsing stage that incorporates a language parsing module with large language models to enhance the comprehension of textual inputs, along with a visual parsing module that integrates an interactive segmentation module to swiftly identify detailed visual elements within images; and 2) a logic composition stage that combines multiple user search intents into a unified logic expression for more sophisticated operations in complex searching scenarios. Moreover, the intent expansion framework enables users to perform flexible contextualized interactions with the search results to further specify or adjust their detailed search intents iteratively. We implemented the framework into an image search system for NFT (non-fungible token) search and conducted a user study to evaluate its usability and novel properties. The results indicate that the proposed framework significantly improves users' image search experience. Particularly the parsing and contextualized interactions prove useful in allowing users to express their search intents more accurately and engage in a more enjoyable iterative search experience.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {180},
numpages = {31},
keywords = {composed retrieval, digital gallery, image retrieval, large language model, multi-modality, vision-language model}
}

@proceedings{10.1145/3641032,
title = {ICISE '23: Proceedings of the 2023 8th International Conference on Information Systems Engineering},
year = {2023},
isbn = {9798400709173},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bangkok, Thailand}
}

@proceedings{10.1145/3641067,
title = {ICSeB '23: Proceedings of the 2023 7th International Conference on Software and e-Business},
year = {2023},
isbn = {9798400717239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Osaka, Japan}
}

@proceedings{10.1145/3641142,
title = {ACSW '24: Proceedings of the 2024 Australasian Computer Science Week},
year = {2024},
isbn = {9798400717307},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Sydney, NSW, Australia}
}

@proceedings{10.1145/3641343,
title = {ICEITSA '23: Proceedings of the 3rd International Conference on Electronic Information Technology and Smart Agriculture},
year = {2023},
isbn = {9798400716775},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Sanya, China}
}

@proceedings{10.1145/3641399,
title = {ISEC '24: Proceedings of the 17th Innovations in Software Engineering Conference},
year = {2024},
isbn = {9798400717673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bangalore, India}
}

@proceedings{10.1145/3641584,
title = {AIPR '23: Proceedings of the 2023 6th International Conference on Artificial Intelligence and Pattern Recognition},
year = {2023},
isbn = {9798400707674},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xiamen, China}
}

@proceedings{10.1145/3641822,
title = {CHASE '24: Proceedings of the 2024 IEEE/ACM 17th International Conference on Cooperative and Human Aspects of Software Engineering},
year = {2024},
isbn = {9798400705335},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {CHASE 2024 continues the tradition of a high-quality venue for research related to the cooperative and human aspects of software engineering. Researchers and practitioners have long recognized the need to investigate the cooperative and human aspects. However, their articles have been scattered across many conferences and communities. The CHASE conference provides academics and practitioners with a unified forum for discussing high-quality research studies, models, methods, and tools for human and cooperative aspects of software engineering.},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3642968,
title = {EdgeSys '24: Proceedings of the 7th International Workshop on Edge Systems, Analytics and Networking},
year = {2024},
isbn = {9798400705397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Athens, Greece}
}

@proceedings{10.1145/3642970,
title = {EuroMLSys '24: Proceedings of the 4th Workshop on Machine Learning and Systems},
year = {2024},
isbn = {9798400705410},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Athens, Greece}
}

@proceedings{10.1145/3643479,
title = {AIQAM '24: Proceedings of the 1st ACM Workshop on AI-Powered Q&amp;A Systems for Multimedia},
year = {2024},
isbn = {9798400705472},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Phuket, Thailand}
}

@proceedings{10.1145/3643491,
title = {MAD '24: Proceedings of the 3rd ACM International Workshop on Multimedia AI against Disinformation},
year = {2024},
isbn = {9798400705526},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Phuket, Thailand}
}

@inproceedings{10.1145/3643491.3660286,
author = {Choi, Jeong-Eun and Sch\"{a}fer, Karla and Zmudzinski, Sascha},
title = {Introduction to Audio Deepfake Generation: Academic Insights for Non-Experts},
year = {2024},
isbn = {9798400705526},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643491.3660286},
doi = {10.1145/3643491.3660286},
abstract = {With the advancement of artificial intelligence, the methods for generating audio deepfakes have improved, but the technology behind it has become more complex. Despite this, non-expert users are able to generate audio deepfakes due to the increased accessibility of the latest technologies. These technologies can be used to support content creators, singers, and businesses such as the advertisement or entertainment industries. However, they can also be misused to create disinformation, CEO fraud, and voice scams. Therefore, with the increasing demand for countermeasures against their misuse, continuous interdisciplinary exchange is required. This work introduces recent techniques for generating audio deepfakes, with a focus on Text-to-Speech Synthesis and Voice Conversion for non-experts. It covers background knowledge, the latest trends and models, as well as open-source and closed-source software to explore both technological and practical aspects of audio deepfakes.},
booktitle = {Proceedings of the 3rd ACM International Workshop on Multimedia AI against Disinformation},
pages = {3–12},
numpages = {10},
keywords = {Attacks, Audio Deepfakes, Disinformation, Text-to-Speech Synthesis, Voice Conversion},
location = {Phuket, Thailand},
series = {MAD '24}
}

@article{10.1145/3643546,
author = {Wang, Shuning and Zhong, Linghui and Fu, Yongjian and Chen, Lili and Ren, Ju and Zhang, Yaoxue},
title = {UFace: Your Smartphone Can "Hear" Your Facial Expression!},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {1},
url = {https://doi.org/10.1145/3643546},
doi = {10.1145/3643546},
abstract = {Facial expression recognition (FER) is a crucial task for human-computer interaction and a multitude of multimedia applications that typically call for friendly, unobtrusive, ubiquitous, and even long-term monitoring. Achieving such a FER system meeting these multi-requirements faces critical challenges, mainly including the tiny irregular non-periodic deformation of emotion movements, high variability in facial positions and severe self-interference caused by users' own other behavior. In this work, we present UFace, a long-term, unobtrusive and reliable FER system for daily life using acoustic signals generated by a portable smartphone. We design an innovative network model with dual-stream input based on the attention mechanism, which can leverage distance-time profile features from various viewpoints to extract fine-grained emotion-related signal changes, thus enabling accurate identification of many kinds of expressions. Meanwhile, we propose effective mechanisms to deal with a series of interference issues during actual use. We implement UFace prototype with a daily-used smartphone and conduct extensive experiments in various real-world environments. The results demonstrate that UFace can successfully recognize 7 typical facial expressions with an average accuracy of 87.8\% across 20 participants. Besides, the evaluation of different distances, angles, and interferences proves the great potential of the proposed system to be employed in practical scenarios.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {22},
numpages = {27},
keywords = {Acoustic sensing, Deep learning, Facial expression recognition, Smartphone}
}

@proceedings{10.1145/3643832,
title = {MOBISYS '24: Proceedings of the 22nd Annual International Conference on Mobile Systems, Applications and Services},
year = {2024},
isbn = {9798400705816},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Minato-ku, Tokyo, Japan}
}

@inproceedings{10.1145/3643832.3661892,
author = {Jia, Fucheng and Jiang, Shiqi and Cao, Ting and Cui, Wei and Xia, Tianrui and Cao, Xu and Li, Yuanchun and Wang, Qipeng and Zhang, Deyu and Ren, Ju and Liu, Yunxin and Qiu, Lili and Yang, Mao},
title = {Empowering In-Browser Deep Learning Inference on Edge Through Just-In-Time Kernel Optimization},
year = {2024},
isbn = {9798400705816},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643832.3661892},
doi = {10.1145/3643832.3661892},
abstract = {Web is increasingly becoming the primary platform to deliver AI services onto edge devices, making in-browser deep learning (DL) inference more prominent. Nevertheless, the heterogeneity of edge devices, combined with the underdeveloped state of Web hardware acceleration practices, hinders current in-browser inference from achieving its full performance potential on target devices.To address this issue, this paper presents the pioneering inbrowser inference system, nnJIT, which enables just-in-time (JIT) auto-generation of optimized computing kernels for edge devices. nnJIT is built upon two novel techniques that significantly reduce kernel search and compilation overhead while improving performance firmly: Tensor-Web Compiling Co-Design lowers compiling costs by around 100\texttimes{} through eliminating redundant and ineffective compiling passes; Web-Specific Lite Kernel Optimization Space reduces kernel tuning costs by focusing on Web programming requirements and efficient device resource utilization, pruning the optimization space from millions to only dozens.nnJIT1 is evaluated for modern models, e.g., BART, T5, and Llama 2, on a range of edge devices including laptops and smartphones using different browsers and hardware from ARM, Intel, AMD and Nvidia. The results show that nnJIT can achieve up to 8.2\texttimes{} faster within 30 seconds compared to the existing baselines.},
booktitle = {Proceedings of the 22nd Annual International Conference on Mobile Systems, Applications and Services},
pages = {438–450},
numpages = {13},
keywords = {in-browser deep learning inference, just-in-time kernel optimizations, WebAssembly, WebGPU},
location = {Minato-ku, Tokyo, Japan},
series = {MOBISYS '24}
}

@proceedings{10.1145/3643833,
title = {WiSec '24: Proceedings of the 17th ACM Conference on Security and Privacy in Wireless and Mobile Networks},
year = {2024},
isbn = {9798400705823},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 2024 ACM Conference on Security and Privacy in Wireless and Mobile Networks (ACM WiSec)!Now in its 17th year, WiSec continues to be the premier venue for research on all aspects of security and privacy in wireless and mobile networks, their systems, and their applications. We are hosted by the Korea Institute of Information Security \&amp; Cryptology, located in the city center of Seoul, Korea - a city known for its dynamic mix of 600-year-old palaces and the contemporary urban landscape characterized by towering skyscrapers.We begin our exciting three-day main conference program on May 27th with single-track technical paper sessions, a poster and demo session, two excellent keynotes from telecommunication security expert Prof. Jean-Pierre Seifert (TU Berlin) and wireless security expert Mathy Vanhoef (KU Leuven), and a panel on wireless security and AI. Three invited talks named "Vision Talk" discuss the future of wireless and mobile security issues. The WiseML Workshop follows the main program on May 30th. We invite participants to attend the exciting paper presentations and keynotes, interact with the presenters during the Q&amp;A sessions after each talk, network during the coffee breaks and lunches each day, and socialize during the banquet dinner.},
location = {Seoul, Republic of Korea}
}

@inproceedings{10.1145/3643833.3656128,
author = {Wang, Ruxin and Huang, Long and Madden, Kaitlyn and Wang, Chen},
title = {Enhancing QR Code System Security by Verifying the Scanner's Gripping Hand Biometric},
year = {2024},
isbn = {9798400705823},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643833.3656128},
doi = {10.1145/3643833.3656128},
abstract = {Because of the great convenience and being not readable to humans, Quick Response (QR) codes are increasingly being utilized to offer a variety of security applications to mobile users, such as online payments, website logins, and private data sharing. To facilitate these security applications, QR codes usually contain sensitive information, such as bank account details, credit card numbers, and personal/organizational/device data, or they are specifically designed to work with cloud servers to provide security services. However, there is currently no existing solution to verify the identity of the smartphone user who scans a QR code from a Kiosk or another phone's screen. Verifying the scanner's identity is essential to ensure that financial transactions go to the correct recipient and that sensitive data is securely shared to its intended destination. This work aims to equip QR code providers with the ability to verify human scanners' identities, facilitating authorization and auditing. When a phone is held close to scan a QR code, we utilize the front camera of the code provider (a Kiosk or phone) to simultaneously verify the scanner's hand. Instead of requiring the scanner to present a stretched palm to obtain traditional hand geometries, we find that the geometry of an individual's hand, when it grips a phone, is also identifiable. We thus design a vision-based approach to extract gripping hand biometrics. We leverage the QR code's screen to cast light onto the scanner's gripping hand, ensuring adequate illumination even in low-light conditions. We then use a hand tracking tool, MediaPipe, to detect and localize the hand and develop a transformer-based algorithm to verify four types of gripping hand biometric features extracted from the hand image, including hand contour, skeleton, color, and surface. We further capture the subtle hand joint movements for liveness validation, because the user needs to click touchscreen buttons to start QR code scanning. Extensive experiments, including a long-term study spanning over 32 months, show that the system achieves 98.3\% accuracy in verifying the user and mitigating 2D and 3D replay attacks. Compared to the widely used facial recognition, this approach addresses the recent struggles of identifying faces behind masks and the public concerns about privacy erosion.},
booktitle = {Proceedings of the 17th ACM Conference on Security and Privacy in Wireless and Mobile Networks},
pages = {42–53},
numpages = {12},
keywords = {QR code security, authentication, hand biometric},
location = {Seoul, Republic of Korea},
series = {WiSec '24}
}

@proceedings{10.1145/3643915,
title = {SEAMS '24: Proceedings of the 19th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
year = {2024},
isbn = {9798400705854},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, AA, Portugal}
}

@proceedings{10.1145/3643916,
title = {ICPC '24: Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension},
year = {2024},
isbn = {9798400705861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {ICPC is the premier (CORE A) venue for research on program comprehension. Research on program comprehension encompasses both human activities for comprehending the software and technologies for supporting such comprehension.},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3643916.3644402,
author = {Corso, Vincenzo and Mariani, Leonardo and Micucci, Daniela and Riganelli, Oliviero},
title = {Generating Java Methods: An Empirical Assessment of Four AI-Based Code Assistants},
year = {2024},
isbn = {9798400705861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643916.3644402},
doi = {10.1145/3643916.3644402},
abstract = {AI-based code assistants are promising tools that can facilitate and speed up code development. They exploit machine learning algorithms and natural language processing to interact with developers, suggesting code snippets (e.g., method implementations) that can be incorporated into projects. Recent studies empirically investigated the effectiveness of code assistants using simple exemplary problems (e.g., the re-implementation of well-known algorithms), which fail to capture the spectrum and nature of the tasks actually faced by developers.In this paper, we expand the knowledge in the area by comparatively assessing four popular AI-based code assistants, namely GitHub Copilot, Tabnine, ChatGPT, and Google Bard, with a dataset of 100 methods that we constructed from real-life open-source Java projects, considering a variety of cases for complexity and dependency from contextual elements. Results show that Copilot is often more accurate than other techniques, yet none of the assistants is completely subsumed by the rest of the approaches. Interestingly, the effectiveness of these solutions dramatically decreases when dealing with dependencies outside the boundaries of single classes.},
booktitle = {Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension},
pages = {13–23},
numpages = {11},
keywords = {AI-based code assistants, code completion, copilot, ChatGPT, tabnine, bard, empirical study},
location = {Lisbon, Portugal},
series = {ICPC '24}
}

@inproceedings{10.1145/3643916.3644403,
author = {Ma, Zexiong and An, Shengnan and Xie, Bing and Lin, Zeqi},
title = {Compositional API Recommendation for Library-Oriented Code Generation},
year = {2024},
isbn = {9798400705861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643916.3644403},
doi = {10.1145/3643916.3644403},
abstract = {Large language models (LLMs) have achieved exceptional performance in code generation. However, the performance remains unsatisfactory in generating library-oriented code, especially for the libraries not present in the training data of LLMs. Previous work utilizes API recommendation technology to help LLMs use libraries: it retrieves APIs related to the user requirements, then leverages them as context to prompt LLMs. However, developmental requirements can be coarse-grained, requiring a combination of multiple fine-grained APIs. This granularity inconsistency makes API recommendation a challenging task.To address this, we propose CAPIR (Compositional API Recommendation), which adopts a "divide-and-conquer" strategy to recommend APIs for coarse-grained requirements. Specifically, CAPIR employs an LLM-based Decomposer to break down a coarse-grained task description into several detailed subtasks. Then, CAPIR applies an embedding-based Retriever to identify relevant APIs corresponding to each subtask. Moreover, CAPIR leverages an LLM-based Reranker to filter out redundant APIs and provides the final recommendation.To facilitate the evaluation of API recommendation methods on coarse-grained requirements, we present two challenging benchmarks, RAPID (Recommend APIs based on Documentation) and LOCG (Library-Oriented Code Generation). Experimental results on these benchmarks, demonstrate the effectiveness of CAPIR in comparison to existing baselines. Specifically, on RAPID's Torchdata-AR dataset, compared to the state-of-the-art API recommendation approach, CAPIR improves recall@5 from 18.7\% to 43.2\% and precision@5 from 15.5\% to 37.1\%. On LOCG's Torchdata-Code dataset, compared to code generation without API recommendation, CAPIR improves pass@100 from 16.0\% to 28.0\%.},
booktitle = {Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension},
pages = {87–98},
numpages = {12},
keywords = {API recommendation, code generation, requirements decomposition, large language model},
location = {Lisbon, Portugal},
series = {ICPC '24}
}

@inproceedings{10.1145/3643916.3644414,
author = {Chen, Xiangping and Li, Yangzi and Tang, Zhicao and Huang, Yuan and Zhou, Haojie and Tang, Mingdong and Zheng, Zibin},
title = {ESGen: Commit Message Generation Based on Edit Sequence of Code Change},
year = {2024},
isbn = {9798400705861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643916.3644414},
doi = {10.1145/3643916.3644414},
abstract = {Commit messages provide important information for comprehending the code changes, and a number of researchers try to generate commit messages by using an automatic way. These research on commit message generation has profited from the code tokens or code structures such as AST. Since the edit sequence of code change is also important for capturing the code change intent, we propose a new commit message generation method called ESGen, which extracts AST edit sequences of code changes as model input. Specifically, we employ an O(ND) difference algorithm to extract the edit sequence from AST by comparing the ASTs before and after applying the code changes. Then, we construct a Bi-Encoder, which encodes the textual information and the AST edit sequence information of code change. The experimental results show that ESGen outperforms other baseline models, improving the BLEU-4 to 15.14. Also, when applying the edit sequence to 7 baseline models, they improve the BLEU-4 scores of these models by an average of 8.5\%. Additionally, a human evaluation confirmed the effectiveness of ESGen in generating commit messages.},
booktitle = {Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension},
pages = {112–124},
numpages = {13},
keywords = {commit message generation, code change, edit sequence, biencoder, abstract syntax tree},
location = {Lisbon, Portugal},
series = {ICPC '24}
}

@inproceedings{10.1145/3643916.3644424,
author = {Siddiq, Mohammed Latif and Zhang, Jiahao and Santos, Joanna Cecilia Da Silva},
title = {Understanding Regular Expression Denial of Service (ReDoS): Insights from LLM-Generated Regexes and Developer Forums},
year = {2024},
isbn = {9798400705861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643916.3644424},
doi = {10.1145/3643916.3644424},
abstract = {Regular expression Denial of Service (ReDoS) represents an algorithmic complexity attack that exploits the processing of regular expressions (regexes) to produce a denial-of-service attack. This attack occurs when a regex's evaluation time scales polynomially or exponentially with input length, posing significant challenges for software developers. The advent of Large Language Models (LLMs) has revolutionized the generation of regexes from natural language prompts, but not without its risks. Prior works showed that LLMs can generate code with vulnerabilities and security smells. In this paper, we examined the correctness and security of regexes generated by LLMs as well as the characteristics of LLM-generated vulnerable regexes. Our study also examined ReDoS patterns in actual software projects, aligning them with corresponding regex equivalence classes and algorithmic complexity. Moreover, we analyzed developer discussions on GitHub and StackOverflow, constructing a taxonomy to investigate their experiences and perspectives on ReDoS. In this study, we found that GPT-3.5 was the best LLM to generate regexes that are both correct and secure. We also observed that LLM-generated regexes mainly have polynomial ReDoS vulnerability patterns, and it is consistent with vulnerable regexes found in open source projects. We also found that developers' main discussions around insecure regexes is related to mitigation strategies to remove vulnerable regexes.},
booktitle = {Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension},
pages = {190–201},
numpages = {12},
keywords = {ReDoS, DoS attack, large language models, regex generation},
location = {Lisbon, Portugal},
series = {ICPC '24}
}

@proceedings{10.1145/3644032,
title = {AST '24: Proceedings of the 5th ACM/IEEE International Conference on Automation of Software Test (AST 2024)},
year = {2024},
isbn = {9798400705885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {AST continues to be a venue for researchers and practitioners where they can discuss high quality research contributions on methods for software test automation, and various case studies reporting practices in this field. Indeed, software test automation is a discipline that has produced noteworthy research in the last decade.The special theme of AST 2024 is "Test automation for and with Generative AI". This innovative and promising research direction deals with the application of test automation technologies to the testing of Generative AI applications, as well as the adoption of generative AI to facilitate test automation.},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3644033,
title = {FormaliSE '24: Proceedings of the 2024 IEEE/ACM 12th International Conference on Formal Methods in Software Engineering (FormaliSE)},
year = {2024},
isbn = {9798400705892},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Historically, formal methods academic research and practical software development have had limited mutual interactions—except possibly in specialized domains such as safety-critical software. In recent times, the outlook has considerably improved: on the one hand, formal methods research has delivered more flexible techniques and tools that can support various aspects of the software development process—from user requirements elicitation, to design, implementation, verification and validation, as well as the creation of documentation. On the other hand, software engineering has developed a growing interest in rigorous techniques applied at scale.This evolution, and the desire to further improve it, motivated the creation of FormaliSE: a well-established annual conference whose main goal is to promote work at the intersection of the formal methods and software engineering communities, providing a venue to exchange ideas, experiences, techniques, and results. The collaboration between these two communities can be mutually beneficial by fostering the creation of formal methods that are practically useful and by helping develop higher-quality software.},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3644116,
title = {ISAIMS '23: Proceedings of the 2023 4th International Symposium on Artificial Intelligence for Medicine Science},
year = {2023},
isbn = {9798400708138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Chengdu, China}
}

@proceedings{10.1145/3644479,
title = {EBIMCS '23: Proceedings of the 2023 6th International Conference on E-Business, Information Management and Computer Science},
year = {2023},
isbn = {9798400709333},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hong Kong, Hong Kong}
}

@proceedings{10.1145/3644523,
title = {ICCSMT '23: Proceedings of the 2023 4th International Conference on Computer Science and Management Technology},
year = {2023},
isbn = {9798400709517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xi'an, China}
}

@proceedings{10.1145/3644713,
title = {ICFNDS '23: Proceedings of the 7th International Conference on Future Networks and Distributed Systems},
year = {2023},
isbn = {9798400709036},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Dubai, United Arab Emirates}
}

@proceedings{10.1145/3644815,
title = {CAIN '24: Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The goal of the CAIN Conference Series is to bring together researchers and practitioners in software engineering, data science, and artificial intelligence (AI) as part of a growing community that is targeting the challenges of Software Engineering for AI-enabled systems.},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3644815.3644945,
author = {Barnett, Scott and Kurniawan, Stefanus and Thudumu, Srikanth and Brannelly, Zach and Abdelrazek, Mohamed},
title = {Seven Failure Points When Engineering a Retrieval Augmented Generation System},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644945},
doi = {10.1145/3644815.3644945},
abstract = {Software engineers are increasingly adding semantic search capabilities to applications using a strategy known as Retrieval Augmented Generation (RAG). A RAG system involves finding documents that semantically match a query and then passing the documents to a large language model (LLM) such as ChatGPT to extract the right answer using an LLM. RAG systems aim to: a) reduce the problem of hallucinated responses from LLMs, b) link sources/references to generated responses, and c) remove the need for annotating documents with meta-data. However, RAG systems suffer from limitations inherent to information retrieval systems and from reliance on LLMs. In this paper, we present an experience report on the failure points of RAG systems from three case studies from separate domains: research, education, and biomedical. We share the lessons learned and present 7 failure points to consider when designing a RAG system. The two key takeaways arising from our work are: 1) validation of a RAG system is only feasible during operation, and 2) the robustness of a RAG system evolves rather than designed in at the start. We conclude with a list of potential research directions on RAG systems for the software engineering community.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {194–199},
numpages = {6},
keywords = {retrieval augmented generation, RAG, SE4AI, case study},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@inproceedings{10.1145/3644815.3644946,
author = {Li, Ziyu and Shin, Donghwan},
title = {Mutation-based Consistency Testing for Evaluating the Code Understanding Capability of LLMs},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644946},
doi = {10.1145/3644815.3644946},
abstract = {Large Language Models (LLMs) have shown remarkable capabilities in processing both natural and programming languages, which have enabled various applications in software engineering, such as requirement engineering, code generation, and software testing. However, existing code generation benchmarks do not necessarily assess the code understanding performance of LLMs, especially for the subtle inconsistencies that may arise between code and its semantics described in natural language.In this paper, we propose a novel method, called Mutation-based Consistency Testing (MCT), to systematically assess the code understanding performance of LLMs, particularly focusing on subtle differences between code and its descriptions, by introducing code mutations to existing code generation datasets. Code mutations are small changes that alter the semantics of the original code, creating a mismatch with the natural language description. MCT uses different types of code mutations, such as operator replacement and statement deletion, to generate inconsistent code-description pairs. MCT then uses these pairs to test the ability of LLMs to detect the inconsistencies correctly.We conduct a case study on the two popular LLMs, GPT-3.5 and GPT-4, using the state-of-the-art code generation benchmark, HumanEval-X, which consists of 164 programming problems written in six programming languages (Python, C++, Java, Go, JavaScript, and Rust). The results show that the LLMs have significant variations in their code understanding performance and that they have different strengths and weaknesses depending on the mutation type and language. We further explain conditions under which the LLMs result in correct answers using input characteristics (e.g., number of tokens) and investigate to what extent the test results can be improved using one-shot prompts (i.e., providing an additional example). Our MCT method and the case study results provide valuable implications for future research and development of LLM-based software engineering.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {150–159},
numpages = {10},
keywords = {large language models, software engineering, mutation analysis},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@inproceedings{10.1145/3644815.3644947,
author = {Baldassarre, Maria Teresa and Gigante, Domenico and Kalinowski, Marcos and Ragone, Azzurra},
title = {POLARIS: A Framework to Guide the Development of Trustworthy AI Systems},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644947},
doi = {10.1145/3644815.3644947},
abstract = {In the ever-expanding landscape of Artificial Intelligence (AI), where innovation thrives and new products and services are continuously being delivered, ensuring that AI systems are designed and developed responsibly throughout their entire lifecycle is crucial. To this end, several AI ethics principles and guidelines have been issued to which AI systems should conform. Nevertheless, relying solely on high-level AI ethics principles is far from sufficient to ensure the responsible engineering of AI systems. In this field, AI professionals often navigate by sight. Indeed, while recommendations promoting Trustworthy AI (TAI) exist, they are often high-level statements difficult to translate into concrete implementation strategies. Currently, there is a significant gap between high-level AI ethics principles and low-level concrete practices for AI professionals. To address this challenge, our work presents an experience report where we develop a novel holistic framework for Trustworthy AI --- designed to bridge the gap between theory and practice --- and report insights from its application in an industrial case study. The framework builds up from the results of a systematic review of the state of the practice as well as a survey and think-aloud interviews with 34 AI practitioners. The framework, unlike most of the ones in literature, is designed to provide actionable guidelines and tools to support different types of stakeholders throughout the entire Software Development Life Cycle (SDLC). Our goal is to empower AI professionals to confidently navigate the ethical dimensions of TAI through practical insights, ensuring that the vast potential of AI is exploited responsibly for the benefit of society as a whole.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {200–210},
numpages = {11},
keywords = {artificial intelligence, software engineering, trustworthy AI, knowledge base, framework},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@inproceedings{10.1145/3644815.3644949,
author = {Pinto, Gustavo and De Souza, Cleidson and Rocha, Thayssa and Steinmacher, Igor and Souza, Alberto and Monteiro, Edward},
title = {Developer Experiences with a Contextualized AI Coding Assistant: Usability, Expectations, and Outcomes},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644949},
doi = {10.1145/3644815.3644949},
abstract = {In the rapidly advancing field of artificial intelligence, software development has emerged as a key area of innovation. Despite the plethora of general-purpose AI assistants available, their effectiveness diminishes in complex, domain-specific scenarios. Noting this limitation, both the academic community and industry players are relying on contextualized coding AI assistants. These assistants surpass general-purpose AI tools by integrating proprietary, domain-specific knowledge, offering precise and relevant solutions. Our study focuses on the initial experiences of 62 participants who used a contextualized coding AI assistant --- named StackSpot AI--- in a controlled setting. According to the participants, the assistants' use resulted in significant time savings, easier access to documentation, and the generation of accurate codes for internal APIs. However, challenges associated with the knowledge sources necessary to make the coding assistant access more contextual information as well as variable responses and limitations in handling complex codes were observed. The study's findings, detailing both the benefits and challenges of contextualized AI assistants, underscore their potential to revolutionize software development practices, while also highlighting areas for further refinement.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {81–91},
numpages = {11},
keywords = {LLM, LLM-based applications, user expectations, perception of productivity},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@proceedings{10.1145/3645259,
title = {IPMV '24: Proceedings of the 2024 6th International Conference on Image Processing and Machine Vision},
year = {2024},
isbn = {9798400708473},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Macau, China}
}

@proceedings{10.1145/3645279,
title = {BDMIP '23: Proceedings of the 2023 International Conference on Big Data Mining and Information Processing},
year = {2023},
isbn = {9798400709166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xiamen City, China, China}
}

@proceedings{10.1145/3647444,
title = {ICIMMI '23: Proceedings of the 5th International Conference on Information Management \&amp; Machine Intelligence},
year = {2023},
isbn = {9798400709418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Jaipur, India}
}

@proceedings{10.1145/3647632,
title = {MOBILESoft '24: Proceedings of the IEEE/ACM 11th International Conference on Mobile Software Engineering and Systems},
year = {2024},
isbn = {9798400705946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3647649,
title = {ICIGP '24: Proceedings of the 2024 7th International Conference on Image and Graphics Processing},
year = {2024},
isbn = {9798400716720},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Beijing, China}
}

@proceedings{10.1145/3647722,
title = {ICSIM '24: Proceedings of the 2024 7th International Conference on Software Engineering and Information Management},
year = {2024},
isbn = {9798400709197},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Suva, Fiji}
}

@proceedings{10.1145/3647750,
title = {ICMLSC '24: Proceedings of the 2024 8th International Conference on Machine Learning and Soft Computing},
year = {2024},
isbn = {9798400716546},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Singapore, Singapore}
}

@proceedings{10.1145/3647782,
title = {ICCMB '24: Proceedings of the 2024 7th International Conference on Computers in Management and Business},
year = {2024},
isbn = {9798400716652},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Singapore, Singapore}
}

@inproceedings{10.1145/3647782.3647804,
author = {Pudasaini, Shushanta and Ghimire, Sunil and Ale, Prabhat and Shakya, Aman and Paudel, Prakriti and Joshi, Basanta},
title = {Application of Nepali Large Language Models to Improve Sentiment Analysis},
year = {2024},
isbn = {9798400716652},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3647782.3647804},
doi = {10.1145/3647782.3647804},
abstract = {With the rise in internet usage, Nepali individuals have left a flood of opinionated comments in their language on YouTube and other social media sites. Such remarks can be subjected to sentiment analysis, which can be useful for both research and business purposes. Such sentiment analysis models can be extremely useful in understanding the user's expectations towards the product which can uplift the business of any organization. Similarly, with the rise of Large Language models in the NLP space, there are several large language models pre-trained on the BERT architecture upon the Nepali text corpus. This research focuses on developing a benchmarking dataset for sentiment analysis in the Nepali language and demonstrating how large Nepali language models can be used to improve the results on downstream NLP tasks like sentiment analysis on such benchmark datasets. This paper describes an approach to how proper embeddings for a Nepali sentence can be extracted from the pre-trained Nepali language models. The comparison of transfer learning applied to the dataset on different machine learning and deep learning algorithms has been done in this study. From this experimentation, a state-of-the-art sentiment analysis model in the Nepali language with an F-score of 0.88 has been developed.},
booktitle = {Proceedings of the 2024 7th International Conference on Computers in Management and Business},
pages = {144–150},
numpages = {7},
keywords = {Bidirectional Encoders for Representational Transformers, Finetuning, Large Language Models, Machine Learning Algorithms, Natural Language Processing, Sentiment Analysis, Transfer Learning},
location = {Singapore, Singapore},
series = {ICCMB '24}
}

@proceedings{10.1145/3648115,
title = {IWOCL '24: Proceedings of the 12th International Workshop on OpenCL and SYCL},
year = {2024},
isbn = {9798400717901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Chicago, IL, USA}
}

@proceedings{10.1145/3648536,
title = {TAHRI '24: Proceedings of the 2024 International Symposium on Technological Advances in Human-Robot Interaction},
year = {2024},
isbn = {9798400716614},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Boulder, CO, USA}
}

@inproceedings{10.1145/3648536.3648543,
author = {Paetzel-Pr\"{u}smann, Maike and Lehman, Jill Fain and Gomez, Celia J. and Kennedy, James},
title = {An Automatic Evaluation Framework for Social Conversations with Robots},
year = {2024},
isbn = {9798400716614},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3648536.3648543},
doi = {10.1145/3648536.3648543},
abstract = {When deploying social robots in the wild, it is crucial for developers to gain an understanding of how the interactions between the robot and its human conversational partners are progressing. Unlike in traditional task-based settings in which a human and a robot work on a tangible outcome that can serve as a proxy for how well a conversation is going, social settings require a deeper understanding of the underlying interaction dynamics. In this paper, we assess a set of recorded features of a robot having social conversations in a multi-party, multi-session setting and correlate them with how people rated their interaction. We then propose a framework that combines the features into a model that can automatically assess an ongoing conversation and determine its performance.},
booktitle = {Proceedings of the 2024 International Symposium on Technological Advances in Human-Robot Interaction},
pages = {56–64},
numpages = {9},
keywords = {Conversational Dialogue Systems, Conversational Quality, Human-Robot Interaction Evaluation, Social Robotics},
location = {Boulder, CO, USA},
series = {TAHRI '24}
}

@proceedings{10.1145/3649476,
title = {GLSVLSI '24: Proceedings of the Great Lakes Symposium on VLSI 2024},
year = {2024},
isbn = {9798400706059},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Clearwater, FL, USA}
}

@proceedings{10.1145/3649792,
title = {IHM '24: Proceedings of the 35th Conference on l'Interaction Humain-Machine},
year = {2024},
isbn = {9798400718113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Paris, France}
}

@article{10.1145/3649825,
author = {Ding, Yangruibo and Min, Marcus J. and Kaiser, Gail and Ray, Baishakhi},
title = {CYCLE: Learning to Self-Refine the Code Generation},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {OOPSLA1},
url = {https://doi.org/10.1145/3649825},
doi = {10.1145/3649825},
abstract = {Pre-trained code language models have achieved promising performance in code generation and improved the programming efficiency of human developers. However, their self-refinement capability is typically overlooked by the existing evaluations of code LMs, which focus only on the accuracy of the one-time prediction. For the cases when code LMs fail to implement the correct program, developers actually find it hard to debug and fix the faulty prediction since it is not written by the developers themselves. Unfortunately, our study reveals that code LMs cannot efficiently self-refine their faulty generations as well. In this paper, we propose CYCLE framework, learning to self-refine the faulty generation according to the available feedback, such as the execution results reported by the test suites. We evaluate CYCLE on three popular code generation benchmarks, HumanEval, MBPP, and APPS. The results reveal that CYCLE successfully maintains, sometimes improves, the quality of one-time code generation, while significantly improving the self-refinement capability of code LMs. We implement four variants of CYCLE with varied numbers of parameters across 350M, 1B, 2B, and 3B, and the experiments show that CYCLE consistently boosts the code generation performance, by up to 63.5},
journal = {Proc. ACM Program. Lang.},
month = apr,
articleno = {108},
numpages = {27},
keywords = {Code Generation, Code Language Models, Iterative Programming, Source Code Modeling}
}

@article{10.1145/3649829,
author = {Chen, Qian and Yu, Chenyang and Liu, Ruyan and Zhang, Chi and Wang, Yu and Wang, Ke and Su, Ting and Wang, Linzhang},
title = {Evaluating the Effectiveness of Deep Learning Models for Foundational Program Analysis Tasks},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {OOPSLA1},
url = {https://doi.org/10.1145/3649829},
doi = {10.1145/3649829},
abstract = {While deep neural networks provide state-of-the-art solutions to a wide range of programming language tasks, their effectiveness in dealing with foundational program analysis tasks remains under explored. In this paper, we present an empirical study that evaluates four prominent models of code (i.e., CuBERT, CodeBERT, GGNN, and Graph Sandwiches) in two such foundational tasks: (1) alias prediction, in which models predict whether two pointers must alias, may alias or must not alias; and (2) equivalence prediction, in which models predict whether or not two programs are semantically equivalent. At the core of this study is CodeSem, a dataset built upon the source code of real-world flagship software (e.g., Linux Kernel, GCC, MySQL) and manually validated for the two prediction tasks.  
Results show that all models are accurate in both prediction tasks, especially CuBERT with an accuracy of 89\% and 84\% in alias prediction and equivalence prediction, respectively. We also conduct a comprehensive, in-depth analysis of the results of all models in both tasks, concluding that deep learning models are generally capable of performing foundational tasks in program analysis even though in specific cases their weaknesses are also evident.  

Our code and evaluation data are publicly available at https://github.com/CodeSemDataset/CodeSem.},
journal = {Proc. ACM Program. Lang.},
month = apr,
articleno = {112},
numpages = {29},
keywords = {Alias Analysis, Deep Learning, Equivalence Checking}
}

@article{10.1145/3649850,
author = {Zhang, Jialu and Cambronero, Jos\'{e} Pablo and Gulwani, Sumit and Le, Vu and Piskac, Ruzica and Soares, Gustavo and Verbruggen, Gust},
title = {PyDex: Repairing Bugs in Introductory Python Assignments using LLMs},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {OOPSLA1},
url = {https://doi.org/10.1145/3649850},
doi = {10.1145/3649850},
abstract = {Students often make mistakes in their introductory programming assignments as part of their learning process. Unfortunately, providing custom repairs for these mistakes can require a substantial amount of time and effort from class instructors. Automated program repair (APR) techniques can be used to synthesize such fixes. Prior work has explored the use of symbolic and neural techniques for APR in the education domain. Both types of approaches require either substantial engineering efforts or large amounts of data and training. We propose to use a large language model trained on code, such as Codex (a version of GPT), to build an APR system -- PyDex -- for introductory Python programming assignments. Our system can fix both syntactic and semantic mistakes by combining multi-modal prompts, iterative querying, test-case-based selection of few-shots, and program chunking. We evaluate PyDex on 286 real student programs and compare to three baselines, including one that combines a state-of-the-art Python syntax repair engine, BIFI, and a state-of-the-art Python semantic repair engine for student assignments, Refactory. We find that PyDex can fix more programs and produce smaller patches on average.},
journal = {Proc. ACM Program. Lang.},
month = apr,
articleno = {133},
numpages = {25},
keywords = {AI for programming education, automated program repair, large language models}
}

@article{10.1145/3649862,
author = {Xu, Pei and Lei, Yuxiang and Sui, Yulei and Xue, Jingling},
title = {Iterative-Epoch Online Cycle Elimination for Context-Free Language Reachability},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {OOPSLA1},
url = {https://doi.org/10.1145/3649862},
doi = {10.1145/3649862},
abstract = {Context-free language reachability (CFL-reachability) is a fundamental framework for implementing various static analyses. CFL-reachability utilizes context-free grammar (CFG) to extend the expressiveness of ordinary graph reachability from an unlabeled graph to an edge-labeled graph. Solving CFL-reachability requires a (sub)cubic time complexity with respect to the graph size, which limits its scalability in practice. Thus, an approach that can effectively reduce the graph size while maintaining the reachability result is highly desirable. Most of the existing graph simplification techniques for CFL-reachability work during the preprocessing stage, i.e., before the dynamic CFL-reachability solving process. However, in real-world CFL-reachability analyses, there is a large number of reducible nodes and edges that can only be discovered during dynamic solving, leaving significant room for on-the-fly improvements.  

This paper aims to reduce the graph size of CFL-reachability dynamically via online cycle elimination. We propose a simple yet effective approach to detect collapsible cycles in the graph based on the input context-free grammar. Our key insight is that symbols with particular forms of production rules in the grammar are the essence of transitivity of reachability relations in the graph. Specifically, in the graph, a reachability relation to a node v_i can be "transited" to another node v_j if there is a transitive relation from v_i to v_j, and cycles formed by transitive relations are collapsible. In this paper, we present an approach to identify the transitive symbols in a context-free grammar and propose an iterative-epoch framework for online cycle elimination. From the perspective of non-parallelized CFL-reachability solving, our iterative-epoch framework is well compatible with both the standard (unordered) solver and the recent ordered solver, and can significantly improve their performance. Our experiment on context-sensitive value-flow analysis for C/C++ and field-sensitive alias analysis for Java demonstrates promising performance improvement by our iterative-epoch cycle elimination technique. By collapsing cycles online, our technique accelerates the standard solver by 17.17\texttimes{} and 13.94\texttimes{} for value-flow analysis and alias analysis, respectively, with memory reductions of 48.8\% and 45.0\%. Besides, our technique can also accelerate the ordered solver by 14.32\texttimes{} and 8.36\texttimes{} for value-flow analysis and alias analysis, respectively, with memory reductions of 55.2\% and 57.8\%.},
journal = {Proc. ACM Program. Lang.},
month = apr,
articleno = {145},
numpages = {26},
keywords = {CFL-reachability, online graph simplification, performance}
}

@proceedings{10.1145/3649902,
title = {ETRA '24: Proceedings of the 2024 Symposium on Eye Tracking Research and Applications},
year = {2024},
isbn = {9798400706073},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Glasgow, United Kingdom}
}

@proceedings{10.1145/3650105,
title = {FORGE '24: Proceedings of the 2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering},
year = {2024},
isbn = {9798400706097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {FORGE aims to bring researchers, practitioners, and educators from the AI and Software Engineering community to solve the new challenges we meet in the era of foundation models.},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3650105.3652289,
author = {van Dam, Tim and van der Heijden, Frank and de Bekker, Philippe and Nieuwschepen, Berend and Otten, Marc and Izadi, Maliheh},
title = {Investigating the Performance of Language Models for Completing Code in Functional Programming Languages: a Haskell Case Study},
year = {2024},
isbn = {9798400706097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650105.3652289},
doi = {10.1145/3650105.3652289},
abstract = {Language model-based code completion models have quickly grown in use, helping thousands of developers write code in many different programming languages. However, research on code completion models typically focuses on imperative languages such as Python and JavaScript, which results in a lack of representation for functional programming languages. Consequently, these models often perform poorly on functional languages such as Haskell. To investigate whether this can be alleviated, we evaluate the performance of two language models for code, CodeGPT and UniXcoder, on the functional programming language Haskell. We fine-tune and evaluate the models on Haskell functions sourced from a publicly accessible Haskell dataset on HuggingFace. Additionally, we manually evaluate the models using our novel translated HumanEval dataset. Our automatic evaluation shows that knowledge of imperative programming languages in the pre-training of LLMs may not transfer well to functional languages, but that code completion on functional languages is feasible. Consequently, this shows the need for more high-quality Haskell datasets. A manual evaluation on HumanEval-Haskell indicates CodeGPT frequently generates empty predictions and extra comments, while UniXcoder more often produces incomplete or incorrect predictions. Finally, we release HumanEval-Haskell, along with the fine-tuned models and all code required to reproduce our experiments on GitHub [41].},
booktitle = {Proceedings of the 2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering},
pages = {91–102},
numpages = {12},
keywords = {language models, automatic code completion, line completion, programming languages, functional programming, haskell, CodeGPT, UniXcoder},
location = {Lisbon, Portugal},
series = {FORGE '24}
}

@inproceedings{10.1145/3650105.3652297,
author = {Wang, Guanyu and Li, Yuekang and Liu, Yi and Deng, Gelei and Li, Tianlin and Xu, Guosheng and Liu, Yang and Wang, Haoyu and Wang, Kailong},
title = {MeTMaP: Metamorphic Testing for Detecting False Vector Matching Problems in LLM Augmented Generation},
year = {2024},
isbn = {9798400706097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650105.3652297},
doi = {10.1145/3650105.3652297},
abstract = {Augmented generation techniques such as Retrieval-Augmented Generation (RAG) and Cache-Augmented Generation (CAG) have revolutionized the field by enhancing large language model (LLM) outputs with external knowledge and cached information. However, the integration of vector databases, which serve as a backbone for these augmentations, introduces critical challenges, particularly in ensuring accurate vector matching. False vector matching in these databases can significantly compromise the integrity and reliability of LLM outputs, leading to misinformation or erroneous responses. Despite the crucial impact of these issues, there is a notable research gap in methods to effectively detect and address false vector matches in LLM-augmented generation.This paper presents MeTMaP, a metamorphic testing framework developed to identify false vector matching in LLM-augmented generation systems. We derive eight metamorphic relations (MRs) from six NLP datasets, which form our method's core, based on the idea that semantically similar texts should match and dissimilar ones should not. MeTMaP uses these MRs to create sentence triplets for testing, simulating real-world matching scenarios. Our evaluation of MeTMaP over 203 vector matching configurations, involving 29 embedding models and 7 distance metrics, uncovers significant inaccuracies. The results, showing a maximum accuracy of only 41.51\% on our tests compared to the original datasets, emphasize the widespread issue of false matches in vector matching methods and the critical need for effective detection and mitigation in LLM-augmented applications.},
booktitle = {Proceedings of the 2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering},
pages = {12–23},
numpages = {12},
keywords = {metamorphic testing, vector matching, augmented generation},
location = {Lisbon, Portugal},
series = {FORGE '24}
}

@inproceedings{10.1145/3650105.3652298,
author = {Katzy, Jonathan and Popescu, Razvan and Van Deursen, Arie and Izadi, Maliheh},
title = {An Exploratory Investigation into Code License Infringements in Large Language Model Training Datasets},
year = {2024},
isbn = {9798400706097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650105.3652298},
doi = {10.1145/3650105.3652298},
abstract = {Does the training of large language models potentially infringe upon code licenses? Furthermore, are there any datasets available that can be safely used for training these models without violating such licenses? In our study, we assess the current trends in the field and the importance of incorporating code into the training of large language models. Additionally, we examine publicly available datasets to see whether these models can be trained on them without the risk of legal issues in the future. To accomplish this, we compiled a list of 53 large language models trained on file-level code. We then extracted their datasets and analyzed how much they overlap with a dataset we created, consisting exclusively of strong copyleft code.Our analysis revealed that every dataset we examined contained license inconsistencies, despite being selected based on their associated repository licenses. We analyzed a total of 514 million code files, discovering 38 million exact duplicates present in our strong copyleft dataset. Additionally, we examined 171 million file-leading comments, identifying 16 million with strong copyleft licenses and another 11 million comments that discouraged copying without explicitly mentioning a license. Based on the findings of our study, which highlights the pervasive issue of license inconsistencies in large language models trained on code, our recommendation for both researchers and the community is to prioritize the development and adoption of best practices for dataset creation and management.},
booktitle = {Proceedings of the 2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering},
pages = {74–85},
numpages = {12},
keywords = {large language models, foundation models, code licensing, software engineering, ML4SE, machine learning, datasets},
location = {Lisbon, Portugal},
series = {FORGE '24}
}

@proceedings{10.1145/3650200,
title = {ICS '24: Proceedings of the 38th ACM International Conference on Supercomputing},
year = {2024},
isbn = {9798400706103},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Kyoto, Japan}
}

@inproceedings{10.1145/3650200.3656598,
author = {Gao, Wei and Zhang, Xu and Huang, Shan and Guo, Shangwei and Sun, Peng and Wen, Yonggang and Zhang, Tianwei},
title = {AutoSched: An Adaptive Self-configured Framework for Scheduling Deep Learning Training Workloads},
year = {2024},
isbn = {9798400706103},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650200.3656598},
doi = {10.1145/3650200.3656598},
abstract = {Modern Deep Learning Training (DLT) schedulers in GPU datacenters are designed to be very sophisticated with many configurations. These configurations need to be adjusted delicately as they can significantly affect the scheduling performance. Existing schedulers require the datacenter operator to tune the configurations only once before they are deployed, based on the historical workload traces. Unfortunately, workloads in a datacenter would experience dynamic changes and deviate a lot from the historical ones over time, making the pre-determined configurations less effective. To address this dilemma, we design AutoSched, a framework that can automatically, efficiently, and dynamically adjust the configuration parameters of DLT schedulers. Motivated by our characterization analysis of real-world DLT workloads and existing schedulers, we introduce two innovative system designs. (1) We develop a Generation Engine to produce workloads that can reveal the future trace pattern, which facilitates accurate configuration tuning. (2) We design a Search Engine to reduce the exorbitant overhead of configuration tuning. AutoSched is general and can be integrated with off-the-shelf schedulers. We showcase how AutoSched strengthens three representative DLT schedulers and evaluate them on varying DLT traces. Extensive experiments demonstrate that AutoSched improves the performance of state-of-the-art schedulers by up to 46\% with 132 \texttimes{} configuration tuning latency reduction.},
booktitle = {Proceedings of the 38th ACM International Conference on Supercomputing},
pages = {473–484},
numpages = {12},
keywords = {Cluster Management System, Deep Learning Training},
location = {Kyoto, Japan},
series = {ICS '24}
}

@inproceedings{10.1145/3650200.3656619,
author = {Mu, Baorun and Giannoula, Christina and Wang, Shang and Pekhimenko, Gennady},
title = {Sylva: Sparse Embedded Adapters via Hierarchical Approximate Second-Order Information},
year = {2024},
isbn = {9798400706103},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650200.3656619},
doi = {10.1145/3650200.3656619},
abstract = {Fine-tuning is the gateway to transferring learned knowledge in a pre-trained Large Language Model (LLM) on many downstream applications. To make LLM fine-tuning more affordable, prior works follow two paths: i) adapters freeze the pre-trained LLM weights and inject a small number of trainable weights during fine-tuning, and ii) pruners remove the less important weights in pre-trained LLMs and train the remaining sparse weights during fine-tuning. We find that the former introduces computation overheads due to the injected trainable parameters, while the latter introduces an expensive pre-processing step to identify the important weights and degrades model quality. To get the best of both worlds, we propose Sylva, a novel LLM fine-tuning procedure that provides high system performance during fine-tuning and attains state-of-the-art model quality on downstream applications. Sylva identifies the most important LLM weights via second-order information in a pre-processing step, and significantly reduces the computation and storage costs of the pre-processing step via i) a hierarchical approximation of second-order information, and ii) an online projection and rediagonalization algorithm. Sylva trains only the sparse important weights and embeds these sparse weights into the pre-trained LLM during fine-tuning to provide high system performance. We show that end-to-end fine-tuning with Sylva is, on average, 5.1 \texttimes{} faster than ZeRO and 1.2 \texttimes{} faster than LoRA, the state-of-the-art adapter approach. Sylva’s hierarchical approximation reduces the peak GPU memory in the pre-processing step by 2.3 \texttimes{} compared to K-FAC, the most widely used approximation to second-order information. The source code of Sylva is publicly available at https://github.com/CentML/Sylva.},
booktitle = {Proceedings of the 38th ACM International Conference on Supercomputing},
pages = {485–497},
numpages = {13},
keywords = {GPUs, fine-tuning, large language models},
location = {Kyoto, Japan},
series = {ICS '24}
}

@proceedings{10.1145/3650203,
title = {DEEM '24: Proceedings of the Eighth Workshop on Data Management for End-to-End Machine Learning},
year = {2024},
isbn = {9798400706110},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Santiago, AA, Chile}
}

@proceedings{10.1145/3650215,
title = {ICMLCA '23: Proceedings of the 2023 4th International Conference on Machine Learning and Computer Application},
year = {2023},
isbn = {9798400709449},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hangzhou, China}
}

@proceedings{10.1145/3650400,
title = {EITCE '23: Proceedings of the 2023 7th International Conference on Electronic Information Technology and Computer Engineering},
year = {2023},
isbn = {9798400708305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xiamen, China}
}

@article{10.1145/3651313,
author = {Denisenko, Natalia and Zhang, Youzhi and Pulice, Chiara and Bhattasali, Shohini and Jajodia, Sushil and Resnik, Philip and Subrahmanian, V.S.},
title = {A Psycholinguistics-inspired Method to Counter IP Theft Using Fake Documents},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {2158-656X},
url = {https://doi.org/10.1145/3651313},
doi = {10.1145/3651313},
abstract = {Intellectual property (IP) theft is a growing problem. We build on prior work to deter IP theft by generating n fake versions of a technical document so a thief has to expend time and effort in identifying the correct document. Our new SbFAKE framework proposes, for the first time, a novel combination of language processing, optimization, and the psycholinguistic concept of surprisal to generate a set of such fakes. We start by combining psycholinguistic-based surprisal scores and optimization to generate two bilevel surprisal optimization problems (an Explicit one and a simpler Implicit one) whose solutions correspond directly to the desired set of fakes. As bilevel problems are usually hard to solve, we then show that these two bilevel surprisal optimization problems can each be reduced to equivalent surprisal-based linear programs. We performed detailed parameter tuning experiments and identified the best parameters for each of these algorithms. We then tested these two variants of SbFAKE (with their best parameter settings) against the best performing prior work in the field. Our experiments show that SbFAKE is able to more effectively generate convincing fakes than past work. In addition, we show that replacing words in an original document with words having similar surprisal scores generates greater levels of deception.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = jun,
articleno = {7},
numpages = {25},
keywords = {AI for security, fake document generation}
}

@proceedings{10.1145/3651623,
title = {APIT '24: Proceedings of the 2024 6th Asia Pacific Information Technology Conference},
year = {2024},
isbn = {9798400716218},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bangkok, Thailand}
}

@proceedings{10.1145/3651655,
title = {ICBTA '23: Proceedings of the 2023 6th International Conference on Blockchain Technology and Applications},
year = {2023},
isbn = {9798400708671},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xi'an, China}
}

@proceedings{10.1145/3651671,
title = {ICMLC '24: Proceedings of the 2024 16th International Conference on Machine Learning and Computing},
year = {2024},
isbn = {9798400709234},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Shenzhen, China}
}

@proceedings{10.1145/3651781,
title = {ICSCA '24: Proceedings of the 2024 13th International Conference on Software and Computer Applications},
year = {2024},
isbn = {9798400708329},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bali Island, Indonesia}
}

@proceedings{10.1145/3652212,
title = {MMVE '24: Proceedings of the 16th International Workshop on Immersive Mixed and Virtual Environment Systems},
year = {2024},
isbn = {9798400706189},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are pleased to present the technical program of the 16th ACM International Workshop on Immersive Mixed and Virtual Environment systems (MMVE) 2024. This workshop has always embraced a multidisciplinary approach, exploring not only the evolution of immersive experiences but also the crossroads where immersive technology intersects with diverse domains. Co-located with ACM Multimedia Systems Conference (MMSys) 2024, MMVE allows the gathering and interaction of researchers in the field of immersive technology, from both academia and industry, with multimedia system researchers.},
location = {Bari, Italy}
}

@proceedings{10.1145/3652583,
title = {ICMR '24: Proceedings of the 2024 International Conference on Multimedia Retrieval},
year = {2024},
isbn = {9798400706196},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are pleased to present the 2024 edition of the ACM International Conference on Multimedia Retrieval, ACM ICMR 2024, that took place from 10-14 June 2024, in Phuket, Thailand.Effectively and efficiently retrieving information from multimedia collections (e.g., text, image, video, audio, sensor data, 3D) based on user needs is one of the most exciting areas in multimedia research. The Annual ACM International Conference on Multimedia Retrieval (ICMR) offers a great opportunity for exchanging leading-edge multimedia retrieval ideas among researchers, practitioners, and other potential users of multimedia retrieval systems. ACM ICMR was created in 2011 in a merger of ACM CIVR (International Conference on Image and Video Retrieval) and ACM MIR (International Conference on Multimedia Information Retrieval). ACM ICMR serves to illuminate the state of the art in multimedia retrieval. ACM ICMR 2024 in Phuket follows the successful previous editions of ICMR in Trento, Italy 2011; Hong Kong, China 2012; Dallas, USA 2013; Glasgow, UK 2014; Shanghai, China 2015; New York, USA 2016; Bucharest, Romania 2017; Yokohama, Japan 2018; Ottawa, Canada 2019; Dublin, Ireland 2020 (online); Taipei, Taiwan 2021 (online); Newark, USA 2022 (hybrid); and Thessaloniki, Greece 2023 (hybrid).},
location = {Phuket, Thailand}
}

@inproceedings{10.1145/3652583.3658094,
author = {Liu, Yang and Shen, Tongfei and Zhang, Dong and Sun, Qingying and Li, Shoushan and Zhou, Guodong},
title = {Comment-aided Video-Language Alignment via Contrastive Pre-training for Short-form Video Humor Detection},
year = {2024},
isbn = {9798400706196},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652583.3658094},
doi = {10.1145/3652583.3658094},
abstract = {The growing importance of multi-modal humor detection within affective computing correlates with the expanding influence of short-form video sharing on social media platforms. In this paper, we propose a novel two-branch hierarchical model for short-form video humor detection (SVHD), named Comment-aided Video-Language Alignment (CVLA) via data-augmented multi-modal contrastive pre-training. Notably, our CVLA not only operates on raw signals across various modal channels but also yields an appropriate multi-modal representation by aligning the video and language components within a consistent semantic space. The experimental results on two humor detection datasets, including DY11k and UR-FUNNY, demonstrate that CVLA dramatically outperforms state-of-the-art and several competitive baseline approaches. Our dataset and code release at https://github.com/yliu-cs/CVLA.},
booktitle = {Proceedings of the 2024 International Conference on Multimedia Retrieval},
pages = {442–450},
numpages = {9},
keywords = {contrastive pre-training, dataset, humor detection, interactive comments, short-form video, video-language alignment},
location = {Phuket, Thailand},
series = {ICMR '24}
}

@proceedings{10.1145/3652628,
title = {ICAICE '23: Proceedings of the 4th International Conference on Artificial Intelligence and Computer Engineering},
year = {2023},
isbn = {9798400708831},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Dalian, China}
}

@proceedings{10.1145/3652920,
title = {AHs '24: Proceedings of the Augmented Humans International Conference 2024},
year = {2024},
isbn = {9798400709807},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Melbourne, VIC, Australia}
}

@proceedings{10.1145/3652963,
title = {SIGMETRICS/PERFORMANCE '24: Abstracts of the 2024 ACM SIGMETRICS/IFIP PERFORMANCE Joint International Conference on Measurement and Modeling of Computer Systems},
year = {2024},
isbn = {9798400706240},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 2024 ACM SIGMETRICS/IFIP Performance Conference on Measurement and Modeling of Computer Systems, held in Venice, Italy from June 10, 2024 to June 14, 2024.We are grateful to our sponsors ACM SIGMETRICS and IFIP for the scientific and technical support of the event, to the U.S. National Science Foundation for providing a generous contribution to support student travel-grants, and to our corporate sponsors Huawei, Akamai, IBM, Imdea Networks, Google, and Almaviva Digitaltec. Moreover, we would like to profusely thank SIGMETRICS General Chair Mor Harchol-Balter, IFIP Working Group 7.3 Chair Mark S. Squillante, and the rest of the SIGMETRICS board for their invaluable assistance throughout the organization of this edition, as well as Giuliano Casale and the previous outgoing board.},
location = {Venice, Italy}
}

@proceedings{10.1145/3653081,
title = {IoTAAI '23: Proceedings of the 2023 5th International Conference on Internet of Things, Automation and Artificial Intelligence},
year = {2023},
isbn = {9798400716485},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Nanchang, China}
}

@inproceedings{10.1145/3653081.3653092,
author = {Zhang, Shangkun and Lei, Haopeng and Zhang, He},
title = {Sketch2RealGAN: A Conditional GAN-based Method for Generating Clothing Images from Sketches},
year = {2024},
isbn = {9798400716485},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3653081.3653092},
doi = {10.1145/3653081.3653092},
abstract = {This algorithm is an innovative algorithm that can automatically generate clothing images from clothing sketches. In order to improve the generation performance, the algorithm uses feature extraction network to extract semantic information from the original sketch, and uses semantic feature encoder to encode these semantic information into feature tensors. High quality clothing image generation is realized by input both the original sketch and the feature tensor into the conditional generation adversarial network. In addition, a two-stage generation algorithm is proposed to generate clothing images from original sketches. The algorithm uses the same model structure in both stages, and finally realizes the clothing image generation by gradually generating the intermediate image.},
booktitle = {Proceedings of the 2023 5th International Conference on Internet of Things, Automation and Artificial Intelligence},
pages = {59–65},
numpages = {7},
keywords = {Clothing image synthesis, generative adversarial network, sketch-to-image translation},
location = {Nanchang, China},
series = {IoTAAI '23}
}

@article{10.1145/3653693,
author = {Alberts, Lize and Lyngs, Ulrik and Van Kleek, Max},
title = {Computers as Bad Social Actors: Dark Patterns and Anti-Patterns in Interfaces that Act Socially},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW1},
url = {https://doi.org/10.1145/3653693},
doi = {10.1145/3653693},
abstract = {Interfaces increasingly mimic human social behaviours. Beyond prototypical examples like chatbots, basic automated systems like app notifications or self-checkout machines likewise address or 'talk to' people in person-like ways. Whilst early evidence suggests social cues can enhance user experience, we lack a good understanding of when, and why, their use in interaction design may be inappropriate. We combined a qualitative survey (n=80) with experience sampling, interview, and workshop studies (n=11) to understand people's attitudes and preferences regarding how a range of automated systems talk to/at them. We thematically analysed examples of phrasings or conduct our participants disliked, their reasons, and how they would prefer to be treated instead. One category of inappropriate use we identified is when social design elements are used to manipulate user behaviour. We distinguish four such tactics: 'agents' playing on users' emotions (e.g., guilt-tripping, coaxing), being pushy, mothering users, or being passive-aggressive. Another category regards pragmatics: personal or situational factors that can make even a seemingly helpful or friendly message come across as rude, tactless, invasive, etc. These include contextual insensitivity (e.g., embarrassing users in public); expressing clearly false personalised care; or treating a user in ways they find misaligned with the system's role or the nature of their relationship. We discuss these inappropriate uses in terms of an emerging 'social' class of dark and anti-patterns. From participant suggestions, we offer recommendations for improving how interfaces treat people in interaction, including broader normative reflections on treating users respectfully.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {202},
numpages = {25},
keywords = {app notifications, chatbots, computers are social actors, conversational user interface, dark patterns, deceptive patterns, dialogue agents, interactional ethics, manipulation, mixed qualitative methods, respect, social engineering}
}

@article{10.1145/3653695,
author = {Wang, Skyler},
title = {How Platform Exchange and Safeguards Matter: The Case of Sexual Risk in Airbnb and Couchsurfing},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW1},
url = {https://doi.org/10.1145/3653695},
doi = {10.1145/3653695},
abstract = {Recent work in CHI and CSCW has devoted increasing attention to how the design of network hospitality platforms shapes user experiences and relational outcomes. In this article, I interrogate how different risk factors emerge based on the type of exchanges these platforms facilitate. To do so, I juxtapose two prominent network hospitality platforms-one facilitating negotiated exchange (i.e., Airbnb) with another facilitating reciprocal exchange (i.e., Couchsurfing). Homing in on sexual risk, an underexplored form of platform danger, and drawing on interviews with 40 female dual-platform users, I argue that Airbnb's provision of binding negotiated exchange and institutional safeguards reduces risk through three mechanisms: casting initial guest-host relation into a buyer-seller arrangement, stabilizing interactional scripts, and formalizing sexual violence recourse. Conversely, Couchsurfing's focus on reciprocal exchange and lack of safeguards increase sexual precarity for users both on- and off-platform. This study demonstrates how platforms with strong prosocial motivations can jeopardize sociality and concludes with design implications for protecting vulnerable user populations.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {204},
numpages = {23},
keywords = {network hospitality, risk, safety, sexual violence, sharing economy}
}

@article{10.1145/3653698,
author = {B\o{}dker, Susanne and Hoggan, Eve and Larsen-Ledet, Ida},
title = {Material Mediation in Collaborative Activity},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW1},
url = {https://doi.org/10.1145/3653698},
doi = {10.1145/3653698},
abstract = {The material qualities of technological mediators are vital to collaborative activity, but current paradigms for collaboration support leave the potential of material mediation largely untapped. The HCI literature addresses both material mediation for individuals and coordination between collaborators - but rarely does it discuss the more direct role of the material as standing between people: its communicative role. This paper unfolds a material/linguistic analysis of four empirical examples from previous work on collaborative writing to showcase how material qualities of both tools and the text-in-progress, used in both planned and improvised manners, help co-authors shift between levels of collaboration, from independent co-ordinated activity to highly collaborative co-constructive activity. On one hand, we see co-authors successfully collaborating through material means; on the other, we see frustrations resulting from limited material expressivity in current tools. This duality between the significance of material mediation and obstacles to drawing on its potential makes clear that our conception of materiality needs elaboration. We point to multimodality as one opportunity for this.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {207},
numpages = {24},
keywords = {activity theory, collaboration, material, mediation}
}

@article{10.1145/3653705,
author = {Madaio, Michael A. and Chen, Jingya and Wallach, Hanna and Wortman Vaughan, Jennifer},
title = {Tinker, Tailor, Configure, Customize: The Articulation Work of Contextualizing an AI Fairness Checklist},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW1},
url = {https://doi.org/10.1145/3653705},
doi = {10.1145/3653705},
abstract = {Many responsible AI resources, such as toolkits, playbooks, and checklists, have been developed to support AI practitioners in identifying, measuring, and mitigating potential fairness-related harms. These resources are often designed to be general purpose in order to be applicable to a variety of use cases, domains, and deployment contexts. However, this can lead to decontextualization, where such resources lack the level of relevance or specificity needed to use them. To understand how AI practitioners might contextualize one such resource, an AI fairness checklist, for their particular use cases, domains, and deployment contexts, we conducted a retrospective contextual inquiry with 13 AI practitioners from seven organizations. We identify how contextualizing this checklist introduces new forms of work for AI practitioners and other stakeholders, as well as opening up new sites for negotiation and contestation of values in AI. We also identify how the contextualization process may help AI practitioners develop a shared language around AI fairness, and we identify tensions related to ownership over this process that suggest larger issues of accountability in responsible AI work.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {214},
numpages = {20},
keywords = {articulation work, ethics, fairness, responsible ai}
}

@article{10.1145/3653707,
author = {Hwang, Sohyeon and Kiene, Charles and Ong, Serene and Shaw, Aaron},
title = {Adopting Third-party Bots for Managing Online Communities},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW1},
url = {https://doi.org/10.1145/3653707},
doi = {10.1145/3653707},
abstract = {Bots have become critical for managing online communities on platforms, especially to match the increasing technical sophistication of online harms. However, community leaders often adoptthird-party bots, creating room for misalignment in their assumptions, expectations, and understandings (i.e., their technological frames) about them. On platforms where sharing bots can be extremely valuable, how community leaders can revise their frames about bots to more effectively adopt them is unclear. In this work, we conducted a qualitative interview study with 16 community leaders on Discord examining how they adopt third-party bots. We found that participants addressed challenges stemming from uncertainties about a bot's security, reliability, and fit through emergent social ecosystems. Formal and informal opportunities to discuss bots with others across communities enabled participants to revise their technological frames over time, closing gaps in bot-specific skills and knowledge. This social process of learning shifted participants' perspectives of the labor of bot adoption into something that was satisfying and fun, underscoring the value of collaborative and communal approaches to adopting bots. Finally, by shaping participants' mental models of the nature, value, and use of bots, social ecosystems also raise some practical tensions in how they support user creativity and customization in third-party bot use. Together, the social nature of adopting third-party bots in our interviews offers insight into how we can better support the sharing of valuable user-facing tools across online communities.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {216},
numpages = {26},
keywords = {bots, community management, moderation, online communities, technology adoption}
}

@proceedings{10.1145/3653804,
title = {CVDL '24: Proceedings of the International Conference on Computer Vision and Deep Learning},
year = {2024},
isbn = {9798400718199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Changsha, China}
}

@proceedings{10.1145/3653863,
title = {SSIP '23: Proceedings of the 2023 6th International Conference on Sensors, Signal and Image Processing},
year = {2023},
isbn = {9798400707995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Nanjing, China}
}

@proceedings{10.1145/3654446,
title = {SPCNC '23: Proceedings of the 2nd International Conference on Signal Processing, Computer Networks and Communications},
year = {2023},
isbn = {9798400716430},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xiamen, China}
}

@proceedings{10.1145/3654823,
title = {CACML '24: Proceedings of the 2024 3rd Asia Conference on Algorithms, Computing and Machine Learning},
year = {2024},
isbn = {9798400716416},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Shanghai, China}
}

@article{10.1145/3654930,
author = {Li, Haoyang and Zhang, Jing and Liu, Hanbing and Fan, Ju and Zhang, Xiaokang and Zhu, Jun and Wei, Renjie and Pan, Hongyan and Li, Cuiping and Chen, Hong},
title = {CodeS: Towards Building Open-source Language Models for Text-to-SQL},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
url = {https://doi.org/10.1145/3654930},
doi = {10.1145/3654930},
abstract = {Language models have shown promising performance on the task of translating natural language questions into SQL queries (Text-to-SQL). However, most of the state-of-the-art (SOTA) approaches rely on powerful yet closed-source large language models (LLMs), such as ChatGPT and GPT-4, which may have the limitations of unclear model architectures, data privacy risks, and expensive inference overheads. To address the limitations, we introduce CodeS, a series of pre-trained language models with parameters ranging from 1B to 15B, specifically designed for the text-to-SQL task. CodeS is a fully open-source language model, which achieves superior accuracy with much smaller parameter sizes. This paper studies the research challenges in building CodeS. To enhance the SQL generation abilities of CodeS, we adopt an incremental pre-training approach using a specifically curated SQL-centric corpus. Based on this, we address the challenges of schema linking and rapid domain adaptation through strategic prompt construction and a bi-directional data augmentation technique. We conduct comprehensive evaluations on multiple datasets, including the widely used Spider benchmark, the newly released BIRD benchmark, robustness-diagnostic benchmarks such as Spider-DK, Spider-Syn, Spider-Realistic, and Dr.Spider, as well as two real-world datasets created for financial and academic applications. The experimental results show that our CodeS achieves new SOTA accuracy and robustness on nearly all challenging text-to-SQL benchmarks.},
journal = {Proc. ACM Manag. Data},
month = may,
articleno = {127},
numpages = {28},
keywords = {language model, natural language interface for databases, text-to-SQL}
}

@article{10.1145/3654963,
author = {Pirhadi, Alireza and Moslemi, Mohammad Hossein and Cloninger, Alexander and Milani, Mostafa and Salimi, Babak},
title = {OTClean: Data Cleaning for Conditional Independence Violations using Optimal Transport},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
url = {https://doi.org/10.1145/3654963},
doi = {10.1145/3654963},
abstract = {Ensuring Conditional Independence (CI) constraints is pivotal for the development of fair and trustworthy machine learning models. In this paper, we introduce OTClean, a framework that harnesses optimal transport theory for data repair under CI constraints. Optimal transport theory provides a rigorous framework for measuring the discrepancy between probability distributions, thereby ensuring control over data utility. We formulate the data repair problem concerning CIs as a Quadratically Constrained Linear Program (QCLP) and propose an alternating method for its solution. However, this approach faces scalability issues due to the computational cost associated with computing optimal transport distances, such as the Wasserstein distance. To overcome these scalability challenges, we reframe our problem as a regularized optimization problem, enabling us to develop an iterative algorithm inspired by Sinkhorn's matrix scaling algorithm, which efficiently addresses high-dimensional and large-scale data. Through extensive experiments, we demonstrate the efficacy and efficiency of our proposed methods, showcasing their practical utility in real-world data cleaning and preprocessing tasks. Furthermore, we provide comparisons with traditional approaches, highlighting the superiority of our techniques in terms of preserving data utility while ensuring adherence to the desired CI constraints.},
journal = {Proc. ACM Manag. Data},
month = may,
articleno = {160},
numpages = {26},
keywords = {algorithmic fairness, conditional independence, data cleaning, data integrity, data transformation, dataset repair, machine learning}
}

@article{10.1145/3654966,
author = {Le, Van-Hoang and Zhang, Hongyu},
title = {PreLog: A Pre-trained Model for Log Analytics},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
url = {https://doi.org/10.1145/3654966},
doi = {10.1145/3654966},
abstract = {Large-scale software-intensive systems often produce a large volume of logs to record runtime status and events for troubleshooting purposes. The rich information in log data enables a variety of system management and diagnosis tasks. Over the years, many approaches have been proposed for automated log analytics. However, these approaches usually design separate models for each specific task, which cannot be generalized to other tasks. They are also not robust when dealing with logs from heterogeneous sources. In this paper, we propose PreLog, a novel pre-trained model for log analytics. PreLog is pre-trained on a large amount of unlabelled log data to capture the semantic meaning of logs. We design two log-specific pre-training objectives, including entry-level and sequence-level objectives, which enable PreLog to better understand the hidden structure and semantics of logs. To perform downstream log analytics tasks, we leverage a prompt tuning paradigm to convert downstream tasks' objectives into a similar form as the pre-training stage. We have conducted extensive experiments on two main log analytics tasks (i.e., log parsing and log-based anomaly detection). Experimental results show that PreLog achieves better or comparable results in comparison with the state-of-the-art, task-specific approaches. PreLog is cost-effective and can be uniformly applied to many log analytics tasks through the prompt tuning paradigm.},
journal = {Proc. ACM Manag. Data},
month = may,
articleno = {163},
numpages = {28},
keywords = {log analytics, log data, log parsing, log-based anomaly detection, pre-training}
}

@article{10.1145/3654975,
author = {D\"{o}hmen, Till and Geacu, Radu and Hulsebos, Madelon and Schelter, Sebastian},
title = {SchemaPile: A Large Collection of Relational Database Schemas},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
url = {https://doi.org/10.1145/3654975},
doi = {10.1145/3654975},
abstract = {Access to fine-grained schema information is crucial for understanding how relational databases are designed and used in practice, and for building systems that help users interact with them. Furthermore, such information is required as training data to leverage the potential of large language models (LLMs) for improving data preparation, data integration and natural language querying. Existing single-table corpora such as GitTables provide insights into how tables are structured in-the-wild, but lack detailed schema information about how tables relate to each other, as well as metadata like data types or integrity constraints. On the other hand, existing multi-table (or database schema) datasets are rather small and attribute-poor, leaving it unclear to what extent they actually represent typical real-world database schemas.In order to address these challenges, we present SchemaPile, a corpus of 221,171 database schemas, extracted from SQL files on GitHub. It contains 1.7 million tables with 10 million column definitions, 700 thousand foreign key relationships, seven million integrity constraints, and data content for more than 340 thousand tables. We conduct an in-depth analysis on the millions of schema metadata properties in our corpus, as well as its highly diverse language and topic distribution. In addition, we showcase the potential of corpus to improve a variety of data management applications, e.g., fine-tuning LLMs for schema-only foreign key detection, improving CSV header detection and evaluating multi-dialect SQL parsers. We publish the code and data for recreating SchemaPile and a permissively licensed subset SchemaPile-Perm.},
journal = {Proc. ACM Manag. Data},
month = may,
articleno = {172},
numpages = {25},
keywords = {csv parsing, dataset, foreign key detection, large language models, relational database schemas, sql parsing}
}

@article{10.1145/3654979,
author = {Li, Peng and He, Yeye and Yashar, Dror and Cui, Weiwei and Ge, Song and Zhang, Haidong and Rifinski Fainman, Danielle and Zhang, Dongmei and Chaudhuri, Surajit},
title = {Table-GPT: Table Fine-tuned GPT for Diverse Table Tasks},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
url = {https://doi.org/10.1145/3654979},
doi = {10.1145/3654979},
abstract = {Language models, such as GPT-3 and ChatGPT, demonstrate remarkable abilities to follow diverse human instructions and perform a wide range of tasks, using instruction fine-tuning. However, when we test language models with a range of basic table-understanding tasks, we observe that today's language models are still sub-optimal in many table-related tasks, likely because they are pre-trained predominantly on one-dimensional natural-language texts, whereas relational tables are two-dimensional objects. In this work, we propose a new "emphtable fine-tuning '' paradigm, where we continue to train/fine-tune language models like GPT-3.5 and ChatGPT, using diverse table-tasks synthesized from real tables as training data, which is analogous to "instruction fine-tuning'', but with the goal of enhancing language models' ability to understand tables and perform table tasks. We show that our resulting sys models demonstrate: (1) better table-understanding capabilities, by consistently outperforming the vanilla GPT-3.5 and ChatGPT, on a wide range of table tasks (data transformation, data cleaning, data profiling, data imputation, table-QA, etc.), including tasks that are completely holdout and unseen during training, and (2) strong generalizability, in its ability to respond to diverse human instructions to perform new and unseen table-tasks, in a manner similar to GPT-3.5 and ChatGPT. Our code and data have been released at https://github.com/microsoft/Table-GPT for future research.},
journal = {Proc. ACM Manag. Data},
month = may,
articleno = {176},
numpages = {28},
keywords = {instruction fine-tuning, language models, model generalizability, multi-task training, synthesized training data, table fine-tuning, table models, table tasks, unseen tasks}
}

@article{10.1145/3654992,
author = {Wu, Yang and Wan, Yao and Zhang, Hongyu and Sui, Yulei and Wei, Wucai and Zhao, Wei and Xu, Guandong and Jin, Hai},
title = {Automated Data Visualization from Natural Language via Large Language Models: An Exploratory Study},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
url = {https://doi.org/10.1145/3654992},
doi = {10.1145/3654992},
abstract = {The Natural Language to Visualization (NL2Vis) task aims to transform natural-language descriptions into visual representations for a grounded table, enabling users to gain insights from vast amounts of data. Recently, many deep learning-based approaches have been developed for NL2Vis. Despite the considerable efforts made by these approaches, challenges persist in visualizing data sourced from unseen databases or spanning multiple tables. Taking inspiration from the remarkable generation capabilities of Large Language Models (LLMs), this paper conducts an empirical study to evaluate their potential in generating visualizations, and explore the effectiveness of in-context learning prompts for enhancing this task. In particular, we first explore the ways of transforming structured tabular data into sequential text prompts, as to feed them into LLMs and analyze which table content contributes most to the NL2Vis. Our findings suggest that transforming structured tabular data into programs is effective, and it is essential to consider the table schema when formulating prompts. Furthermore, we evaluate two types of LLMs: finetuned models (e.g., T5-Small) and inference-only models (e.g., GPT-3.5), against state-of-the-art methods, using the NL2Vis benchmarks (i.e., nvBench). The experimental results reveal that LLMs outperform baselines, with inference-only models consistently exhibiting performance improvements, at times even surpassing fine-tuned models when provided with certain few-shot demonstrations through in-context learning. Finally, we analyze when the LLMs fail in NL2Vis, and propose to iteratively update the results using strategies such as chain-of-thought, role-playing, and code-interpreter. The experimental results confirm the efficacy of iterative updates and hold great potential for future study.},
journal = {Proc. ACM Manag. Data},
month = may,
articleno = {115},
numpages = {28},
keywords = {code generation, data analysis, data visualization, exploratory study, large language models, natural language processing}
}

@proceedings{10.1145/3655693,
title = {EICC '24: Proceedings of the 2024 European Interdisciplinary Cybersecurity Conference},
year = {2024},
isbn = {9798400716515},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xanthi, Greece}
}

@inproceedings{10.1145/3655693.3655701,
author = {Y\i{}ld\i{}r\i{}m, Recep and Ayd\i{}n, Kerem and \c{C}etin, Or\c{c}un},
title = {Evaluating the Impact of Conventional Code Analysis Against Large Language Models in API Vulnerability Detection},
year = {2024},
isbn = {9798400716515},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3655693.3655701},
doi = {10.1145/3655693.3655701},
abstract = {In the rapidly changing world of digital technologies, application programming interfaces (APIs) have become extremely important to allow different software applications to communicate with each other. This communication has greatly enhanced the capabilities and functionality of web applications. This shift towards using more APIs in software development marks a major change in how digital services connect with each other. However, this progress also brings certain security concerns. The increasing reliance on APIs underscores the importance of employing tools that allow early detection and remediation of security vulnerabilities. In this paper, we detail a study that engaged 10 static code analysers and four popular Large Language Models (LLMs), each queried with two unique prompts. Our focus was on assessing their ability to detect a compilation of 40 API vulnerabilities in the source code, specifically selected to represent each category within the OWASP Top 10 API Security Risks. Our results revealed significant variations in the performance of these tools. ChatGPT 4 emerged as the most effective LLM, with a detection rate of 62.5\% for the first prompt and 42.5\% for the second prompt. In contrast, LLaMA 2 showed the lowest effectiveness in both prompts. Meanwhile, static code analyser results showed a generally low detection rate of API vulnerabilities. Snyk led the group with a 25\% detection rate, while several analysers such as pylint, Pyre, and Trivy did not detect any vulnerabilities. These findings indicate that while static code analysers are valuable in certain contexts, their effectiveness remains lower than LLMs when appropriately prompted.},
booktitle = {Proceedings of the 2024 European Interdisciplinary Cybersecurity Conference},
pages = {57–64},
numpages = {8},
keywords = {AI in cybersecurity, API security, API vulnerabilities, Large language models, Static code analysis, Vulnerability detection},
location = {Xanthi, Greece},
series = {EICC '24}
}

@proceedings{10.1145/3655755,
title = {IVSP '24: Proceedings of the 2024 6th International Conference on Image, Video and Signal Processing},
year = {2024},
isbn = {9798400716829},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Ikuta, Japan}
}

@article{10.1145/3656296,
author = {Wang, Changjie and Scazzariello, Mariano and Farshin, Alireza and Ferlin, Simone and Kosti\'{c}, Dejan and Chiesa, Marco},
title = {NetConfEval: Can LLMs Facilitate Network Configuration?},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {CoNEXT2},
url = {https://doi.org/10.1145/3656296},
doi = {10.1145/3656296},
abstract = {This paper explores opportunities to utilize Large Language Models (LLMs) to make network configuration human-friendly, simplifying the configuration of network devices \&amp; development of routing algorithms and minimizing errors. We design a set of benchmarks (NetConfEval) to examine the effectiveness of different models in facilitating and automating network configuration. More specifically, we focus on the scenarios where LLMs translate high-level policies, requirements, and descriptions (i.e., specified in natural language) into low-level network configurations \&amp; Python code. NetConfEval considers four tasks that could potentially facilitate network configuration, such as (i) generating high-level requirements into a formal specification format, (ii) generating API/function calls from high-level requirements, (iii) developing routing algorithms based on high-level descriptions, and (iv) generating low-level configuration for existing and new protocols based on input documentation. Learning from the results of our study, we propose a set of principles to design LLM-based systems to configure networks. Finally, we present two GPT-4-based prototypes to (i) automatically configure P4-enabled devices from a set of high-level requirements and (ii) integrate LLMs into existing network synthesizers.},
journal = {Proc. ACM Netw.},
month = jun,
articleno = {7},
numpages = {25},
keywords = {benchmark, code generation, function calling, large language models (llms), network configuration, network synthesizer, p4, rag, routing algorithms}
}

@proceedings{10.1145/3656650,
title = {AVI '24: Proceedings of the 2024 International Conference on Advanced Visual Interfaces},
year = {2024},
isbn = {9798400717642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {AVI 2024 is the 17th edition of the International Conference on Advanced Visual Interfaces, held in Arenzano, Genoa (IT), in cooperation with ACM, ACM SIGCHI, ACM SIGMM, and ACM SIGWEB.Every two years since 1992, AVI has gathered a vast international community of experts with a wide range of backgrounds. Throughout three decades, AVI has gained and holds a prestigious position among International HCI conferences, boasting a dedicated nucleus of returning participants, but also providing a venue for young researchers to show their achievements and establish contacts with senior community members.AVI 2024 presents a broad and sound scientific program covering traditional AVI topics on information and data visualization, interaction with multimodal user interfaces, augmented and virtual reality, while also addressing emerging topics including the application of generative artificial intelligence in HCI design and evaluation.The program features the presentation of 21 long research papers and 28 short papers selected through a rigorous double-blind reviewing process and organized into sessions on 13 main topics. Furthermore, it includes the presentation of 48 poster papers, 9 demo papers, and 11 doctoral consortium papers, selected through a single-blind reviewing process. Finally, the rich and vibrant program includes 3 keynote talks, 3 tutorials, and 10 workshops addressing some of the most exciting issues in HCI.Submissions to AVI 2024 came from 34 different countries distributed in descending order in Europe, Asia, North America, South America, and Africa.},
location = {Arenzano, Genoa, Italy}
}

@proceedings{10.1145/3656766,
title = {ICBAR '23: Proceedings of the 2023 3rd International Conference on Big Data, Artificial Intelligence and Risk Management},
year = {2023},
isbn = {9798400716478},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Chengdu, China}
}

@proceedings{10.1145/3657054,
title = {dg.o '24: Proceedings of the 25th Annual International Conference on Digital Government Research},
year = {2024},
isbn = {9798400709883},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Taipei, Taiwan}
}

@inproceedings{10.1145/3657054.3657056,
author = {Lin, Kun-Hsien and Shen, Cheng-An and Cheng, Su-Chuan},
title = {Applications of AI in Digital Governance Services for Local Taxes- a case of the Local Tax Bureau of Taichung City Government},
year = {2024},
isbn = {9798400709883},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657054.3657056},
doi = {10.1145/3657054.3657056},
abstract = {Since the onset of the COVID-19 pandemic, all Countries have been actively promoting adaptive governance in the digital government. Initiatives such as remote work, online application processes, and telemedicine have seen significant advancement. Pre-trained AI chatbots can be pre-equipped with specialized knowledge relevant to government agencies and can seamlessly convert non-structured verbal queries from the public into correctly formulated questions with standardized answers. This capability ensures that individuals no longer face difficulties in obtaining the desired responses due to variations in the order or inadequacy of question descriptions.This study has three main research objectives. First purpose is to enhance the precision of pre-trained AI chatbot responses through the utilization of normalized training corpora methods. Second purpose is to construct a functional robot capable of answering tax-related questions and providing services. The third purpose is to evaluate the original training corpora and system responses of the robot through practical inquiries in this study.},
booktitle = {Proceedings of the 25th Annual International Conference on Digital Government Research},
pages = {6–18},
numpages = {13},
keywords = {citizens’ adoption of IT, digital governance service, pre-trained AI chatbots},
location = {Taipei, Taiwan},
series = {dg.o '24}
}

@inproceedings{10.1145/3657054.3657079,
author = {Barcellos, Raissa and Bernardini, Flavia and Zuiderwijk, Anneke and Viterbo, Jose},
title = {Exploring Interpretability in Open Government Data with ChatGPT},
year = {2024},
isbn = {9798400709883},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657054.3657079},
doi = {10.1145/3657054.3657079},
abstract = {The global initiative supporting open government data (OGD) has witnessed significant strides in the last decade. This study delves into the prospective integration of Artificial Intelligence (AI) with Hippolyta, a framework meticulously crafted to amplify the interpretability of government data. The aim is to scrutinize the viability of this integration, conducting a technical investigation in the realms of open government data and artificial intelligence. In contributing to the expansive field of OGD, this research focuses on elucidating the interpretability of data originating from governmental sources. Through an exploration of the technical feasibility surrounding the fusion of AI with Hippolyta, we aim to pave the path for advancements, fostering heightened interpretability and overarching enhancements in the understanding of government data.},
booktitle = {Proceedings of the 25th Annual International Conference on Digital Government Research},
pages = {186–195},
numpages = {10},
keywords = {Open government data, data interpretability},
location = {Taipei, Taiwan},
series = {dg.o '24}
}

@article{10.1145/3657284,
author = {Shen, Meng and Tan, Zhehui and Niyato, Dusit and Liu, Yuzhi and Kang, Jiawen and Xiong, Zehui and Zhu, Liehuang and Wang, Wei and Shen, Xuemin (Sherman)},
title = {Artificial Intelligence for Web 3.0: A Comprehensive Survey},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {10},
issn = {0360-0300},
url = {https://doi.org/10.1145/3657284},
doi = {10.1145/3657284},
abstract = {Web 3.0 is the next generation of the Internet built on decentralized technologies such as blockchain and cryptography. It is born to solve the problems faced by the previous generation of the Internet such as imbalanced distribution of interests, monopoly of platform resources, and leakage of personal privacy. In this survey, we discuss the latest development status of Web 3.0 and the application of emerging AI technologies in it. First, we investigate the current successful practices of Web 3.0 and various components in the current Web 3.0 ecosystem and thus propose the hierarchical architecture of the Web 3.0 ecosystem from the perspective of application scenarios. The architecture we proposed contains four layers: data management, value circulation, ecological governance, and application scenarios. We dive into the current state of development and the main challenges and issues present in each layer. In this context, we find that AI technology will have great potential. We first briefly introduce the role that artificial intelligence technology may play in the development of Web 3.0. Then, we conduct an in-depth analysis of the current application status of artificial intelligence technology in the four layers of Web 3.0 and provide some insights into its potential future development directions.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {247},
numpages = {39},
keywords = {Web 3.0, artificial intelligence, blockchain, computing network}
}

@proceedings{10.1145/3658271,
title = {SBSI '24: Proceedings of the 20th Brazilian Symposium on Information Systems},
year = {2024},
isbn = {9798400709968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Juiz de Fora, Brazil}
}

@proceedings{10.1145/3659211,
title = {BDEIM '23: Proceedings of the 2023 4th International Conference on Big Data Economy and Information Management},
year = {2023},
isbn = {9798400716669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Zhengzhou, China}
}

@article{10.1145/3659589,
author = {Zhou, Yexu and Zhao, Haibin and Huang, Yiran and R\"{o}ddiger, Tobias and Kurnaz, Murat and Riedel, Till and Beigl, Michael},
title = {AutoAugHAR: Automated Data Augmentation for Sensor-based Human Activity Recognition},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
url = {https://doi.org/10.1145/3659589},
doi = {10.1145/3659589},
abstract = {Sensor-based HAR models face challenges in cross-subject generalization due to the complexities of data collection and annotation, impacting the size and representativeness of datasets. While data augmentation has been successfully employed in domains like natural language and image processing, its application in HAR remains underexplored. This study presents AutoAugHAR, an innovative two-stage gradient-based data augmentation optimization framework. AutoAugHAR is designed to take into account the unique attributes of candidate augmentation operations and the unique nature and challenges of HAR tasks. Notably, it optimizes the augmentation pipeline during HAR model training without substantially extending the training duration. In evaluations on eight inertial-measurement-units-based benchmark datasets using five HAR models, AutoAugHAR has demonstrated superior robustness and effectiveness compared to other leading data augmentation frameworks. A salient feature of AutoAugHAR is its model-agnostic design, allowing for its seamless integration with any HAR model without the need for structural modifications. Furthermore, we also demonstrate the generalizability and flexible extensibility of AutoAugHAR on four datasets from other adjacent domains. We strongly recommend its integration as a standard protocol in HAR model training and will release it as an open-source tool1.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = may,
articleno = {48},
numpages = {27},
keywords = {automated data augmentation, human activity recognition, machine learning}
}

@article{10.1145/3659600,
author = {Xu, Zhenyu and Xu, Hailin and Lu, Zhouyang and Zhao, Yingying and Zhu, Rui and Wang, Yujiang and Dong, Mingzhi and Chang, Yuhu and Lv, Qin and Dick, Robert P. and Yang, Fan and Lu, Tun and Gu, Ning and Shang, Li},
title = {Can Large Language Models Be Good Companions? An LLM-Based Eyewear System with Conversational Common Ground},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
url = {https://doi.org/10.1145/3659600},
doi = {10.1145/3659600},
abstract = {Developing chatbots as personal companions has long been a goal of artificial intelligence researchers. Recent advances in Large Language Models (LLMs) have delivered a practical solution for endowing chatbots with anthropomorphic language capabilities. However, it takes more than LLMs to enable chatbots that can act as companions. Humans use their understanding of individual personalities to drive conversations. Chatbots also require this capability to enable human-like companionship. They should act based on personalized, real-time, and time-evolving knowledge of their users. We define such essential knowledge as the common ground between chatbots and their users, and we propose to build a common-ground-aware dialogue system from an LLM-based module, named OS-1, to enable chatbot companionship. Hosted by eyewear, OS-1 can sense the visual and audio signals the user receives and extract real-time contextual semantics. Those semantics are categorized and recorded to formulate historical contexts from which the user's profile is distilled and evolves over time, i.e., OS-1 gradually learns about its user. OS-1 combines knowledge from real-time semantics, historical contexts, and user-specific profiles to produce a common-ground-aware prompt input into the LLM module. The LLM's output is converted to audio, spoken to the wearer when appropriate. We conduct laboratory and in-field studies to assess OS-1's ability to build common ground between the chatbot and its user. The technical feasibility and capabilities of the system are also evaluated. Our results show that by utilizing personal context, OS-1 progressively develops a better understanding of its users. This enhances user satisfaction and potentially leads to various personal service scenarios, such as emotional support and assistance.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = may,
articleno = {87},
numpages = {41},
keywords = {Smart eyewear, common ground, context-aware, large language model}
}

@article{10.1145/3659612,
author = {Wu, Ziyu and Xie, Fangting and Fang, Yiran and Liang, Zhen and Wan, Quan and Xiong, Yufan and Cai, Xiaohui},
title = {Seeing through the Tactile: 3D Human Shape Estimation from Temporal In-Bed Pressure Images},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
url = {https://doi.org/10.1145/3659612},
doi = {10.1145/3659612},
abstract = {Humans spend about one-third of their lives resting. Reconstructing human dynamics in in-bed scenarios is of considerable significance in sleep studies, bedsore monitoring, and biomedical factor extractions. However, the mainstream human pose and shape estimation methods mainly focus on visual cues, facing serious issues in non-line-of-sight environments. Since in-bed scenarios contain complicated human-environment contact, pressure-sensing bedsheets provide a non-invasive and privacy-preserving approach to capture the pressure distribution on the contact surface, and have shown prospects in many downstream tasks. However, few studies focus on in-bed human mesh recovery. To explore the potential of reconstructing human meshes from the sensed pressure distribution, we first build a high-quality temporal human in-bed pose dataset, TIP, with 152K multi-modality synchronized images. We then propose a label generation pipeline for in-bed scenarios to generate reliable 3D mesh labels with a SMPLify-based optimizer. Finally, we present PIMesh, a simple yet effective temporal human shape estimator to directly generate human meshes from pressure image sequences. We conduct various experiments to evaluate PIMesh's performance, showing that PIMesh archives 79.17mm joint position errors on our TIP dataset. The results demonstrate that the pressure-sensing bedsheet could be a promising alternative for long-term in-bed human shape estimation.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = may,
articleno = {86},
numpages = {39},
keywords = {datasets, deep learning, human mesh recovery, pressure-sensing mattress, smart textile}
}

@proceedings{10.1145/3659914,
title = {PASC '24: Proceedings of the Platform for Advanced Scientific Computing Conference},
year = {2024},
isbn = {9798400706394},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The PASC Conference series is an international and interdisciplinary platform for the exchange of knowledge in scientific computing and computational science with a strong focus on methods, tools, algorithms, workflows, application challenges, and novel techniques in the context of scientific usage of high-performance computing.},
location = {Zurich, Switzerland}
}

@proceedings{10.1145/3660043,
title = {ICIEAI '23: Proceedings of the 2023 International Conference on Information Education and Artificial Intelligence},
year = {2023},
isbn = {9798400716157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xiamen, China}
}

@proceedings{10.1145/3660395,
title = {AIBDF '23: Proceedings of the 2023 3rd Guangdong-Hong Kong-Macao Greater Bay Area Artificial Intelligence and Big Data Forum},
year = {2023},
isbn = {9798400716362},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Guangzhou, China}
}

@inproceedings{10.1145/3661167.3661200,
author = {Mastropaolo, Antonio and Nardone, Vittoria and Bavota, Gabriele and Di Penta, Massimiliano},
title = {How the Training Procedure Impacts the Performance of Deep Learning-based Vulnerability Patching},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661200},
doi = {10.1145/3661167.3661200},
abstract = {Generative deep learning (DL) models have been successfully adopted for vulnerability patching. However, such models require the availability of a large dataset of patches to learn from. To overcome this issue, researchers have proposed to start from models pre-trained with general knowledge, either on the programming language or on similar tasks such as bug fixing. Despite the efforts in the area of automated vulnerability patching, there is a lack of systematic studies on how these different training procedures impact the performance of DL models for such a task. This paper provides a manyfold contribution to bridge this gap, by (i) comparing existing solutions of self-supervised and supervised pre-training for vulnerability patching; and (ii) for the first time, experimenting with different kinds of prompt-tuning for this task. The study required to train/test 23 DL models. We found that a supervised pre-training focused on bug-fixing, while expensive in terms of data collection, substantially improves DL-based vulnerability patching. When applying prompt-tuning on top of this supervised pre-trained model, there is no significant gain in performance. Instead, prompt-tuning is an effective and cheap solution to substantially boost the performance of self-supervised pre-trained models, i.e., those not relying on the bug-fixing pre-training.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {150–159},
numpages = {10},
keywords = {Machine Learning on Code, Pre-Trained Models, Prompt Tuning, Software Vulnerability Repair},
location = {Salerno, Italy},
series = {EASE '24}
}

@proceedings{10.1145/3661304,
title = {GRADES-NDA '24: Proceedings of the 7th Joint Workshop on Graph Data Management Experiences \&amp; Systems (GRADES) and Network Data Analytics (NDA)},
year = {2024},
isbn = {9798400706530},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are delighted to present the papers from the 7th GRADES-NDA Joint Workshop on Graph Data Management Experiences \&amp; Systems and Network Data Analytics which took place on 14th June 2024 co-located with ACM SIGMOD held in Santiago, Chile.},
location = {Santiago, AA, Chile}
}

@proceedings{10.1145/3661638,
title = {AISNS '23: Proceedings of the 2023 International Conference on Artificial Intelligence, Systems and Network Security},
year = {2023},
isbn = {9798400716966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Mianyang, China}
}

@proceedings{10.1145/3662004,
title = {NetAISys '24: Proceedings of the 2nd International Workshop on Networked AI Systems},
year = {2024},
isbn = {9798400706615},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Minato-ku, Tokyo, Japan}
}

@proceedings{10.1145/3662158,
title = {PODC '24: Proceedings of the 43rd ACM Symposium on Principles of Distributed Computing},
year = {2024},
isbn = {9798400706684},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {PODC is the premier forum for presentation of research on all aspects of distributed computing, including the theory, design, implementation, and applications of distributed algorithms, systems, and networks.},
location = {Nantes, France}
}

@proceedings{10.1145/3662165,
title = {DBTest '24: Proceedings of the Tenth International Workshop on Testing Database Systems},
year = {2024},
isbn = {9798400706691},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Santiago, AA, Chile}
}

@proceedings{10.1145/3663741,
title = {BiDEDE '24: Proceedings of the International Workshop on Big Data in Emergent Distributed Environments},
year = {2024},
isbn = {9798400706790},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Santiago, AA, Chile}
}

@proceedings{10.1145/3663742,
title = {aiDM '24: Proceedings of the Seventh International Workshop on Exploiting Artificial Intelligence Techniques for Data Management},
year = {2024},
isbn = {9798400706806},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Santiago, AA, Chile}
}

@inproceedings{10.1145/3663742.3663971,
author = {Jamil, Hasan M.},
title = {Smart Science Needs Linked Open Data with a Dash of Large Language Models and Extended Relations},
year = {2024},
isbn = {9798400706806},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663742.3663971},
doi = {10.1145/3663742.3663971},
abstract = {Quality scientific inquiries depend on access to data distributed over the entire globe. Linked open data (LOD) and FAIRness play major roles in ensuring access to data that scientists need to answer interesting questions. However, a data model and a query language to compute responses to complex scientific inquiries remain outstanding. As the recent emergence of large language models (LLM) reshape how we interact with machines, an intriguing prospect of posing scientific inquiries to smart machines suddenly appears realizable in which a natural language ChatBot is empowered with a LOD knowledgebase as its data source. In this paper, we introduce a model for an LLM interpreter, called ProAb, that aims to answer natural language scientific queries using a structured query language called Needle in which the LOD is viewed as a set of tables. We discuss the contours of ProAb, present its preliminary and experimental design, and highlight its salient features using an illustrative example. It should be apparent that a full automation of ProAb is feasible with further research.},
booktitle = {Proceedings of the Seventh International Workshop on Exploiting Artificial Intelligence Techniques for Data Management},
articleno = {1},
numpages = {11},
keywords = {Extended Relational Model, Intelligent User Interface, Large Language Model, Query Processing, Structured Query Language},
location = {Santiago, AA, Chile},
series = {aiDM '24}
}

@book{10.1145/3664191,
author = {Kumar, Amruth N. and Raj, Rajendra K. and Aly, Sherif G. and Anderson, Monica D. and Becker, Brett A. and Blumenthal, Richard L. and Eaton, Eric and Epstein, Susan L. and Goldweber, Michael and Jalote, Pankaj and Lea, Douglas and Oudshoorn, Michael and Pias, Marcelo and Reiser, Susan and Servin, Christian and Simha, Rahul and Winters, Titus and Xiang, Qiao},
title = {Computer Science Curricula 2023},
year = {2024},
isbn = {9798400710339},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA}
}

@article{10.1145/3664295,
author = {Popa, Raluca Ada},
title = {Confidential Computing or Cryptographic Computing? Tradeoffs between cryptography and hardware enclaves},
year = {2024},
issue_date = {March/April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {2},
issn = {1542-7730},
url = {https://doi.org/10.1145/3664295},
doi = {10.1145/3664295},
abstract = {Secure computation via MPC/homomorphic encryption versus hardware enclaves presents tradeoffs involving deployment, security, and performance. Regarding performance, it matters a lot which workload you have in mind. For simple workloads such as simple summations, low-degree polynomials, or simple machine-learning tasks, both approaches can be ready to use in practice, but for rich computations such as complex SQL analytics or training large machine-learning models, only the hardware enclave approach is at this moment practical enough for many real-world deployment scenarios.},
journal = {Queue},
month = may,
pages = {108–132},
numpages = {25}
}

@proceedings{10.1145/3665601,
title = {GUIDE-AI '24: Proceedings of the Conference on Governance, Understanding and Integration of Data for Effective and Responsible AI},
year = {2024},
isbn = {9798400706943},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Santiago, AA, Chile}
}

@article{10.14778/3641204.3641221,
author = {Gao, Dawei and Wang, Haibin and Li, Yaliang and Sun, Xiuyu and Qian, Yichen and Ding, Bolin and Zhou, Jingren},
title = {Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation},
year = {2024},
issue_date = {January 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {5},
issn = {2150-8097},
url = {https://doi.org/10.14778/3641204.3641221},
doi = {10.14778/3641204.3641221},
abstract = {Large language models (LLMs) have emerged as a new paradigm for Text-to-SQL task. However, the absence of a systematical benchmark inhibits the development of designing effective, efficient and economic LLM-based Text-to-SQL solutions. To address this challenge, in this paper, we first conduct a systematical and extensive comparison over existing prompt engineering methods, including question representation, example selection and example organization, and with these experimental results, we elaborate their pros and cons. Based on these findings, we propose a new integrated solution, named DAIL-SQL, which refreshes the Spider leaderboard with 86.6\% execution accuracy and sets a new bar.To explore the potential of open-source LLM, we investigate them in various scenarios, and further enhance their performance with supervised fine-tuning. Our explorations highlight open-source LLMs' potential in Text-to-SQL, as well as the advantages and disadvantages of the supervised fine-tuning. Additionally, towards an efficient and economic LLM-based Text-to-SQL solution, we emphasize the token efficiency in prompt engineering and compare the prior studies under this metric. We hope that our work provides a deeper understanding of Text-to-SQL with LLMs, and inspires further investigations and broad applications.},
journal = {Proc. VLDB Endow.},
month = jan,
pages = {1132–1145},
numpages = {14}
}

@article{10.14778/3659437.3659449,
author = {Lao, Jiale and Wang, Yibo and Li, Yufei and Wang, Jianping and Zhang, Yunjia and Cheng, Zhiyuan and Chen, Wanghu and Tang, Mingjie and Wang, Jianguo},
title = {GPTuner: A Manual-Reading Database Tuning System via GPT-Guided Bayesian Optimization},
year = {2024},
issue_date = {April 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {8},
issn = {2150-8097},
url = {https://doi.org/10.14778/3659437.3659449},
doi = {10.14778/3659437.3659449},
abstract = {Modern database management systems (DBMS) expose hundreds of configurable knobs to control system behaviours. Determining the appropriate values for these knobs to improve DBMS performance is a long-standing problem in the database community. As there is an increasing number of knobs to tune and each knob could be in continuous or categorical values, manual tuning becomes impractical. Recently, automatic tuning systems using machine learning methods have shown great potentials. However, existing approaches still incur significant tuning costs or only yield sub-optimal performance. This is because they either ignore the extensive domain knowledge available (e.g., DBMS manuals and forum discussions) and only rely on the runtime feedback of benchmark evaluations to guide the optimization, or they utilize the domain knowledge in a limited way. Hence, we propose GPTuner, a manual-reading database tuning system that leverages domain knowledge extensively and automatically to optimize search space and enhance the runtime feedback-based optimization process. Firstly, we develop a Large Language Model (LLM)-based pipeline to collect and refine heterogeneous knowledge, and propose a prompt ensemble algorithm to unify a structured view of the refined knowledge. Secondly, using the structured knowledge, we (1) design a workload-aware and training-free knob selection strategy, (2) develop a search space optimization technique considering the value range of each knob, and (3) propose a Coarse-to-Fine Bayesian Optimization Framework to explore the optimized space. Finally, we evaluate GPTuner under different benchmarks (TPC-C and TPC-H), metrics (throughput and latency) as well as DBMS (PostgreSQL and MySQL). Compared to the state-of-the-art approaches, GPTuner identifies better configurations in 16x less time on average. Moreover, GPTuner achieves up to 30\% performance improvement (higher throughput or lower latency) over the best-performing alternative.},
journal = {Proc. VLDB Endow.},
month = apr,
pages = {1939–1952},
numpages = {14}
}

@proceedings{10.5555/3635637,
title = {AAMAS '24: Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems},
year = {2024},
isbn = {9798400704864},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Welcome to AAMAS-2024, the 23th edition of the International Conference on Autonomous Agents and Multiagent Systems!AAMAS is the largest and most influential conference in the area of agents and multiagent systems, bringing together researchers and practitioners in all areas of agent technology and providing an internationally renowned high-profile forum for publishing and finding out about the latest developments in the field. AAMAS is the flagship conference of the non-profit International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS).After two attempts to hold AAMAS in New Zealand for the first time, which were forced online by the COVID19 pandemic, we are happy that the 2024 edition finally comes to Auckland, New Zealand. Previous editions were held in Bologna (2002), Melbourne (2003), New York (2004), Utrecht (2005), Hakodate (2006), Honolulu (2007), Estoril (2008), Budapest (2009), Toronto (2010), Taipei (2011), Valencia (2012), Saint Paul (2013), Paris (2014), Istanbul (2015), Singapore (2016), Sao Paulo (2017), Stockholm (2018), Montreal (2019), Auckland/online (2020), London/online (2021), Auckland/online (2022), and London (2023).},
location = {Auckland, New Zealand}
}

@proceedings{10.5555/3643142,
title = {WSC '23: Proceedings of the Winter Simulation Conference},
year = {2023},
isbn = {9798350369663},
publisher = {IEEE Press},
location = {San Antonio, Texas, USA}
}

