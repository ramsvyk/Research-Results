Scopus
EXPORT DATE: 08 April 2025

@ARTICLE{Tang20201572,
	author = {Tang, Zhan-Yong and Tian, Chao-Xiong and Ye, Gui-Xin and Li, Jing and Wang, Wei and Gong, Xiao-Qing and Chen, Xiao-Jiang and Fand, Ding-Yi},
	title = {A Recognition Method for Text-Based Captcha Based on CGAN; [一种基于条件生成式对抗网络的文本类验证码识别方法]},
	year = {2020},
	volume = {43},
	number = {8},
	pages = {1572 – 1588},
	doi = {10.11897/SP.J.1016.2020.01572},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092413283&doi=10.11897%2fSP.J.1016.2020.01572&partnerID=40&md5=2b3e01596d6884f052ac34e7fff16165},
	abstract = {Captchas are widely used in the login and registration of websites to enhance authentication and prevent automatically attacks from computer programs. Captchas can be divided into three categories: text-based captcha, image-based captcha and audio-based captcha. Among the three captcha schemes, text-based Captchas are extensively used by most mainstream websites for its large password space and simple interaction mode. Due to the wide deployment of text-based captchas, a compromise on the captcha scheme can have significant implications and could result in serious consequences. At present, in order to protect text-based captcha against automatic recognition by computer programs, text-based Captchas generally use a random combination of different security features, such as complexity obstacle backgrounds, characters warp, rotate and overlapping. In spite of researchers have proposed a number of attacks, text-based Captchas are still being used by most popular websites such as Google, Microsoft, Alipay, etc. One of the reasons is that the previous model-based attacking methods are scheme-specific. This means that a small change in the captcha such as a noisier background, more overlapping characters can easily invalid a prior attack. The other reason is that prior deep learning-based attacks require millions of training samples. However, collecting and labelling so many captchas requires a labor-intensive and time-consuming process to construct. In order to address the above challenges, we present a generic generative adversarial network-based attack on text-based Captchas. Unlike previous machine-learning-based attacks, our approach does not require a large volume of real captchas to learn an effective solver, we significantly reduces the number of real captchas needed. This is achieved by first using CGAN to remove the background interference information and stretch the character spacing of the Captchas. Then we use the optimization of segmentation algorithms to segment the stretched Captchas effectively, and use GoogLeNet to perform single character identification. In addition, it is difficult to obtain a large number of real Captchas at a low cost. This paper designs a program to simulate these real Captchas for network training, and the training cost is far lower than other existing methods and the training effects are the same. In our experiments, we automatically collected 10 text-based captcha schemes which are widely used by some of the top-50 popular websites ranked by alexa.com as of March, 2018. These websites include eBay, Alipay, JD, Wikipedia, many of which employ advanced security features such as complex background, rotated, distorted and overlapping characters. For each captcha scheme, we collected and labelled 200 target captchas. We generated 30000 synthetic captchas for training the preprocessing model and the captcha solver. We evaluate our approach using the collected captchas. The experimental results demonstrate that our generic attack needs less number of real text-based captchas instead of millions to learn a text-based captcha solver, but the learned captcha solver can greatly outperform prior start-of-the arts. Extensive experimental results also show that the method proposed in this paper can successfully identify the Captchas catch from some famous websites, such as Microsoft, Wikipedia, Baidu, Alipay, Sina, and so on. Furthermore, the highest success rate of our approach is 70.2% higher than the traditional methods. © 2020, Science Press. All right reserved.},
	keywords = {Authentication; Complex networks; Computer crime; Deep learning; Electronic mail filters; Image segmentation; Security systems; Websites; Adversarial networks; Automatic recognition; Character identification; Character spacings; Complex background; Random combination; Recognition methods; Segmentation algorithms; Character recognition},
	publisher = {Science Press},
	issn = {02544164},
	coden = {JIXUD}
}

@ARTICLE{Guo20252111,
	author = {Guo, Qing and Qi, Hua and Sun, Jingyang and Juefei-Xu, Felix and Ma, Lei and Lin, Di and Feng, Wei and Wang, Song},
	title = {EfficientDeRain+: Learning Uncertainty-Aware Filtering via RainMix Augmentation for High-Efficiency Deraining},
	year = {2025},
	volume = {133},
	number = {4},
	pages = {2111 – 2135},
	doi = {10.1007/s11263-024-02281-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001503255&doi=10.1007%2fs11263-024-02281-7&partnerID=40&md5=6522b744314387077ccbd6d43c1f94ff},
	abstract = {Deraining is a significant and fundamental computer vision task, aiming to remove the rain streaks and accumulations in an image or video. Existing deraining methods usually make heuristic assumptions of the rain model, which compels them to employ complex optimization or iterative refinement for high recovery quality. However, this leads to time-consuming methods and affects the effectiveness of addressing rain patterns, deviating from the assumptions. This paper proposes a simple yet efficient deraining method by formulating deraining as a predictive filtering problem without complex rain model assumptions. Specifically, we identify spatially-variant predictive filtering (SPFilt) that adaptively predicts proper kernels via a deep network to filter different individual pixels. Since the filtering can be implemented via well-accelerated convolution, our method can be significantly efficient. We further propose the EfDeRain+ that contains three main contributions to address residual rain traces, multi-scale, and diverse rain patterns without harming efficiency. First, we propose the uncertainty-aware cascaded predictive filtering (UC-PFilt) that can identify the difficulties of reconstructing clean pixels via predicted kernels and remove the residual rain traces effectively. Second, we design the weight-sharing multi-scale dilated filtering (WS-MS-DFilt) to handle multi-scale rain streaks without harming the efficiency. Third, to eliminate the gap across diverse rain patterns, we propose a novel data augmentation method (i.e., RainMix) to train our deep models. By combining all contributions with sophisticated analysis on different variants, our final method outperforms baseline methods on six single-image deraining datasets and one video-deraining dataset in terms of both recovery quality and speed. In particular, EfDeRain+ can derain within about 6.3 ms on a 481×321 image and is over 74 times faster than the top baseline method with even better recovery quality. We release code in https://github.com/tsingqguo/efficientderainplus. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.},
	keywords = {Adaptive filters; Image coding; Microfiltration; Scales (weighing instruments); Uranium compounds; Cascaded dilation filtering; Data augmentation; Deraining; Multi-scale dilated filtering; Multi-scales; Predictive filtering; Rain modeling; Rainmix; Recovery quality; Uncertainty; Adaptive filtering},
	publisher = {Springer},
	issn = {09205691},
	coden = {IJCVE}
}

@ARTICLE{Makse20241,
	author = {Makse, Hernán A. and Zava, Marta},
	title = {The Science of Influencers and Superspreaders: Using Networks and Artificial Intelligence to Understand Fake News, Pandemics, Markets, and the Brain},
	year = {2024},
	volume = {Part F4274},
	pages = {1 – 447},
	doi = {10.1007/978-3-031-78058-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000632337&doi=10.1007%2f978-3-031-78058-5&partnerID=40&md5=a6f7cd7c59271a8e7b8376ab5298212b},
	abstract = {This book explores the identification of influencers in complex networks, bridging theoretical approaches with practical applications across diverse fields. It examines interdisciplinary complex systems, including online social media, biological networks, brain networks, socioeconomic and financial systems, and ecosystems. The research presented aims to benefit scientists in relevant areas and inspire new scientific inquiries, potentially advancing the field of influencer identification. In this context, 'influencer' serves as an umbrella term for essential, core, or central nodes within any complex network. The book investigates various manifestations of influencers, such as key figures in social media, critical nodes in genetic and brain networks, keystone species in ecosystems, systemically important banks in financial markets, and disease superspreaders. These diverse scenarios are approached by mapping the influencer identification problem to challenges in physics or computer science. The book caters to readers at three distinct levels: 1. Those seeking mathematically rigorous theories of influencers will find Chapter 2 particularly valuable, as it delves into the mathematical foundations of influencer identification algorithms. Subsequent chapters explore the application of these theories across various disciplines. 2. Data scientists interested in implementing these algorithms in their research and practical work will find relevant information throughout the book. 3. Professionals in finance, marketing, politics, and social media, as well as readers curious about the intersection of big data, influencers, and AI, will gain insights into how these tools can enhance decision-making processes. These readers are encouraged to focus on the introduction and chapters most relevant to their fields, while briefly reviewing the more technical sections. By offering this multi-layered approach, the book aims to provide a comprehensive understanding of influencer identification in complex networks, from theoretical foundations to real-world applications across various domains. © TheEditor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18600832}
}

@CONFERENCE{Ungless20258992,
	author = {Ungless, Eddie L. and Vitsakis, Nikolas and Talat, Zeerak and Garforth, James and Ross, Björn and Onken, Arno and Kasirzadeh, Atoosa and Birch, Alexandra},
	title = {The Only Way is Ethics: A Guide to Ethical Research with Large Language Models},
	year = {2025},
	volume = {Part F206484-1},
	pages = {8992 – 9005},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218492393&partnerID=40&md5=5980ee4246e1cfcf460595d0964dcd2a},
	abstract = {There is a significant body of work looking at the ethical considerations of large language models (LLMs): critiquing tools to measure performance and harms; proposing toolkits to aid in ideation; discussing the risks to workers; considering legislation around privacy and security etc. As yet there is no work that integrates these resources into a single practical guide that focuses on LLMs; we attempt this ambitious goal. We introduce LLM ETHICS WHITEPAPER, which we provide as an open and living resource for NLP practitioners, and those tasked with evaluating the ethical implications of others' work. Our goal is to translate ethics literature into concrete recommendations and provocations for thinking with clear first steps, aimed at computer scientists. LLM ETHICS WHITEPAPER distils a thorough literature review into clear Do's and Don'ts, which we present also in this paper. We likewise identify useful toolkits to support ethical work. We refer the interested reader to the full LLM ETHICS WHITEPAPER, which provides a succinct discussion of ethical considerations at each stage in a project lifecycle, as well as citations for the hundreds of papers from which we drew our recommendations. The present paper can be thought of as a pocket guide to conducting ethical research with LLMs. © 2025 Association for Computational Linguistics.},
	keywords = {Computer aided language translation; Economic and social effects; Ethical aspects; Laws and legislation; Computer scientists; Ethical considerations; Ethical implications; Language model; Literature reviews; Performance; Practical guide; Privacy and security; Project lifecycle; Workers'; Computational linguistics},
	publisher = {Association for Computational Linguistics (ACL)},
	issn = {29512093},
	isbn = {979-889176196-4}
}

@ARTICLE{Gorwa2024,
	author = {Gorwa, Robert and Veale, Michael},
	title = {Moderating model marketplaces: platform governance puzzles for AI intermediaries},
	year = {2024},
	doi = {10.1080/17579961.2024.2388914},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208017860&doi=10.1080%2f17579961.2024.2388914&partnerID=40&md5=657c8dca7af75cc08aba7bde7d06928c},
	abstract = {The AI development community is increasingly making use of hosting intermediaries, such as Hugging Face, which provide easy access to user-uploaded models and training data. These model marketplaces lower technical deployment barriers for hundreds of thousands of users, yet can be used in numerous potentially harmful and illegal ways. In this article, we explain the ways in which AI systems, which can both ‘contain’ content and be open-ended tools, present one of the trickiest platform governance challenges seen to date. We provide case studies of several incidents across three illustrative platforms–Hugging Face, GitHub and Civitai–to examine how model marketplaces moderate models. Building on this analysis, we outline important (and yet nevertheless limited) practices that industry has been developing to respond to moderation demands: licensing, access and use restrictions, automated content moderation, and open policy development. While the policy challenge at hand is a considerable one, we conclude with some ideas as to how platforms could better mobilise resources to act as a careful, fair, and proportionate regulatory access point. © 2024 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.},
	publisher = {Taylor and Francis Ltd.},
	issn = {17579961}
}

@ARTICLE{Thomas2022972,
	author = {Thomas, Armin W. and Ré, Christopher and Poldrack, Russell A.},
	title = {Interpreting mental state decoding with deep learning models},
	year = {2022},
	volume = {26},
	number = {11},
	pages = {972 – 986},
	doi = {10.1016/j.tics.2022.07.003},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139590885&doi=10.1016%2fj.tics.2022.07.003&partnerID=40&md5=0de6c87cf5d2e6660e515837643acd69},
	abstract = {In mental state decoding, researchers aim to identify the set of mental states (e.g., experiencing happiness or fear) that can be reliably identified from the activity patterns of a brain region (or network). Deep learning (DL) models are highly promising for mental state decoding because of their unmatched ability to learn versatile representations of complex data. However, their widespread application in mental state decoding is hindered by their lack of interpretability, difficulties in applying them to small datasets, and in ensuring their reproducibility and robustness. We recommend approaching these challenges by leveraging recent advances in explainable artificial intelligence (XAI) and transfer learning, and also provide recommendations on how to improve the reproducibility and robustness of DL models in mental state decoding. © 2022 Elsevier Ltd},
	keywords = {Artificial Intelligence; Brain; Brain Mapping; Deep Learning; Humans; Reproducibility of Results; Brain; Deep learning; Learning systems; Neuroimaging; Robustness (control systems); Activity patterns; Brain networks; Deep learning; Explainable artificial intelligence; Learning models; Mental state; Mental state decoding; Reproducibilities; Robustness; Transfer learning; artificial intelligence; brain region; deep learning; fear; happiness; human; human experiment; mental health; neuroimaging; reproducibility; review; transfer of learning; artificial intelligence; brain; brain mapping; reproducibility; Decoding},
	publisher = {Elsevier Ltd},
	issn = {13646613},
	coden = {TCSCF}
}

@ARTICLE{Makhortykh2023,
	author = {Makhortykh, Mykola and Zucker, Eve M. and Simon, David J. and Bultmann, Daniel and Ulloa, Roberto},
	title = {Shall androids dream of genocides? How generative AI can change the future of memorialization of mass atrocities},
	year = {2023},
	volume = {3},
	number = {1},
	doi = {10.1007/s44163-023-00072-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174380272&doi=10.1007%2fs44163-023-00072-6&partnerID=40&md5=9dfce90068a3188dd025dd7beeecc431},
	abstract = {The memorialization of mass atrocities such as war crimes and genocides facilitates the remembrance of past suffering, honors those who resisted the perpetrators, and helps prevent the distortion of historical facts. Digital technologies have transformed memorialization practices by enabling less top-down and more creative approaches to remember mass atrocities. At the same time, they may also facilitate the spread of denialism and distortion, attempt to justify past crimes and attack the dignity of victims. The emergence of generative forms of artificial intelligence (AI), which produce textual and visual content, has the potential to revolutionize the field of memorialization even further. AI can identify patterns in training data to create new narratives for representing and interpreting mass atrocities—and do so in a fraction of the time it takes for humans. The use of generative AI in this context raises numerous questions: For example, can the paucity of training data on mass atrocities distort how AI interprets some atrocity-related inquiries? How important is the ability to differentiate between human- and AI-made content concerning mass atrocities? Can AI-made content be used to promote false information concerning atrocities? This article addresses these and other questions by examining the opportunities and risks associated with using generative AIs for memorializing mass atrocities. It also discusses recommendations for AIs integration in memorialization practices to steer the use of these technologies toward a more ethical and sustainable direction. © The Author(s) 2023.},
	keywords = {Artificial intelligence; Ethical technology; Creatives; Digital technologies; Information concerning; Textual content; Topdown; Training data; Visual content; War crimes; Crime},
	publisher = {Springer Nature},
	issn = {27310809}
}

@ARTICLE{Zhu2024,
	author = {Zhu, Han and Chen, Zhenzhong and Liu, Shan},
	title = {Information Bottleneck based Self-distillation: Boosting Lightweight Network for Real-world Super-Resolution},
	year = {2024},
	doi = {10.1109/TCSVT.2024.3519136},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212757263&doi=10.1109%2fTCSVT.2024.3519136&partnerID=40&md5=9c922f4baf92ea789a0d015785cc1c4d},
	abstract = {Most existing single-image super-resolution (SISR) methods focus on addressing predefined uniform degradations, such as bicubic. However, these methods often perform poorly in real-world scenarios due to complicated and varying realistic degradations. In this paper, we propose a novel information bottle-neck-based self-distillation method (IBSD) to boost lightweight networks for real-world image super-resolution. The proposed IBSD leverages the principle of information bottleneck to guide SR networks to learn invariant correlations from low-resolution (LR) to high-resolution (HR) across various degradations, thereby improving their generalization capacity. Specifically, the target super-resolution network (i.e., student) is interpreted as a Markov chain, and the distillation process is carried out through two modules. Mutual information (MI) estimation networks are used to quantify the mutual information between adjacent nodes within the Markov chain. To enhance robustness against blur and noise in real-world scenarios, an auxiliary loss with a progressive soft target is employed to better identify what is effective for reconstruction in the high-frequency domain. Minimizing the mutual information while preserving task-relevant features can help remove information that reflects spurious correlations between specific degradations and reconstructed targets. Experiments conducted on real-world image super-resolution datasets demonstrate that our proposed method can significantly improve the performance of recent lightweight SR models without adding any extra inference complexity, and it outperforms existing self-distillation approaches. Code is publicly available at https://github.com/hanzhu1121/IBSD. © 1991-2012 IEEE.},
	keywords = {Adaptive boosting; Frequency estimation; Health risks; HTTP; Image correlation; Inference engines; Image super resolutions; Information bottleneck; Information bottleneck principles; Knowledge distillation; Lightweight network; Mutual information estimations; Real-world; Real-world scenario; Real-world super-resolution; Superresolution; Markov chains},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {10518215},
	coden = {ITCTE}
}

@CONFERENCE{Bui2024,
	author = {Bui, Anh and Vuong, Long and Doan, Khanh and Le, Trung and Montague, Paul and Abraham, Tamas and Phung, Dinh},
	title = {Erasing Undesirable Concepts in Diffusion Models with Adversarial Preservation},
	year = {2024},
	volume = {37},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000544285&partnerID=40&md5=3c5e00553067225d4c73052bdbdc7852},
	abstract = {Diffusion models excel at generating visually striking content from text but can inadvertently produce undesirable or harmful content when trained on unfiltered internet data. A practical solution is to selectively removing target concepts from the model, but this may impact the remaining concepts. Prior approaches have tried to balance this by introducing a loss term to preserve neutral content or a regularization term to minimize changes in the model parameters, yet resolving this trade-off remains challenging. In this work, we propose to identify and preserving concepts most affected by parameter changes, termed as adversarial concepts. This approach ensures stable erasure with minimal impact on the other concepts. We demonstrate the effectiveness of our method using the Stable Diffusion model, showing that it outperforms state-of-the-art erasure methods in eliminating unwanted content while maintaining the integrity of other unrelated elements. Our code is available at https://github.com/tuananhbui89/Erasing-Adversarial-Preservation. © 2024 Neural information processing systems foundation. All rights reserved.},
	publisher = {Neural information processing systems foundation},
	issn = {10495258}
}

@ARTICLE{Lee2022,
	author = {Lee, Benjamin D. and Gitter, Anthony and Greene, Casey S. and Raschka, Sebastian and Maguire, Finlay and Titus, Alexander J. and Kessler, Michael D. and Lee, Alexandra J. and Chevrette, Marc G. and Stewart, Paul Allen and Britto-Borges, Thiago and Cofer, Evan M. and Yu, Kun-Hsing and Carmona, Juan Jose and Fertig, Elana J. and Kalinin, Alexandr A. and Signal, Brandon and Lengerich, Benjamin J. and Triche, Timothy J. and Boca, Simina M.},
	title = {Ten quick tips for deep learning in biology},
	year = {2022},
	volume = {18},
	number = {3},
	doi = {10.1371/journal.pcbi.1009803},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127019209&doi=10.1371%2fjournal.pcbi.1009803&partnerID=40&md5=b9855b65ebedcbf0098699571b294c5d},
	keywords = {Computational Biology; Deep Learning; Article; artificial neural network; Bayesian learning; biology; computer vision; convolutional neural network; data analysis; data privacy; data processing; data quality; deep learning; deep neural network; ethics; human; hyperparameter; information processing; k nearest neighbor; logistic regression analysis; medical research; natural language processing; problem solving; random forest; reinforcement learning (machine learning); reproducibility; research ethics; sample size; statistical parameters; support vector machine; Deep learning},
	publisher = {Public Library of Science},
	issn = {1553734X}
}

@BOOK{Fitch20201,
	author = {Fitch, Kate and Motion, Judy},
	title = {Popular culture and social change: The hidden work of public relations},
	year = {2020},
	pages = {1 – 158},
	doi = {10.4324/9781315203515},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096253508&doi=10.4324%2f9781315203515&partnerID=40&md5=3352e203bd3bbc6a7d6e0245d553c52a},
	abstract = {Popular Culture and Social Change: The Hidden Work of Public Relations argues the complicated and contradictory relationship between public relations, popular culture and social change is a neglected theoretical project. Its diverse chapters identify ways in which public relations influences the production of popular culture and how alternative, often community-driven conceptualisations of public relations work can be harnessed for social change and in pursuit of social justice. This book opens up critical scholarship on public relations in that it moves beyond corporate understandings and perspectives to explore alternative and eclectic communicative cultures, in part to consider a more optimistic conceptualisation of public relations as a resource for progressive social change. Fitch and Motion began with an interest in identifying the ways in which public relations both draws on and influences the production of popular culture by creating, promoting and amplifying particular narratives and images. The chapters in this book consider how public relations creates popular cultures that are deeply compromised and commercialised, but at the same time can be harnessed to advocate for social change in supporting, reproducing, challenging or resisting the status quo. Drawing on critical and sociocultural perspectives, this book is an important resource for researchers, educators and students exploring public relations theory, strategic communication and promotional culture. It investigates the entanglement of public relations, popular culture and social change in different social, cultural and political contexts - from fashion and fortune telling to race activism and aesthetic labour - in order to better understand the (often subterranean) societal influence of public relations activity. © 2021 Kate Fitch and Judy Motion.},
	publisher = {Taylor and Francis},
	isbn = {978-135178825-0; 978-113870280-6}
}

@ARTICLE{Basak2022,
	author = {Basak, Hritam and Kundu, Rohit and Sarkar, Ram},
	title = {MFSNet: A multi focus segmentation network for skin lesion segmentation},
	year = {2022},
	volume = {128},
	doi = {10.1016/j.patcog.2022.108673},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127686767&doi=10.1016%2fj.patcog.2022.108673&partnerID=40&md5=ca4b72b4070d3426e6533f6ef4a24b95},
	abstract = {Segmentation is essential for medical image analysis to identify and localize diseases, monitor morphological changes, and extract discriminative features for further diagnosis. Skin cancer is one of the most common types of cancer globally, and its early diagnosis is pivotal for the complete elimination of malignant tumors from the body. This research develops an Artificial Intelligence (AI) framework for supervised skin lesion segmentation employing the deep learning approach. The proposed framework, called MFSNet (Multi-Focus Segmentation Network), uses differently scaled feature maps for computing the final segmentation mask using raw input RGB images of skin lesions. In doing so, initially, the images are preprocessed to remove unwanted artifacts and noises. The MFSNet employs the Res2Net backbone, a recently proposed convolutional neural network (CNN), for obtaining deep features used in a Parallel Partial Decoder (PPD) module to get a global map of the segmentation mask. In different stages of the network, convolution features and multi-scale maps are used in two boundary attention (BA) modules and two reverse attention (RA) modules to generate the final segmentation output. MFSNet, when evaluated on three publicly available datasets: PH2, ISIC 2017, and HAM10000, outperforms state-of-the-art methods, justifying the reliability of the framework. The relevant codes for the proposed approach are accessible at https://github.com/Rohit-Kundu/MFSNet. © 2022 Elsevier Ltd},
	keywords = {Convolution; Convolutional neural networks; Decoding; Deep learning; Diagnosis; Diseases; Image segmentation; Medical imaging; Attention module; Deep learning; Lesion segmentations; Medical image analysis; Morphological changes; Multi-focus; Parallel partial decoder; Segmentation masks; Skin lesion; Skin melanoma; Dermatology},
	publisher = {Elsevier Ltd},
	issn = {00313203},
	coden = {PTNRA}
}

@BOOK{Miao2024359,
	author = {Miao, Xin and Brooker, Richard and Monroe, Samantha},
	title = {Where Generative AI Fits Within and in Addition to Existing AI K12 Education Interactions: Industry and Research Perspectives},
	year = {2024},
	pages = {359 – 384},
	doi = {10.1007/978-981-99-9379-6_17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193573376&doi=10.1007%2f978-981-99-9379-6_17&partnerID=40&md5=71f365bc9aaa5d52988dfadf30abed1c},
	abstract = {Recent developments in Generative AI have led capital market, industry, and research institutions to explore its education applications as solutions to K12 challenges. However, there is currently a gap of analytical review of these trends. This chapter attempts to review and analyze predominant Generative AI education efforts within and in addition to existing AI education frameworks that include contributions from both industry and research institutions. Our aim is to present a holistic review of AI Education key interactions, explore the opportunities that Generative AI presents, share industry experience in implementing Generative AI in AIED products and identify future work directions. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	publisher = {Springer Nature},
	isbn = {978-981999379-6; 978-981999378-9}
}

@ARTICLE{Qin2024,
	author = {Qin, Dong and Amariucai, George T. and Qiao, Daji and Guan, Yong and Fu, Shen},
	title = {A comprehensive and reliable feature attribution method: Double-sided remove and reconstruct (DoRaR)},
	year = {2024},
	volume = {173},
	doi = {10.1016/j.neunet.2024.106166},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185405209&doi=10.1016%2fj.neunet.2024.106166&partnerID=40&md5=e5d9f6083f889a42e4975d398e701525},
	abstract = {The limited transparency of the inner decision-making mechanism in deep neural networks (DNN) and other machine learning (ML) models has hindered their application in several domains. In order to tackle this issue, feature attribution methods have been developed to identify the crucial features that heavily influence decisions made by these black box models. However, many feature attribution methods have inherent downsides. For example, one category of feature attribution methods suffers from the artifacts problem, which feeds out-of-distribution masked inputs directly through the classifier that was originally trained on natural data points. Another category of feature attribution method finds explanations by using jointly trained feature selectors and predictors. While avoiding the artifacts problem, this new category suffers from the Encoding Prediction in the Explanation (EPITE) problem, in which the predictor's decisions rely not on the features, but on the masks that selects those features. As a result, the credibility of attribution results is undermined by these downsides. In this research, we introduce the Double-sided Remove and Reconstruct (DoRaR) feature attribution method based on several improvement methods that addresses these issues. By conducting thorough testing on MNIST, CIFAR10 and our own synthetic dataset, we demonstrate that the DoRaR feature attribution method can effectively bypass the above issues and can aid in training a feature selector that outperforms other state-of-the-art feature attribution methods. Our code is available at https://github.com/dxq21/DoRaR. © 2024 Elsevier Ltd},
	keywords = {Machine Learning; Neural Networks, Computer; Decision making; Deep neural networks; Learning systems; Statistical tests; Decision-making mechanisms; Double sided; Feature attribution method; Generative model; Interpretable machine learning; Machine-learning; Model transparency; Real time modeling; Real-time model explanation; XAI; Article; artifact; decision making; deep neural network; human; machine learning; mathematical model; artificial neural network; machine learning; Transparency},
	publisher = {Elsevier Ltd},
	issn = {08936080},
	coden = {NNETE}
}

@CONFERENCE{Zhang202446,
	author = {Zhang, Zhaoxi and Zhang, Xiaomei and Zhang, Yanjun and Zhang, Leo Yu and Chen, Chao and Hu, Shengshan and Gill, Asif and Pan, Shirui},
	title = {Stealing Watermarks of Large Language Models via Mixed Integer Programming},
	year = {2024},
	pages = {46 – 60},
	doi = {10.1109/ACSAC63791.2024.00021},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001344664&doi=10.1109%2fACSAC63791.2024.00021&partnerID=40&md5=94487fc25e6d162a137b0c0e0c7b63c9},
	abstract = {The Large Language Model (LLM) watermark is a newly emerging technique that shows promise in addressing concerns surrounding LLM copyright, monitoring AI-generated text, and preventing its misuse. The LLM watermark scheme commonly includes generating secret keys to partition the vocabulary into green and red lists, applying a perturbation to the logits of tokens in the green list to increase their sampling likelihood, thus facilitating watermark detection to identify AI-generated text if the proportion of green tokens exceeds a threshold. However, recent research indicates that watermarking methods using numerous keys are susceptible to removal attacks, such as token editing, synonym substitution, and paraphrasing, with robustness declining as the number of keys increases. Therefore, the state-of-the-art watermark schemes that employ fewer or single keys have been demonstrated to be more robust against text editing and paraphrasing. In this paper, we propose a novel green list stealing attack against the state-of-the-art LLM watermark scheme and systematically examine its vulnerability to this attack. We formalize the attack as a mixed integer programming problem with constraints. We evaluate our attack under a comprehensive threat model, including an extreme scenario where the attacker has no prior knowledge, lacks access to the watermark detector API, and possesses no information about the LLM’s parameter settings or watermark injection/detection scheme. Extensive experiments on LLMs, such as OPT and LLaMA, demonstrate that our attack can successfully steal the green list and remove the watermark across all settings. © 2024 IEEE.},
	keywords = {Integer linear programming; Watermarking; Language model; Large language model; Large language model security; Mixed-Integer Programming; Model security; Privacy; Security; State of the art; Watermark scheme; Mixed-integer linear programming},
	publisher = {Association for Computing Machinery},
	issn = {10639527},
	isbn = {979-833152088-5},
	coden = {CMSCE}
}

@ARTICLE{Mei2023587,
	author = {Mei, Kangfu and Patel, Vishal M.},
	title = {LTT-GAN: Looking Through Turbulence by Inverting GANs},
	year = {2023},
	volume = {17},
	number = {3},
	pages = {587 – 598},
	doi = {10.1109/JSTSP.2023.3238552},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147316812&doi=10.1109%2fJSTSP.2023.3238552&partnerID=40&md5=0a98831bee7a4579d58f18666e14c631},
	abstract = {In many applications of long-range imaging, such as surveillance, we are faced with a scenario where we have to recover and identify facial images appearing in the captured imagery degraded by atmospheric turbulence. One way to deal with this problem is to develop methods that can remove the effect of turbulence from images. However, restoring images degraded by atmospheric turbulence is difficult since it causes images to be geometrically distorted and blurry. To mitigate the effect of turbulence, we propose a method in which well-trained Generative Adversarial Networks (GANs) are leveraged as effective priors. Different from the existing GAN inversion models, it learns to restore images in the context of semantic space that is represented by a set of augmented images with the same identity but different appearances. Such a context can enforce the network to learn to preserve identity while producing visually pleasant results. In addition, we propose to connect hierarchical layers of a GAN to get multiple images with the same identity at the same time, which enriches the context and helps to better improve the restoration performance. Extensive experiments on both synthetic and real images show that our method outperforms the existing state-of-the-art methods.  © 2023 IEEE.},
	keywords = {Atmospheric thermodynamics; Atmospheric turbulence; Face recognition; Generative adversarial networks; Network coding; Restoration; Atmospheric turbulence degradation; Code; Degraded images; Face Verification; Learn+; Longrange imaging; Mitigation methods; Optimisations; Range imaging; Turbulence effect; Image reconstruction},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {19324553}
}

@ARTICLE{Yang2021474,
	author = {Yang, Fei and Zhang, Jialu and Zhang, Qian},
	title = {Multi-scale capsule generative adversarial network for snow removal},
	year = {2021},
	volume = {15},
	number = {7},
	pages = {474 – 486},
	doi = {10.1049/cvi2.12038},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141802481&doi=10.1049%2fcvi2.12038&partnerID=40&md5=2ff6297386d90970d7f85658efe09698},
	abstract = {Snowflakes captured on photos may severely decrease the visual quality and cause difficulties for vision analysis systems. Most noise removal frameworks are designed for deraining or de-hazing, regarding rain or haze as translucent masks on clean images. However, snowflakes are different from them in terms of sizes, shapes, transparencies and floating trajectories, which decreases the performance of de-raining or de-hazing models in processing snowy images. In this work, we propose an effective multi-scale generative adversarial network framework for single-image snow removal, which is built with a multi-scale structure to identify various scales of snowflakes and a capsulebased structure to fuse the features extracted from the multi-scale encoding branches, so that different scaled features could be summarised and learnt by a joint framework. The overall framework is supervised by a weighted joint loss with an iterative training procedure to keep the training stability for the multi-branch-based structure. The experimental results demonstrate that our model outperforms the state-of-the-art comparisons. © 2021, John Wiley and Sons Inc. All rights reserved.},
	keywords = {Snow; Analysis system; Clean images; Multi-scales; Network frameworks; Noises removal; Performance; Single images; Snow removal; Translucents; Visual qualities; Generative adversarial networks},
	publisher = {John Wiley and Sons Inc},
	issn = {17519632}
}

@BOOK{Wilson20251,
	author = {Wilson, M. Roy and Beachy, Sarah H. and Schumm, Samantha N.},
	title = {Rethinking race and ethnicity in biomedical research},
	year = {2025},
	pages = {1 – 271},
	doi = {10.17226/27913},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217614135&doi=10.17226%2f27913&partnerID=40&md5=658574fe16f34bffb4e0faf5b1207068},
	abstract = {In 2023, the National Academies convened an expert committee to assess the current use of racial and ethnic categories in biomedical research, review existing guidance for researchers, and provide new guidance for future use. The resulting 2024 report, Rethinking Race and Ethnicity in Biomedical Research, outlines nine actionable recommendations and associated resources for advancing the responsible use of race and ethnicity. The recommendations of Rethinking Race and Ethnicity in Biomedical Research address how to: decide whether to use race and ethnicity in different research contexts; characterize and disclose limitations of datasets that include racial and ethnic information; identify factors to investigate instead of or alongside race and ethnicity; include overlooked populations in analysis; and support sustained community engagement. © 2025 by the National Academy of Sciences. All rights reserved.},
	publisher = {National Academies Press},
	isbn = {978-030972463-0; 978-030972464-7}
}

@BOOK{Kumar20241,
	author = {Kumar, Rajendra and Ong, Eng Tek and Anggoro, Subuh and Toh, Tin Lam and Fukui, Masanori},
	title = {Transdisciplinary teaching and technological integration for improved learning: Case studies and practical approaches},
	year = {2024},
	pages = {1 – 414},
	doi = {10.4018/979-8-3693-8217-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204337137&doi=10.4018%2f979-8-3693-8217-2&partnerID=40&md5=a785fb3d9f290545c47036203ad27cf8},
	abstract = {In the modern era of research, the significance of transdisciplinary and multidisciplinary approaches in enhancing higher education learning outcomes cannot be overlooked. These approaches break down traditional academic silos, fostering a more holistic and interconnected understanding of complex problems. By integrating diverse perspectives and methodologies, they promote critical thinking, creativity, and innovation among students. Educators and institutions must embrace and implement transdisciplinary teaching and technological integration to prepare students for the demands of the future and drive meaningful advancements in education. Transdisciplinary Teaching and Technological Integration for Improved Learning: Case Studies and Practical Approaches embodies a commitment to these approaches, incorporating three cyclical activities-research, participation, and action-that collaboratively seek answers to practical questions through features of participatory and situational research. The book explores problem identification, action planning, observation collection, and behavioral data analysis. Covering topics such as artificial intelligence tools, higher education institutions, and university student satisfaction, this book is an excellent resource for higher education faculty, academic administrators, curriculum developers, educational technology specialists, researchers, and more. © 2024 by IGI Global. All rights reserved.},
	publisher = {IGI Global},
	isbn = {979-836938219-6; 979-836938217-2}
}

@ARTICLE{Wang2022242,
	author = {Wang, Cong and Zhu, Honghe and Fan, Wanshu and Wu, Xiao-Ming and Chen, Junyang},
	title = {Single image rain removal using recurrent scale-guide networks},
	year = {2022},
	volume = {467},
	pages = {242 – 255},
	doi = {10.1016/j.neucom.2021.10.029},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117112579&doi=10.1016%2fj.neucom.2021.10.029&partnerID=40&md5=e06b37809023d9eb5cfa77c6f2c7ea2f},
	abstract = {Recently, removing rain streaks from a single image has attracted a lot of attention because rain streaks can severely degrade the perceptual quality of the image and cause many practical vision systems to fail. Single image deraining can be served as a pre-processing step to improve the performance of high-level vision tasks such as object detection and video surveillance. In this paper, we propose recurrent scale-guide networks for single image deraining. Although the multi-scale strategy has been successfully applied to many computer vision problems, the correlation between different scales has not been explored in most existing methods. To overcome this deficiency, we propose two types of scale-guide blocks and develop two combinations between the blocks. One type of scale-guide block is that small scale guides the large, and the other is that large scale guides the small. Moreover, we extend the single-stage deraining model to the multi-stage recurrent framework and introduce the Long Short-Term Memory (LSTM) to link every stage. Extensive experiments verify that the scale-guide manner boosts the deraining performance and the recurrent style improves the deraining results. Experimental results demonstrate that the proposed method outperforms other state-of-the-art deraining methods on three widely used datasets: Rain100H, Rain100L, and Rain1200. The source codes can be found at https://supercong94.wixsite.com/supercong94. © 2021 Elsevier B.V.},
	keywords = {Image enhancement; Object detection; Rain; Security systems; Deep-learning; Deraining; Perceptual quality; Performance; Pre-processing step; Rain removals; Recurrent networks; Scale-guide; Single images; Vision systems; article; computer vision; deep learning; short term memory; Long short-term memory},
	publisher = {Elsevier B.V.},
	issn = {09252312},
	coden = {NRCGE}
}

@ARTICLE{Adrian-Alin20242783,
	author = {Adrian-Alin, Barglazan and Remus, Brad},
	title = {Wavelet Based Inpainting Detection},
	year = {2024},
	volume = {4},
	number = {3},
	pages = {2783 – 2809},
	doi = {10.54364/AAIML.2024.43162},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206490574&doi=10.54364%2fAAIML.2024.43162&partnerID=40&md5=39ae4e75366eabc12beb9170f18b3465},
	abstract = {With the advancement in image editing tools, manipulating digital images has become alarmingly easy. Inpainting, which is used to remove objects or fill in parts of an image, serves as a powerful tool for both image restoration and forgery. This paper introduces a novel approach for detecting image inpainting forgeries by combining DT-CWT with Hierarchical Feature segmentation and with noise inconsistency analysis. The DT-CWT offers several advantages for this task, including inherent shift-invariance, which makes it robust to minor manipulations during the inpainting process, and directional selectivity, which helps capture subtle artifacts introduced by inpainting in specific frequency bands and orientations. By first applying colour image segmentation and then analysing for each segment, noise inconsistency obtained via DT-CW we can identify patterns indicative of inpainting forgeries. The proposed method is evaluated on a benchmark dataset created for this purpose and is compared with existing forgery detection techniques. Our approach demonstrates superior results compared with SOTA in detecting inpainted images. The proposed methodology source code is uploaded here: https://github.com/jmaba/Wavelet-based-inpainting-detection. © 2024 Barglazan Adrian-Alin and Brad Remus.},
	publisher = {Shimur Publications},
	issn = {25829793}
}

@CONFERENCE{Ramanathan2023,
	author = {Ramanathan, Vishwesh and Han, Wenchao and Bassiouny, Dina and Rakovitch, Eileen and Martel, Anne L.},
	title = {Ink Removal in Whole Slide Images using Hallucinated Data},
	year = {2023},
	volume = {12471},
	doi = {10.1117/12.2653281},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160536193&doi=10.1117%2f12.2653281&partnerID=40&md5=fa7baf85803b116f56852c5e4a8dc06d},
	abstract = {Pathologists regularly use ink markings on histopathology slides to highlight specific areas of interest or orientation, making it an integral part of the workflow. Unfortunately, digitization of these ink-annotated slides hinders any computer-aided analyses, particularly deep learning algorithms, which require clean data free from artifacts. We propose a methodology that can identify and remove the ink markings for the purpose of computational analyses. We propose a two-stage network with a binary classifier for ink filtering and Pix2Pix for ink removal. We trained our network by artificially generating pseudo ink markings using only clean slides, requiring no manual annotation or curation of data. Furthermore, we demonstrate our algorithm's efficacy over an independent dataset of H&E stained breast carcinoma slides scanned before and after the removal of pen markings. Our quantitative analysis shows promising results, achieving 98.7% accuracy for the binary classifier. For Pix2Pix, we observed a 65.6% increase in structure similarity index, a 21.3% increase in peak signal-to-noise ratio, and a 30% increase in visual information fidelity. As only clean slides are required for training, the pipeline can be adapted to multiple colors of ink markings or new domains, making it easy to deploy over different sets of histopathology slides. Code and trained models are available at: https://github.com/Vishwesh4/Ink-WSI. © 2023 SPIE.},
	keywords = {Computer aided analysis; Computer aided diagnosis; Computer aided instruction; Deep learning; Image classification; Medical imaging; Pathology; Quality control; Signal to noise ratio; Area of interest; Binary classifiers; Digital pathologies; Image translation; Image-to-image translation; Ink markings; Ink removal; Specific areas; Synthetic data; Whole slide images; Classification (of information)},
	publisher = {SPIE},
	issn = {16057422},
	isbn = {978-151066047-2}
}

@ARTICLE{Cai2023618,
	author = {Cai, Lei and Fu, Yuli and Huo, Wanliang and Xiang, Youjun and Zhu, Tao and Zhang, Ying and Zeng, Huanqiang and Zeng, Delu},
	title = {Multiscale Attentive Image De-Raining Networks via Neural Architecture Search},
	year = {2023},
	volume = {33},
	number = {2},
	pages = {618 – 633},
	doi = {10.1109/TCSVT.2022.3207516},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139389991&doi=10.1109%2fTCSVT.2022.3207516&partnerID=40&md5=4b8ebd1e70a2cbb71fe53a6074c70690},
	abstract = {Multi-scale architectures and attention modules have shown effectiveness in many deep learning-based image de-raining methods. However, manually designing and integrating these two components into a neural network requires a bulk of labor and extensive expertise. In this article, a high-performance multi-scale attentive neural architecture search (MANAS) framework is technically developed for image de-raining. The proposed method formulates a new multi-scale attention search space with multiple flexible modules that are favorite to the image de-raining task. Under the search space, multi-scale attentive cells are built, which are further used to construct a powerful image de-raining network. The internal multi-scale attentive architecture of the de-raining network is searched automatically through a gradient-based search algorithm, which avoids the daunting procedure of the manual design to some extent. Moreover, in order to obtain a robust image de-raining model, a practical and effective multi-to- one training strategy is also presented to allow the de-raining network to get sufficient background information from multiple rainy images with the same background scene, and meanwhile, multiple loss functions including external loss, internal loss, architecture regularization loss, and model complexity loss are jointly optimized to achieve robust de-raining performance and controllable model complexity. Extensive experimental results on both synthetic and realistic rainy images, as well as the down-stream vision applications (i.e., objection detection and segmentation) consistently demonstrate the superiority of our proposed method. The code is publicly available at https://github.com/lcai-gz/MANAS.  © 1991-2012 IEEE.},
	keywords = {Complex networks; Network architecture; Image de-raining; Modeling complexity; Multi-scale attentive neural architecture search; Multi-scales; Multi-to-one training strategy; Neural architectures; Performance; Search spaces; Training strategy; Two-component; Deep learning},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {10518215},
	coden = {ITCTE}
}

@ARTICLE{Simmons2023617,
	author = {Simmons, Beth A. and Hulvey, Rachel A.},
	title = {CYBERBORDERS: EXERCISING STATE SOVEREIGNTY ONLINE},
	year = {2023},
	volume = {95},
	number = {4},
	pages = {617 – 640},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181833012&partnerID=40&md5=eec819af57e4a2e455817eccf36cea47},
	abstract = {The internet brings challenges that threaten national identities and the foundations of what it means to be a state. Well-known challenges include difficulties maintaining important national values, competition threatening local economic plans, and even the inability to maintain a meaningful informational environment for self-governance. These influences are plausibly understood as challenges to some of the basic functions of a sovereign state. Despite these challenges, we identify the social practice of establishing control over mercurial mediums. States have responded by erecting cyberborders with a collection of laws, practices, and internet architecture designed to filter digital information within the territorial jurisdiction of the state. We contend that new digital bordering methods largely reflect and reproduce the territorial identity of the state. Border allusions, informed by concepts of geography, walls, and territoriality, are rife in states’ official internet rhetoric. In policy and practice, states are not only guided by vertical relations between state and society, but also have horizontal orientations for controlling cross-border flows. We define these preferences as a state’s border orientation or the underlying state preference for preserving national identity by filtering global forces. These preferences explain the rise of legal efforts to control the entry and exit of data and explain national approaches to sovereignty online across regime types. © 2023 Temple University. All rights reserved.},
	publisher = {Temple University},
	issn = {08998086}
}

@ARTICLE{Mengara202429004,
	author = {Mengara, Orson and Avila, Anderson and Falk, Tiago H.},
	title = {Backdoor Attacks to Deep Neural Networks: A Survey of the Literature, Challenges, and Future Research Directions},
	year = {2024},
	volume = {12},
	pages = {29004 – 29023},
	doi = {10.1109/ACCESS.2024.3355816},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182917500&doi=10.1109%2fACCESS.2024.3355816&partnerID=40&md5=ec465e672556109395d3f147932705a1},
	abstract = {Deep neural network (DNN) classifiers are potent instruments that can be used in various security-sensitive applications. Nonetheless, they are vulnerable to certain attacks that impede or distort their learning process. For example, backdoor attacks involve polluting the DNN learning set with a few samples from one or more source classes, which are then labeled as target classes by an attacker. Even if the DNN is trained on clean samples with no backdoors, this attack will still be successful if a backdoor pattern exists in the training data. Backdoor attacks are difficult to spot and can be used to make the DNN behave maliciously, depending on the target selected by the attacker. In this study, we survey the literature and highlight the latest advances in backdoor attack strategies and defense mechanisms. We finalize the discussion on challenges and open issues, as well as future research opportunities.  © 2013 IEEE.},
	keywords = {Classification (of information); Malware; Network security; AI security; Backdoor attack; Backdoors; Deep learning; Detection algorithm; Neural trojan; Training data; Trojan attack; Trojans; Vulnerability detection; Deep neural networks},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536}
}

@ARTICLE{Lima2022,
	author = {Lima, Aklima Akter and Mridha, M. Firoz and Das, Sujoy Chandra and Kabir, Muhammad Mohsin and Islam, Md. Rashedul and Watanobe, Yutaka},
	title = {A Comprehensive Survey on the Detection, Classification, and Challenges of Neurological Disorders},
	year = {2022},
	volume = {11},
	number = {3},
	doi = {10.3390/biology11030469},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127603830&doi=10.3390%2fbiology11030469&partnerID=40&md5=5eb0fb2668afbf2da68cc9e9cd9c4900},
	abstract = {Neurological disorders (NDs) are becoming more common, posing a concern to pregnant women, parents, healthy infants, and children. Neurological disorders arise in a wide variety of forms, each with its own set of origins, complications, and results. In recent years, the intricacy of brain functionalities has received a better understanding due to neuroimaging modalities, such as magnetic resonance imaging (MRI), magnetoencephalography (MEG), and positron emission tomography (PET), etc. With high-performance computational tools and various machine learning (ML) and deep learning (DL) methods, these modalities have discovered exciting possibilities for identifying and diagnosing neurological disorders. This study follows a computer-aided diagnosis methodology, leading to an overview of pre-processing and feature extraction techniques. The performance of existing ML and DL approaches for detecting NDs is critically reviewed and compared in this article. A comprehensive portion of this study also shows various modalities and disease-specified datasets that detect and records images, signals, and speeches, etc. Limited related works are also summarized on NDs, as this domain has significantly fewer works focused on disease and detection criteria. Some of the standard evaluation metrics are also presented in this study for better result analysis and comparison. This research has also been outlined in a consistent workflow. At the conclusion, a mandatory discussion section has been included to elaborate on open research challenges and directions for future work in this emerging field. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.},
	publisher = {MDPI},
	issn = {20797737}
}

@ARTICLE{Frosio20181,
	author = {Frosio, Giancarlo F.},
	title = {Why keep a dog and bark yourself? From intermediary liability to responsibility},
	year = {2018},
	volume = {26},
	number = {1},
	pages = {1 – 33},
	doi = {10.1093/ijlit/eax021},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041050850&doi=10.1093%2fijlit%2feax021&partnerID=40&md5=638949652bfce29d3866c48b52fa5a41},
	abstract = {This article contextualizes the recent developments in intermediary liability theory and policy within a broader move towards private ordering online. In this context, online intermediaries' governance would move away from a well-established utilitarian approach and towards a moral approach by rejecting negligence-based intermediary liability arrangements. Miscellaneous policy tools-such as monitoring and filtering obligations, blocking orders, graduated response, payment blockades and follow-the-money strategies, private Domain Name System content regulation, online search manipulation, or administrative enforcement-might reflect this change in perspective. In particular, policy makers-and interested third-parties such as intellectual property rightholders-try to coerce online intermediaries into implementing these policy strategies through voluntary measures and self-regulation, in addition to validly enacted obligations. This process might be pushing an amorphous notion of responsibility that incentivizes intermediaries' self-intervention to police allegedly infringing activities in the Internet. In this sense, the intermediary liability discourse is shifting towards an intermediary responsibility discourse. Furthermore, enforcement would be looking once again for an 'answer to the machine in the machine'. By enlisting online intermediaries as watchdogs, governments would de facto delegate online enforcement to algorithmic tools. Due process and fundamental guarantees get mauled by technological enforcement, curbing fair uses of content online and silencing speech according to the mainstream ethical discourse. © The Author (2017). Published by Oxford University Press. All rights reserved.},
	publisher = {Oxford University Press},
	issn = {09670769}
}

@ARTICLE{Su20221642,
	author = {Su, Zhipeng and Zhang, Yixiong and Shi, Jianghong and Zhang, Xiao-Ping},
	title = {Recurrent Network Knowledge Distillation for Image Rain Removal},
	year = {2022},
	volume = {14},
	number = {4},
	pages = {1642 – 1653},
	doi = {10.1109/TCDS.2021.3131045},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120575631&doi=10.1109%2fTCDS.2021.3131045&partnerID=40&md5=60d8e3a0a85da2f09ae4b397224fd739},
	abstract = {Single-image rain removal (SIRR) based on deep learning has long been a problem of great interest in low-level vision systems. However, traditional convolutional neural network (CNN)-based approaches fail to capture long-range location dependencies effectively and may cause the image background blurred. In this article, we propose a knowledge distilling deraining network (KDRN) to address the SIRR problem. In the proposed network, the teacher regards rain streaks as a linear combination of many residual networks. It is used for image reconstruction at different resolutions. With the aid of a teacher network, the proposed deraining network performs better. A spatial channel aggregation residual attention block (SCARAB) is designed to remove the rain streaks. The block not only concentrates on the rain streak features but also captures the spatial-channel information of the image. For the network structure, we used an end-to-end approach to design the teacher and student networks separately. The proposed KDRN obtains the predicted residual image by a combination of the stage-wise results and the original input image. Extensive experiments show that the proposed KDRN obtains better subjective quality than most of the compared methods, on both heavy and light rain data sets.  © 2016 IEEE.},
	keywords = {Deep learning; Distillation; Flow visualization; Image reconstruction; Media streaming; Rain; Teaching; Attention.; Computational modelling; Convolutional neural network; Deep learning; Images reconstruction; Knowledge distilling; Rain removals; Streaming medium; Task analysis; Teachers'; Convolution},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {23798920}
}

@BOOK{Uddin20221,
	author = {Uddin, Zia},
	title = {Applied Machine Learning for Assisted Living},
	year = {2022},
	pages = {1 – 131},
	doi = {10.1007/978-3-031-11534-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166112050&doi=10.1007%2f978-3-031-11534-9&partnerID=40&md5=f275dc47e67cfb76605aa422957f8bdc},
	abstract = {User care at home is a matter of great concern since unforeseen circumstances might occur that affect people's well-being. Technologies that assist people in independent living are essential for enhancing care in a cost-effective and reliable manner. Assisted care applications often demand real-time observation of the environment and the resident’s activities using an event-driven system. As an emerging area of research and development, it is necessary to explore the approaches of the user care system in the literature to identify current practices for future research directions. Therefore, this book is aimed at a comprehensive review of data sources (e.g., sensors) with machine learning for various smart user care systems. To encourage the readers in the field, insights of practical essence of different machine learning algorithms with sensor data (e.g., publicly available datasets) are also discussed. Some code segments are also included to motivate the researchers of the related fields to practically implement the features and machine learning techniques. It is an effort to obtain knowledge of different types of sensor-based user monitoring technologies in-home environments. With the aim of adopting these technologies, research works, and their outcomes are reported. Besides, up to date references are included for the user monitoring technologies with the aim of facilitating independent living. Research that is related to the use of user monitoring technologies in assisted living is very widespread, but it is still consists mostly of limited-scale studies. Hence, user monitoring technology is a very promising field, especially for long-term care. However, monitoring of the users for smart assisted technologies should be taken to the next level with more detailed studies that evaluate and demonstrate their potential to contribute to prolonging the independent living of people. The target of this book is to contribute towards that direction. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2022.},
	publisher = {Springer International Publishing},
	isbn = {978-303111534-9; 978-303111533-2}
}

@ARTICLE{Kalantari2020224,
	author = {Kalantari, Somayeh and Nazemi, Eslam and Masoumi, Behrooz},
	title = {Emergence phenomena in self-organizing systems: a systematic literature review of concepts, researches, and future prospects},
	year = {2020},
	volume = {30},
	number = {3},
	pages = {224 – 265},
	doi = {10.1080/10919392.2020.1748977},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085495954&doi=10.1080%2f10919392.2020.1748977&partnerID=40&md5=3655624c246f96a604952384c57adb5f},
	abstract = {Context: Today, we are facing the growing development of distributed systems which their vast scale has challenged their centralized management. Therefore, many researchers design these systems as self-organizing. After implementing self-organizing systems, new behaviors known as emergence form at a global level of the system. Objective: The purpose of this paper is to study the concept of emergence in various natural and artificial systems, categorize research activities, identify research pathways of emergence in computer science, and shed light on future research directions. Method: In this paper, for a systematic literature review, numerous articles regarding emergence phenomena in self-organizing systems are studied and investigated. Result: Emergence is one of the issues that has attracted the attention of researchers these days. In this paper, concerning nine research questions, 180 research papers are studied. In addition to exploring definitions and features of emergence, a variety of research interests has been found, including studies on why and how to identify, measure, validate, predict, model, simulate, and control emergence. Conclusion: This study shows that much research had been done not only in computer science but also in other sciences on emergence. In addition to a need to provide new methods, based on various technologies, for identifying, measuring, verifying, modeling, simulating, predicting, and controlling emergence in future research, there is a lack of work regarding many issues on emergence. © 2020 Taylor & Francis Group, LLC.},
	publisher = {Taylor and Francis Inc.},
	issn = {10919392}
}

@ARTICLE{Bibiano2023,
	author = {Bibiano, Ana Carla and Uchôa, Anderson and Assunção, Wesley K.G. and Tenório, Daniel and Colanzi, Thelma E. and Vergilio, Silvia Regina and Garcia, Alessandro},
	title = {Composite refactoring: Representations, characteristics and effects on software projects},
	year = {2023},
	volume = {156},
	doi = {10.1016/j.infsof.2022.107134},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145966825&doi=10.1016%2fj.infsof.2022.107134&partnerID=40&md5=581350936b5b9365cc7476ca1738340b},
	abstract = {Context: code refactoring is a code transformation that aims to improve software quality. A composite refactoring (or, simply, composite) is defined by two or more interrelated refactorings, which is often applied by developers. Each composite needs to be somehow represented and has its own characteristics (e.g., code scope) as well as its effects on software quality. However, these basic elements of composites are rarely studied systematically. The lack of systematic knowledge also misguides the design of automated support tools for supporting composite refactoring. Thus, researchers might have controversial views about basic elements of composite refactorings. An example of these literature conflicts concerns the effect of composites: while some studies suggest composites more often remove code smells, other studies indicate composites often introduce code smells. Objective: in this sense, our study aims at analyzing the technical literature of composite refactoring and building a conceptual framework of the representation models, characteristics, and the effect of composite refactoring. Method: we conducted a systematic mapping with 140 primary empirical studies about refactoring. Our systematic mapping summarizes the current knowledge on composites and also presents a conceptual framework intended to characterize composite refactoring. Results: our conceptual framework presents seven representation models, nine characteristics, and thirteen effects of composites. We found out that studies used multidimensional representations, like graphs, to determine what refactoring(s) may be suggested and combined. On composite characteristics, studies mentioned developers often finish a composite in up to a month. However, these studies do not detail why and when composites span for several weeks. Then, we discussed other existing gaps on the current literature of composites. For instance, while most of the studies report the effect of composites on internal software quality, e.g., code smells, their effect on external software quality is little explored. Conclusion: our results can motivate future studies to more deeply investigate composite refactoring applications, and the improvement of tooling support for composite refactorings. © 2022 Elsevier B.V.},
	keywords = {Codes (symbols); Computer software maintenance; Cosine transforms; Mapping; Basic-elements; Code re-factoring; Code smell; Composite refactoring; Conceptual frameworks; Refactorings; Representation model; Software project; Software Quality; Systematic mapping; Odors},
	publisher = {Elsevier B.V.},
	issn = {09505849},
	coden = {ISOTE}
}

@ARTICLE{Kim20211737,
	author = {Kim, Bach Ngoc and Dolz, Jose and Jodoin, Pierre-Marc and Desrosiers, Christian},
	title = {Privacy-Net: An Adversarial Approach for Identity-Obfuscated Segmentation of Medical Images},
	year = {2021},
	volume = {40},
	number = {7},
	pages = {1737 – 1749},
	doi = {10.1109/TMI.2021.3065727},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102694607&doi=10.1109%2fTMI.2021.3065727&partnerID=40&md5=1c8b6ea535bb917063c52853f68698d7},
	abstract = {This paper presents a client/server privacy-preserving network in the context of multicentric medical image analysis. Our approach is based on adversarial learning which encodes images to obfuscate the patient identity while preserving enough information for a target task. Our novel architecture is composed of three components: 1) an encoder network which removes identity-specific features from input medical images, 2) a discriminator network that attempts to identify the subject from the encoded images, 3) a medical image analysis network which analyzes the content of the encoded images (segmentation in our case). By simultaneously fooling the discriminator and optimizing the medical analysis network, the encoder learns to remove privacy-specific features while keeping those essentials for the target task. Our approach is illustrated on the problem of segmenting brain MRI from the large-scale Parkinson Progression Marker Initiative (PPMI) dataset. Using longitudinal data from PPMI, we show that the discriminator learns to heavily distort input images while allowing for highly accurate segmentation results. Our results also demonstrate that an encoder trained on the PPMI dataset can be used for segmenting other datasets, without the need for retraining. The code is made available at: https://github.com/bachkimn/Privacy-Net-An-Adversarial-Approach-forIdentity-Obfuscated-Segmentation-of-MedicalImages  © 1982-2012 IEEE.},
	keywords = {Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Privacy; Discriminators; Image analysis; Image segmentation; Large dataset; Magnetic resonance imaging; Network coding; Privacy by design; Adversarial learning; Longitudinal data; Medical analysis; Novel architecture; Privacy preserving; Segmentation of medical images; Segmentation results; Three component; anonymization; Article; brain region; brain tissue; clinical evaluation; cross validation; data privacy; deep learning; diagnostic accuracy; human; human tissue; image analysis; image segmentation; information retrieval; information security; major clinical study; network learning; noise; Parkinson disease; patient identification; T1 weighted imaging; image processing; nuclear magnetic resonance imaging; privacy; Medical image processing},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {02780062},
	coden = {ITMID}
}

@CONFERENCE{Liu2024523,
	author = {Liu, Ruofan and Lin, Yun and Teoh, Xiwen and Liu, Gongshen and Huang, Zhiyong and Dong, Jin Song},
	title = {Less Defined Knowledge and More True Alarms: Reference-based Phishing Detection without a Pre-defined Reference List},
	year = {2024},
	pages = {523 – 540},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205018960&partnerID=40&md5=c0440e0b7e1e86e344e14c0cf49e1215},
	abstract = {Phishing, a pervasive form of social engineering attack that compromises user credentials, has led to significant financial losses and undermined public trust. Modern phishing detection has gravitated to reference-based methods for their explainability and robustness against zero-day phishing attacks. These methods maintain and update predefined reference lists to specify domain-brand relationships, alarming phishing websites by the inconsistencies between its domain (e.g., payp0l.com) and intended brand (e.g., PayPal). However, the curated lists are largely limited by their lack of comprehensiveness and high maintenance costs in practice. In this work, we present PhishLLM as a novel reference-based phishing detector that operates without an explicit predefined reference list. Our rationale lies in that modern LLMs have encoded far more extensive brand-domain information than any predefined list. Further, the detection of many webpage semantics such as credential-taking intention analysis is more like a linguistic problem, but they are processed as a vision problem now. Thus, we design PhishLLM to decode (or retrieve) the domain-brand relationships from LLM and effectively parse the credential-taking intention of a webpage, without the cost of maintaining and updating an explicit reference list. Moreover, to control the hallucination of LLMs, we introduce a search-engine-based validation mechanism to remove the misinformation. Our extensive experiments show that PhishLLM significantly outperforms state-of-the-art solutions such as Phishpedia and PhishIntention, improving the recall by 21% to 66%, at the cost of negligible precision. Our field studies show that PhishLLM discovers (1) 6 times more zero-day phishing webpages compared to existing approaches such as PhishIntention and (2) close to 2 times more zero-day phishing webpages even if it is enhanced by DynaPhish. Our code is available at https://github.com/code-philia/PhishLLM/. © USENIX Security Symposium 2024.All rights reserved.},
	keywords = {Cost benefit analysis; Economic and social effects; Hypertext systems; Search engines; Semantics; Web Design; Zero-day attack; Financial loss; Maintenance cost; Phishing; Phishing attacks; Phishing detections; Phishing websites; Public trust; Reference list; Social engineering; Web-page; Phishing},
	publisher = {USENIX Association},
	isbn = {978-193913344-1}
}

@ARTICLE{Bhat2023,
	author = {Bhat, Parnika and Behal, Sunny and Dutta, Kamlesh},
	title = {A system call-based android malware detection approach with homogeneous & heterogeneous ensemble machine learning},
	year = {2023},
	volume = {130},
	doi = {10.1016/j.cose.2023.103277},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158002130&doi=10.1016%2fj.cose.2023.103277&partnerID=40&md5=06aad5a9375d00537c1910acc159d756},
	abstract = {The enormous popularity of Android in the smartphone market has gained the attention of malicious actors as well. Also, considering its open system architecture, malicious attacks don't seem to wane anytime soon. Cybercriminals use deceptive attack strategies like obfuscation or dynamic code loading to evade the system. A conventional static analysis approach fails to identify such attacks. Mitigating a wide range of evasive attacks requires excogitating savvy dynamic analysis framework. This paper proposes a precise dynamic analysis approach to identify a slew of malicious attacks. The proposed method focus on behavioral analysis of malware that requires reconstructing the behavior of Android malware. The dynamic behavior features used include system calls, binders, and complex Android objects (composite behavior). For efficient malware detection and classification, a feature selection method is used to remove extraneous features. For classification, we use homogeneous and heterogeneous ensemble machine learning algorithms. The stacking approach has the best classification results with an accuracy rate of 98.08%. The rigorous experimental results show the effectiveness and superiority of the model. © 2023 Elsevier Ltd},
	keywords = {Android (operating system); Classification (of information); Feature Selection; Learning algorithms; Mobile security; Network security; Static analysis; Android; Android malware; Dynamics analysis; Ensemble machine learning; Features selection; Heterogeneous ensembles; Machine-learning; Malicious attack; Malware detection; System calls; Android malware},
	publisher = {Elsevier Ltd},
	issn = {01674048},
	coden = {CPSED}
}